{
  "repo_path": "C:\\Users\\chuba\\wikillm",
  "repo_name": "wikillm",
  "files": [
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\api.py",
      "file_type": "code",
      "language": "python",
      "imports": [
        "asyncio",
        "json",
        "traceback",
        "pathlib.Path",
        "typing.Dict",
        "typing.List",
        "typing.Any",
        "typing.Optional",
        "fastapi.FastAPI",
        "fastapi.HTTPException",
        "fastapi.BackgroundTasks",
        "fastapi.UploadFile",
        "fastapi.File",
        "fastapi.middleware.cors.CORSMiddleware",
        "fastapi.responses.StreamingResponse",
        "fastapi.responses.JSONResponse",
        "fastapi.staticfiles.StaticFiles",
        "pydantic.BaseModel",
        "uvicorn",
        "config.settings",
        "repository_analyzer.RepositoryAnalyzer",
        "ollama_client.OllamaClient",
        "vector_store.VectorStore",
        "rag_system.RAGSystem",
        "documentation_generator.DocumentationBuilder",
        "documentation_generator.DocumentationConfig"
      ],
      "elements": [
        {
          "name": "QueryRequest",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\api.py",
          "line_start": 23,
          "line_end": 27,
          "docstring": null,
          "signature": "class QueryRequest",
          "content": null,
          "dependencies": []
        },
        {
          "name": "ChatMessage",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\api.py",
          "line_start": 29,
          "line_end": 31,
          "docstring": null,
          "signature": "class ChatMessage",
          "content": null,
          "dependencies": []
        },
        {
          "name": "ChatRequest",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\api.py",
          "line_start": 33,
          "line_end": 35,
          "docstring": null,
          "signature": "class ChatRequest",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryRequest",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\api.py",
          "line_start": 37,
          "line_end": 39,
          "docstring": null,
          "signature": "class RepositoryRequest",
          "content": null,
          "dependencies": []
        },
        {
          "name": "ExplainCodeRequest",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\api.py",
          "line_start": 41,
          "line_end": 44,
          "docstring": null,
          "signature": "class ExplainCodeRequest",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationRequest",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\api.py",
          "line_start": 46,
          "line_end": 51,
          "docstring": null,
          "signature": "class DocumentationRequest",
          "content": null,
          "dependencies": []
        },
        {
          "name": "main",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\api.py",
          "line_start": 422,
          "line_end": 438,
          "docstring": "Main function to run the API server.",
          "signature": "def main()",
          "content": null,
          "dependencies": []
        }
      ],
      "summary": null,
      "content": "\"\"\"FastAPI server for Local DeepWiki.\"\"\"\n\nimport asyncio\nimport json\nimport traceback\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional\nfrom fastapi import FastAPI, HTTPException, BackgroundTasks, UploadFile, File\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import StreamingResponse, JSONResponse\nfrom fastapi.staticfiles import StaticFiles\nfrom pydantic import BaseModel\nimport uvicorn\n\nfrom config import settings\nfrom repository_analyzer import RepositoryAnalyzer\nfrom ollama_client import OllamaClient\nfrom vector_store import VectorStore\nfrom rag_system import RAGSystem\nfrom documentation_generator import DocumentationBuilder, DocumentationConfig\n\n# Pydantic models for API\nclass QueryRequest(BaseModel):\n    query: str\n    repo_name: Optional[str] = None\n    file_path: Optional[str] = None\n    stream: Optional[bool] = False\n\nclass ChatMessage(BaseModel):\n    role: str  # 'user' or 'assistant'\n    content: str\n\nclass ChatRequest(BaseModel):\n    messages: List[ChatMessage]\n    repo_name: Optional[str] = None\n\nclass RepositoryRequest(BaseModel):\n    repo_path: str\n    repo_name: Optional[str] = None\n\nclass ExplainCodeRequest(BaseModel):\n    code: str\n    language: Optional[str] = None\n    context: Optional[str] = None\n\nclass DocumentationRequest(BaseModel):\n    repo_name: str\n    include_overview: bool = True\n    include_api_docs: bool = True\n    include_examples: bool = True\n    include_architecture: bool = True\n\n# Global instances\napp = FastAPI(title=\"Local DeepWiki\", version=\"1.0.0\")\nollama_client = OllamaClient()\nvector_store = VectorStore()\nrag_system = RAGSystem(vector_store, ollama_client)\nrepository_analyzer = RepositoryAnalyzer()\ndocumentation_builder = DocumentationBuilder(ollama_client)\n\n# Add CORS middleware\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Health check endpoints\n@app.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    ollama_available = ollama_client.is_available()\n    vector_stats = vector_store.get_collection_stats()\n    \n    return {\n        \"status\": \"healthy\",\n        \"ollama_available\": ollama_available,\n        \"ollama_url\": settings.OLLAMA_BASE_URL,\n        \"ollama_model\": settings.OLLAMA_MODEL,\n        \"vector_store\": vector_stats\n    }\n\n@app.get(\"/models\")\nasync def list_models():\n    \"\"\"List available Ollama models.\"\"\"\n    try:\n        models = ollama_client.list_models()\n        return {\"models\": models}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error listing models: {str(e)}\")\n\n# Repository management endpoints\n@app.post(\"/repositories/analyze\")\nasync def analyze_repository(request: RepositoryRequest, background_tasks: BackgroundTasks):\n    \"\"\"Analyze a repository and add it to the vector store.\"\"\"\n    repo_path = Path(request.repo_path)\n    \n    if not repo_path.exists():\n        raise HTTPException(status_code=404, detail=f\"Repository path not found: {repo_path}\")\n    \n    repo_name = request.repo_name or repo_path.name\n    \n    try:\n        # Start analysis in background\n        background_tasks.add_task(analyze_repository_task, str(repo_path), repo_name)\n        \n        return {\n            \"message\": f\"Repository analysis started for {repo_name}\",\n            \"repo_name\": repo_name,\n            \"repo_path\": str(repo_path)\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error starting analysis: {str(e)}\")\n\nasync def analyze_repository_task(repo_path: str, repo_name: str):\n    \"\"\"Background task to analyze repository.\"\"\"\n    try:\n        print(f\"Starting analysis of {repo_name} at {repo_path}\")\n        \n        # Analyze repository\n        analysis = repository_analyzer.analyze_repository(repo_path)\n        analysis['repo_name'] = repo_name\n        \n        # Save analysis\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\"{repo_name}_analysis.json\"\n        repository_analyzer.save_analysis(analysis, str(analysis_path))\n        \n        # Add to vector store\n        chunks_added = vector_store.add_repository(analysis)\n        \n        print(f\"Analysis complete for {repo_name}: {chunks_added} chunks added to vector store\")\n        \n    except Exception as e:\n        print(f\"Error in repository analysis task: {str(e)}\")\n        traceback.print_exc()\n\n@app.get(\"/repositories\")\nasync def list_repositories():\n    \"\"\"List analyzed repositories.\"\"\"\n    repos = []\n    repos_dir = Path(settings.REPOS_DIRECTORY)\n    \n    if repos_dir.exists():\n        for analysis_file in repos_dir.glob(\"*_analysis.json\"):\n            try:\n                analysis = repository_analyzer.load_analysis(str(analysis_file))\n                repos.append({\n                    \"name\": analysis.get('repo_name', analysis_file.stem.replace('_analysis', '')),\n                    \"path\": analysis.get('repo_path', ''),\n                    \"files\": analysis.get('statistics', {}).get('total_files', 0),\n                    \"languages\": list(analysis.get('statistics', {}).get('languages', {}).keys())\n                })\n            except Exception as e:\n                print(f\"Error loading analysis from {analysis_file}: {e}\")\n    \n    return {\"repositories\": repos}\n\n@app.delete(\"/repositories/{repo_name}\")\nasync def delete_repository(repo_name: str):\n    \"\"\"Delete repository from vector store.\"\"\"\n    try:\n        vector_store.delete_repository(repo_name)\n        \n        # Also delete analysis file\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\"{repo_name}_analysis.json\"\n        if analysis_path.exists():\n            analysis_path.unlink()\n        \n        return {\"message\": f\"Repository {repo_name} deleted successfully\"}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error deleting repository: {str(e)}\")\n\n# Query endpoints\n@app.post(\"/query\")\nasync def query_repository(request: QueryRequest):\n    \"\"\"Query repository using RAG system.\"\"\"\n    try:\n        if request.stream:\n            # Return streaming response\n            return StreamingResponse(\n                stream_query_response(request),\n                media_type=\"text/plain\"\n            )\n        else:\n            # Return complete response\n            result = rag_system.query(\n                request.query,\n                repo_name=request.repo_name,\n                file_path=request.file_path,\n                stream=False\n            )\n            return result\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error processing query: {str(e)}\")\n\nasync def stream_query_response(request: QueryRequest):\n    \"\"\"Stream query response for real-time updates.\"\"\"\n    try:\n        # Get context first\n        filter_metadata = {}\n        if request.repo_name:\n            filter_metadata['repo_name'] = request.repo_name\n        if request.file_path:\n            filter_metadata['file_path'] = request.file_path\n        \n        retrieved_chunks = rag_system.retrieve_context(\n            request.query, \n            n_results=5, \n            filter_metadata=filter_metadata or None\n        )\n        \n        if not retrieved_chunks:\n            yield \"No relevant context found for query.\\n\"\n            return\n        \n        context_text = rag_system.build_context_text(retrieved_chunks)\n        \n        # Build prompt\n        system_prompt = rag_system.system_prompts['general_question']\n        full_prompt = f\"\"\"{system_prompt}\n\nCONTEXT:\n{context_text}\n\nUSER QUERY: {request.query}\n\nPlease provide a helpful response based on the context above.\"\"\"\n\n        # Stream response\n        async for chunk in ollama_client.generate_stream(full_prompt, temperature=0.3):\n            yield chunk\n            \n    except Exception as e:\n        yield f\"Error: {str(e)}\\n\"\n\n@app.post(\"/chat\")\nasync def chat_with_repository(request: ChatRequest):\n    \"\"\"Chat interface for conversational interaction.\"\"\"\n    try:\n        messages = [{\"role\": msg.role, \"content\": msg.content} for msg in request.messages]\n        response = rag_system.chat_with_repo(messages, request.repo_name)\n        \n        return {\n            \"response\": response,\n            \"repo_name\": request.repo_name\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error in chat: {str(e)}\")\n\n@app.post(\"/explain\")\nasync def explain_code(request: ExplainCodeRequest):\n    \"\"\"Explain code snippet.\"\"\"\n    try:\n        explanation = rag_system.explain_code(\n            request.code,\n            request.language,\n            request.context\n        )\n        return {\"explanation\": explanation}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error explaining code: {str(e)}\")\n\n@app.post(\"/improve\")\nasync def suggest_improvements(request: ExplainCodeRequest):\n    \"\"\"Suggest code improvements.\"\"\"\n    try:\n        suggestions = rag_system.suggest_improvements(\n            request.code,\n            request.language\n        )\n        return {\"suggestions\": suggestions}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error suggesting improvements: {str(e)}\")\n\n@app.get(\"/repositories/{repo_name}/overview\")\nasync def get_repository_overview(repo_name: str):\n    \"\"\"Get repository overview.\"\"\"\n    try:\n        overview = rag_system.get_repository_overview(repo_name)\n        return {\"overview\": overview, \"repo_name\": repo_name}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error getting overview: {str(e)}\")\n\n@app.get(\"/repositories/{repo_name}/files/{file_path:path}/summary\")\nasync def get_file_summary(repo_name: str, file_path: str):\n    \"\"\"Get file summary.\"\"\"\n    try:\n        summary = rag_system.get_file_summary(file_path, repo_name)\n        return {\"summary\": summary, \"file_path\": file_path, \"repo_name\": repo_name}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error getting file summary: {str(e)}\")\n\n# Documentation endpoints\n@app.post(\"/repositories/{repo_name}/generate-docs\")\nasync def generate_documentation(repo_name: str, request: DocumentationRequest, background_tasks: BackgroundTasks):\n    \"\"\"Generate comprehensive documentation for repository.\"\"\"\n    try:\n        # Load repository analysis\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\"{repo_name}_analysis.json\"\n        if not analysis_path.exists():\n            raise HTTPException(status_code=404, detail=f\"Repository {repo_name} not found. Please analyze it first.\")\n        \n        analysis = repository_analyzer.load_analysis(str(analysis_path))\n        \n        config = DocumentationConfig(\n            include_overview=request.include_overview,\n            include_api_docs=request.include_api_docs,\n            include_examples=request.include_examples,\n            include_architecture=request.include_architecture\n        )\n        \n        # Start documentation generation in background\n        background_tasks.add_task(generate_docs_task, analysis, config, repo_name)\n        \n        return {\n            \"message\": f\"Documentation generation started for {repo_name}\",\n            \"repo_name\": repo_name\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error starting documentation generation: {str(e)}\")\n\nasync def generate_docs_task(analysis: Dict[str, Any], config: DocumentationConfig, repo_name: str):\n    \"\"\"Background task to generate documentation.\"\"\"\n    try:\n        print(f\"Starting documentation generation for {repo_name}\")\n        docs = documentation_builder.generate_full_documentation(analysis, config)\n        print(f\"Documentation generation complete for {repo_name}: {len(docs)} files generated\")\n    except Exception as e:\n        print(f\"Error in documentation generation task: {str(e)}\")\n        traceback.print_exc()\n\n@app.get(\"/repositories/{repo_name}/docs\")\nasync def list_generated_docs(repo_name: str):\n    \"\"\"List generated documentation files.\"\"\"\n    docs_dir = Path(settings.DOCS_DIRECTORY) / repo_name\n    \n    if not docs_dir.exists():\n        return {\"documents\": []}\n    \n    docs = []\n    for doc_file in docs_dir.rglob(\"*.md\"):\n        relative_path = doc_file.relative_to(docs_dir)\n        docs.append({\n            \"name\": doc_file.name,\n            \"path\": str(relative_path),\n            \"size\": doc_file.stat().st_size\n        })\n    \n    return {\"documents\": docs}\n\n@app.get(\"/repositories/{repo_name}/docs/{doc_path:path}\")\nasync def get_documentation(repo_name: str, doc_path: str):\n    \"\"\"Get specific documentation file.\"\"\"\n    doc_file = Path(settings.DOCS_DIRECTORY) / repo_name / doc_path\n    \n    if not doc_file.exists():\n        raise HTTPException(status_code=404, detail=\"Documentation file not found\")\n    \n    try:\n        with open(doc_file, 'r', encoding='utf-8') as f:\n            content = f.read()\n        \n        return {\n            \"content\": content,\n            \"path\": doc_path,\n            \"repo_name\": repo_name\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error reading documentation: {str(e)}\")\n\n# Search endpoints\n@app.get(\"/search\")\nasync def search_all_repositories(q: str, limit: int = 10):\n    \"\"\"Search across all repositories.\"\"\"\n    try:\n        results = vector_store.search(q, n_results=limit)\n        return {\"results\": results, \"query\": q}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error searching: {str(e)}\")\n\n@app.get(\"/repositories/{repo_name}/search\")\nasync def search_repository(repo_name: str, q: str, limit: int = 10):\n    \"\"\"Search within specific repository.\"\"\"\n    try:\n        results = vector_store.search(\n            q, \n            n_results=limit, \n            filter_metadata={\"repo_name\": repo_name}\n        )\n        return {\"results\": results, \"query\": q, \"repo_name\": repo_name}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error searching repository: {str(e)}\")\n\n# Statistics endpoint\n@app.get(\"/stats\")\nasync def get_system_stats():\n    \"\"\"Get system statistics.\"\"\"\n    try:\n        vector_stats = vector_store.get_collection_stats()\n        \n        # Count repositories\n        repos_dir = Path(settings.REPOS_DIRECTORY)\n        repo_count = len(list(repos_dir.glob(\"*_analysis.json\"))) if repos_dir.exists() else 0\n        \n        # Count generated docs\n        docs_dir = Path(settings.DOCS_DIRECTORY)\n        doc_count = len(list(docs_dir.rglob(\"*.md\"))) if docs_dir.exists() else 0\n        \n        return {\n            \"repositories\": repo_count,\n            \"documents_in_vector_store\": vector_stats.get('total_documents', 0),\n            \"generated_docs\": doc_count,\n            \"ollama_available\": ollama_client.is_available(),\n            \"ollama_model\": settings.OLLAMA_MODEL\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Error getting stats: {str(e)}\")\n\n# Main function to run the server\ndef main():\n    \"\"\"Main function to run the API server.\"\"\"\n    print(f\"Starting Local DeepWiki server on {settings.API_HOST}:{settings.API_PORT}\")\n    print(f\"Ollama URL: {settings.OLLAMA_BASE_URL}\")\n    print(f\"Model: {settings.OLLAMA_MODEL}\")\n    \n    # Check Ollama availability\n    if not ollama_client.is_available():\n        print(\"WARNING: Ollama server not available. Please start Ollama first.\")\n        print(\"Run: ollama serve\")\n    \n    uvicorn.run(\n        \"api:app\",\n        host=settings.API_HOST,\n        port=settings.API_PORT,\n        reload=True\n    )\n\nif __name__ == \"__main__\":\n    main()\n"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\basic_station.md",
      "file_type": "documentation",
      "language": null,
      "imports": [],
      "elements": [],
      "summary": null,
      "content": "[![regr-tests](https://github.com/lorabasics/basicstation/actions/workflows/regr-tests.yml/badge.svg?branch=master)](https://github.com/lorabasics/basicstation/actions/workflows/regr-tests.yml?query=branch%3Amaster)\n\n# LoRa Basicsâ„¢ Station\n\n[Basic Station](https://doc.sm.tc/station) is a LoRaWAN Gateway implementation, including features like\n\n*  **Ready for LoRaWAN Classes A, B, and C**\n*  **Unified Radio Abstraction Layer supporting Concentrator Reference Designs [v1.5](https://doc.sm.tc/station/gw_v1.5.html), [v2](https://doc.sm.tc/station/gw_v2.html) and [Corecell](https://doc.sm.tc/station/gw_corecell.html)**\n\n*  **Powerful Backend Protocols** (read [here](https://doc.sm.tc/station/tcproto.html) and [here](https://doc.sm.tc/station/cupsproto.html))\n    -  Centralized update and configuration management\n    -  Centralized channel-plan management\n    -  Centralized time synchronization and transfer\n    -  Various authentication schemes (client certificate, auth tokens)\n    -  Remote interactive shell\n\n*  **Lean Design**\n    -  No external software dependencies (except mbedTLS and libloragw/-v2)\n    -  Portable C code, no C++, dependent only on GNU libc\n    -  Easily portable to Linux-based gateways and embedded systems\n    -  No dependency on local time keeping\n    -  No need for incoming connections\n\n## Documentation\n\nThe full documentation is available at [https://doc.sm.tc/station](https://doc.sm.tc/station).\n\n### High Level Architecture\n\n![High Level Station Architecture](https://doc.sm.tc/station/_images/architecture.png)\n\n## Prerequisites\n\nBuilding the Station binary from source, requires\n\n* gcc (C11 with GNU extensions)\n* GNU make\n* git\n* bash\n\n## First Steps\n\nThe following is a three-step quick start guide on how to build and run Station. It uses a Raspberry Pi as host platform and assumes a Concentrator Reference Design 1.5 compatible radio board connected via SPI, and assumes that SPI port is enabled using the [raspi-config](https://www.raspberrypi.org/documentation/configuration/raspi-config.md) tool. In this example the build process is done on the target platform itself (the make environment also supports cross compilation in which case the toolchain is expected in `~/toolchain-$platform` - see [setup.gmk](setup.gmk)).\n\n#### Step 1: Cloning the Station Repository\n\n``` sourceCode\ngit clone https://github.com/lorabasics/basicstation.git\n```\n\n#### Step 2: Compiling the Station Binary\n\n``` sourceCode\ncd basicstation\nmake platform=rpi variant=std\n```\n\nThe build process consists of the following steps:\n\n*  Fetch and build dependencies, namely [mbedTLS](https://github.com/ARMmbed/mbedtls) and [libloragw](https://github.com/Lora-net/lora_gateway)\n*  Setup build environment within subdirectory `build-$platform-$variant/`\n*  Compile station source files into executable `build-$platform-$variant/bin/station`\n\n#### Step 3: Running the Example Configuration on a Raspberry Pi\n\n``` sourceCode\ncd examples/live-s2.sm.tc\nRADIODEV=/dev/spidev0.0 ../../build-rpi-std/bin/station\n```\n\n**Note:** The SPI device for the radio MAY be passed as an environment variable using `RADIODEV`.\n\nThe example configuration connects to a public test server [s2.sm.tc](wss://s2.sm.tc) through which Station fetches all required credentials and a channel plan matching the region as determined from the IP address of the gateway. Provided there are active LoRa devices in proximity, received LoRa frames are printed in the log output on `stderr`.\n\n## Instruction for Supported Platfroms\n\n#### Corecell Platform (Raspberry Pi as HOST + [SX1302CxxxxGW Concentrator](https://www.semtech.com/products/wireless-rf/lora-gateways/sx1302cxxxgw1))\n\n##### Compile and Running the Example\n\n``` sourceCode\ncd basicstation\nmake platform=corecell variant=std\ncd examples/corecell\n./start-station.sh -l ./lns-ttn\n```\n\nThis example configuration for Corecell connects to [The Things Network](https://www.thethingsnetwork.org/) public LNS. The example [station.conf](station.conf) file holds the required radio configurations and station fetches the channel plan from the configured LNS url ([tc.uri](tc.uri)).\n\nNote: SPI port requires to be activated on Raspberry Pi thanks to [raspi-config](https://www.raspberrypi.org/documentation/configuration/raspi-config.md) tool.\n\n#### PicoCell Gateway (Linux OS as HOST + [SX1308 USB Reference design](https://www.semtech.com/products/wireless-rf/lora-gateways/sx1308p868gw))\n\n\n##### Compile and Running the Example\n\n``` sourceCode\ncd basicstation\nmake platform=linuxpico variant=std\ncd examples/live-s2.sm.tc\nRADIODEV=/dev/ttyACM0 ../../build-linuxpico-std/bin/station\n```\n\n**Note:** The serial device for the PicoCell MAY be passed as an environment variable using `RADIODEV`.\n\n## Next Steps\n\nNext,\n\n*  consult the help menu of Station via `station --help`,\n*  inspect the `station.conf` and `cups-boot.*` [example configuration files](/examples/live-s2.sm.tc),\n*  tune your local [configuration](https://doc.sm.tc/station/conf.html),\n*  learn how to [compile Station](https://doc.sm.tc/station/compile.html) for your target platform.\n\nCheck out the other examples:\n\n*  [Simulation Example](/examples/simulation) - An introduction to the simulation environment.\n*  [CUPS Example](/examples/cups) - Demonstration of the CUPS protocol within the simulation environment.\n*  [Station to Pkfwd Protocol Bridge Example](/examples/station2pkfwd) - Connect Basic Station to LNS supporting the legacy protocol.\n\n## Usage\n\nThe Station binary accepts the following command-line options:\n\n```\nUsage: station [OPTION...]\n\n  -d, --daemon               First check if another process is still alive. If\n                             so do nothing and exit. Otherwise fork a worker\n                             process to operate the radios and network\n                             protocols. If the subprocess died respawn it with\n                             an appropriate back off.\n  -f, --force                If a station process is already running, kill it\n                             before continuing with requested operation mode.\n  -h, --home=DIR             Home directory for configuration files. Default is\n                             the current working directory. Overrides\n                             environment STATION_DIR.\n  -i, --radio-init=cmd       Program/script to run before reinitializing radio\n                             hardware. By default nothing is being executed.\n                             Overrides environment STATION_RADIOINIT.\n  -k, --kill                 Kill a currently running station process.\n  -l, --log-level=LVL|0..7   Set a log level LVL=#loglvls# or use a numeric\n                             value. Overrides environment STATION_LOGLEVEL.\n  -L, --log-file=FILE[,SIZE[,ROT]]\n                             Write log entries to FILE. If FILE is '-' then\n                             write to stderr. Optionally followed by a max file\n                             SIZE and a number of rotation files. If ROT is 0\n                             then keep only FILE. If ROT is 1 then keep one\n                             more old log file around. Overrides environment\n                             STATION_LOGFILE.\n  -N, --no-tc                Do not connect to a LNS. Only run CUPS\n                             functionality.\n  -p, --params               Print current parameter settings.\n  -t, --temp=DIR             Temp directory for frequently written files.\n                             Default is /tmp. Overrides environment\n                             STATION_TEMPDIR.\n  -x, --eui-prefix=id6       Turn MAC address into EUI by adding this prefix.\n                             If the argument has value ff:fe00:0 then the EUI\n                             is formed by inserting FFFE in the middle. If\n                             absent use MAC or routerid as is. Overrides\n                             environment STATION_EUIPREFIX.\n  -?, --help                 Give this help list\n      --usage                Give a short usage message\n  -v, --version              Print station version.\n\nMandatory or optional arguments to long options are also mandatory or optional\nfor any corresponding short options.\n```"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\config.py",
      "file_type": "code",
      "language": "python",
      "imports": [
        "os",
        "pathlib.Path",
        "typing.List",
        "typing.Dict",
        "typing.Any",
        "pydantic_settings.BaseSettings"
      ],
      "elements": [
        {
          "name": "Settings",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\config.py",
          "line_start": 8,
          "line_end": 53,
          "docstring": "Application settings.",
          "signature": "class Settings",
          "content": null,
          "dependencies": []
        },
        {
          "name": "Config",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\config.py",
          "line_start": 52,
          "line_end": 53,
          "docstring": null,
          "signature": "class Config",
          "content": null,
          "dependencies": []
        }
      ],
      "summary": null,
      "content": "\"\"\"Configuration settings for Local DeepWiki.\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom typing import List, Dict, Any\nfrom pydantic_settings import BaseSettings\n\nclass Settings(BaseSettings):\n    \"\"\"Application settings.\"\"\"\n    \n    # Ollama settings\n    OLLAMA_BASE_URL: str = \"http://localhost:11434\"\n    OLLAMA_MODEL: str = \"gemma2:9b\"  # Using Gemma2 9B for chat\n    OLLAMA_EMBEDDING_MODEL: str = \"nomic-embed-text:latest\"\n    \n    # Vector database settings\n    CHROMA_PERSIST_DIRECTORY: str = \"./data/chroma_db\"\n    COLLECTION_NAME: str = \"codebase_docs\"\n    \n    # Repository settings\n    REPOS_DIRECTORY: str = \"./data/repos\"\n    DOCS_DIRECTORY: str = \"./data/generated_docs\"\n    \n    # Generation settings\n    MAX_CHUNK_SIZE: int = 2000\n    CHUNK_OVERLAP: int = 200\n    MAX_CONTEXT_LENGTH: int = 4000\n    \n    # API settings\n    API_HOST: str = \"0.0.0.0\"\n    API_PORT: int = 8000\n    \n    # Supported file extensions\n    CODE_EXTENSIONS: List[str] = [\n        \".py\", \".js\", \".ts\", \".jsx\", \".tsx\", \".java\", \".cpp\", \".c\", \".h\",\n        \".cs\", \".php\", \".rb\", \".go\", \".rs\", \".swift\", \".kt\", \".scala\",\n        \".r\", \".sql\", \".sh\", \".yaml\", \".yml\", \".json\", \".xml\", \".html\",\n        \".css\", \".scss\", \".less\", \".vue\", \".svelte\"\n    ]\n    \n    DOC_EXTENSIONS: List[str] = [\".md\", \".rst\", \".txt\", \".adoc\"]\n    \n    # Ignored directories\n    IGNORED_DIRS: List[str] = [\n        \".git\", \".svn\", \".hg\", \"__pycache__\", \".pytest_cache\",\n        \"node_modules\", \".npm\", \".yarn\", \"bower_components\",\n        \".venv\", \"venv\", \"env\", \".env\", \"virtualenv\",\n        \"dist\", \"build\", \"target\", \"bin\", \"obj\",\n        \".idea\", \".vscode\", \".vs\", \"*.egg-info\"\n    ]\n    \n    class Config:\n        env_file = \".env\"\n\n# Global settings instance\nsettings = Settings()\n\n# Ensure data directories exist\nPath(settings.CHROMA_PERSIST_DIRECTORY).mkdir(parents=True, exist_ok=True)\nPath(settings.REPOS_DIRECTORY).mkdir(parents=True, exist_ok=True)\nPath(settings.DOCS_DIRECTORY).mkdir(parents=True, exist_ok=True)\n"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\DEVELOPMENT.md",
      "file_type": "documentation",
      "language": null,
      "imports": [],
      "elements": [],
      "summary": null,
      "content": "# Development Guide\n\n## Setting up the development environment\n\n1. Install Python 3.8+\n2. Install dependencies: `pip install -r requirements.txt`\n3. Install and start Ollama\n4. Pull required models: `ollama pull deepseek-coder:6.7b`\n\n## Running the system\n\n### Analyze a repository\n```bash\npython main.py analyze . --name myproject\n```\n\n### Query the repository\n```bash\npython main.py query \"How does authentication work?\" --repo myproject\n```\n\n### Start the API server\n```bash\npython main.py server\n```\n\n## Key Components\n\n- **config.py**: Configuration settings\n- **repository_analyzer.py**: Code parsing and analysis\n- **vector_store.py**: ChromaDB integration\n- **rag_system.py**: RAG implementation\n- **api.py**: FastAPI server"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
      "file_type": "code",
      "language": "python",
      "imports": [
        "os",
        "json",
        "pathlib.Path",
        "typing.Dict",
        "typing.List",
        "typing.Any",
        "typing.Optional",
        "dataclasses.dataclass",
        "markdown",
        "jinja2.Template",
        "ollama_client.OllamaClient",
        "ollama_client.DocumentationGenerator",
        "repository_analyzer.RepositoryAnalyzer",
        "config.settings"
      ],
      "elements": [
        {
          "name": "DocumentationConfig",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 15,
          "line_end": 22,
          "docstring": "Configuration for documentation generation.",
          "signature": "class DocumentationConfig",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationBuilder",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 24,
          "line_end": 502,
          "docstring": "Build comprehensive documentation from repository analysis.",
          "signature": "class DocumentationBuilder",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationBuilder.__init__",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 27,
          "line_end": 94,
          "docstring": null,
          "signature": "def __init__(self, ollama_client)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationBuilder.generate_full_documentation",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 96,
          "line_end": 161,
          "docstring": "Generate complete documentation for a repository.",
          "signature": "def generate_full_documentation(self, repo_analysis, config, output_dir)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationBuilder.generate_repository_readme",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 163,
          "line_end": 224,
          "docstring": "Generate main repository README.",
          "signature": "def generate_repository_readme(self, repo_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationBuilder.generate_file_api_docs",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 226,
          "line_end": 303,
          "docstring": "Generate API documentation for a single file.",
          "signature": "def generate_file_api_docs(self, file_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationBuilder.generate_architecture_docs",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 305,
          "line_end": 366,
          "docstring": "Generate architecture documentation.",
          "signature": "def generate_architecture_docs(self, repo_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationBuilder.generate_examples_docs",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 368,
          "line_end": 447,
          "docstring": "Generate usage examples documentation.",
          "signature": "def generate_examples_docs(self, repo_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationBuilder.generate_table_of_contents",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 449,
          "line_end": 470,
          "docstring": "Generate table of contents for all documentation.",
          "signature": "def generate_table_of_contents(self, documentation)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationBuilder.update_existing_docs",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 472,
          "line_end": 502,
          "docstring": "Update existing documentation files with new analysis.",
          "signature": "def update_existing_docs(self, repo_path, analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "__init__",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 27,
          "line_end": 94,
          "docstring": null,
          "signature": "def __init__(self, ollama_client)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "generate_full_documentation",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 96,
          "line_end": 161,
          "docstring": "Generate complete documentation for a repository.",
          "signature": "def generate_full_documentation(self, repo_analysis, config, output_dir)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "generate_repository_readme",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 163,
          "line_end": 224,
          "docstring": "Generate main repository README.",
          "signature": "def generate_repository_readme(self, repo_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "generate_file_api_docs",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 226,
          "line_end": 303,
          "docstring": "Generate API documentation for a single file.",
          "signature": "def generate_file_api_docs(self, file_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "generate_architecture_docs",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 305,
          "line_end": 366,
          "docstring": "Generate architecture documentation.",
          "signature": "def generate_architecture_docs(self, repo_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "generate_examples_docs",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 368,
          "line_end": 447,
          "docstring": "Generate usage examples documentation.",
          "signature": "def generate_examples_docs(self, repo_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "generate_table_of_contents",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 449,
          "line_end": 470,
          "docstring": "Generate table of contents for all documentation.",
          "signature": "def generate_table_of_contents(self, documentation)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "update_existing_docs",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\documentation_generator.py",
          "line_start": 472,
          "line_end": 502,
          "docstring": "Update existing documentation files with new analysis.",
          "signature": "def update_existing_docs(self, repo_path, analysis)",
          "content": null,
          "dependencies": []
        }
      ],
      "summary": null,
      "content": "\"\"\"Documentation generation system using local LLMs.\"\"\"\n\nimport os\nimport json\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass\nimport markdown\nfrom jinja2 import Template\nfrom ollama_client import OllamaClient, DocumentationGenerator\nfrom repository_analyzer import RepositoryAnalyzer\nfrom config import settings\n\n@dataclass\nclass DocumentationConfig:\n    \"\"\"Configuration for documentation generation.\"\"\"\n    include_overview: bool = True\n    include_api_docs: bool = True\n    include_examples: bool = True\n    include_architecture: bool = True\n    output_format: str = 'markdown'  # 'markdown', 'html'\n    template_style: str = 'default'  # 'default', 'minimal', 'detailed'\n\nclass DocumentationBuilder:\n    \"\"\"Build comprehensive documentation from repository analysis.\"\"\"\n    \n    def __init__(self, ollama_client: OllamaClient):\n        self.ollama_client = ollama_client\n        self.doc_generator = DocumentationGenerator(ollama_client)\n        \n        # Documentation templates\n        self.templates = {\n            'repository_readme': \"\"\"# {{ repo_name }}\n\n{{ overview }}\n\n## Architecture\n\n{{ architecture }}\n\n## Getting Started\n\n{{ getting_started }}\n\n## API Documentation\n\n{{ api_docs }}\n\n## Examples\n\n{{ examples }}\n\n## Contributing\n\n{{ contributing }}\n\n\"\"\",\n            \n            'api_reference': \"\"\"# API Reference - {{ file_name }}\n\n{{ file_overview }}\n\n## Classes\n\n{{ classes }}\n\n## Functions\n\n{{ functions }}\n\n## Constants\n\n{{ constants }}\n\n\"\"\",\n            \n            'module_docs': \"\"\"# {{ module_name }}\n\n{{ description }}\n\n## Usage\n\n{{ usage }}\n\n## Implementation Details\n\n{{ implementation }}\n\n## Dependencies\n\n{{ dependencies }}\n\n\"\"\"\n        }\n    \n    def generate_full_documentation(self, \n                                  repo_analysis: Dict[str, Any], \n                                  config: DocumentationConfig = None,\n                                  output_dir: str = None) -> Dict[str, str]:\n        \"\"\"Generate complete documentation for a repository.\"\"\"\n        \n        if config is None:\n            config = DocumentationConfig()\n        \n        if output_dir is None:\n            output_dir = settings.DOCS_DIRECTORY\n        \n        output_dir = Path(output_dir)\n        repo_name = repo_analysis.get('repo_name', 'unknown')\n        repo_output_dir = output_dir / repo_name\n        repo_output_dir.mkdir(parents=True, exist_ok=True)\n        \n        documentation = {}\n        \n        # Generate main README\n        if config.include_overview:\n            readme_content = self.generate_repository_readme(repo_analysis)\n            readme_path = repo_output_dir / 'README.md'\n            with open(readme_path, 'w', encoding='utf-8') as f:\n                f.write(readme_content)\n            documentation['README.md'] = readme_content\n        \n        # Generate API documentation for each file\n        if config.include_api_docs:\n            api_dir = repo_output_dir / 'api'\n            api_dir.mkdir(exist_ok=True)\n            \n            for file_data in repo_analysis.get('files', []):\n                if file_data.get('file_type') == 'code':\n                    api_doc = self.generate_file_api_docs(file_data)\n                    file_name = Path(file_data['file_path']).stem\n                    api_file_path = api_dir / f\"{file_name}.md\"\n                    \n                    with open(api_file_path, 'w', encoding='utf-8') as f:\n                        f.write(api_doc)\n                    documentation[f'api/{file_name}.md'] = api_doc\n        \n        # Generate architecture documentation\n        if config.include_architecture:\n            arch_doc = self.generate_architecture_docs(repo_analysis)\n            arch_path = repo_output_dir / 'ARCHITECTURE.md'\n            with open(arch_path, 'w', encoding='utf-8') as f:\n                f.write(arch_doc)\n            documentation['ARCHITECTURE.md'] = arch_doc\n        \n        # Generate examples\n        if config.include_examples:\n            examples_doc = self.generate_examples_docs(repo_analysis)\n            examples_path = repo_output_dir / 'EXAMPLES.md'\n            with open(examples_path, 'w', encoding='utf-8') as f:\n                f.write(examples_doc)\n            documentation['EXAMPLES.md'] = examples_doc\n        \n        # Generate table of contents\n        toc = self.generate_table_of_contents(documentation)\n        toc_path = repo_output_dir / 'TABLE_OF_CONTENTS.md'\n        with open(toc_path, 'w', encoding='utf-8') as f:\n            f.write(toc)\n        documentation['TABLE_OF_CONTENTS.md'] = toc\n        \n        return documentation\n    \n    def generate_repository_readme(self, repo_analysis: Dict[str, Any]) -> str:\n        \"\"\"Generate main repository README.\"\"\"\n        repo_name = repo_analysis.get('repo_name', 'Repository')\n        stats = repo_analysis.get('statistics', {})\n        \n        # Build context for LLM\n        context = []\n        context.append(f\"Repository: {repo_name}\")\n        context.append(f\"Total files: {stats.get('total_files', 0)}\")\n        context.append(f\"Code files: {stats.get('code_files', 0)}\")\n        context.append(f\"Languages: {', '.join(stats.get('languages', {}).keys())}\")\n        \n        # Add git information\n        git_info = repo_analysis.get('git_info')\n        if git_info:\n            context.append(f\"Current branch: {git_info.get('current_branch', 'main')}\")\n            if git_info.get('last_commit'):\n                commit = git_info['last_commit']\n                context.append(f\"Last commit: {commit.get('message', '')[:100]}\")\n        \n        # Add file structure overview\n        main_files = []\n        config_files = []\n        doc_files = []\n        \n        for file_data in repo_analysis.get('files', []):\n            file_path = file_data['file_path']\n            if any(name in file_path.lower() for name in ['readme', 'license', 'changelog']):\n                doc_files.append(file_path)\n            elif any(ext in file_path.lower() for ext in ['.json', '.yaml', '.yml', '.toml', '.ini']):\n                config_files.append(file_path)\n            elif file_data.get('file_type') == 'code':\n                main_files.append(file_path)\n        \n        context.append(f\"Main code files: {', '.join(main_files[:10])}\")\n        if config_files:\n            context.append(f\"Configuration files: {', '.join(config_files[:5])}\")\n        if doc_files:\n            context.append(f\"Documentation files: {', '.join(doc_files)}\")\n        \n        context_str = '\\n'.join(context)\n        \n        prompt = f\"\"\"Generate a comprehensive README.md for this repository based on the following information:\n\n{context_str}\n\nPlease include:\n1. Project title and brief description\n2. Features and capabilities\n3. Installation instructions\n4. Quick start guide\n5. Usage examples\n6. Project structure overview\n7. Contributing guidelines\n8. License information\n\nMake it professional and well-formatted with proper Markdown syntax.\"\"\"\n\n        try:\n            return self.ollama_client.generate(prompt, temperature=0.3)\n        except Exception as e:\n            return f\"# {repo_name}\\n\\nError generating README: {str(e)}\"\n    \n    def generate_file_api_docs(self, file_analysis: Dict[str, Any]) -> str:\n        \"\"\"Generate API documentation for a single file.\"\"\"\n        file_path = file_analysis['file_path']\n        language = file_analysis.get('language', 'Unknown')\n        elements = file_analysis.get('elements', [])\n        \n        # Group elements by type\n        classes = [e for e in elements if e['type'] == 'class']\n        functions = [e for e in elements if e['type'] in ['function', 'method']]\n        \n        doc_content = f\"# API Reference - {Path(file_path).name}\\n\\n\"\n        doc_content += f\"**File**: `{file_path}`  \\n\"\n        doc_content += f\"**Language**: {language}\\n\\n\"\n        \n        # File overview\n        overview_prompt = f\"\"\"Provide a brief overview of this {language} file:\n\nFile: {file_path}\nElements: {len(elements)} total ({len(classes)} classes, {len(functions)} functions)\n\nContent preview:\n{file_analysis.get('content', '')[:1000]}...\n\nWrite a 2-3 sentence overview of what this file does.\"\"\"\n\n        try:\n            overview = self.ollama_client.generate(overview_prompt, temperature=0.3)\n            doc_content += f\"## Overview\\n\\n{overview}\\n\\n\"\n        except:\n            doc_content += f\"## Overview\\n\\nThis file contains {len(elements)} code elements.\\n\\n\"\n        \n        # Document classes\n        if classes:\n            doc_content += \"## Classes\\n\\n\"\n            for cls in classes:\n                doc_content += f\"### {cls['name']}\\n\\n\"\n                if cls.get('docstring'):\n                    doc_content += f\"{cls['docstring']}\\n\\n\"\n                \n                # Get methods for this class\n                class_methods = [e for e in elements if e['type'] == 'method' and e['name'].startswith(f\"{cls['name']}.\")]\n                if class_methods:\n                    doc_content += \"#### Methods\\n\\n\"\n                    for method in class_methods:\n                        method_name = method['name'].split('.')[-1]\n                        doc_content += f\"- **{method_name}**\"\n                        if method.get('signature'):\n                            doc_content += f\": `{method['signature']}`\"\n                        if method.get('docstring'):\n                            doc_content += f\" - {method['docstring'][:100]}...\"\n                        doc_content += \"\\n\"\n                    doc_content += \"\\n\"\n        \n        # Document functions\n        if functions:\n            doc_content += \"## Functions\\n\\n\"\n            for func in functions:\n                if func['type'] == 'method':\n                    continue  # Skip methods (already documented with classes)\n                \n                doc_content += f\"### {func['name']}\\n\\n\"\n                if func.get('signature'):\n                    doc_content += f\"```{language}\\n{func['signature']}\\n```\\n\\n\"\n                if func.get('docstring'):\n                    doc_content += f\"{func['docstring']}\\n\\n\"\n        \n        # Add imports if available\n        imports = file_analysis.get('imports', [])\n        if imports:\n            doc_content += \"## Dependencies\\n\\n\"\n            doc_content += \"This file imports:\\n\\n\"\n            for imp in imports[:10]:  # Limit to first 10 imports\n                doc_content += f\"- `{imp}`\\n\"\n            if len(imports) > 10:\n                doc_content += f\"- ... and {len(imports) - 10} more\\n\"\n            doc_content += \"\\n\"\n        \n        return doc_content\n    \n    def generate_architecture_docs(self, repo_analysis: Dict[str, Any]) -> str:\n        \"\"\"Generate architecture documentation.\"\"\"\n        repo_name = repo_analysis.get('repo_name', 'Repository')\n        stats = repo_analysis.get('statistics', {})\n        \n        # Analyze project structure\n        languages = stats.get('languages', {})\n        files = repo_analysis.get('files', [])\n        \n        # Group files by directory\n        directories = {}\n        for file_data in files:\n            dir_path = str(Path(file_data['file_path']).parent)\n            if dir_path not in directories:\n                directories[dir_path] = []\n            directories[dir_path].append(file_data)\n        \n        # Build context for architecture analysis\n        context = []\n        context.append(f\"Repository: {repo_name}\")\n        context.append(f\"Languages: {', '.join(languages.keys())}\")\n        context.append(f\"Total files: {stats.get('total_files', 0)}\")\n        \n        context.append(\"\\nDirectory structure:\")\n        for dir_path, dir_files in sorted(directories.items())[:15]:  # Limit directories\n            file_count = len(dir_files)\n            main_types = set()\n            for f in dir_files:\n                if f.get('language'):\n                    main_types.add(f['language'])\n            context.append(f\"- {dir_path}: {file_count} files ({', '.join(main_types)})\")\n        \n        # Add key files analysis\n        key_files = []\n        for file_data in files:\n            if any(keyword in file_data['file_path'].lower() for keyword in ['main', 'app', 'index', '__init__', 'server', 'client']):\n                key_files.append(file_data['file_path'])\n        \n        if key_files:\n            context.append(f\"\\nKey files: {', '.join(key_files[:10])}\")\n        \n        context_str = '\\n'.join(context)\n        \n        prompt = f\"\"\"Analyze the architecture of this project and generate comprehensive architecture documentation:\n\n{context_str}\n\nPlease provide:\n1. High-level architecture overview\n2. Component breakdown and relationships\n3. Data flow and system interactions\n4. Design patterns used\n5. Technology stack analysis\n6. Scalability considerations\n7. Deployment architecture\n\nFormat as professional technical documentation with proper Markdown structure.\"\"\"\n\n        try:\n            return self.ollama_client.generate(prompt, temperature=0.3)\n        except Exception as e:\n            return f\"# Architecture Documentation\\n\\nError generating architecture docs: {str(e)}\"\n    \n    def generate_examples_docs(self, repo_analysis: Dict[str, Any]) -> str:\n        \"\"\"Generate usage examples documentation.\"\"\"\n        repo_name = repo_analysis.get('repo_name', 'Repository')\n        languages = repo_analysis.get('statistics', {}).get('languages', {})\n        \n        # Find main entry points\n        entry_points = []\n        main_classes = []\n        main_functions = []\n        \n        for file_data in repo_analysis.get('files', []):\n            if file_data.get('file_type') == 'code':\n                elements = file_data.get('elements', [])\n                \n                # Look for main functions or entry points\n                for element in elements:\n                    if element['name'].lower() in ['main', 'run', 'start', 'init']:\n                        entry_points.append({\n                            'name': element['name'],\n                            'file': file_data['file_path'],\n                            'signature': element.get('signature', ''),\n                            'type': element['type']\n                        })\n                    \n                    if element['type'] == 'class' and len(element.get('name', '')) > 3:\n                        main_classes.append({\n                            'name': element['name'],\n                            'file': file_data['file_path'],\n                            'signature': element.get('signature', ''),\n                            'docstring': element.get('docstring', '')\n                        })\n                    \n                    if element['type'] == 'function' and element.get('docstring'):\n                        main_functions.append({\n                            'name': element['name'],\n                            'file': file_data['file_path'],\n                            'signature': element.get('signature', ''),\n                            'docstring': element.get('docstring', '')\n                        })\n        \n        # Build context\n        context = []\n        context.append(f\"Repository: {repo_name}\")\n        context.append(f\"Languages: {', '.join(languages.keys())}\")\n        \n        if entry_points:\n            context.append(\"\\nEntry points:\")\n            for ep in entry_points[:5]:\n                context.append(f\"- {ep['name']} in {ep['file']}\")\n        \n        if main_classes:\n            context.append(\"\\nMain classes:\")\n            for cls in main_classes[:5]:\n                context.append(f\"- {cls['name']} in {cls['file']}\")\n        \n        if main_functions:\n            context.append(\"\\nKey functions:\")\n            for func in main_functions[:5]:\n                context.append(f\"- {func['name']} in {func['file']}: {func['docstring'][:50]}...\")\n        \n        context_str = '\\n'.join(context)\n        \n        prompt = f\"\"\"Generate practical usage examples and tutorials for this project:\n\n{context_str}\n\nPlease provide:\n1. Quick start example\n2. Basic usage patterns\n3. Common use cases with code examples\n4. Integration examples\n5. Configuration examples\n6. Troubleshooting common issues\n\nInclude actual code snippets with explanations. Format with proper Markdown and code blocks.\"\"\"\n\n        try:\n            return self.ollama_client.generate(prompt, temperature=0.3)\n        except Exception as e:\n            return f\"# Usage Examples\\n\\nError generating examples: {str(e)}\"\n    \n    def generate_table_of_contents(self, documentation: Dict[str, str]) -> str:\n        \"\"\"Generate table of contents for all documentation.\"\"\"\n        toc_content = \"# Table of Contents\\n\\n\"\n        toc_content += \"This repository contains the following documentation:\\n\\n\"\n        \n        # Main documentation\n        main_docs = ['README.md', 'ARCHITECTURE.md', 'EXAMPLES.md']\n        for doc in main_docs:\n            if doc in documentation:\n                toc_content += f\"- [{doc}](./{doc})\\n\"\n        \n        # API documentation\n        api_docs = [k for k in documentation.keys() if k.startswith('api/')]\n        if api_docs:\n            toc_content += \"\\n## API Documentation\\n\\n\"\n            for doc in sorted(api_docs):\n                file_name = Path(doc).stem\n                toc_content += f\"- [{file_name}](./{doc})\\n\"\n        \n        toc_content += f\"\\n---\\n\\n*Documentation generated automatically from codebase analysis.*\"\n        \n        return toc_content\n    \n    def update_existing_docs(self, repo_path: str, analysis: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Update existing documentation files with new analysis.\"\"\"\n        repo_path = Path(repo_path)\n        updates = {}\n        \n        # Check for existing README\n        readme_path = repo_path / 'README.md'\n        if readme_path.exists():\n            with open(readme_path, 'r', encoding='utf-8') as f:\n                existing_readme = f.read()\n            \n            # Generate enhancement suggestions\n            prompt = f\"\"\"Analyze this existing README and suggest improvements based on the codebase analysis:\n\nCurrent README:\n{existing_readme[:2000]}...\n\nCodebase info:\n- Files: {analysis.get('statistics', {}).get('total_files', 0)}\n- Languages: {', '.join(analysis.get('statistics', {}).get('languages', {}).keys())}\n- Key components: {len(analysis.get('files', []))} files analyzed\n\nSuggest specific improvements while preserving the existing structure and content.\"\"\"\n\n            try:\n                suggestions = self.ollama_client.generate(prompt, temperature=0.3)\n                updates['README_suggestions.md'] = suggestions\n            except Exception as e:\n                updates['README_suggestions.md'] = f\"Error generating suggestions: {str(e)}\"\n        \n        return updates\n"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
      "file_type": "code",
      "language": "python",
      "imports": [
        "argparse",
        "asyncio",
        "sys",
        "pathlib.Path",
        "typing.Optional",
        "config.settings",
        "repository_analyzer.RepositoryAnalyzer",
        "ollama_client.OllamaClient",
        "vector_store.VectorStore",
        "rag_system.RAGSystem",
        "documentation_generator.DocumentationBuilder",
        "documentation_generator.DocumentationConfig",
        "api.main"
      ],
      "elements": [
        {
          "name": "LocalDeepWiki",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 21,
          "line_end": 254,
          "docstring": "Main class for Local DeepWiki functionality.",
          "signature": "class LocalDeepWiki",
          "content": null,
          "dependencies": []
        },
        {
          "name": "LocalDeepWiki.__init__",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 24,
          "line_end": 30,
          "docstring": "Initialize LocalDeepWiki with all components.",
          "signature": "def __init__(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "LocalDeepWiki.check_prerequisites",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 32,
          "line_end": 65,
          "docstring": "Check if all prerequisites are met.",
          "signature": "def check_prerequisites(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "LocalDeepWiki.analyze_repository",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 67,
          "line_end": 104,
          "docstring": "Analyze a repository and add it to the vector store.",
          "signature": "def analyze_repository(self, repo_path, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "LocalDeepWiki.query_repository",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 106,
          "line_end": 129,
          "docstring": "Query a repository using the RAG system.",
          "signature": "def query_repository(self, query, repo_name, stream)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "LocalDeepWiki.interactive_chat",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 131,
          "line_end": 164,
          "docstring": "Start an interactive chat session.",
          "signature": "def interactive_chat(self, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "LocalDeepWiki.generate_documentation",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 166,
          "line_end": 199,
          "docstring": "Generate documentation for a repository.",
          "signature": "def generate_documentation(self, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "LocalDeepWiki.list_repositories",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 201,
          "line_end": 231,
          "docstring": "List all analyzed repositories.",
          "signature": "def list_repositories(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "LocalDeepWiki.show_stats",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 233,
          "line_end": 254,
          "docstring": "Show system statistics.",
          "signature": "def show_stats(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "main",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 256,
          "line_end": 342,
          "docstring": "Main CLI interface.",
          "signature": "def main()",
          "content": null,
          "dependencies": []
        },
        {
          "name": "__init__",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 24,
          "line_end": 30,
          "docstring": "Initialize LocalDeepWiki with all components.",
          "signature": "def __init__(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "check_prerequisites",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 32,
          "line_end": 65,
          "docstring": "Check if all prerequisites are met.",
          "signature": "def check_prerequisites(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "analyze_repository",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 67,
          "line_end": 104,
          "docstring": "Analyze a repository and add it to the vector store.",
          "signature": "def analyze_repository(self, repo_path, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "query_repository",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 106,
          "line_end": 129,
          "docstring": "Query a repository using the RAG system.",
          "signature": "def query_repository(self, query, repo_name, stream)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "interactive_chat",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 131,
          "line_end": 164,
          "docstring": "Start an interactive chat session.",
          "signature": "def interactive_chat(self, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "generate_documentation",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 166,
          "line_end": 199,
          "docstring": "Generate documentation for a repository.",
          "signature": "def generate_documentation(self, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "list_repositories",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 201,
          "line_end": 231,
          "docstring": "List all analyzed repositories.",
          "signature": "def list_repositories(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "show_stats",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\main.py",
          "line_start": 233,
          "line_end": 254,
          "docstring": "Show system statistics.",
          "signature": "def show_stats(self)",
          "content": null,
          "dependencies": []
        }
      ],
      "summary": null,
      "content": "#!/usr/bin/env python3\n\"\"\"\nLocal DeepWiki - Main entry point and CLI interface.\n\nA local implementation of DeepWiki using Ollama for LLM inference.\n\"\"\"\n\nimport argparse\nimport asyncio\nimport sys\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom config import settings\nfrom repository_analyzer import RepositoryAnalyzer\nfrom ollama_client import OllamaClient\nfrom vector_store import VectorStore\nfrom rag_system import RAGSystem\nfrom documentation_generator import DocumentationBuilder, DocumentationConfig\n\nclass LocalDeepWiki:\n    \"\"\"Main class for Local DeepWiki functionality.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize LocalDeepWiki with all components.\"\"\"\n        self.ollama_client = OllamaClient()\n        self.vector_store = VectorStore()\n        self.rag_system = RAGSystem(self.vector_store, self.ollama_client)\n        self.repository_analyzer = RepositoryAnalyzer()\n        self.documentation_builder = DocumentationBuilder(self.ollama_client)\n    \n    def check_prerequisites(self) -> bool:\n        \"\"\"Check if all prerequisites are met.\"\"\"\n        print(\"Checking prerequisites...\")\n        \n        # Check Ollama\n        if not self.ollama_client.is_available():\n            print(\"X Ollama server is not available at\", settings.OLLAMA_BASE_URL)\n            print(\"Please start Ollama first:\")\n            print(\"  ollama serve\")\n            return False\n        \n        print(\"OK Ollama server is available\")\n        \n        # Check model\n        models = self.ollama_client.list_models()\n        model_names = [model['name'] for model in models]\n        \n        if settings.OLLAMA_MODEL not in model_names:\n            print(f\"X Model '{settings.OLLAMA_MODEL}' is not available\")\n            print(\"Available models:\", model_names)\n            print(f\"To download the model, run:\")\n            print(f\"  ollama pull {settings.OLLAMA_MODEL}\")\n            return False\n        \n        print(f\"OK Model '{settings.OLLAMA_MODEL}' is available\")\n        \n        # Check embedding model\n        if settings.OLLAMA_EMBEDDING_MODEL not in model_names:\n            print(f\"! Embedding model '{settings.OLLAMA_EMBEDDING_MODEL}' not found\")\n            print(\"Will use fallback embedding model\")\n        else:\n            print(f\"OK Embedding model '{settings.OLLAMA_EMBEDDING_MODEL}' is available\")\n        \n        return True\n    \n    def analyze_repository(self, repo_path: str, repo_name: Optional[str] = None) -> bool:\n        \"\"\"Analyze a repository and add it to the vector store.\"\"\"\n        repo_path = Path(repo_path).resolve()\n        \n        if not repo_path.exists():\n            print(f\"X Repository path does not exist: {repo_path}\")\n            return False\n        \n        repo_name = repo_name or repo_path.name\n        print(f\"* Analyzing repository: {repo_name}\")\n        print(f\"   Path: {repo_path}\")\n        \n        try:\n            # Analyze repository structure\n            print(\"   Parsing files and extracting structure...\")\n            analysis = self.repository_analyzer.analyze_repository(str(repo_path))\n            analysis['repo_name'] = repo_name\n            \n            # Save analysis\n            analysis_path = Path(settings.REPOS_DIRECTORY) / f\"{repo_name}_analysis.json\"\n            self.repository_analyzer.save_analysis(analysis, str(analysis_path))\n            print(f\"   Analysis saved to: {analysis_path}\")\n            \n            # Add to vector store\n            print(\"   Adding to vector store...\")\n            chunks_added = self.vector_store.add_repository(analysis)\n            \n            print(f\"OK Repository analysis complete!\")\n            print(f\"   Files analyzed: {analysis['statistics']['total_files']}\")\n            print(f\"   Code files: {analysis['statistics']['code_files']}\")\n            print(f\"   Languages: {', '.join(analysis['statistics']['languages'].keys())}\")\n            print(f\"   Chunks added to vector store: {chunks_added}\")\n            \n            return True\n            \n        except Exception as e:\n            print(f\"X Error analyzing repository: {e}\")\n            return False\n    \n    def query_repository(self, query: str, repo_name: Optional[str] = None, stream: bool = True):\n        \"\"\"Query a repository using the RAG system.\"\"\"\n        print(f\"? Query: {query}\")\n        if repo_name:\n            print(f\"   Repository: {repo_name}\")\n        \n        try:\n            result = self.rag_system.query(query, repo_name=repo_name, stream=False)\n            \n            if result['context']:\n                print(\"\\n> Response:\")\n                print(result['response'])\n                \n                if result['sources']:\n                    print(\"\\n* Sources:\")\n                    for i, source in enumerate(result['sources'], 1):\n                        print(f\"   {i}. {source.get('file_path', 'Unknown')}\")\n                        if source.get('element_name'):\n                            print(f\"      Element: {source['element_name']}\")\n            else:\n                print(\"X No relevant context found for your query.\")\n                \n        except Exception as e:\n            print(f\"X Error processing query: {e}\")\n    \n    def interactive_chat(self, repo_name: Optional[str] = None):\n        \"\"\"Start an interactive chat session.\"\"\"\n        print(\"* Interactive Chat Mode\")\n        print(\"Type 'quit' or 'exit' to end the session\")\n        if repo_name:\n            print(f\"Querying repository: {repo_name}\")\n        print(\"-\" * 50)\n        \n        messages = []\n        \n        while True:\n            try:\n                user_input = input(\"\\nYou: \").strip()\n                \n                if user_input.lower() in ['quit', 'exit', 'q']:\n                    print(\"Goodbye!\")\n                    break\n                \n                if not user_input:\n                    continue\n                \n                messages.append({\"role\": \"user\", \"content\": user_input})\n                \n                print(\"\\nAssistant: \", end=\"\", flush=True)\n                response = self.rag_system.chat_with_repo(messages, repo_name)\n                print(response)\n                \n                messages.append({\"role\": \"assistant\", \"content\": response})\n                \n            except KeyboardInterrupt:\n                print(\"\\nGoodbye!\")\n                break\n            except Exception as e:\n                print(f\"\\nX Error: {e}\")\n    \n    def generate_documentation(self, repo_name: str):\n        \"\"\"Generate documentation for a repository.\"\"\"\n        print(f\"* Generating documentation for: {repo_name}\")\n        \n        # Load analysis\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\"{repo_name}_analysis.json\"\n        if not analysis_path.exists():\n            print(f\"X Repository {repo_name} not found. Please analyze it first.\")\n            return False\n        \n        try:\n            analysis = self.repository_analyzer.load_analysis(str(analysis_path))\n            \n            config = DocumentationConfig(\n                include_overview=True,\n                include_api_docs=True,\n                include_examples=True,\n                include_architecture=True\n            )\n            \n            docs = self.documentation_builder.generate_full_documentation(analysis, config)\n            \n            print(f\"OK Documentation generated!\")\n            print(f\"   Files created: {len(docs)}\")\n            print(f\"   Output directory: {Path(settings.DOCS_DIRECTORY) / repo_name}\")\n            \n            for doc_name in docs.keys():\n                print(f\"   - {doc_name}\")\n            \n            return True\n            \n        except Exception as e:\n            print(f\"X Error generating documentation: {e}\")\n            return False\n    \n    def list_repositories(self):\n        \"\"\"List all analyzed repositories.\"\"\"\n        repos_dir = Path(settings.REPOS_DIRECTORY)\n        \n        if not repos_dir.exists():\n            print(\"No repositories found.\")\n            return\n        \n        analysis_files = list(repos_dir.glob(\"*_analysis.json\"))\n        \n        if not analysis_files:\n            print(\"No repositories found.\")\n            return\n        \n        print(\"* Analyzed Repositories:\")\n        print(\"-\" * 50)\n        \n        for analysis_file in analysis_files:\n            try:\n                analysis = self.repository_analyzer.load_analysis(str(analysis_file))\n                repo_name = analysis.get('repo_name', analysis_file.stem.replace('_analysis', ''))\n                stats = analysis.get('statistics', {})\n                \n                print(f\"+ {repo_name}\")\n                print(f\"   Path: {analysis.get('repo_path', 'Unknown')}\")\n                print(f\"   Files: {stats.get('total_files', 0)} total, {stats.get('code_files', 0)} code\")\n                print(f\"   Languages: {', '.join(stats.get('languages', {}).keys())}\")\n                print()\n                \n            except Exception as e:\n                print(f\"X Error loading {analysis_file}: {e}\")\n    \n    def show_stats(self):\n        \"\"\"Show system statistics.\"\"\"\n        print(\"* System Statistics\")\n        print(\"-\" * 30)\n        \n        # Vector store stats\n        vector_stats = self.vector_store.get_collection_stats()\n        print(f\"Documents in vector store: {vector_stats.get('total_documents', 0)}\")\n        \n        # Repository count\n        repos_dir = Path(settings.REPOS_DIRECTORY)\n        repo_count = len(list(repos_dir.glob(\"*_analysis.json\"))) if repos_dir.exists() else 0\n        print(f\"Analyzed repositories: {repo_count}\")\n        \n        # Generated docs count\n        docs_dir = Path(settings.DOCS_DIRECTORY)\n        doc_count = len(list(docs_dir.rglob(\"*.md\"))) if docs_dir.exists() else 0\n        print(f\"Generated documentation files: {doc_count}\")\n        \n        # Ollama status\n        print(f\"Ollama available: {'OK' if self.ollama_client.is_available() else 'X'}\")\n        print(f\"Current model: {settings.OLLAMA_MODEL}\")\n\ndef main():\n    \"\"\"Main CLI interface.\"\"\"\n    parser = argparse.ArgumentParser(description=\"Local DeepWiki - Chat with your code repositories\")\n    \n    subparsers = parser.add_subparsers(dest='command', help='Available commands')\n    \n    # Check command\n    subparsers.add_parser('check', help='Check system prerequisites')\n    \n    # Analyze command\n    analyze_parser = subparsers.add_parser('analyze', help='Analyze a repository')\n    analyze_parser.add_argument('repo_path', help='Path to the repository')\n    analyze_parser.add_argument('--name', help='Custom name for the repository')\n    \n    # Query command\n    query_parser = subparsers.add_parser('query', help='Query a repository')\n    query_parser.add_argument('query', help='Your question or query')\n    query_parser.add_argument('--repo', help='Repository name to query')\n    \n    # Chat command\n    chat_parser = subparsers.add_parser('chat', help='Start interactive chat')\n    chat_parser.add_argument('--repo', help='Repository name to chat with')\n    \n    # Docs command\n    docs_parser = subparsers.add_parser('docs', help='Generate documentation')\n    docs_parser.add_argument('repo_name', help='Repository name')\n    \n    # List command\n    subparsers.add_parser('list', help='List analyzed repositories')\n    \n    # Stats command\n    subparsers.add_parser('stats', help='Show system statistics')\n    \n    # Server command\n    server_parser = subparsers.add_parser('server', help='Start web server')\n    server_parser.add_argument('--host', default=settings.API_HOST, help='Host address')\n    server_parser.add_argument('--port', type=int, default=settings.API_PORT, help='Port number')\n    \n    args = parser.parse_args()\n    \n    if not args.command:\n        parser.print_help()\n        return\n    \n    # Initialize LocalDeepWiki\n    ldw = LocalDeepWiki()\n    \n    if args.command == 'check':\n        if ldw.check_prerequisites():\n            print(\"\\nOK All prerequisites are met! You're ready to use Local DeepWiki.\")\n        else:\n            print(\"\\nX Please fix the issues above before using Local DeepWiki.\")\n            sys.exit(1)\n    \n    elif args.command == 'analyze':\n        if not ldw.check_prerequisites():\n            sys.exit(1)\n        ldw.analyze_repository(args.repo_path, args.name)\n    \n    elif args.command == 'query':\n        if not ldw.check_prerequisites():\n            sys.exit(1)\n        ldw.query_repository(args.query, args.repo)\n    \n    elif args.command == 'chat':\n        if not ldw.check_prerequisites():\n            sys.exit(1)\n        ldw.interactive_chat(args.repo)\n    \n    elif args.command == 'docs':\n        if not ldw.check_prerequisites():\n            sys.exit(1)\n        ldw.generate_documentation(args.repo_name)\n    \n    elif args.command == 'list':\n        ldw.list_repositories()\n    \n    elif args.command == 'stats':\n        ldw.show_stats()\n    \n    elif args.command == 'server':\n        if not ldw.check_prerequisites():\n            sys.exit(1)\n        \n        # Import and run the API server\n        from api import main as run_server\n        run_server()\n\nif __name__ == \"__main__\":\n    main()\n"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
      "file_type": "code",
      "language": "python",
      "imports": [
        "json",
        "requests",
        "asyncio",
        "aiohttp",
        "typing.Dict",
        "typing.List",
        "typing.Any",
        "typing.Optional",
        "typing.AsyncGenerator",
        "config.settings"
      ],
      "elements": [
        {
          "name": "OllamaClient",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 10,
          "line_end": 231,
          "docstring": "Client for interacting with Ollama local LLM server.",
          "signature": "class OllamaClient",
          "content": null,
          "dependencies": []
        },
        {
          "name": "OllamaClient.__init__",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 13,
          "line_end": 16,
          "docstring": null,
          "signature": "def __init__(self, base_url, model)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "OllamaClient.is_available",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 18,
          "line_end": 24,
          "docstring": "Check if Ollama server is available.",
          "signature": "def is_available(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "OllamaClient.list_models",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 26,
          "line_end": 34,
          "docstring": "List available models.",
          "signature": "def list_models(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "OllamaClient.pull_model",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 36,
          "line_end": 57,
          "docstring": "Pull a model if not already available.",
          "signature": "def pull_model(self, model_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "OllamaClient.generate",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 59,
          "line_end": 80,
          "docstring": "Generate text using Ollama.",
          "signature": "def generate(self, prompt, model)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "OllamaClient.get_embeddings",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 141,
          "line_end": 160,
          "docstring": "Get embeddings for text.",
          "signature": "def get_embeddings(self, text, model)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "OllamaClient.chat",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 185,
          "line_end": 206,
          "docstring": "Chat completion using Ollama.",
          "signature": "def chat(self, messages, model)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationGenerator",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 233,
          "line_end": 352,
          "docstring": "Generate documentation using Ollama.",
          "signature": "class DocumentationGenerator",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationGenerator.__init__",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 236,
          "line_end": 237,
          "docstring": null,
          "signature": "def __init__(self, ollama_client)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationGenerator.generate_file_documentation",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 239,
          "line_end": 295,
          "docstring": "Generate documentation for a single file.",
          "signature": "def generate_file_documentation(self, file_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "DocumentationGenerator.generate_repository_overview",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 297,
          "line_end": 352,
          "docstring": "Generate high-level repository documentation.",
          "signature": "def generate_repository_overview(self, repo_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "__init__",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 13,
          "line_end": 16,
          "docstring": null,
          "signature": "def __init__(self, base_url, model)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "is_available",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 18,
          "line_end": 24,
          "docstring": "Check if Ollama server is available.",
          "signature": "def is_available(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "list_models",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 26,
          "line_end": 34,
          "docstring": "List available models.",
          "signature": "def list_models(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "pull_model",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 36,
          "line_end": 57,
          "docstring": "Pull a model if not already available.",
          "signature": "def pull_model(self, model_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "generate",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 59,
          "line_end": 80,
          "docstring": "Generate text using Ollama.",
          "signature": "def generate(self, prompt, model)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "get_embeddings",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 141,
          "line_end": 160,
          "docstring": "Get embeddings for text.",
          "signature": "def get_embeddings(self, text, model)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "chat",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 185,
          "line_end": 206,
          "docstring": "Chat completion using Ollama.",
          "signature": "def chat(self, messages, model)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "__init__",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 236,
          "line_end": 237,
          "docstring": null,
          "signature": "def __init__(self, ollama_client)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "generate_file_documentation",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 239,
          "line_end": 295,
          "docstring": "Generate documentation for a single file.",
          "signature": "def generate_file_documentation(self, file_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "generate_repository_overview",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\ollama_client.py",
          "line_start": 297,
          "line_end": 352,
          "docstring": "Generate high-level repository documentation.",
          "signature": "def generate_repository_overview(self, repo_analysis)",
          "content": null,
          "dependencies": []
        }
      ],
      "summary": null,
      "content": "\"\"\"Ollama client for local LLM inference.\"\"\"\n\nimport json\nimport requests\nimport asyncio\nimport aiohttp\nfrom typing import Dict, List, Any, Optional, AsyncGenerator\nfrom config import settings\n\nclass OllamaClient:\n    \"\"\"Client for interacting with Ollama local LLM server.\"\"\"\n    \n    def __init__(self, base_url: str = None, model: str = None):\n        self.base_url = base_url or settings.OLLAMA_BASE_URL\n        self.model = model or settings.OLLAMA_MODEL\n        self.embedding_model = settings.OLLAMA_EMBEDDING_MODEL\n        \n    def is_available(self) -> bool:\n        \"\"\"Check if Ollama server is available.\"\"\"\n        try:\n            response = requests.get(f\"{self.base_url}/api/tags\", timeout=5)\n            return response.status_code == 200\n        except:\n            return False\n    \n    def list_models(self) -> List[Dict[str, Any]]:\n        \"\"\"List available models.\"\"\"\n        try:\n            response = requests.get(f\"{self.base_url}/api/tags\")\n            response.raise_for_status()\n            return response.json().get('models', [])\n        except Exception as e:\n            print(f\"Error listing models: {e}\")\n            return []\n    \n    def pull_model(self, model_name: str) -> bool:\n        \"\"\"Pull a model if not already available.\"\"\"\n        try:\n            response = requests.post(\n                f\"{self.base_url}/api/pull\",\n                json={\"name\": model_name},\n                stream=True\n            )\n            \n            for line in response.iter_lines():\n                if line:\n                    data = json.loads(line)\n                    if data.get('status'):\n                        print(f\"Pulling {model_name}: {data['status']}\")\n                    if data.get('error'):\n                        print(f\"Error: {data['error']}\")\n                        return False\n            \n            return True\n        except Exception as e:\n            print(f\"Error pulling model {model_name}: {e}\")\n            return False\n    \n    def generate(self, prompt: str, model: str = None, **kwargs) -> str:\n        \"\"\"Generate text using Ollama.\"\"\"\n        model = model or self.model\n        \n        payload = {\n            \"model\": model,\n            \"prompt\": prompt,\n            \"stream\": False,\n            **kwargs\n        }\n        \n        try:\n            response = requests.post(\n                f\"{self.base_url}/api/generate\",\n                json=payload,\n                timeout=120\n            )\n            response.raise_for_status()\n            return response.json()['response']\n        except Exception as e:\n            print(f\"Error generating text: {e}\")\n            raise\n    \n    async def generate_async(self, prompt: str, model: str = None, **kwargs) -> str:\n        \"\"\"Generate text asynchronously.\"\"\"\n        model = model or self.model\n        \n        payload = {\n            \"model\": model,\n            \"prompt\": prompt,\n            \"stream\": False,\n            **kwargs\n        }\n        \n        async with aiohttp.ClientSession() as session:\n            try:\n                async with session.post(\n                    f\"{self.base_url}/api/generate\",\n                    json=payload,\n                    timeout=aiohttp.ClientTimeout(total=120)\n                ) as response:\n                    response.raise_for_status()\n                    result = await response.json()\n                    return result['response']\n            except Exception as e:\n                print(f\"Error generating text: {e}\")\n                raise\n    \n    async def generate_stream(self, prompt: str, model: str = None, **kwargs) -> AsyncGenerator[str, None]:\n        \"\"\"Generate text with streaming response.\"\"\"\n        model = model or self.model\n        \n        payload = {\n            \"model\": model,\n            \"prompt\": prompt,\n            \"stream\": True,\n            **kwargs\n        }\n        \n        async with aiohttp.ClientSession() as session:\n            try:\n                async with session.post(\n                    f\"{self.base_url}/api/generate\",\n                    json=payload,\n                    timeout=aiohttp.ClientTimeout(total=None)\n                ) as response:\n                    response.raise_for_status()\n                    \n                    async for line in response.content:\n                        if line:\n                            try:\n                                data = json.loads(line)\n                                if 'response' in data:\n                                    yield data['response']\n                                if data.get('done', False):\n                                    break\n                            except json.JSONDecodeError:\n                                continue\n            except Exception as e:\n                print(f\"Error in streaming generation: {e}\")\n                raise\n    \n    def get_embeddings(self, text: str, model: str = None) -> List[float]:\n        \"\"\"Get embeddings for text.\"\"\"\n        model = model or self.embedding_model\n        \n        payload = {\n            \"model\": model,\n            \"prompt\": text\n        }\n        \n        try:\n            response = requests.post(\n                f\"{self.base_url}/api/embeddings\",\n                json=payload,\n                timeout=60\n            )\n            response.raise_for_status()\n            return response.json()['embedding']\n        except Exception as e:\n            print(f\"Error getting embeddings: {e}\")\n            raise\n    \n    async def get_embeddings_async(self, text: str, model: str = None) -> List[float]:\n        \"\"\"Get embeddings asynchronously.\"\"\"\n        model = model or self.embedding_model\n        \n        payload = {\n            \"model\": model,\n            \"prompt\": text\n        }\n        \n        async with aiohttp.ClientSession() as session:\n            try:\n                async with session.post(\n                    f\"{self.base_url}/api/embeddings\",\n                    json=payload,\n                    timeout=aiohttp.ClientTimeout(total=60)\n                ) as response:\n                    response.raise_for_status()\n                    result = await response.json()\n                    return result['embedding']\n            except Exception as e:\n                print(f\"Error getting embeddings: {e}\")\n                raise\n    \n    def chat(self, messages: List[Dict[str, str]], model: str = None, **kwargs) -> str:\n        \"\"\"Chat completion using Ollama.\"\"\"\n        model = model or self.model\n        \n        payload = {\n            \"model\": model,\n            \"messages\": messages,\n            \"stream\": False,\n            **kwargs\n        }\n        \n        try:\n            response = requests.post(\n                f\"{self.base_url}/api/chat\",\n                json=payload,\n                timeout=120\n            )\n            response.raise_for_status()\n            return response.json()['message']['content']\n        except Exception as e:\n            print(f\"Error in chat completion: {e}\")\n            raise\n    \n    async def chat_async(self, messages: List[Dict[str, str]], model: str = None, **kwargs) -> str:\n        \"\"\"Chat completion asynchronously.\"\"\"\n        model = model or self.model\n        \n        payload = {\n            \"model\": model,\n            \"messages\": messages,\n            \"stream\": False,\n            **kwargs\n        }\n        \n        async with aiohttp.ClientSession() as session:\n            try:\n                async with session.post(\n                    f\"{self.base_url}/api/chat\",\n                    json=payload,\n                    timeout=aiohttp.ClientTimeout(total=120)\n                ) as response:\n                    response.raise_for_status()\n                    result = await response.json()\n                    return result['message']['content']\n            except Exception as e:\n                print(f\"Error in chat completion: {e}\")\n                raise\n\nclass DocumentationGenerator:\n    \"\"\"Generate documentation using Ollama.\"\"\"\n    \n    def __init__(self, ollama_client: OllamaClient):\n        self.client = ollama_client\n    \n    def generate_file_documentation(self, file_analysis: Dict[str, Any]) -> str:\n        \"\"\"Generate documentation for a single file.\"\"\"\n        \n        # Build context from file analysis\n        context = []\n        context.append(f\"File: {file_analysis['file_path']}\")\n        context.append(f\"Language: {file_analysis.get('language', 'Unknown')}\")\n        \n        if file_analysis.get('imports'):\n            context.append(f\"Imports: {', '.join(file_analysis['imports'][:10])}\")\n        \n        # Add code elements\n        elements_summary = []\n        for element in file_analysis.get('elements', []):\n            elem_type = element['type']\n            name = element['name']\n            signature = element.get('signature', '')\n            docstring = element.get('docstring', '')\n            \n            elem_desc = f\"{elem_type}: {name}\"\n            if signature:\n                elem_desc += f\" - {signature}\"\n            if docstring:\n                elem_desc += f\" - {docstring[:100]}...\"\n            \n            elements_summary.append(elem_desc)\n        \n        if elements_summary:\n            context.append(\"Code Elements:\")\n            context.extend(elements_summary[:15])  # Limit to prevent prompt overflow\n        \n        # Add file content preview\n        content = file_analysis.get('content', '')\n        if content:\n            content_preview = content[:2000] + \"...\" if len(content) > 2000 else content\n            context.append(f\"Content Preview:\\n```\\n{content_preview}\\n```\")\n        \n        context_str = \"\\n\".join(context)\n        \n        prompt = f\"\"\"Analyze the following code file and generate comprehensive documentation in Markdown format.\n\n{context_str}\n\nPlease provide:\n1. A brief overview of what this file does\n2. Main components and their purposes\n3. Key functions/classes with descriptions\n4. Usage examples if applicable\n5. Dependencies and relationships\n\nFormat the output as clean Markdown with appropriate headers and code blocks.\"\"\"\n\n        try:\n            return self.client.generate(prompt, temperature=0.3, max_tokens=2000)\n        except Exception as e:\n            print(f\"Error generating documentation for {file_analysis['file_path']}: {e}\")\n            return f\"# {file_analysis['file_path']}\\n\\nError generating documentation: {str(e)}\"\n    \n    def generate_repository_overview(self, repo_analysis: Dict[str, Any]) -> str:\n        \"\"\"Generate high-level repository documentation.\"\"\"\n        \n        stats = repo_analysis.get('statistics', {})\n        structure = repo_analysis.get('structure', {})\n        \n        context = []\n        context.append(f\"Repository: {repo_analysis.get('repo_name', 'Unknown')}\")\n        context.append(f\"Total Files: {stats.get('total_files', 0)}\")\n        context.append(f\"Code Files: {stats.get('code_files', 0)}\")\n        context.append(f\"Documentation Files: {stats.get('doc_files', 0)}\")\n        context.append(f\"Total Lines: {stats.get('total_lines', 0)}\")\n        \n        if stats.get('languages'):\n            langs = list(stats['languages'].keys())\n            context.append(f\"Languages: {', '.join(langs)}\")\n        \n        # Add git info if available\n        git_info = repo_analysis.get('git_info')\n        if git_info:\n            context.append(f\"Current Branch: {git_info.get('current_branch', 'Unknown')}\")\n            if git_info.get('last_commit'):\n                commit = git_info['last_commit']\n                context.append(f\"Last Commit: {commit.get('message', '')[:100]}\")\n        \n        # Add main files/directories\n        main_files = []\n        for file_data in repo_analysis.get('files', [])[:10]:\n            if file_data.get('file_type') == 'documentation':\n                main_files.append(file_data['file_path'])\n        \n        if main_files:\n            context.append(f\"Key Documentation: {', '.join(main_files)}\")\n        \n        context_str = \"\\n\".join(context)\n        \n        prompt = f\"\"\"Analyze this code repository and generate a comprehensive overview documentation in Markdown format.\n\nRepository Information:\n{context_str}\n\nPlease provide:\n1. Project overview and purpose\n2. Architecture and structure\n3. Key components and modules\n4. Getting started guide\n5. Development setup instructions\n6. Main features and capabilities\n\nFormat as professional README-style documentation with proper Markdown structure.\"\"\"\n\n        try:\n            return self.client.generate(prompt, temperature=0.3, max_tokens=3000)\n        except Exception as e:\n            print(f\"Error generating repository overview: {e}\")\n            return f\"# Repository Overview\\n\\nError generating overview: {str(e)}\"\n"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
      "file_type": "code",
      "language": "python",
      "imports": [
        "json",
        "typing.List",
        "typing.Dict",
        "typing.Any",
        "typing.Optional",
        "typing.Tuple",
        "dataclasses.dataclass",
        "ollama_client.OllamaClient",
        "vector_store.VectorStore"
      ],
      "elements": [
        {
          "name": "RAGContext",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 10,
          "line_end": 15,
          "docstring": "Context information for RAG system.",
          "signature": "class RAGContext",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 17,
          "line_end": 329,
          "docstring": "Retrieval-Augmented Generation system.",
          "signature": "class RAGSystem",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem.__init__",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 20,
          "line_end": 62,
          "docstring": null,
          "signature": "def __init__(self, vector_store, ollama_client)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem.determine_query_type",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 64,
          "line_end": 75,
          "docstring": "Determine the type of query to select appropriate prompt.",
          "signature": "def determine_query_type(self, query)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem.retrieve_context",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 77,
          "line_end": 79,
          "docstring": "Retrieve relevant context for the query.",
          "signature": "def retrieve_context(self, query, n_results, filter_metadata)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem.build_context_text",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 81,
          "line_end": 110,
          "docstring": "Build context text from retrieved chunks.",
          "signature": "def build_context_text(self, retrieved_chunks, max_context_length)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem.generate_response",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 112,
          "line_end": 133,
          "docstring": "Generate response using RAG context.",
          "signature": "def generate_response(self, query, context, stream)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem.query",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 135,
          "line_end": 191,
          "docstring": "Main query interface for RAG system.",
          "signature": "def query(self, query, repo_name, file_path, n_results, stream)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem.explain_code",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 193,
          "line_end": 214,
          "docstring": "Explain a specific code snippet.",
          "signature": "def explain_code(self, code, language, context)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem.suggest_improvements",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 216,
          "line_end": 237,
          "docstring": "Suggest improvements for code.",
          "signature": "def suggest_improvements(self, code, language)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem.search_similar_code",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 239,
          "line_end": 248,
          "docstring": "Find similar code in the repository.",
          "signature": "def search_similar_code(self, code_snippet, language, n_results)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem.get_file_summary",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 250,
          "line_end": 282,
          "docstring": "Get a summary of a specific file.",
          "signature": "def get_file_summary(self, file_path, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem.get_repository_overview",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 284,
          "line_end": 295,
          "docstring": "Get an overview of the repository.",
          "signature": "def get_repository_overview(self, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RAGSystem.chat_with_repo",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 297,
          "line_end": 329,
          "docstring": "Chat interface for conversational interaction with repository.",
          "signature": "def chat_with_repo(self, messages, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "__init__",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 20,
          "line_end": 62,
          "docstring": null,
          "signature": "def __init__(self, vector_store, ollama_client)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "determine_query_type",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 64,
          "line_end": 75,
          "docstring": "Determine the type of query to select appropriate prompt.",
          "signature": "def determine_query_type(self, query)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "retrieve_context",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 77,
          "line_end": 79,
          "docstring": "Retrieve relevant context for the query.",
          "signature": "def retrieve_context(self, query, n_results, filter_metadata)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "build_context_text",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 81,
          "line_end": 110,
          "docstring": "Build context text from retrieved chunks.",
          "signature": "def build_context_text(self, retrieved_chunks, max_context_length)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "generate_response",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 112,
          "line_end": 133,
          "docstring": "Generate response using RAG context.",
          "signature": "def generate_response(self, query, context, stream)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "query",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 135,
          "line_end": 191,
          "docstring": "Main query interface for RAG system.",
          "signature": "def query(self, query, repo_name, file_path, n_results, stream)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "explain_code",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 193,
          "line_end": 214,
          "docstring": "Explain a specific code snippet.",
          "signature": "def explain_code(self, code, language, context)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "suggest_improvements",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 216,
          "line_end": 237,
          "docstring": "Suggest improvements for code.",
          "signature": "def suggest_improvements(self, code, language)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "search_similar_code",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 239,
          "line_end": 248,
          "docstring": "Find similar code in the repository.",
          "signature": "def search_similar_code(self, code_snippet, language, n_results)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "get_file_summary",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 250,
          "line_end": 282,
          "docstring": "Get a summary of a specific file.",
          "signature": "def get_file_summary(self, file_path, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "get_repository_overview",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 284,
          "line_end": 295,
          "docstring": "Get an overview of the repository.",
          "signature": "def get_repository_overview(self, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "chat_with_repo",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\rag_system.py",
          "line_start": 297,
          "line_end": 329,
          "docstring": "Chat interface for conversational interaction with repository.",
          "signature": "def chat_with_repo(self, messages, repo_name)",
          "content": null,
          "dependencies": []
        }
      ],
      "summary": null,
      "content": "\"\"\"RAG (Retrieval-Augmented Generation) system for context-aware responses.\"\"\"\n\nimport json\nfrom typing import List, Dict, Any, Optional, Tuple\nfrom dataclasses import dataclass\nfrom ollama_client import OllamaClient\nfrom vector_store import VectorStore\n\n@dataclass\nclass RAGContext:\n    \"\"\"Context information for RAG system.\"\"\"\n    query: str\n    retrieved_chunks: List[Dict[str, Any]]\n    context_text: str\n    metadata: Dict[str, Any]\n\nclass RAGSystem:\n    \"\"\"Retrieval-Augmented Generation system.\"\"\"\n    \n    def __init__(self, vector_store: VectorStore, ollama_client: OllamaClient):\n        self.vector_store = vector_store\n        self.ollama_client = ollama_client\n        \n        # System prompts for different types of queries\n        self.system_prompts = {\n            'code_explanation': \"\"\"You are an expert code analyst. Your task is to explain code clearly and concisely based on the provided context. \n\nFocus on:\n- What the code does\n- How it works\n- Key components and their relationships\n- Usage examples when relevant\n- Best practices and potential improvements\n\nBe accurate and reference the specific code provided in the context.\"\"\",\n\n            'general_question': \"\"\"You are a helpful assistant that answers questions about codebases and documentation. \n\nUse the provided context to give accurate, helpful answers. If the context doesn't contain enough information to answer fully, say so and provide what information you can from the context.\n\nBe concise but thorough, and always ground your answers in the provided context.\"\"\",\n\n            'documentation': \"\"\"You are a technical documentation expert. Generate clear, well-structured documentation based on the provided code and context.\n\nFocus on:\n- Clear explanations of functionality\n- Proper formatting with headers and code blocks\n- Usage examples and best practices\n- Integration with other parts of the system\n\nUse proper Markdown formatting.\"\"\",\n\n            'troubleshooting': \"\"\"You are a debugging expert. Help identify issues, suggest solutions, and provide troubleshooting guidance based on the code context.\n\nFocus on:\n- Identifying potential problems\n- Suggesting specific solutions\n- Explaining the reasoning behind recommendations\n- Providing preventive measures\n\nBe practical and actionable in your suggestions.\"\"\"\n        }\n    \n    def determine_query_type(self, query: str) -> str:\n        \"\"\"Determine the type of query to select appropriate prompt.\"\"\"\n        query_lower = query.lower()\n        \n        if any(word in query_lower for word in ['how does', 'what does', 'explain', 'how to']):\n            return 'code_explanation'\n        elif any(word in query_lower for word in ['document', 'generate docs', 'create documentation']):\n            return 'documentation'\n        elif any(word in query_lower for word in ['error', 'bug', 'fix', 'problem', 'issue', 'debug']):\n            return 'troubleshooting'\n        else:\n            return 'general_question'\n    \n    def retrieve_context(self, query: str, n_results: int = 5, filter_metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\n        \"\"\"Retrieve relevant context for the query.\"\"\"\n        return self.vector_store.search(query, n_results, filter_metadata)\n    \n    def build_context_text(self, retrieved_chunks: List[Dict[str, Any]], max_context_length: int = 4000) -> str:\n        \"\"\"Build context text from retrieved chunks.\"\"\"\n        context_parts = []\n        current_length = 0\n        \n        for chunk in retrieved_chunks:\n            text = chunk['text']\n            metadata = chunk.get('metadata', {})\n            \n            # Add metadata header for context\n            header = \"\"\n            if metadata.get('file_path'):\n                header += f\"File: {metadata['file_path']}\\n\"\n            if metadata.get('element_name'):\n                header += f\"Element: {metadata['element_name']} ({metadata.get('element_type', 'unknown')})\\n\"\n            if metadata.get('type'):\n                header += f\"Type: {metadata['type']}\\n\"\n            \n            chunk_text = header + \"\\n\" + text + \"\\n\" + \"=\"*50 + \"\\n\"\n            \n            # Check if adding this chunk would exceed max length\n            if current_length + len(chunk_text) > max_context_length:\n                if not context_parts:  # If first chunk is too long, truncate it\n                    context_parts.append(chunk_text[:max_context_length])\n                break\n            \n            context_parts.append(chunk_text)\n            current_length += len(chunk_text)\n        \n        return \"\\n\".join(context_parts)\n    \n    def generate_response(self, query: str, context: RAGContext, stream: bool = False) -> str:\n        \"\"\"Generate response using RAG context.\"\"\"\n        query_type = self.determine_query_type(query)\n        system_prompt = self.system_prompts.get(query_type, self.system_prompts['general_question'])\n        \n        # Build the full prompt\n        full_prompt = f\"\"\"{system_prompt}\n\nCONTEXT:\n{context.context_text}\n\nUSER QUERY: {query}\n\nPlease provide a helpful response based on the context above. If the context doesn't contain sufficient information, clearly state what information is missing.\"\"\"\n\n        try:\n            if stream:\n                return self.ollama_client.generate_stream(full_prompt, temperature=0.3)\n            else:\n                return self.ollama_client.generate(full_prompt, temperature=0.3)\n        except Exception as e:\n            return f\"Error generating response: {str(e)}\"\n    \n    def query(self, \n              query: str, \n              repo_name: str = None, \n              file_path: str = None,\n              n_results: int = 5,\n              stream: bool = False) -> Dict[str, Any]:\n        \"\"\"Main query interface for RAG system.\"\"\"\n        \n        # Build filter for specific repository or file\n        filter_metadata = {}\n        if repo_name:\n            filter_metadata['repo_name'] = repo_name\n        if file_path:\n            filter_metadata['file_path'] = file_path\n        \n        # Retrieve relevant context\n        retrieved_chunks = self.retrieve_context(query, n_results, filter_metadata or None)\n        \n        if not retrieved_chunks:\n            return {\n                'response': f\"No relevant context found for query: {query}\",\n                'context': None,\n                'sources': []\n            }\n        \n        # Build context\n        context_text = self.build_context_text(retrieved_chunks)\n        context = RAGContext(\n            query=query,\n            retrieved_chunks=retrieved_chunks,\n            context_text=context_text,\n            metadata={'repo_name': repo_name, 'file_path': file_path}\n        )\n        \n        # Generate response\n        response = self.generate_response(query, context, stream)\n        \n        # Extract sources\n        sources = []\n        for chunk in retrieved_chunks:\n            metadata = chunk.get('metadata', {})\n            source = {\n                'file_path': metadata.get('file_path'),\n                'element_name': metadata.get('element_name'),\n                'type': metadata.get('type'),\n                'distance': chunk.get('distance', 0)\n            }\n            # Remove None values\n            source = {k: v for k, v in source.items() if v is not None}\n            if source and source not in sources:\n                sources.append(source)\n        \n        return {\n            'response': response,\n            'context': context,\n            'sources': sources[:5]  # Limit to top 5 sources\n        }\n    \n    def explain_code(self, code: str, language: str = None, context: str = None) -> str:\n        \"\"\"Explain a specific code snippet.\"\"\"\n        prompt = f\"\"\"Explain the following code clearly and concisely:\n\nLanguage: {language or 'Unknown'}\n{f'Context: {context}' if context else ''}\n\nCode:\n```{language or ''}\n{code}\n```\n\nPlease explain:\n1. What this code does\n2. How it works\n3. Key components and their purpose\n4. Any notable patterns or techniques used\"\"\"\n\n        try:\n            return self.ollama_client.generate(prompt, temperature=0.3)\n        except Exception as e:\n            return f\"Error explaining code: {str(e)}\"\n    \n    def suggest_improvements(self, code: str, language: str = None) -> str:\n        \"\"\"Suggest improvements for code.\"\"\"\n        prompt = f\"\"\"Analyze the following code and suggest improvements:\n\nLanguage: {language or 'Unknown'}\n\nCode:\n```{language or ''}\n{code}\n```\n\nPlease provide:\n1. Code quality assessment\n2. Potential improvements\n3. Best practices recommendations\n4. Performance optimizations if applicable\n5. Security considerations if relevant\"\"\"\n\n        try:\n            return self.ollama_client.generate(prompt, temperature=0.3)\n        except Exception as e:\n            return f\"Error suggesting improvements: {str(e)}\"\n    \n    def search_similar_code(self, code_snippet: str, language: str = None, n_results: int = 3) -> List[Dict[str, Any]]:\n        \"\"\"Find similar code in the repository.\"\"\"\n        # Create a search query from the code\n        query = f\"code similar to: {code_snippet[:200]}...\"\n        \n        filter_metadata = {}\n        if language:\n            filter_metadata['language'] = language\n        \n        return self.retrieve_context(query, n_results, filter_metadata or None)\n    \n    def get_file_summary(self, file_path: str, repo_name: str = None) -> str:\n        \"\"\"Get a summary of a specific file.\"\"\"\n        filter_metadata = {'file_path': file_path}\n        if repo_name:\n            filter_metadata['repo_name'] = repo_name\n        \n        # Get file overview chunk\n        chunks = self.vector_store.search(\n            f\"file overview {file_path}\", \n            n_results=1, \n            filter_metadata=filter_metadata\n        )\n        \n        if not chunks:\n            return f\"No information found for file: {file_path}\"\n        \n        chunk = chunks[0]\n        context_text = chunk['text']\n        \n        prompt = f\"\"\"Provide a concise summary of this file:\n\n{context_text}\n\nSummary should include:\n- Purpose of the file\n- Main components\n- Key functionality\n- Dependencies\"\"\"\n\n        try:\n            return self.ollama_client.generate(prompt, temperature=0.3)\n        except Exception as e:\n            return f\"Error generating file summary: {str(e)}\"\n    \n    def get_repository_overview(self, repo_name: str) -> str:\n        \"\"\"Get an overview of the repository.\"\"\"\n        chunks = self.vector_store.search(\n            f\"repository overview {repo_name}\",\n            n_results=1,\n            filter_metadata={'repo_name': repo_name, 'type': 'repository_overview'}\n        )\n        \n        if not chunks:\n            return f\"No overview found for repository: {repo_name}\"\n        \n        return chunks[0]['text']\n    \n    def chat_with_repo(self, messages: List[Dict[str, str]], repo_name: str = None) -> str:\n        \"\"\"Chat interface for conversational interaction with repository.\"\"\"\n        if not messages:\n            return \"No messages provided\"\n        \n        # Get the latest user message\n        latest_message = messages[-1]['content']\n        \n        # Get context for the latest query\n        result = self.query(latest_message, repo_name=repo_name, stream=False)\n        \n        # Build conversation context\n        conversation_context = \"\\n\".join([\n            f\"{msg['role']}: {msg['content']}\" \n            for msg in messages[:-1]  # Exclude the latest message\n        ])\n        \n        # Enhanced prompt with conversation history\n        prompt = f\"\"\"You are having a conversation about a codebase. Here's the conversation history:\n\n{conversation_context}\n\nCurrent context from the codebase:\n{result['context'].context_text if result['context'] else 'No relevant context found'}\n\nCurrent question: {latest_message}\n\nPlease provide a helpful response that considers both the conversation history and the current context.\"\"\"\n\n        try:\n            return self.ollama_client.generate(prompt, temperature=0.4)\n        except Exception as e:\n            return f\"Error in chat response: {str(e)}\"\n"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\README.md",
      "file_type": "documentation",
      "language": null,
      "imports": [],
      "elements": [],
      "summary": null,
      "content": "# Local DeepWiki\n\nA local implementation of DeepWiki that allows you to chat with your code repositories using Ollama and local LLMs. This system provides repository analysis, documentation generation, and conversational AI capabilities - all running locally on your machine.\n\n## Features\n\n- ðŸ” **Repository Analysis**: Automatically parse and understand code structure\n- ðŸ¤– **Local LLM Integration**: Uses Ollama for privacy-focused AI inference\n- ðŸ“š **Documentation Generation**: Create comprehensive docs from your codebase\n- ðŸ’¬ **Interactive Chat**: Ask questions about your code in natural language\n- ðŸ”Ž **Semantic Search**: Find relevant code and documentation quickly\n- ðŸŒ **Web Interface**: Clean, modern UI for easy interaction\n- ðŸ“– **RAG System**: Context-aware responses grounded in your actual code\n\n## Prerequisites\n\n1. **Python 3.8+**\n2. **Ollama** - Download from [ollama.ai](https://ollama.ai)\n3. **Git** (optional, for repository information)\n\n## Installation\n\n1. **Clone this repository:**\n```bash\ngit clone <repository-url>\ncd local_deepwiki\n```\n\n2. **Install Python dependencies:**\n```bash\npip install -r requirements.txt\n```\n\n3. **Install and start Ollama:**\n```bash\n# Install Ollama (see https://ollama.ai for platform-specific instructions)\n\n# Start Ollama server\nollama serve\n\n# Pull required models (in another terminal)\nollama pull llama2          # Main language model\nollama pull nomic-embed-text  # Embedding model (optional)\n```\n\n4. **Check prerequisites:**\n```bash\npython main.py check\n```\n\n## Quick Start\n\n### 1. Analyze a Repository\n\n```bash\n# Analyze your current directory\npython main.py analyze .\n\n# Analyze a specific repository\npython main.py analyze /path/to/your/repo --name my-project\n\n# Analyze with custom name\npython main.py analyze ~/projects/my-app --name my-awesome-app\n```\n\n### 2. Chat with Your Code\n\n```bash\n# Start interactive chat\npython main.py chat\n\n# Chat with specific repository\npython main.py chat --repo my-project\n```\n\n### 3. Query Your Repository\n\n```bash\n# Ask a specific question\npython main.py query \"How does user authentication work?\" --repo my-project\n\n# Query without specifying repository (searches all)\npython main.py query \"Show me the main entry point\"\n```\n\n### 4. Generate Documentation\n\n```bash\n# Generate comprehensive documentation\npython main.py docs my-project\n```\n\n### 5. Web Interface\n\n```bash\n# Start the web server\npython main.py server\n\n# Or with custom host/port\npython main.py server --host 127.0.0.1 --port 8080\n```\n\nThen open http://localhost:8000 in your browser.\n\n## Configuration\n\nCreate a `.env` file to customize settings:\n\n```env\n# Ollama Configuration\nOLLAMA_BASE_URL=http://localhost:11434\nOLLAMA_MODEL=llama2\nOLLAMA_EMBEDDING_MODEL=nomic-embed-text\n\n# API Configuration\nAPI_HOST=0.0.0.0\nAPI_PORT=8000\n\n# Storage Configuration\nCHROMA_PERSIST_DIRECTORY=./data/chroma_db\nREPOS_DIRECTORY=./data/repos\nDOCS_DIRECTORY=./data/generated_docs\n\n# Processing Configuration\nMAX_CHUNK_SIZE=2000\nCHUNK_OVERLAP=200\nMAX_CONTEXT_LENGTH=4000\n```\n\n## Supported Languages\n\nThe system can analyze and understand code in:\n\n- Python (.py)\n- JavaScript/TypeScript (.js, .ts, .jsx, .tsx)\n- Java (.java)\n- C/C++ (.c, .cpp, .h)\n- C# (.cs)\n- PHP (.php)\n- Ruby (.rb)\n- Go (.go)\n- Rust (.rs)\n- Swift (.swift)\n- Kotlin (.kt)\n- Scala (.scala)\n- And more...\n\nPlus documentation files:\n- Markdown (.md)\n- reStructuredText (.rst)\n- Plain text (.txt)\n\n## CLI Commands\n\n### Repository Management\n```bash\n# List analyzed repositories\npython main.py list\n\n# Show system statistics\npython main.py stats\n```\n\n### Analysis and Documentation\n```bash\n# Analyze repository\npython main.py analyze <path> [--name <name>]\n\n# Generate documentation\npython main.py docs <repo-name>\n```\n\n### Querying\n```bash\n# One-time query\npython main.py query \"<question>\" [--repo <name>]\n\n# Interactive chat\npython main.py chat [--repo <name>]\n```\n\n### Web Server\n```bash\n# Start web interface\npython main.py server [--host <host>] [--port <port>]\n```\n\n## API Endpoints\n\nWhen running the web server, these endpoints are available:\n\n### Health & System\n- `GET /health` - System health check\n- `GET /stats` - System statistics\n- `GET /models` - List available Ollama models\n\n### Repository Management\n- `POST /repositories/analyze` - Analyze repository\n- `GET /repositories` - List repositories\n- `DELETE /repositories/{name}` - Delete repository\n\n### Querying\n- `POST /query` - Query with RAG system\n- `POST /chat` - Chat interface\n- `POST /explain` - Explain code snippet\n- `POST /improve` - Suggest code improvements\n\n### Documentation\n- `POST /repositories/{name}/generate-docs` - Generate docs\n- `GET /repositories/{name}/docs` - List generated docs\n- `GET /repositories/{name}/docs/{path}` - Get specific doc\n\n### Search\n- `GET /search` - Search all repositories\n- `GET /repositories/{name}/search` - Search specific repository\n\n## How It Works\n\n1. **Repository Analysis**: The system parses your codebase, extracting:\n   - File structure and organization\n   - Functions, classes, and their relationships\n   - Import dependencies\n   - Documentation and comments\n   - Git information (if available)\n\n2. **Vector Embeddings**: Code and documentation are chunked and converted to embeddings using:\n   - Ollama embedding models (preferred)\n   - Sentence Transformers (fallback)\n   - ChromaDB for efficient storage and retrieval\n\n3. **RAG System**: When you ask questions:\n   - Your query is embedded and matched against the codebase\n   - Relevant code snippets and documentation are retrieved\n   - Context is provided to the LLM for accurate, grounded responses\n\n4. **Documentation Generation**: Using the analyzed structure:\n   - README files with project overviews\n   - API documentation for each file\n   - Architecture documentation\n   - Usage examples and tutorials\n\n## Example Queries\n\nHere are some example questions you can ask:\n\n### Code Understanding\n- \"How does user authentication work in this project?\"\n- \"What is the main entry point of the application?\"\n- \"Show me all the API endpoints\"\n- \"How is data validation handled?\"\n\n### Architecture Questions\n- \"What's the overall architecture of this system?\"\n- \"How do the different modules interact?\"\n- \"What design patterns are used?\"\n- \"What are the main dependencies?\"\n\n### Implementation Details\n- \"How is error handling implemented?\"\n- \"Where is the database connection configured?\"\n- \"How are user permissions checked?\"\n- \"What testing framework is used?\"\n\n### Documentation\n- \"Generate API documentation for the user service\"\n- \"Create a getting started guide\"\n- \"Explain the deployment process\"\n\n## Troubleshooting\n\n### Ollama Issues\n```bash\n# Check if Ollama is running\ncurl http://localhost:11434/api/tags\n\n# Pull required models\nollama pull llama2\nollama pull nomic-embed-text\n\n# Check model availability\nollama list\n```\n\n### Common Problems\n\n1. **\"Ollama server not available\"**\n   - Make sure Ollama is installed and running (`ollama serve`)\n   - Check the OLLAMA_BASE_URL in your configuration\n\n2. **\"Model not found\"**\n   - Pull the required model: `ollama pull llama2`\n   - Update OLLAMA_MODEL in configuration if using a different model\n\n3. **\"No relevant context found\"**\n   - Make sure the repository has been analyzed\n   - Try rephrasing your question\n   - Check that the repository contains relevant code\n\n4. **Slow responses**\n   - Consider using a smaller, faster model (e.g., `llama2:7b`)\n   - Reduce MAX_CONTEXT_LENGTH in configuration\n   - Use more specific queries\n\n### Performance Tips\n\n1. **Model Selection**: \n   - Use `codellama` for better code understanding\n   - Use `llama2:7b` for faster responses\n   - Use `mistral` for a good balance\n\n2. **Configuration Tuning**:\n   - Adjust MAX_CHUNK_SIZE for your hardware\n   - Reduce MAX_CONTEXT_LENGTH for faster responses\n   - Increase CHUNK_OVERLAP for better context\n\n3. **Repository Size**:\n   - Large repositories may take time to analyze\n   - Consider analyzing specific directories for faster results\n   - Use .gitignore patterns to exclude unnecessary files\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Make your changes\n4. Add tests if applicable\n5. Submit a pull request\n\n## License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## Acknowledgments\n\n- [Ollama](https://ollama.ai) for local LLM inference\n- [ChromaDB](https://www.trychroma.com/) for vector storage\n- [LangChain](https://langchain.com/) for RAG implementation\n- [FastAPI](https://fastapi.tiangolo.com/) for the web API\n- [Vue.js](https://vuejs.org/) for the web interface\n\n## Roadmap\n\n- [ ] Support for more programming languages\n- [ ] Advanced code analysis (call graphs, dependency analysis)\n- [ ] Integration with popular IDEs\n- [ ] Multi-repository projects support\n- [ ] Custom model fine-tuning\n- [ ] Collaborative features\n- [ ] Plugin system for extensibility\n"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
      "file_type": "code",
      "language": "python",
      "imports": [
        "os",
        "ast",
        "re",
        "json",
        "pathlib.Path",
        "typing.Dict",
        "typing.List",
        "typing.Any",
        "typing.Optional",
        "typing.Tuple",
        "dataclasses.dataclass",
        "dataclasses.asdict",
        "git",
        "config.settings"
      ],
      "elements": [
        {
          "name": "CodeElement",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 14,
          "line_end": 28,
          "docstring": "Represents a code element (function, class, etc.).",
          "signature": "class CodeElement",
          "content": null,
          "dependencies": []
        },
        {
          "name": "CodeElement.__post_init__",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 26,
          "line_end": 28,
          "docstring": null,
          "signature": "def __post_init__(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "FileAnalysis",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 31,
          "line_end": 45,
          "docstring": "Analysis results for a single file.",
          "signature": "class FileAnalysis",
          "content": null,
          "dependencies": []
        },
        {
          "name": "FileAnalysis.__post_init__",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 41,
          "line_end": 45,
          "docstring": null,
          "signature": "def __post_init__(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 47,
          "line_end": 348,
          "docstring": "Analyzes code repositories to extract structure and content.",
          "signature": "class RepositoryAnalyzer",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer.__init__",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 50,
          "line_end": 69,
          "docstring": null,
          "signature": "def __init__(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer.analyze_repository",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 71,
          "line_end": 132,
          "docstring": "Analyze an entire repository.",
          "signature": "def analyze_repository(self, repo_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer.analyze_file",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 134,
          "line_end": 170,
          "docstring": "Analyze a single file.",
          "signature": "def analyze_file(self, file_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer._analyze_python_file",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 172,
          "line_end": 230,
          "docstring": "Analyze Python file for structure.",
          "signature": "def _analyze_python_file(self, analysis, content)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer._analyze_js_ts_file",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 232,
          "line_end": 285,
          "docstring": "Analyze JavaScript/TypeScript file for structure.",
          "signature": "def _analyze_js_ts_file(self, analysis, content)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer._get_function_args",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 287,
          "line_end": 292,
          "docstring": "Extract function arguments as string.",
          "signature": "def _get_function_args(self, node)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer._get_files_to_analyze",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 294,
          "line_end": 307,
          "docstring": "Get list of files to analyze, respecting ignore patterns.",
          "signature": "def _get_files_to_analyze(self, repo_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer._should_ignore_dir",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 309,
          "line_end": 311,
          "docstring": "Check if directory should be ignored.",
          "signature": "def _should_ignore_dir(self, dirname)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer._should_analyze_file",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 313,
          "line_end": 316,
          "docstring": "Check if file should be analyzed.",
          "signature": "def _should_analyze_file(self, file_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer._build_directory_structure",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 318,
          "line_end": 338,
          "docstring": "Build a tree representation of the directory structure.",
          "signature": "def _build_directory_structure(self, repo_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer.save_analysis",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 340,
          "line_end": 343,
          "docstring": "Save analysis results to JSON file.",
          "signature": "def save_analysis(self, analysis, output_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "RepositoryAnalyzer.load_analysis",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 345,
          "line_end": 348,
          "docstring": "Load analysis results from JSON file.",
          "signature": "def load_analysis(self, input_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "__post_init__",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 26,
          "line_end": 28,
          "docstring": null,
          "signature": "def __post_init__(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "__post_init__",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 41,
          "line_end": 45,
          "docstring": null,
          "signature": "def __post_init__(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "__init__",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 50,
          "line_end": 69,
          "docstring": null,
          "signature": "def __init__(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "analyze_repository",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 71,
          "line_end": 132,
          "docstring": "Analyze an entire repository.",
          "signature": "def analyze_repository(self, repo_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "analyze_file",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 134,
          "line_end": 170,
          "docstring": "Analyze a single file.",
          "signature": "def analyze_file(self, file_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "_analyze_python_file",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 172,
          "line_end": 230,
          "docstring": "Analyze Python file for structure.",
          "signature": "def _analyze_python_file(self, analysis, content)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "_analyze_js_ts_file",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 232,
          "line_end": 285,
          "docstring": "Analyze JavaScript/TypeScript file for structure.",
          "signature": "def _analyze_js_ts_file(self, analysis, content)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "_get_function_args",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 287,
          "line_end": 292,
          "docstring": "Extract function arguments as string.",
          "signature": "def _get_function_args(self, node)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "_get_files_to_analyze",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 294,
          "line_end": 307,
          "docstring": "Get list of files to analyze, respecting ignore patterns.",
          "signature": "def _get_files_to_analyze(self, repo_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "_should_ignore_dir",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 309,
          "line_end": 311,
          "docstring": "Check if directory should be ignored.",
          "signature": "def _should_ignore_dir(self, dirname)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "_should_analyze_file",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 313,
          "line_end": 316,
          "docstring": "Check if file should be analyzed.",
          "signature": "def _should_analyze_file(self, file_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "_build_directory_structure",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 318,
          "line_end": 338,
          "docstring": "Build a tree representation of the directory structure.",
          "signature": "def _build_directory_structure(self, repo_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "save_analysis",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 340,
          "line_end": 343,
          "docstring": "Save analysis results to JSON file.",
          "signature": "def save_analysis(self, analysis, output_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "load_analysis",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 345,
          "line_end": 348,
          "docstring": "Load analysis results from JSON file.",
          "signature": "def load_analysis(self, input_path)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "build_tree",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\repository_analyzer.py",
          "line_start": 320,
          "line_end": 336,
          "docstring": null,
          "signature": "def build_tree(path)",
          "content": null,
          "dependencies": []
        }
      ],
      "summary": null,
      "content": "\"\"\"Repository analysis module for extracting code structure and content.\"\"\"\n\nimport os\nimport ast\nimport re\nimport json\nfrom pathlib import Path\nfrom typing import Dict, List, Any, Optional, Tuple\nfrom dataclasses import dataclass, asdict\nimport git\nfrom config import settings\n\n@dataclass\nclass CodeElement:\n    \"\"\"Represents a code element (function, class, etc.).\"\"\"\n    name: str\n    type: str  # 'function', 'class', 'method', 'variable'\n    file_path: str\n    line_start: int\n    line_end: int\n    docstring: Optional[str] = None\n    signature: Optional[str] = None\n    content: Optional[str] = None\n    dependencies: List[str] = None\n    \n    def __post_init__(self):\n        if self.dependencies is None:\n            self.dependencies = []\n\n@dataclass\nclass FileAnalysis:\n    \"\"\"Analysis results for a single file.\"\"\"\n    file_path: str\n    file_type: str  # 'code', 'documentation', 'config'\n    language: Optional[str] = None\n    imports: List[str] = None\n    elements: List[CodeElement] = None\n    summary: Optional[str] = None\n    content: Optional[str] = None\n    \n    def __post_init__(self):\n        if self.imports is None:\n            self.imports = []\n        if self.elements is None:\n            self.elements = []\n\nclass RepositoryAnalyzer:\n    \"\"\"Analyzes code repositories to extract structure and content.\"\"\"\n    \n    def __init__(self):\n        self.supported_languages = {\n            '.py': 'python',\n            '.js': 'javascript', \n            '.ts': 'typescript',\n            '.jsx': 'javascript',\n            '.tsx': 'typescript',\n            '.java': 'java',\n            '.cpp': 'cpp',\n            '.c': 'c',\n            '.h': 'c',\n            '.cs': 'csharp',\n            '.php': 'php',\n            '.rb': 'ruby',\n            '.go': 'go',\n            '.rs': 'rust',\n            '.swift': 'swift',\n            '.kt': 'kotlin',\n            '.scala': 'scala'\n        }\n    \n    def analyze_repository(self, repo_path: str) -> Dict[str, Any]:\n        \"\"\"Analyze an entire repository.\"\"\"\n        repo_path = Path(repo_path)\n        \n        if not repo_path.exists():\n            raise ValueError(f\"Repository path does not exist: {repo_path}\")\n        \n        analysis = {\n            'repo_path': str(repo_path),\n            'repo_name': repo_path.name,\n            'files': [],\n            'structure': {},\n            'statistics': {\n                'total_files': 0,\n                'code_files': 0,\n                'doc_files': 0,\n                'languages': {},\n                'total_lines': 0\n            }\n        }\n        \n        # Get git info if available\n        try:\n            repo = git.Repo(repo_path)\n            analysis['git_info'] = {\n                'remote_url': repo.remotes.origin.url if repo.remotes else None,\n                'current_branch': repo.active_branch.name,\n                'last_commit': {\n                    'hash': repo.head.commit.hexsha[:8],\n                    'message': repo.head.commit.message.strip(),\n                    'author': str(repo.head.commit.author),\n                    'date': repo.head.commit.committed_datetime.isoformat()\n                }\n            }\n        except:\n            analysis['git_info'] = None\n        \n        # Analyze files\n        for file_path in self._get_files_to_analyze(repo_path):\n            file_analysis = self.analyze_file(file_path)\n            if file_analysis:\n                analysis['files'].append(asdict(file_analysis))\n                \n                # Update statistics\n                analysis['statistics']['total_files'] += 1\n                if file_analysis.file_type == 'code':\n                    analysis['statistics']['code_files'] += 1\n                    if file_analysis.language:\n                        lang = file_analysis.language\n                        analysis['statistics']['languages'][lang] = \\\n                            analysis['statistics']['languages'].get(lang, 0) + 1\n                elif file_analysis.file_type == 'documentation':\n                    analysis['statistics']['doc_files'] += 1\n                \n                # Count lines\n                if file_analysis.content:\n                    analysis['statistics']['total_lines'] += len(file_analysis.content.split('\\n'))\n        \n        # Build directory structure\n        analysis['structure'] = self._build_directory_structure(repo_path)\n        \n        return analysis\n    \n    def analyze_file(self, file_path: Path) -> Optional[FileAnalysis]:\n        \"\"\"Analyze a single file.\"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                content = f.read()\n        except Exception as e:\n            print(f\"Error reading file {file_path}: {e}\")\n            return None\n        \n        file_ext = file_path.suffix.lower()\n        relative_path = str(file_path)\n        \n        # Determine file type and language\n        if file_ext in settings.CODE_EXTENSIONS:\n            file_type = 'code'\n            language = self.supported_languages.get(file_ext)\n        elif file_ext in settings.DOC_EXTENSIONS:\n            file_type = 'documentation'\n            language = None\n        else:\n            file_type = 'config'\n            language = None\n        \n        analysis = FileAnalysis(\n            file_path=relative_path,\n            file_type=file_type,\n            language=language,\n            content=content\n        )\n        \n        # Language-specific analysis\n        if language == 'python':\n            self._analyze_python_file(analysis, content)\n        elif language in ['javascript', 'typescript']:\n            self._analyze_js_ts_file(analysis, content)\n        \n        return analysis\n    \n    def _analyze_python_file(self, analysis: FileAnalysis, content: str):\n        \"\"\"Analyze Python file for structure.\"\"\"\n        try:\n            tree = ast.parse(content)\n            \n            # Extract imports\n            for node in ast.walk(tree):\n                if isinstance(node, ast.Import):\n                    for alias in node.names:\n                        analysis.imports.append(alias.name)\n                elif isinstance(node, ast.ImportFrom):\n                    module = node.module or ''\n                    for alias in node.names:\n                        analysis.imports.append(f\"{module}.{alias.name}\")\n            \n            # Extract classes and functions\n            for node in ast.walk(tree):\n                if isinstance(node, ast.ClassDef):\n                    element = CodeElement(\n                        name=node.name,\n                        type='class',\n                        file_path=analysis.file_path,\n                        line_start=node.lineno,\n                        line_end=getattr(node, 'end_lineno', node.lineno),\n                        docstring=ast.get_docstring(node),\n                        signature=f\"class {node.name}\"\n                    )\n                    analysis.elements.append(element)\n                    \n                    # Extract methods\n                    for item in node.body:\n                        if isinstance(item, ast.FunctionDef):\n                            method = CodeElement(\n                                name=f\"{node.name}.{item.name}\",\n                                type='method',\n                                file_path=analysis.file_path,\n                                line_start=item.lineno,\n                                line_end=getattr(item, 'end_lineno', item.lineno),\n                                docstring=ast.get_docstring(item),\n                                signature=f\"def {item.name}({self._get_function_args(item)})\"\n                            )\n                            analysis.elements.append(method)\n                \n                elif isinstance(node, ast.FunctionDef):\n                    # Only top-level functions (not methods)\n                    if isinstance(getattr(node, 'parent', None), ast.Module) or not hasattr(node, 'parent'):\n                        element = CodeElement(\n                            name=node.name,\n                            type='function',\n                            file_path=analysis.file_path,\n                            line_start=node.lineno,\n                            line_end=getattr(node, 'end_lineno', node.lineno),\n                            docstring=ast.get_docstring(node),\n                            signature=f\"def {node.name}({self._get_function_args(node)})\"\n                        )\n                        analysis.elements.append(element)\n                        \n        except SyntaxError as e:\n            print(f\"Syntax error in {analysis.file_path}: {e}\")\n    \n    def _analyze_js_ts_file(self, analysis: FileAnalysis, content: str):\n        \"\"\"Analyze JavaScript/TypeScript file for structure.\"\"\"\n        lines = content.split('\\n')\n        \n        # Extract imports (simple regex-based approach)\n        import_patterns = [\n            r'import\\s+.*?\\s+from\\s+[\\'\"]([^\\'\"]+)[\\'\"]',\n            r'const\\s+.*?\\s*=\\s*require\\([\\'\"]([^\\'\"]+)[\\'\"]\\)',\n            r'import\\s*\\(\\s*[\\'\"]([^\\'\"]+)[\\'\"]\\s*\\)'\n        ]\n        \n        for line in lines:\n            for pattern in import_patterns:\n                matches = re.findall(pattern, line)\n                analysis.imports.extend(matches)\n        \n        # Extract functions and classes (basic regex patterns)\n        function_patterns = [\n            r'function\\s+(\\w+)\\s*\\(',\n            r'const\\s+(\\w+)\\s*=\\s*\\(',\n            r'(\\w+)\\s*:\\s*function\\s*\\(',\n            r'(\\w+)\\s*\\([^)]*\\)\\s*=>',\n            r'async\\s+function\\s+(\\w+)\\s*\\('\n        ]\n        \n        class_pattern = r'class\\s+(\\w+)'\n        \n        for i, line in enumerate(lines, 1):\n            # Find classes\n            class_match = re.search(class_pattern, line)\n            if class_match:\n                element = CodeElement(\n                    name=class_match.group(1),\n                    type='class',\n                    file_path=analysis.file_path,\n                    line_start=i,\n                    line_end=i,  # We'd need more sophisticated parsing to find end\n                    signature=line.strip()\n                )\n                analysis.elements.append(element)\n            \n            # Find functions\n            for pattern in function_patterns:\n                func_match = re.search(pattern, line)\n                if func_match:\n                    element = CodeElement(\n                        name=func_match.group(1),\n                        type='function',\n                        file_path=analysis.file_path,\n                        line_start=i,\n                        line_end=i,\n                        signature=line.strip()\n                    )\n                    analysis.elements.append(element)\n    \n    def _get_function_args(self, node: ast.FunctionDef) -> str:\n        \"\"\"Extract function arguments as string.\"\"\"\n        args = []\n        for arg in node.args.args:\n            args.append(arg.arg)\n        return ', '.join(args)\n    \n    def _get_files_to_analyze(self, repo_path: Path) -> List[Path]:\n        \"\"\"Get list of files to analyze, respecting ignore patterns.\"\"\"\n        files = []\n        \n        for root, dirs, filenames in os.walk(repo_path):\n            # Remove ignored directories\n            dirs[:] = [d for d in dirs if not self._should_ignore_dir(d)]\n            \n            for filename in filenames:\n                file_path = Path(root) / filename\n                if self._should_analyze_file(file_path):\n                    files.append(file_path)\n        \n        return files\n    \n    def _should_ignore_dir(self, dirname: str) -> bool:\n        \"\"\"Check if directory should be ignored.\"\"\"\n        return dirname in settings.IGNORED_DIRS or dirname.startswith('.')\n    \n    def _should_analyze_file(self, file_path: Path) -> bool:\n        \"\"\"Check if file should be analyzed.\"\"\"\n        ext = file_path.suffix.lower()\n        return ext in settings.CODE_EXTENSIONS or ext in settings.DOC_EXTENSIONS\n    \n    def _build_directory_structure(self, repo_path: Path) -> Dict[str, Any]:\n        \"\"\"Build a tree representation of the directory structure.\"\"\"\n        def build_tree(path: Path) -> Dict[str, Any]:\n            tree = {'name': path.name, 'type': 'directory', 'children': []}\n            \n            try:\n                for item in sorted(path.iterdir()):\n                    if item.is_dir() and not self._should_ignore_dir(item.name):\n                        tree['children'].append(build_tree(item))\n                    elif item.is_file() and self._should_analyze_file(item):\n                        tree['children'].append({\n                            'name': item.name,\n                            'type': 'file',\n                            'path': str(item.relative_to(repo_path))\n                        })\n            except PermissionError:\n                pass\n            \n            return tree\n        \n        return build_tree(repo_path)\n\n    def save_analysis(self, analysis: Dict[str, Any], output_path: str):\n        \"\"\"Save analysis results to JSON file.\"\"\"\n        with open(output_path, 'w', encoding='utf-8') as f:\n            json.dump(analysis, f, indent=2, ensure_ascii=False)\n    \n    def load_analysis(self, input_path: str) -> Dict[str, Any]:\n        \"\"\"Load analysis results from JSON file.\"\"\"\n        with open(input_path, 'r', encoding='utf-8') as f:\n            return json.load(f)\n"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\requirements.txt",
      "file_type": "documentation",
      "language": null,
      "imports": [],
      "elements": [],
      "summary": null,
      "content": "ollama>=0.2.0\nlangchain>=0.1.0\nlangchain-community>=0.0.20\nchromadb>=0.4.0\nsentence-transformers>=2.2.2\nfastapi>=0.104.0\nuvicorn>=0.24.0\npydantic>=2.5.0\npython-multipart>=0.0.6\ngitpython>=3.1.40\npathspec>=0.12.0\ntiktoken>=0.5.0\njinja2>=3.1.0\nmarkdown>=3.5.0\nbeautifulsoup4>=4.12.0\ntree-sitter>=0.20.0\ntree-sitter-python>=0.20.0\ntree-sitter-javascript>=0.20.0\ntree-sitter-typescript>=0.20.0\naiofiles>=23.2.0\nwatchdog>=3.0.0\n"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
      "file_type": "code",
      "language": "python",
      "imports": [
        "os",
        "hashlib",
        "json",
        "pathlib.Path",
        "typing.List",
        "typing.Dict",
        "typing.Any",
        "typing.Optional",
        "typing.Tuple",
        "chromadb",
        "chromadb.config.Settings",
        "sentence_transformers.SentenceTransformer",
        "tiktoken",
        "config.settings",
        "ollama_client.OllamaClient"
      ],
      "elements": [
        {
          "name": "TextChunker",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 15,
          "line_end": 188,
          "docstring": "Utility class for chunking text into manageable pieces.",
          "signature": "class TextChunker",
          "content": null,
          "dependencies": []
        },
        {
          "name": "TextChunker.__init__",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 18,
          "line_end": 26,
          "docstring": null,
          "signature": "def __init__(self, max_chunk_size, overlap)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "TextChunker.count_tokens",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 28,
          "line_end": 34,
          "docstring": "Count tokens in text.",
          "signature": "def count_tokens(self, text)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "TextChunker.chunk_text",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 36,
          "line_end": 113,
          "docstring": "Split text into chunks with metadata.",
          "signature": "def chunk_text(self, text, metadata)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "TextChunker.chunk_code_file",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 115,
          "line_end": 188,
          "docstring": "Chunk code file based on structure.",
          "signature": "def chunk_code_file(self, content, file_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "VectorStore",
          "type": "class",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 190,
          "line_end": 411,
          "docstring": "Vector store for embeddings using ChromaDB and local embeddings.",
          "signature": "class VectorStore",
          "content": null,
          "dependencies": []
        },
        {
          "name": "VectorStore.__init__",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 193,
          "line_end": 219,
          "docstring": null,
          "signature": "def __init__(self, persist_directory, collection_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "VectorStore.get_embedding",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 221,
          "line_end": 238,
          "docstring": "Get embedding for text using available models.",
          "signature": "def get_embedding(self, text)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "VectorStore.add_repository",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 240,
          "line_end": 270,
          "docstring": "Add entire repository to vector store.",
          "signature": "def add_repository(self, repo_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "VectorStore.add_file_analysis",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 272,
          "line_end": 295,
          "docstring": "Add file analysis to vector store.",
          "signature": "def add_file_analysis(self, file_analysis, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "VectorStore.add_document",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 297,
          "line_end": 300,
          "docstring": "Add a single document to vector store.",
          "signature": "def add_document(self, text, metadata)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "VectorStore.add_chunks",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 302,
          "line_end": 348,
          "docstring": "Add multiple chunks to vector store.",
          "signature": "def add_chunks(self, chunks)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "VectorStore.search",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 350,
          "line_end": 379,
          "docstring": "Search vector store for relevant documents.",
          "signature": "def search(self, query, n_results, filter_metadata)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "VectorStore.get_collection_stats",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 381,
          "line_end": 391,
          "docstring": "Get statistics about the collection.",
          "signature": "def get_collection_stats(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "VectorStore.clear_collection",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 393,
          "line_end": 400,
          "docstring": "Clear all documents from collection.",
          "signature": "def clear_collection(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "VectorStore.delete_repository",
          "type": "method",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 402,
          "line_end": 411,
          "docstring": "Delete all documents from a specific repository.",
          "signature": "def delete_repository(self, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "__init__",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 18,
          "line_end": 26,
          "docstring": null,
          "signature": "def __init__(self, max_chunk_size, overlap)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "count_tokens",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 28,
          "line_end": 34,
          "docstring": "Count tokens in text.",
          "signature": "def count_tokens(self, text)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "chunk_text",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 36,
          "line_end": 113,
          "docstring": "Split text into chunks with metadata.",
          "signature": "def chunk_text(self, text, metadata)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "chunk_code_file",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 115,
          "line_end": 188,
          "docstring": "Chunk code file based on structure.",
          "signature": "def chunk_code_file(self, content, file_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "__init__",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 193,
          "line_end": 219,
          "docstring": null,
          "signature": "def __init__(self, persist_directory, collection_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "get_embedding",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 221,
          "line_end": 238,
          "docstring": "Get embedding for text using available models.",
          "signature": "def get_embedding(self, text)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "add_repository",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 240,
          "line_end": 270,
          "docstring": "Add entire repository to vector store.",
          "signature": "def add_repository(self, repo_analysis)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "add_file_analysis",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 272,
          "line_end": 295,
          "docstring": "Add file analysis to vector store.",
          "signature": "def add_file_analysis(self, file_analysis, repo_name)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "add_document",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 297,
          "line_end": 300,
          "docstring": "Add a single document to vector store.",
          "signature": "def add_document(self, text, metadata)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "add_chunks",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 302,
          "line_end": 348,
          "docstring": "Add multiple chunks to vector store.",
          "signature": "def add_chunks(self, chunks)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "search",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 350,
          "line_end": 379,
          "docstring": "Search vector store for relevant documents.",
          "signature": "def search(self, query, n_results, filter_metadata)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "get_collection_stats",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 381,
          "line_end": 391,
          "docstring": "Get statistics about the collection.",
          "signature": "def get_collection_stats(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "clear_collection",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 393,
          "line_end": 400,
          "docstring": "Clear all documents from collection.",
          "signature": "def clear_collection(self)",
          "content": null,
          "dependencies": []
        },
        {
          "name": "delete_repository",
          "type": "function",
          "file_path": "C:\\Users\\chuba\\wikillm\\vector_store.py",
          "line_start": 402,
          "line_end": 411,
          "docstring": "Delete all documents from a specific repository.",
          "signature": "def delete_repository(self, repo_name)",
          "content": null,
          "dependencies": []
        }
      ],
      "summary": null,
      "content": "\"\"\"Vector embedding and storage system using ChromaDB.\"\"\"\n\nimport os\nimport hashlib\nimport json\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional, Tuple\nimport chromadb\nfrom chromadb.config import Settings\nfrom sentence_transformers import SentenceTransformer\nimport tiktoken\nfrom config import settings\nfrom ollama_client import OllamaClient\n\nclass TextChunker:\n    \"\"\"Utility class for chunking text into manageable pieces.\"\"\"\n    \n    def __init__(self, max_chunk_size: int = None, overlap: int = None):\n        self.max_chunk_size = max_chunk_size or settings.MAX_CHUNK_SIZE\n        self.overlap = overlap or settings.CHUNK_OVERLAP\n        \n        # Initialize tokenizer for accurate token counting\n        try:\n            self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n        except:\n            self.tokenizer = None\n    \n    def count_tokens(self, text: str) -> int:\n        \"\"\"Count tokens in text.\"\"\"\n        if self.tokenizer:\n            return len(self.tokenizer.encode(text))\n        else:\n            # Rough approximation: 1 token â‰ˆ 4 characters\n            return len(text) // 4\n    \n    def chunk_text(self, text: str, metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\n        \"\"\"Split text into chunks with metadata.\"\"\"\n        if metadata is None:\n            metadata = {}\n        \n        chunks = []\n        \n        # Split by paragraphs first\n        paragraphs = text.split('\\n\\n')\n        current_chunk = \"\"\n        current_tokens = 0\n        \n        for para in paragraphs:\n            para_tokens = self.count_tokens(para)\n            \n            # If single paragraph exceeds max size, split it further\n            if para_tokens > self.max_chunk_size:\n                # Save current chunk if not empty\n                if current_chunk.strip():\n                    chunks.append({\n                        'text': current_chunk.strip(),\n                        'tokens': current_tokens,\n                        **metadata\n                    })\n                    current_chunk = \"\"\n                    current_tokens = 0\n                \n                # Split large paragraph by sentences\n                sentences = para.split('. ')\n                for sentence in sentences:\n                    sentence_tokens = self.count_tokens(sentence)\n                    \n                    if current_tokens + sentence_tokens > self.max_chunk_size:\n                        if current_chunk.strip():\n                            chunks.append({\n                                'text': current_chunk.strip(),\n                                'tokens': current_tokens,\n                                **metadata\n                            })\n                        current_chunk = sentence\n                        current_tokens = sentence_tokens\n                    else:\n                        current_chunk += (\". \" if current_chunk else \"\") + sentence\n                        current_tokens += sentence_tokens\n            \n            # Normal paragraph processing\n            elif current_tokens + para_tokens > self.max_chunk_size:\n                # Save current chunk\n                if current_chunk.strip():\n                    chunks.append({\n                        'text': current_chunk.strip(),\n                        'tokens': current_tokens,\n                        **metadata\n                    })\n                \n                # Start new chunk with overlap\n                if self.overlap > 0 and chunks:\n                    # Get last few words for overlap\n                    last_chunk_words = current_chunk.split()\n                    overlap_words = last_chunk_words[-self.overlap:] if len(last_chunk_words) > self.overlap else last_chunk_words\n                    current_chunk = \" \".join(overlap_words) + \"\\n\\n\" + para\n                else:\n                    current_chunk = para\n                \n                current_tokens = self.count_tokens(current_chunk)\n            else:\n                current_chunk += (\"\\n\\n\" if current_chunk else \"\") + para\n                current_tokens += para_tokens\n        \n        # Add final chunk\n        if current_chunk.strip():\n            chunks.append({\n                'text': current_chunk.strip(),\n                'tokens': current_tokens,\n                **metadata\n            })\n        \n        return chunks\n    \n    def chunk_code_file(self, content: str, file_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Chunk code file based on structure.\"\"\"\n        chunks = []\n        \n        # Create chunk for file overview\n        overview_text = f\"File: {file_analysis['file_path']}\\n\"\n        overview_text += f\"Language: {file_analysis.get('language', 'Unknown')}\\n\"\n        \n        if file_analysis.get('imports'):\n            overview_text += f\"Imports: {', '.join(file_analysis['imports'])}\\n\"\n        \n        # Add summary of elements\n        elements = file_analysis.get('elements', [])\n        if elements:\n            overview_text += \"\\nCode Elements:\\n\"\n            for element in elements:\n                overview_text += f\"- {element['type']}: {element['name']}\\n\"\n                if element.get('docstring'):\n                    overview_text += f\"  {element['docstring'][:100]}...\\n\"\n        \n        chunks.append({\n            'text': overview_text,\n            'type': 'file_overview',\n            'file_path': file_analysis['file_path'],\n            'language': file_analysis.get('language'),\n            'source': 'code_analysis'\n        })\n        \n        # Create chunks for individual code elements\n        lines = content.split('\\n')\n        for element in elements:\n            start_line = element.get('line_start', 1) - 1  # Convert to 0-based\n            end_line = element.get('line_end', len(lines))\n            \n            if start_line < len(lines):\n                element_content = '\\n'.join(lines[start_line:min(end_line, len(lines))])\n                \n                element_text = f\"Element: {element['name']} ({element['type']})\\n\"\n                element_text += f\"File: {file_analysis['file_path']}\\n\"\n                \n                if element.get('signature'):\n                    element_text += f\"Signature: {element['signature']}\\n\"\n                \n                if element.get('docstring'):\n                    element_text += f\"Documentation: {element['docstring']}\\n\"\n                \n                element_text += f\"\\nCode:\\n```{file_analysis.get('language', '')}\\n{element_content}\\n```\"\n                \n                chunks.append({\n                    'text': element_text,\n                    'type': 'code_element',\n                    'element_type': element['type'],\n                    'element_name': element['name'],\n                    'file_path': file_analysis['file_path'],\n                    'language': file_analysis.get('language'),\n                    'line_start': element.get('line_start'),\n                    'line_end': element.get('line_end'),\n                    'source': 'code_analysis'\n                })\n        \n        # If no elements found, chunk the entire file content\n        if not elements and content.strip():\n            file_chunks = self.chunk_text(\n                content, \n                {\n                    'type': 'file_content',\n                    'file_path': file_analysis['file_path'],\n                    'language': file_analysis.get('language'),\n                    'source': 'file_content'\n                }\n            )\n            chunks.extend(file_chunks)\n        \n        return chunks\n\nclass VectorStore:\n    \"\"\"Vector store for embeddings using ChromaDB and local embeddings.\"\"\"\n    \n    def __init__(self, persist_directory: str = None, collection_name: str = None):\n        self.persist_directory = persist_directory or settings.CHROMA_PERSIST_DIRECTORY\n        self.collection_name = collection_name or settings.COLLECTION_NAME\n        \n        # Initialize ChromaDB\n        self.client = chromadb.PersistentClient(\n            path=self.persist_directory,\n            settings=Settings(anonymized_telemetry=False)\n        )\n        \n        # Get or create collection\n        try:\n            self.collection = self.client.get_collection(name=self.collection_name)\n        except:\n            self.collection = self.client.create_collection(name=self.collection_name)\n        \n        # Initialize embedding models\n        self.ollama_client = OllamaClient()\n        \n        # Fallback to sentence transformers if Ollama embeddings fail\n        try:\n            self.sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')\n        except:\n            print(\"Warning: Could not load sentence transformer model\")\n            self.sentence_transformer = None\n        \n        self.chunker = TextChunker()\n    \n    def get_embedding(self, text: str) -> List[float]:\n        \"\"\"Get embedding for text using available models.\"\"\"\n        # Try Ollama first\n        if self.ollama_client.is_available():\n            try:\n                return self.ollama_client.get_embeddings(text)\n            except Exception as e:\n                print(f\"Ollama embedding failed: {e}\")\n        \n        # Fallback to sentence transformer\n        if self.sentence_transformer:\n            try:\n                embedding = self.sentence_transformer.encode(text)\n                return embedding.tolist()\n            except Exception as e:\n                print(f\"Sentence transformer embedding failed: {e}\")\n        \n        raise Exception(\"No embedding model available\")\n    \n    def add_repository(self, repo_analysis: Dict[str, Any]) -> int:\n        \"\"\"Add entire repository to vector store.\"\"\"\n        repo_name = repo_analysis.get('repo_name', 'unknown')\n        total_chunks = 0\n        \n        # Add repository overview\n        if repo_analysis.get('files'):\n            overview_text = f\"Repository: {repo_name}\\n\"\n            overview_text += f\"Total files: {repo_analysis['statistics']['total_files']}\\n\"\n            overview_text += f\"Languages: {', '.join(repo_analysis['statistics']['languages'].keys())}\\n\"\n            \n            # Add file list\n            overview_text += \"\\nFiles:\\n\"\n            for file_data in repo_analysis['files'][:20]:  # Limit to first 20 files\n                overview_text += f\"- {file_data['file_path']}\\n\"\n            \n            total_chunks += self.add_document(\n                overview_text,\n                {\n                    'type': 'repository_overview',\n                    'repo_name': repo_name,\n                    'source': 'repository_analysis'\n                }\n            )\n        \n        # Add individual files\n        for file_data in repo_analysis.get('files', []):\n            file_chunks = self.add_file_analysis(file_data, repo_name)\n            total_chunks += file_chunks\n        \n        return total_chunks\n    \n    def add_file_analysis(self, file_analysis: Dict[str, Any], repo_name: str = None) -> int:\n        \"\"\"Add file analysis to vector store.\"\"\"\n        if file_analysis.get('file_type') == 'code':\n            chunks = self.chunker.chunk_code_file(\n                file_analysis.get('content', ''), \n                file_analysis\n            )\n        else:\n            # Regular text chunking for documentation files\n            chunks = self.chunker.chunk_text(\n                file_analysis.get('content', ''),\n                {\n                    'type': 'documentation',\n                    'file_path': file_analysis['file_path'],\n                    'source': 'file_content'\n                }\n            )\n        \n        # Add repository name to all chunks\n        for chunk in chunks:\n            if repo_name:\n                chunk['repo_name'] = repo_name\n        \n        return self.add_chunks(chunks)\n    \n    def add_document(self, text: str, metadata: Dict[str, Any]) -> int:\n        \"\"\"Add a single document to vector store.\"\"\"\n        chunks = self.chunker.chunk_text(text, metadata)\n        return self.add_chunks(chunks)\n    \n    def add_chunks(self, chunks: List[Dict[str, Any]]) -> int:\n        \"\"\"Add multiple chunks to vector store.\"\"\"\n        if not chunks:\n            return 0\n        \n        documents = []\n        metadatas = []\n        ids = []\n        embeddings = []\n        \n        for i, chunk in enumerate(chunks):\n            text = chunk['text']\n            \n            # Create unique ID\n            chunk_id = hashlib.md5(text.encode()).hexdigest()\n            \n            # Prepare metadata (remove 'text' key)\n            metadata = {k: v for k, v in chunk.items() if k != 'text'}\n            \n            try:\n                # Get embedding\n                embedding = self.get_embedding(text)\n                \n                documents.append(text)\n                metadatas.append(metadata)\n                ids.append(chunk_id)\n                embeddings.append(embedding)\n                \n            except Exception as e:\n                print(f\"Error processing chunk {i}: {e}\")\n                continue\n        \n        if documents:\n            try:\n                self.collection.add(\n                    documents=documents,\n                    metadatas=metadatas,\n                    ids=ids,\n                    embeddings=embeddings\n                )\n                print(f\"Added {len(documents)} chunks to vector store\")\n                return len(documents)\n            except Exception as e:\n                print(f\"Error adding to vector store: {e}\")\n                return 0\n        \n        return 0\n    \n    def search(self, query: str, n_results: int = 5, filter_metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\n        \"\"\"Search vector store for relevant documents.\"\"\"\n        try:\n            query_embedding = self.get_embedding(query)\n            \n            search_kwargs = {\n                'query_embeddings': [query_embedding],\n                'n_results': n_results\n            }\n            \n            if filter_metadata:\n                search_kwargs['where'] = filter_metadata\n            \n            results = self.collection.query(**search_kwargs)\n            \n            # Format results\n            formatted_results = []\n            for i in range(len(results['documents'][0])):\n                formatted_results.append({\n                    'text': results['documents'][0][i],\n                    'metadata': results['metadatas'][0][i],\n                    'distance': results['distances'][0][i],\n                    'id': results['ids'][0][i]\n                })\n            \n            return formatted_results\n            \n        except Exception as e:\n            print(f\"Error searching vector store: {e}\")\n            return []\n    \n    def get_collection_stats(self) -> Dict[str, Any]:\n        \"\"\"Get statistics about the collection.\"\"\"\n        try:\n            count = self.collection.count()\n            return {\n                'total_documents': count,\n                'collection_name': self.collection_name\n            }\n        except Exception as e:\n            print(f\"Error getting collection stats: {e}\")\n            return {'total_documents': 0, 'collection_name': self.collection_name}\n    \n    def clear_collection(self):\n        \"\"\"Clear all documents from collection.\"\"\"\n        try:\n            self.client.delete_collection(name=self.collection_name)\n            self.collection = self.client.create_collection(name=self.collection_name)\n            print(\"Collection cleared successfully\")\n        except Exception as e:\n            print(f\"Error clearing collection: {e}\")\n    \n    def delete_repository(self, repo_name: str):\n        \"\"\"Delete all documents from a specific repository.\"\"\"\n        try:\n            # Get all documents with repo_name\n            results = self.collection.get(where={\"repo_name\": repo_name})\n            if results['ids']:\n                self.collection.delete(ids=results['ids'])\n                print(f\"Deleted {len(results['ids'])} documents for repository {repo_name}\")\n        except Exception as e:\n            print(f\"Error deleting repository {repo_name}: {e}\")\n"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\data\\repos\\wikillm_analysis.json",
      "file_type": "code",
      "language": null,
      "imports": [],
      "elements": [],
      "summary": null,
      "content": "{\n  \"repo_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\",\n  \"repo_name\": \"wikillm\",\n  \"files\": [\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\api.py\",\n      \"file_type\": \"code\",\n      \"language\": \"python\",\n      \"imports\": [\n        \"asyncio\",\n        \"json\",\n        \"traceback\",\n        \"pathlib.Path\",\n        \"typing.Dict\",\n        \"typing.List\",\n        \"typing.Any\",\n        \"typing.Optional\",\n        \"fastapi.FastAPI\",\n        \"fastapi.HTTPException\",\n        \"fastapi.BackgroundTasks\",\n        \"fastapi.UploadFile\",\n        \"fastapi.File\",\n        \"fastapi.middleware.cors.CORSMiddleware\",\n        \"fastapi.responses.StreamingResponse\",\n        \"fastapi.responses.JSONResponse\",\n        \"fastapi.staticfiles.StaticFiles\",\n        \"pydantic.BaseModel\",\n        \"uvicorn\",\n        \"config.settings\",\n        \"repository_analyzer.RepositoryAnalyzer\",\n        \"ollama_client.OllamaClient\",\n        \"vector_store.VectorStore\",\n        \"rag_system.RAGSystem\",\n        \"documentation_generator.DocumentationBuilder\",\n        \"documentation_generator.DocumentationConfig\"\n      ],\n      \"elements\": [\n        {\n          \"name\": \"QueryRequest\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\api.py\",\n          \"line_start\": 23,\n          \"line_end\": 27,\n          \"docstring\": null,\n          \"signature\": \"class QueryRequest\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"ChatMessage\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\api.py\",\n          \"line_start\": 29,\n          \"line_end\": 31,\n          \"docstring\": null,\n          \"signature\": \"class ChatMessage\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"ChatRequest\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\api.py\",\n          \"line_start\": 33,\n          \"line_end\": 35,\n          \"docstring\": null,\n          \"signature\": \"class ChatRequest\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryRequest\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\api.py\",\n          \"line_start\": 37,\n          \"line_end\": 39,\n          \"docstring\": null,\n          \"signature\": \"class RepositoryRequest\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"ExplainCodeRequest\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\api.py\",\n          \"line_start\": 41,\n          \"line_end\": 44,\n          \"docstring\": null,\n          \"signature\": \"class ExplainCodeRequest\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationRequest\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\api.py\",\n          \"line_start\": 46,\n          \"line_end\": 51,\n          \"docstring\": null,\n          \"signature\": \"class DocumentationRequest\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"main\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\api.py\",\n          \"line_start\": 422,\n          \"line_end\": 438,\n          \"docstring\": \"Main function to run the API server.\",\n          \"signature\": \"def main()\",\n          \"content\": null,\n          \"dependencies\": []\n        }\n      ],\n      \"summary\": null,\n      \"content\": \"\\\"\\\"\\\"FastAPI server for Local DeepWiki.\\\"\\\"\\\"\\n\\nimport asyncio\\nimport json\\nimport traceback\\nfrom pathlib import Path\\nfrom typing import Dict, List, Any, Optional\\nfrom fastapi import FastAPI, HTTPException, BackgroundTasks, UploadFile, File\\nfrom fastapi.middleware.cors import CORSMiddleware\\nfrom fastapi.responses import StreamingResponse, JSONResponse\\nfrom fastapi.staticfiles import StaticFiles\\nfrom pydantic import BaseModel\\nimport uvicorn\\n\\nfrom config import settings\\nfrom repository_analyzer import RepositoryAnalyzer\\nfrom ollama_client import OllamaClient\\nfrom vector_store import VectorStore\\nfrom rag_system import RAGSystem\\nfrom documentation_generator import DocumentationBuilder, DocumentationConfig\\n\\n# Pydantic models for API\\nclass QueryRequest(BaseModel):\\n    query: str\\n    repo_name: Optional[str] = None\\n    file_path: Optional[str] = None\\n    stream: Optional[bool] = False\\n\\nclass ChatMessage(BaseModel):\\n    role: str  # 'user' or 'assistant'\\n    content: str\\n\\nclass ChatRequest(BaseModel):\\n    messages: List[ChatMessage]\\n    repo_name: Optional[str] = None\\n\\nclass RepositoryRequest(BaseModel):\\n    repo_path: str\\n    repo_name: Optional[str] = None\\n\\nclass ExplainCodeRequest(BaseModel):\\n    code: str\\n    language: Optional[str] = None\\n    context: Optional[str] = None\\n\\nclass DocumentationRequest(BaseModel):\\n    repo_name: str\\n    include_overview: bool = True\\n    include_api_docs: bool = True\\n    include_examples: bool = True\\n    include_architecture: bool = True\\n\\n# Global instances\\napp = FastAPI(title=\\\"Local DeepWiki\\\", version=\\\"1.0.0\\\")\\nollama_client = OllamaClient()\\nvector_store = VectorStore()\\nrag_system = RAGSystem(vector_store, ollama_client)\\nrepository_analyzer = RepositoryAnalyzer()\\ndocumentation_builder = DocumentationBuilder(ollama_client)\\n\\n# Add CORS middleware\\napp.add_middleware(\\n    CORSMiddleware,\\n    allow_origins=[\\\"*\\\"],\\n    allow_credentials=True,\\n    allow_methods=[\\\"*\\\"],\\n    allow_headers=[\\\"*\\\"],\\n)\\n\\n# Health check endpoints\\n@app.get(\\\"/health\\\")\\nasync def health_check():\\n    \\\"\\\"\\\"Health check endpoint.\\\"\\\"\\\"\\n    ollama_available = ollama_client.is_available()\\n    vector_stats = vector_store.get_collection_stats()\\n    \\n    return {\\n        \\\"status\\\": \\\"healthy\\\",\\n        \\\"ollama_available\\\": ollama_available,\\n        \\\"ollama_url\\\": settings.OLLAMA_BASE_URL,\\n        \\\"ollama_model\\\": settings.OLLAMA_MODEL,\\n        \\\"vector_store\\\": vector_stats\\n    }\\n\\n@app.get(\\\"/models\\\")\\nasync def list_models():\\n    \\\"\\\"\\\"List available Ollama models.\\\"\\\"\\\"\\n    try:\\n        models = ollama_client.list_models()\\n        return {\\\"models\\\": models}\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error listing models: {str(e)}\\\")\\n\\n# Repository management endpoints\\n@app.post(\\\"/repositories/analyze\\\")\\nasync def analyze_repository(request: RepositoryRequest, background_tasks: BackgroundTasks):\\n    \\\"\\\"\\\"Analyze a repository and add it to the vector store.\\\"\\\"\\\"\\n    repo_path = Path(request.repo_path)\\n    \\n    if not repo_path.exists():\\n        raise HTTPException(status_code=404, detail=f\\\"Repository path not found: {repo_path}\\\")\\n    \\n    repo_name = request.repo_name or repo_path.name\\n    \\n    try:\\n        # Start analysis in background\\n        background_tasks.add_task(analyze_repository_task, str(repo_path), repo_name)\\n        \\n        return {\\n            \\\"message\\\": f\\\"Repository analysis started for {repo_name}\\\",\\n            \\\"repo_name\\\": repo_name,\\n            \\\"repo_path\\\": str(repo_path)\\n        }\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error starting analysis: {str(e)}\\\")\\n\\nasync def analyze_repository_task(repo_path: str, repo_name: str):\\n    \\\"\\\"\\\"Background task to analyze repository.\\\"\\\"\\\"\\n    try:\\n        print(f\\\"Starting analysis of {repo_name} at {repo_path}\\\")\\n        \\n        # Analyze repository\\n        analysis = repository_analyzer.analyze_repository(repo_path)\\n        analysis['repo_name'] = repo_name\\n        \\n        # Save analysis\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\"{repo_name}_analysis.json\\\"\\n        repository_analyzer.save_analysis(analysis, str(analysis_path))\\n        \\n        # Add to vector store\\n        chunks_added = vector_store.add_repository(analysis)\\n        \\n        print(f\\\"Analysis complete for {repo_name}: {chunks_added} chunks added to vector store\\\")\\n        \\n    except Exception as e:\\n        print(f\\\"Error in repository analysis task: {str(e)}\\\")\\n        traceback.print_exc()\\n\\n@app.get(\\\"/repositories\\\")\\nasync def list_repositories():\\n    \\\"\\\"\\\"List analyzed repositories.\\\"\\\"\\\"\\n    repos = []\\n    repos_dir = Path(settings.REPOS_DIRECTORY)\\n    \\n    if repos_dir.exists():\\n        for analysis_file in repos_dir.glob(\\\"*_analysis.json\\\"):\\n            try:\\n                analysis = repository_analyzer.load_analysis(str(analysis_file))\\n                repos.append({\\n                    \\\"name\\\": analysis.get('repo_name', analysis_file.stem.replace('_analysis', '')),\\n                    \\\"path\\\": analysis.get('repo_path', ''),\\n                    \\\"files\\\": analysis.get('statistics', {}).get('total_files', 0),\\n                    \\\"languages\\\": list(analysis.get('statistics', {}).get('languages', {}).keys())\\n                })\\n            except Exception as e:\\n                print(f\\\"Error loading analysis from {analysis_file}: {e}\\\")\\n    \\n    return {\\\"repositories\\\": repos}\\n\\n@app.delete(\\\"/repositories/{repo_name}\\\")\\nasync def delete_repository(repo_name: str):\\n    \\\"\\\"\\\"Delete repository from vector store.\\\"\\\"\\\"\\n    try:\\n        vector_store.delete_repository(repo_name)\\n        \\n        # Also delete analysis file\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\"{repo_name}_analysis.json\\\"\\n        if analysis_path.exists():\\n            analysis_path.unlink()\\n        \\n        return {\\\"message\\\": f\\\"Repository {repo_name} deleted successfully\\\"}\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error deleting repository: {str(e)}\\\")\\n\\n# Query endpoints\\n@app.post(\\\"/query\\\")\\nasync def query_repository(request: QueryRequest):\\n    \\\"\\\"\\\"Query repository using RAG system.\\\"\\\"\\\"\\n    try:\\n        if request.stream:\\n            # Return streaming response\\n            return StreamingResponse(\\n                stream_query_response(request),\\n                media_type=\\\"text/plain\\\"\\n            )\\n        else:\\n            # Return complete response\\n            result = rag_system.query(\\n                request.query,\\n                repo_name=request.repo_name,\\n                file_path=request.file_path,\\n                stream=False\\n            )\\n            return result\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error processing query: {str(e)}\\\")\\n\\nasync def stream_query_response(request: QueryRequest):\\n    \\\"\\\"\\\"Stream query response for real-time updates.\\\"\\\"\\\"\\n    try:\\n        # Get context first\\n        filter_metadata = {}\\n        if request.repo_name:\\n            filter_metadata['repo_name'] = request.repo_name\\n        if request.file_path:\\n            filter_metadata['file_path'] = request.file_path\\n        \\n        retrieved_chunks = rag_system.retrieve_context(\\n            request.query, \\n            n_results=5, \\n            filter_metadata=filter_metadata or None\\n        )\\n        \\n        if not retrieved_chunks:\\n            yield \\\"No relevant context found for query.\\\\n\\\"\\n            return\\n        \\n        context_text = rag_system.build_context_text(retrieved_chunks)\\n        \\n        # Build prompt\\n        system_prompt = rag_system.system_prompts['general_question']\\n        full_prompt = f\\\"\\\"\\\"{system_prompt}\\n\\nCONTEXT:\\n{context_text}\\n\\nUSER QUERY: {request.query}\\n\\nPlease provide a helpful response based on the context above.\\\"\\\"\\\"\\n\\n        # Stream response\\n        async for chunk in ollama_client.generate_stream(full_prompt, temperature=0.3):\\n            yield chunk\\n            \\n    except Exception as e:\\n        yield f\\\"Error: {str(e)}\\\\n\\\"\\n\\n@app.post(\\\"/chat\\\")\\nasync def chat_with_repository(request: ChatRequest):\\n    \\\"\\\"\\\"Chat interface for conversational interaction.\\\"\\\"\\\"\\n    try:\\n        messages = [{\\\"role\\\": msg.role, \\\"content\\\": msg.content} for msg in request.messages]\\n        response = rag_system.chat_with_repo(messages, request.repo_name)\\n        \\n        return {\\n            \\\"response\\\": response,\\n            \\\"repo_name\\\": request.repo_name\\n        }\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error in chat: {str(e)}\\\")\\n\\n@app.post(\\\"/explain\\\")\\nasync def explain_code(request: ExplainCodeRequest):\\n    \\\"\\\"\\\"Explain code snippet.\\\"\\\"\\\"\\n    try:\\n        explanation = rag_system.explain_code(\\n            request.code,\\n            request.language,\\n            request.context\\n        )\\n        return {\\\"explanation\\\": explanation}\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error explaining code: {str(e)}\\\")\\n\\n@app.post(\\\"/improve\\\")\\nasync def suggest_improvements(request: ExplainCodeRequest):\\n    \\\"\\\"\\\"Suggest code improvements.\\\"\\\"\\\"\\n    try:\\n        suggestions = rag_system.suggest_improvements(\\n            request.code,\\n            request.language\\n        )\\n        return {\\\"suggestions\\\": suggestions}\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error suggesting improvements: {str(e)}\\\")\\n\\n@app.get(\\\"/repositories/{repo_name}/overview\\\")\\nasync def get_repository_overview(repo_name: str):\\n    \\\"\\\"\\\"Get repository overview.\\\"\\\"\\\"\\n    try:\\n        overview = rag_system.get_repository_overview(repo_name)\\n        return {\\\"overview\\\": overview, \\\"repo_name\\\": repo_name}\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error getting overview: {str(e)}\\\")\\n\\n@app.get(\\\"/repositories/{repo_name}/files/{file_path:path}/summary\\\")\\nasync def get_file_summary(repo_name: str, file_path: str):\\n    \\\"\\\"\\\"Get file summary.\\\"\\\"\\\"\\n    try:\\n        summary = rag_system.get_file_summary(file_path, repo_name)\\n        return {\\\"summary\\\": summary, \\\"file_path\\\": file_path, \\\"repo_name\\\": repo_name}\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error getting file summary: {str(e)}\\\")\\n\\n# Documentation endpoints\\n@app.post(\\\"/repositories/{repo_name}/generate-docs\\\")\\nasync def generate_documentation(repo_name: str, request: DocumentationRequest, background_tasks: BackgroundTasks):\\n    \\\"\\\"\\\"Generate comprehensive documentation for repository.\\\"\\\"\\\"\\n    try:\\n        # Load repository analysis\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\"{repo_name}_analysis.json\\\"\\n        if not analysis_path.exists():\\n            raise HTTPException(status_code=404, detail=f\\\"Repository {repo_name} not found. Please analyze it first.\\\")\\n        \\n        analysis = repository_analyzer.load_analysis(str(analysis_path))\\n        \\n        config = DocumentationConfig(\\n            include_overview=request.include_overview,\\n            include_api_docs=request.include_api_docs,\\n            include_examples=request.include_examples,\\n            include_architecture=request.include_architecture\\n        )\\n        \\n        # Start documentation generation in background\\n        background_tasks.add_task(generate_docs_task, analysis, config, repo_name)\\n        \\n        return {\\n            \\\"message\\\": f\\\"Documentation generation started for {repo_name}\\\",\\n            \\\"repo_name\\\": repo_name\\n        }\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error starting documentation generation: {str(e)}\\\")\\n\\nasync def generate_docs_task(analysis: Dict[str, Any], config: DocumentationConfig, repo_name: str):\\n    \\\"\\\"\\\"Background task to generate documentation.\\\"\\\"\\\"\\n    try:\\n        print(f\\\"Starting documentation generation for {repo_name}\\\")\\n        docs = documentation_builder.generate_full_documentation(analysis, config)\\n        print(f\\\"Documentation generation complete for {repo_name}: {len(docs)} files generated\\\")\\n    except Exception as e:\\n        print(f\\\"Error in documentation generation task: {str(e)}\\\")\\n        traceback.print_exc()\\n\\n@app.get(\\\"/repositories/{repo_name}/docs\\\")\\nasync def list_generated_docs(repo_name: str):\\n    \\\"\\\"\\\"List generated documentation files.\\\"\\\"\\\"\\n    docs_dir = Path(settings.DOCS_DIRECTORY) / repo_name\\n    \\n    if not docs_dir.exists():\\n        return {\\\"documents\\\": []}\\n    \\n    docs = []\\n    for doc_file in docs_dir.rglob(\\\"*.md\\\"):\\n        relative_path = doc_file.relative_to(docs_dir)\\n        docs.append({\\n            \\\"name\\\": doc_file.name,\\n            \\\"path\\\": str(relative_path),\\n            \\\"size\\\": doc_file.stat().st_size\\n        })\\n    \\n    return {\\\"documents\\\": docs}\\n\\n@app.get(\\\"/repositories/{repo_name}/docs/{doc_path:path}\\\")\\nasync def get_documentation(repo_name: str, doc_path: str):\\n    \\\"\\\"\\\"Get specific documentation file.\\\"\\\"\\\"\\n    doc_file = Path(settings.DOCS_DIRECTORY) / repo_name / doc_path\\n    \\n    if not doc_file.exists():\\n        raise HTTPException(status_code=404, detail=\\\"Documentation file not found\\\")\\n    \\n    try:\\n        with open(doc_file, 'r', encoding='utf-8') as f:\\n            content = f.read()\\n        \\n        return {\\n            \\\"content\\\": content,\\n            \\\"path\\\": doc_path,\\n            \\\"repo_name\\\": repo_name\\n        }\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error reading documentation: {str(e)}\\\")\\n\\n# Search endpoints\\n@app.get(\\\"/search\\\")\\nasync def search_all_repositories(q: str, limit: int = 10):\\n    \\\"\\\"\\\"Search across all repositories.\\\"\\\"\\\"\\n    try:\\n        results = vector_store.search(q, n_results=limit)\\n        return {\\\"results\\\": results, \\\"query\\\": q}\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error searching: {str(e)}\\\")\\n\\n@app.get(\\\"/repositories/{repo_name}/search\\\")\\nasync def search_repository(repo_name: str, q: str, limit: int = 10):\\n    \\\"\\\"\\\"Search within specific repository.\\\"\\\"\\\"\\n    try:\\n        results = vector_store.search(\\n            q, \\n            n_results=limit, \\n            filter_metadata={\\\"repo_name\\\": repo_name}\\n        )\\n        return {\\\"results\\\": results, \\\"query\\\": q, \\\"repo_name\\\": repo_name}\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error searching repository: {str(e)}\\\")\\n\\n# Statistics endpoint\\n@app.get(\\\"/stats\\\")\\nasync def get_system_stats():\\n    \\\"\\\"\\\"Get system statistics.\\\"\\\"\\\"\\n    try:\\n        vector_stats = vector_store.get_collection_stats()\\n        \\n        # Count repositories\\n        repos_dir = Path(settings.REPOS_DIRECTORY)\\n        repo_count = len(list(repos_dir.glob(\\\"*_analysis.json\\\"))) if repos_dir.exists() else 0\\n        \\n        # Count generated docs\\n        docs_dir = Path(settings.DOCS_DIRECTORY)\\n        doc_count = len(list(docs_dir.rglob(\\\"*.md\\\"))) if docs_dir.exists() else 0\\n        \\n        return {\\n            \\\"repositories\\\": repo_count,\\n            \\\"documents_in_vector_store\\\": vector_stats.get('total_documents', 0),\\n            \\\"generated_docs\\\": doc_count,\\n            \\\"ollama_available\\\": ollama_client.is_available(),\\n            \\\"ollama_model\\\": settings.OLLAMA_MODEL\\n        }\\n    except Exception as e:\\n        raise HTTPException(status_code=500, detail=f\\\"Error getting stats: {str(e)}\\\")\\n\\n# Main function to run the server\\ndef main():\\n    \\\"\\\"\\\"Main function to run the API server.\\\"\\\"\\\"\\n    print(f\\\"Starting Local DeepWiki server on {settings.API_HOST}:{settings.API_PORT}\\\")\\n    print(f\\\"Ollama URL: {settings.OLLAMA_BASE_URL}\\\")\\n    print(f\\\"Model: {settings.OLLAMA_MODEL}\\\")\\n    \\n    # Check Ollama availability\\n    if not ollama_client.is_available():\\n        print(\\\"WARNING: Ollama server not available. Please start Ollama first.\\\")\\n        print(\\\"Run: ollama serve\\\")\\n    \\n    uvicorn.run(\\n        \\\"api:app\\\",\\n        host=settings.API_HOST,\\n        port=settings.API_PORT,\\n        reload=True\\n    )\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\basic_station.md\",\n      \"file_type\": \"documentation\",\n      \"language\": null,\n      \"imports\": [],\n      \"elements\": [],\n      \"summary\": null,\n      \"content\": \"[![regr-tests](https://github.com/lorabasics/basicstation/actions/workflows/regr-tests.yml/badge.svg?branch=master)](https://github.com/lorabasics/basicstation/actions/workflows/regr-tests.yml?query=branch%3Amaster)\\n\\n# LoRa Basicsâ„¢ Station\\n\\n[Basic Station](https://doc.sm.tc/station) is a LoRaWAN Gateway implementation, including features like\\n\\n*  **Ready for LoRaWAN Classes A, B, and C**\\n*  **Unified Radio Abstraction Layer supporting Concentrator Reference Designs [v1.5](https://doc.sm.tc/station/gw_v1.5.html), [v2](https://doc.sm.tc/station/gw_v2.html) and [Corecell](https://doc.sm.tc/station/gw_corecell.html)**\\n\\n*  **Powerful Backend Protocols** (read [here](https://doc.sm.tc/station/tcproto.html) and [here](https://doc.sm.tc/station/cupsproto.html))\\n    -  Centralized update and configuration management\\n    -  Centralized channel-plan management\\n    -  Centralized time synchronization and transfer\\n    -  Various authentication schemes (client certificate, auth tokens)\\n    -  Remote interactive shell\\n\\n*  **Lean Design**\\n    -  No external software dependencies (except mbedTLS and libloragw/-v2)\\n    -  Portable C code, no C++, dependent only on GNU libc\\n    -  Easily portable to Linux-based gateways and embedded systems\\n    -  No dependency on local time keeping\\n    -  No need for incoming connections\\n\\n## Documentation\\n\\nThe full documentation is available at [https://doc.sm.tc/station](https://doc.sm.tc/station).\\n\\n### High Level Architecture\\n\\n![High Level Station Architecture](https://doc.sm.tc/station/_images/architecture.png)\\n\\n## Prerequisites\\n\\nBuilding the Station binary from source, requires\\n\\n* gcc (C11 with GNU extensions)\\n* GNU make\\n* git\\n* bash\\n\\n## First Steps\\n\\nThe following is a three-step quick start guide on how to build and run Station. It uses a Raspberry Pi as host platform and assumes a Concentrator Reference Design 1.5 compatible radio board connected via SPI, and assumes that SPI port is enabled using the [raspi-config](https://www.raspberrypi.org/documentation/configuration/raspi-config.md) tool. In this example the build process is done on the target platform itself (the make environment also supports cross compilation in which case the toolchain is expected in `~/toolchain-$platform` - see [setup.gmk](setup.gmk)).\\n\\n#### Step 1: Cloning the Station Repository\\n\\n``` sourceCode\\ngit clone https://github.com/lorabasics/basicstation.git\\n```\\n\\n#### Step 2: Compiling the Station Binary\\n\\n``` sourceCode\\ncd basicstation\\nmake platform=rpi variant=std\\n```\\n\\nThe build process consists of the following steps:\\n\\n*  Fetch and build dependencies, namely [mbedTLS](https://github.com/ARMmbed/mbedtls) and [libloragw](https://github.com/Lora-net/lora_gateway)\\n*  Setup build environment within subdirectory `build-$platform-$variant/`\\n*  Compile station source files into executable `build-$platform-$variant/bin/station`\\n\\n#### Step 3: Running the Example Configuration on a Raspberry Pi\\n\\n``` sourceCode\\ncd examples/live-s2.sm.tc\\nRADIODEV=/dev/spidev0.0 ../../build-rpi-std/bin/station\\n```\\n\\n**Note:** The SPI device for the radio MAY be passed as an environment variable using `RADIODEV`.\\n\\nThe example configuration connects to a public test server [s2.sm.tc](wss://s2.sm.tc) through which Station fetches all required credentials and a channel plan matching the region as determined from the IP address of the gateway. Provided there are active LoRa devices in proximity, received LoRa frames are printed in the log output on `stderr`.\\n\\n## Instruction for Supported Platfroms\\n\\n#### Corecell Platform (Raspberry Pi as HOST + [SX1302CxxxxGW Concentrator](https://www.semtech.com/products/wireless-rf/lora-gateways/sx1302cxxxgw1))\\n\\n##### Compile and Running the Example\\n\\n``` sourceCode\\ncd basicstation\\nmake platform=corecell variant=std\\ncd examples/corecell\\n./start-station.sh -l ./lns-ttn\\n```\\n\\nThis example configuration for Corecell connects to [The Things Network](https://www.thethingsnetwork.org/) public LNS. The example [station.conf](station.conf) file holds the required radio configurations and station fetches the channel plan from the configured LNS url ([tc.uri](tc.uri)).\\n\\nNote: SPI port requires to be activated on Raspberry Pi thanks to [raspi-config](https://www.raspberrypi.org/documentation/configuration/raspi-config.md) tool.\\n\\n#### PicoCell Gateway (Linux OS as HOST + [SX1308 USB Reference design](https://www.semtech.com/products/wireless-rf/lora-gateways/sx1308p868gw))\\n\\n\\n##### Compile and Running the Example\\n\\n``` sourceCode\\ncd basicstation\\nmake platform=linuxpico variant=std\\ncd examples/live-s2.sm.tc\\nRADIODEV=/dev/ttyACM0 ../../build-linuxpico-std/bin/station\\n```\\n\\n**Note:** The serial device for the PicoCell MAY be passed as an environment variable using `RADIODEV`.\\n\\n## Next Steps\\n\\nNext,\\n\\n*  consult the help menu of Station via `station --help`,\\n*  inspect the `station.conf` and `cups-boot.*` [example configuration files](/examples/live-s2.sm.tc),\\n*  tune your local [configuration](https://doc.sm.tc/station/conf.html),\\n*  learn how to [compile Station](https://doc.sm.tc/station/compile.html) for your target platform.\\n\\nCheck out the other examples:\\n\\n*  [Simulation Example](/examples/simulation) - An introduction to the simulation environment.\\n*  [CUPS Example](/examples/cups) - Demonstration of the CUPS protocol within the simulation environment.\\n*  [Station to Pkfwd Protocol Bridge Example](/examples/station2pkfwd) - Connect Basic Station to LNS supporting the legacy protocol.\\n\\n## Usage\\n\\nThe Station binary accepts the following command-line options:\\n\\n```\\nUsage: station [OPTION...]\\n\\n  -d, --daemon               First check if another process is still alive. If\\n                             so do nothing and exit. Otherwise fork a worker\\n                             process to operate the radios and network\\n                             protocols. If the subprocess died respawn it with\\n                             an appropriate back off.\\n  -f, --force                If a station process is already running, kill it\\n                             before continuing with requested operation mode.\\n  -h, --home=DIR             Home directory for configuration files. Default is\\n                             the current working directory. Overrides\\n                             environment STATION_DIR.\\n  -i, --radio-init=cmd       Program/script to run before reinitializing radio\\n                             hardware. By default nothing is being executed.\\n                             Overrides environment STATION_RADIOINIT.\\n  -k, --kill                 Kill a currently running station process.\\n  -l, --log-level=LVL|0..7   Set a log level LVL=#loglvls# or use a numeric\\n                             value. Overrides environment STATION_LOGLEVEL.\\n  -L, --log-file=FILE[,SIZE[,ROT]]\\n                             Write log entries to FILE. If FILE is '-' then\\n                             write to stderr. Optionally followed by a max file\\n                             SIZE and a number of rotation files. If ROT is 0\\n                             then keep only FILE. If ROT is 1 then keep one\\n                             more old log file around. Overrides environment\\n                             STATION_LOGFILE.\\n  -N, --no-tc                Do not connect to a LNS. Only run CUPS\\n                             functionality.\\n  -p, --params               Print current parameter settings.\\n  -t, --temp=DIR             Temp directory for frequently written files.\\n                             Default is /tmp. Overrides environment\\n                             STATION_TEMPDIR.\\n  -x, --eui-prefix=id6       Turn MAC address into EUI by adding this prefix.\\n                             If the argument has value ff:fe00:0 then the EUI\\n                             is formed by inserting FFFE in the middle. If\\n                             absent use MAC or routerid as is. Overrides\\n                             environment STATION_EUIPREFIX.\\n  -?, --help                 Give this help list\\n      --usage                Give a short usage message\\n  -v, --version              Print station version.\\n\\nMandatory or optional arguments to long options are also mandatory or optional\\nfor any corresponding short options.\\n```\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\config.py\",\n      \"file_type\": \"code\",\n      \"language\": \"python\",\n      \"imports\": [\n        \"os\",\n        \"pathlib.Path\",\n        \"typing.List\",\n        \"typing.Dict\",\n        \"typing.Any\",\n        \"pydantic_settings.BaseSettings\"\n      ],\n      \"elements\": [\n        {\n          \"name\": \"Settings\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\config.py\",\n          \"line_start\": 8,\n          \"line_end\": 53,\n          \"docstring\": \"Application settings.\",\n          \"signature\": \"class Settings\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"Config\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\config.py\",\n          \"line_start\": 52,\n          \"line_end\": 53,\n          \"docstring\": null,\n          \"signature\": \"class Config\",\n          \"content\": null,\n          \"dependencies\": []\n        }\n      ],\n      \"summary\": null,\n      \"content\": \"\\\"\\\"\\\"Configuration settings for Local DeepWiki.\\\"\\\"\\\"\\n\\nimport os\\nfrom pathlib import Path\\nfrom typing import List, Dict, Any\\nfrom pydantic_settings import BaseSettings\\n\\nclass Settings(BaseSettings):\\n    \\\"\\\"\\\"Application settings.\\\"\\\"\\\"\\n    \\n    # Ollama settings\\n    OLLAMA_BASE_URL: str = \\\"http://localhost:11434\\\"\\n    OLLAMA_MODEL: str = \\\"deepseek-coder:6.7b\\\"  # Using available code-focused model\\n    OLLAMA_EMBEDDING_MODEL: str = \\\"nomic-embed-text:latest\\\"\\n    \\n    # Vector database settings\\n    CHROMA_PERSIST_DIRECTORY: str = \\\"./data/chroma_db\\\"\\n    COLLECTION_NAME: str = \\\"codebase_docs\\\"\\n    \\n    # Repository settings\\n    REPOS_DIRECTORY: str = \\\"./data/repos\\\"\\n    DOCS_DIRECTORY: str = \\\"./data/generated_docs\\\"\\n    \\n    # Generation settings\\n    MAX_CHUNK_SIZE: int = 2000\\n    CHUNK_OVERLAP: int = 200\\n    MAX_CONTEXT_LENGTH: int = 4000\\n    \\n    # API settings\\n    API_HOST: str = \\\"0.0.0.0\\\"\\n    API_PORT: int = 8000\\n    \\n    # Supported file extensions\\n    CODE_EXTENSIONS: List[str] = [\\n        \\\".py\\\", \\\".js\\\", \\\".ts\\\", \\\".jsx\\\", \\\".tsx\\\", \\\".java\\\", \\\".cpp\\\", \\\".c\\\", \\\".h\\\",\\n        \\\".cs\\\", \\\".php\\\", \\\".rb\\\", \\\".go\\\", \\\".rs\\\", \\\".swift\\\", \\\".kt\\\", \\\".scala\\\",\\n        \\\".r\\\", \\\".sql\\\", \\\".sh\\\", \\\".yaml\\\", \\\".yml\\\", \\\".json\\\", \\\".xml\\\", \\\".html\\\",\\n        \\\".css\\\", \\\".scss\\\", \\\".less\\\", \\\".vue\\\", \\\".svelte\\\"\\n    ]\\n    \\n    DOC_EXTENSIONS: List[str] = [\\\".md\\\", \\\".rst\\\", \\\".txt\\\", \\\".adoc\\\"]\\n    \\n    # Ignored directories\\n    IGNORED_DIRS: List[str] = [\\n        \\\".git\\\", \\\".svn\\\", \\\".hg\\\", \\\"__pycache__\\\", \\\".pytest_cache\\\",\\n        \\\"node_modules\\\", \\\".npm\\\", \\\".yarn\\\", \\\"bower_components\\\",\\n        \\\".venv\\\", \\\"venv\\\", \\\"env\\\", \\\".env\\\", \\\"virtualenv\\\",\\n        \\\"dist\\\", \\\"build\\\", \\\"target\\\", \\\"bin\\\", \\\"obj\\\",\\n        \\\".idea\\\", \\\".vscode\\\", \\\".vs\\\", \\\"*.egg-info\\\"\\n    ]\\n    \\n    class Config:\\n        env_file = \\\".env\\\"\\n\\n# Global settings instance\\nsettings = Settings()\\n\\n# Ensure data directories exist\\nPath(settings.CHROMA_PERSIST_DIRECTORY).mkdir(parents=True, exist_ok=True)\\nPath(settings.REPOS_DIRECTORY).mkdir(parents=True, exist_ok=True)\\nPath(settings.DOCS_DIRECTORY).mkdir(parents=True, exist_ok=True)\\n\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\DEVELOPMENT.md\",\n      \"file_type\": \"documentation\",\n      \"language\": null,\n      \"imports\": [],\n      \"elements\": [],\n      \"summary\": null,\n      \"content\": \"# Development Guide\\n\\n## Setting up the development environment\\n\\n1. Install Python 3.8+\\n2. Install dependencies: `pip install -r requirements.txt`\\n3. Install and start Ollama\\n4. Pull required models: `ollama pull deepseek-coder:6.7b`\\n\\n## Running the system\\n\\n### Analyze a repository\\n```bash\\npython main.py analyze . --name myproject\\n```\\n\\n### Query the repository\\n```bash\\npython main.py query \\\"How does authentication work?\\\" --repo myproject\\n```\\n\\n### Start the API server\\n```bash\\npython main.py server\\n```\\n\\n## Key Components\\n\\n- **config.py**: Configuration settings\\n- **repository_analyzer.py**: Code parsing and analysis\\n- **vector_store.py**: ChromaDB integration\\n- **rag_system.py**: RAG implementation\\n- **api.py**: FastAPI server\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n      \"file_type\": \"code\",\n      \"language\": \"python\",\n      \"imports\": [\n        \"os\",\n        \"json\",\n        \"pathlib.Path\",\n        \"typing.Dict\",\n        \"typing.List\",\n        \"typing.Any\",\n        \"typing.Optional\",\n        \"dataclasses.dataclass\",\n        \"markdown\",\n        \"jinja2.Template\",\n        \"ollama_client.OllamaClient\",\n        \"ollama_client.DocumentationGenerator\",\n        \"repository_analyzer.RepositoryAnalyzer\",\n        \"config.settings\"\n      ],\n      \"elements\": [\n        {\n          \"name\": \"DocumentationConfig\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 15,\n          \"line_end\": 22,\n          \"docstring\": \"Configuration for documentation generation.\",\n          \"signature\": \"class DocumentationConfig\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationBuilder\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 24,\n          \"line_end\": 502,\n          \"docstring\": \"Build comprehensive documentation from repository analysis.\",\n          \"signature\": \"class DocumentationBuilder\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationBuilder.__init__\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 27,\n          \"line_end\": 94,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self, ollama_client)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationBuilder.generate_full_documentation\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 96,\n          \"line_end\": 161,\n          \"docstring\": \"Generate complete documentation for a repository.\",\n          \"signature\": \"def generate_full_documentation(self, repo_analysis, config, output_dir)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationBuilder.generate_repository_readme\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 163,\n          \"line_end\": 224,\n          \"docstring\": \"Generate main repository README.\",\n          \"signature\": \"def generate_repository_readme(self, repo_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationBuilder.generate_file_api_docs\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 226,\n          \"line_end\": 303,\n          \"docstring\": \"Generate API documentation for a single file.\",\n          \"signature\": \"def generate_file_api_docs(self, file_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationBuilder.generate_architecture_docs\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 305,\n          \"line_end\": 366,\n          \"docstring\": \"Generate architecture documentation.\",\n          \"signature\": \"def generate_architecture_docs(self, repo_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationBuilder.generate_examples_docs\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 368,\n          \"line_end\": 447,\n          \"docstring\": \"Generate usage examples documentation.\",\n          \"signature\": \"def generate_examples_docs(self, repo_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationBuilder.generate_table_of_contents\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 449,\n          \"line_end\": 470,\n          \"docstring\": \"Generate table of contents for all documentation.\",\n          \"signature\": \"def generate_table_of_contents(self, documentation)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationBuilder.update_existing_docs\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 472,\n          \"line_end\": 502,\n          \"docstring\": \"Update existing documentation files with new analysis.\",\n          \"signature\": \"def update_existing_docs(self, repo_path, analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"__init__\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 27,\n          \"line_end\": 94,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self, ollama_client)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"generate_full_documentation\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 96,\n          \"line_end\": 161,\n          \"docstring\": \"Generate complete documentation for a repository.\",\n          \"signature\": \"def generate_full_documentation(self, repo_analysis, config, output_dir)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"generate_repository_readme\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 163,\n          \"line_end\": 224,\n          \"docstring\": \"Generate main repository README.\",\n          \"signature\": \"def generate_repository_readme(self, repo_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"generate_file_api_docs\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 226,\n          \"line_end\": 303,\n          \"docstring\": \"Generate API documentation for a single file.\",\n          \"signature\": \"def generate_file_api_docs(self, file_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"generate_architecture_docs\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 305,\n          \"line_end\": 366,\n          \"docstring\": \"Generate architecture documentation.\",\n          \"signature\": \"def generate_architecture_docs(self, repo_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"generate_examples_docs\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 368,\n          \"line_end\": 447,\n          \"docstring\": \"Generate usage examples documentation.\",\n          \"signature\": \"def generate_examples_docs(self, repo_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"generate_table_of_contents\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 449,\n          \"line_end\": 470,\n          \"docstring\": \"Generate table of contents for all documentation.\",\n          \"signature\": \"def generate_table_of_contents(self, documentation)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"update_existing_docs\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\documentation_generator.py\",\n          \"line_start\": 472,\n          \"line_end\": 502,\n          \"docstring\": \"Update existing documentation files with new analysis.\",\n          \"signature\": \"def update_existing_docs(self, repo_path, analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        }\n      ],\n      \"summary\": null,\n      \"content\": \"\\\"\\\"\\\"Documentation generation system using local LLMs.\\\"\\\"\\\"\\n\\nimport os\\nimport json\\nfrom pathlib import Path\\nfrom typing import Dict, List, Any, Optional\\nfrom dataclasses import dataclass\\nimport markdown\\nfrom jinja2 import Template\\nfrom ollama_client import OllamaClient, DocumentationGenerator\\nfrom repository_analyzer import RepositoryAnalyzer\\nfrom config import settings\\n\\n@dataclass\\nclass DocumentationConfig:\\n    \\\"\\\"\\\"Configuration for documentation generation.\\\"\\\"\\\"\\n    include_overview: bool = True\\n    include_api_docs: bool = True\\n    include_examples: bool = True\\n    include_architecture: bool = True\\n    output_format: str = 'markdown'  # 'markdown', 'html'\\n    template_style: str = 'default'  # 'default', 'minimal', 'detailed'\\n\\nclass DocumentationBuilder:\\n    \\\"\\\"\\\"Build comprehensive documentation from repository analysis.\\\"\\\"\\\"\\n    \\n    def __init__(self, ollama_client: OllamaClient):\\n        self.ollama_client = ollama_client\\n        self.doc_generator = DocumentationGenerator(ollama_client)\\n        \\n        # Documentation templates\\n        self.templates = {\\n            'repository_readme': \\\"\\\"\\\"# {{ repo_name }}\\n\\n{{ overview }}\\n\\n## Architecture\\n\\n{{ architecture }}\\n\\n## Getting Started\\n\\n{{ getting_started }}\\n\\n## API Documentation\\n\\n{{ api_docs }}\\n\\n## Examples\\n\\n{{ examples }}\\n\\n## Contributing\\n\\n{{ contributing }}\\n\\n\\\"\\\"\\\",\\n            \\n            'api_reference': \\\"\\\"\\\"# API Reference - {{ file_name }}\\n\\n{{ file_overview }}\\n\\n## Classes\\n\\n{{ classes }}\\n\\n## Functions\\n\\n{{ functions }}\\n\\n## Constants\\n\\n{{ constants }}\\n\\n\\\"\\\"\\\",\\n            \\n            'module_docs': \\\"\\\"\\\"# {{ module_name }}\\n\\n{{ description }}\\n\\n## Usage\\n\\n{{ usage }}\\n\\n## Implementation Details\\n\\n{{ implementation }}\\n\\n## Dependencies\\n\\n{{ dependencies }}\\n\\n\\\"\\\"\\\"\\n        }\\n    \\n    def generate_full_documentation(self, \\n                                  repo_analysis: Dict[str, Any], \\n                                  config: DocumentationConfig = None,\\n                                  output_dir: str = None) -> Dict[str, str]:\\n        \\\"\\\"\\\"Generate complete documentation for a repository.\\\"\\\"\\\"\\n        \\n        if config is None:\\n            config = DocumentationConfig()\\n        \\n        if output_dir is None:\\n            output_dir = settings.DOCS_DIRECTORY\\n        \\n        output_dir = Path(output_dir)\\n        repo_name = repo_analysis.get('repo_name', 'unknown')\\n        repo_output_dir = output_dir / repo_name\\n        repo_output_dir.mkdir(parents=True, exist_ok=True)\\n        \\n        documentation = {}\\n        \\n        # Generate main README\\n        if config.include_overview:\\n            readme_content = self.generate_repository_readme(repo_analysis)\\n            readme_path = repo_output_dir / 'README.md'\\n            with open(readme_path, 'w', encoding='utf-8') as f:\\n                f.write(readme_content)\\n            documentation['README.md'] = readme_content\\n        \\n        # Generate API documentation for each file\\n        if config.include_api_docs:\\n            api_dir = repo_output_dir / 'api'\\n            api_dir.mkdir(exist_ok=True)\\n            \\n            for file_data in repo_analysis.get('files', []):\\n                if file_data.get('file_type') == 'code':\\n                    api_doc = self.generate_file_api_docs(file_data)\\n                    file_name = Path(file_data['file_path']).stem\\n                    api_file_path = api_dir / f\\\"{file_name}.md\\\"\\n                    \\n                    with open(api_file_path, 'w', encoding='utf-8') as f:\\n                        f.write(api_doc)\\n                    documentation[f'api/{file_name}.md'] = api_doc\\n        \\n        # Generate architecture documentation\\n        if config.include_architecture:\\n            arch_doc = self.generate_architecture_docs(repo_analysis)\\n            arch_path = repo_output_dir / 'ARCHITECTURE.md'\\n            with open(arch_path, 'w', encoding='utf-8') as f:\\n                f.write(arch_doc)\\n            documentation['ARCHITECTURE.md'] = arch_doc\\n        \\n        # Generate examples\\n        if config.include_examples:\\n            examples_doc = self.generate_examples_docs(repo_analysis)\\n            examples_path = repo_output_dir / 'EXAMPLES.md'\\n            with open(examples_path, 'w', encoding='utf-8') as f:\\n                f.write(examples_doc)\\n            documentation['EXAMPLES.md'] = examples_doc\\n        \\n        # Generate table of contents\\n        toc = self.generate_table_of_contents(documentation)\\n        toc_path = repo_output_dir / 'TABLE_OF_CONTENTS.md'\\n        with open(toc_path, 'w', encoding='utf-8') as f:\\n            f.write(toc)\\n        documentation['TABLE_OF_CONTENTS.md'] = toc\\n        \\n        return documentation\\n    \\n    def generate_repository_readme(self, repo_analysis: Dict[str, Any]) -> str:\\n        \\\"\\\"\\\"Generate main repository README.\\\"\\\"\\\"\\n        repo_name = repo_analysis.get('repo_name', 'Repository')\\n        stats = repo_analysis.get('statistics', {})\\n        \\n        # Build context for LLM\\n        context = []\\n        context.append(f\\\"Repository: {repo_name}\\\")\\n        context.append(f\\\"Total files: {stats.get('total_files', 0)}\\\")\\n        context.append(f\\\"Code files: {stats.get('code_files', 0)}\\\")\\n        context.append(f\\\"Languages: {', '.join(stats.get('languages', {}).keys())}\\\")\\n        \\n        # Add git information\\n        git_info = repo_analysis.get('git_info')\\n        if git_info:\\n            context.append(f\\\"Current branch: {git_info.get('current_branch', 'main')}\\\")\\n            if git_info.get('last_commit'):\\n                commit = git_info['last_commit']\\n                context.append(f\\\"Last commit: {commit.get('message', '')[:100]}\\\")\\n        \\n        # Add file structure overview\\n        main_files = []\\n        config_files = []\\n        doc_files = []\\n        \\n        for file_data in repo_analysis.get('files', []):\\n            file_path = file_data['file_path']\\n            if any(name in file_path.lower() for name in ['readme', 'license', 'changelog']):\\n                doc_files.append(file_path)\\n            elif any(ext in file_path.lower() for ext in ['.json', '.yaml', '.yml', '.toml', '.ini']):\\n                config_files.append(file_path)\\n            elif file_data.get('file_type') == 'code':\\n                main_files.append(file_path)\\n        \\n        context.append(f\\\"Main code files: {', '.join(main_files[:10])}\\\")\\n        if config_files:\\n            context.append(f\\\"Configuration files: {', '.join(config_files[:5])}\\\")\\n        if doc_files:\\n            context.append(f\\\"Documentation files: {', '.join(doc_files)}\\\")\\n        \\n        context_str = '\\\\n'.join(context)\\n        \\n        prompt = f\\\"\\\"\\\"Generate a comprehensive README.md for this repository based on the following information:\\n\\n{context_str}\\n\\nPlease include:\\n1. Project title and brief description\\n2. Features and capabilities\\n3. Installation instructions\\n4. Quick start guide\\n5. Usage examples\\n6. Project structure overview\\n7. Contributing guidelines\\n8. License information\\n\\nMake it professional and well-formatted with proper Markdown syntax.\\\"\\\"\\\"\\n\\n        try:\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\n        except Exception as e:\\n            return f\\\"# {repo_name}\\\\n\\\\nError generating README: {str(e)}\\\"\\n    \\n    def generate_file_api_docs(self, file_analysis: Dict[str, Any]) -> str:\\n        \\\"\\\"\\\"Generate API documentation for a single file.\\\"\\\"\\\"\\n        file_path = file_analysis['file_path']\\n        language = file_analysis.get('language', 'Unknown')\\n        elements = file_analysis.get('elements', [])\\n        \\n        # Group elements by type\\n        classes = [e for e in elements if e['type'] == 'class']\\n        functions = [e for e in elements if e['type'] in ['function', 'method']]\\n        \\n        doc_content = f\\\"# API Reference - {Path(file_path).name}\\\\n\\\\n\\\"\\n        doc_content += f\\\"**File**: `{file_path}`  \\\\n\\\"\\n        doc_content += f\\\"**Language**: {language}\\\\n\\\\n\\\"\\n        \\n        # File overview\\n        overview_prompt = f\\\"\\\"\\\"Provide a brief overview of this {language} file:\\n\\nFile: {file_path}\\nElements: {len(elements)} total ({len(classes)} classes, {len(functions)} functions)\\n\\nContent preview:\\n{file_analysis.get('content', '')[:1000]}...\\n\\nWrite a 2-3 sentence overview of what this file does.\\\"\\\"\\\"\\n\\n        try:\\n            overview = self.ollama_client.generate(overview_prompt, temperature=0.3)\\n            doc_content += f\\\"## Overview\\\\n\\\\n{overview}\\\\n\\\\n\\\"\\n        except:\\n            doc_content += f\\\"## Overview\\\\n\\\\nThis file contains {len(elements)} code elements.\\\\n\\\\n\\\"\\n        \\n        # Document classes\\n        if classes:\\n            doc_content += \\\"## Classes\\\\n\\\\n\\\"\\n            for cls in classes:\\n                doc_content += f\\\"### {cls['name']}\\\\n\\\\n\\\"\\n                if cls.get('docstring'):\\n                    doc_content += f\\\"{cls['docstring']}\\\\n\\\\n\\\"\\n                \\n                # Get methods for this class\\n                class_methods = [e for e in elements if e['type'] == 'method' and e['name'].startswith(f\\\"{cls['name']}.\\\")]\\n                if class_methods:\\n                    doc_content += \\\"#### Methods\\\\n\\\\n\\\"\\n                    for method in class_methods:\\n                        method_name = method['name'].split('.')[-1]\\n                        doc_content += f\\\"- **{method_name}**\\\"\\n                        if method.get('signature'):\\n                            doc_content += f\\\": `{method['signature']}`\\\"\\n                        if method.get('docstring'):\\n                            doc_content += f\\\" - {method['docstring'][:100]}...\\\"\\n                        doc_content += \\\"\\\\n\\\"\\n                    doc_content += \\\"\\\\n\\\"\\n        \\n        # Document functions\\n        if functions:\\n            doc_content += \\\"## Functions\\\\n\\\\n\\\"\\n            for func in functions:\\n                if func['type'] == 'method':\\n                    continue  # Skip methods (already documented with classes)\\n                \\n                doc_content += f\\\"### {func['name']}\\\\n\\\\n\\\"\\n                if func.get('signature'):\\n                    doc_content += f\\\"```{language}\\\\n{func['signature']}\\\\n```\\\\n\\\\n\\\"\\n                if func.get('docstring'):\\n                    doc_content += f\\\"{func['docstring']}\\\\n\\\\n\\\"\\n        \\n        # Add imports if available\\n        imports = file_analysis.get('imports', [])\\n        if imports:\\n            doc_content += \\\"## Dependencies\\\\n\\\\n\\\"\\n            doc_content += \\\"This file imports:\\\\n\\\\n\\\"\\n            for imp in imports[:10]:  # Limit to first 10 imports\\n                doc_content += f\\\"- `{imp}`\\\\n\\\"\\n            if len(imports) > 10:\\n                doc_content += f\\\"- ... and {len(imports) - 10} more\\\\n\\\"\\n            doc_content += \\\"\\\\n\\\"\\n        \\n        return doc_content\\n    \\n    def generate_architecture_docs(self, repo_analysis: Dict[str, Any]) -> str:\\n        \\\"\\\"\\\"Generate architecture documentation.\\\"\\\"\\\"\\n        repo_name = repo_analysis.get('repo_name', 'Repository')\\n        stats = repo_analysis.get('statistics', {})\\n        \\n        # Analyze project structure\\n        languages = stats.get('languages', {})\\n        files = repo_analysis.get('files', [])\\n        \\n        # Group files by directory\\n        directories = {}\\n        for file_data in files:\\n            dir_path = str(Path(file_data['file_path']).parent)\\n            if dir_path not in directories:\\n                directories[dir_path] = []\\n            directories[dir_path].append(file_data)\\n        \\n        # Build context for architecture analysis\\n        context = []\\n        context.append(f\\\"Repository: {repo_name}\\\")\\n        context.append(f\\\"Languages: {', '.join(languages.keys())}\\\")\\n        context.append(f\\\"Total files: {stats.get('total_files', 0)}\\\")\\n        \\n        context.append(\\\"\\\\nDirectory structure:\\\")\\n        for dir_path, dir_files in sorted(directories.items())[:15]:  # Limit directories\\n            file_count = len(dir_files)\\n            main_types = set()\\n            for f in dir_files:\\n                if f.get('language'):\\n                    main_types.add(f['language'])\\n            context.append(f\\\"- {dir_path}: {file_count} files ({', '.join(main_types)})\\\")\\n        \\n        # Add key files analysis\\n        key_files = []\\n        for file_data in files:\\n            if any(keyword in file_data['file_path'].lower() for keyword in ['main', 'app', 'index', '__init__', 'server', 'client']):\\n                key_files.append(file_data['file_path'])\\n        \\n        if key_files:\\n            context.append(f\\\"\\\\nKey files: {', '.join(key_files[:10])}\\\")\\n        \\n        context_str = '\\\\n'.join(context)\\n        \\n        prompt = f\\\"\\\"\\\"Analyze the architecture of this project and generate comprehensive architecture documentation:\\n\\n{context_str}\\n\\nPlease provide:\\n1. High-level architecture overview\\n2. Component breakdown and relationships\\n3. Data flow and system interactions\\n4. Design patterns used\\n5. Technology stack analysis\\n6. Scalability considerations\\n7. Deployment architecture\\n\\nFormat as professional technical documentation with proper Markdown structure.\\\"\\\"\\\"\\n\\n        try:\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\n        except Exception as e:\\n            return f\\\"# Architecture Documentation\\\\n\\\\nError generating architecture docs: {str(e)}\\\"\\n    \\n    def generate_examples_docs(self, repo_analysis: Dict[str, Any]) -> str:\\n        \\\"\\\"\\\"Generate usage examples documentation.\\\"\\\"\\\"\\n        repo_name = repo_analysis.get('repo_name', 'Repository')\\n        languages = repo_analysis.get('statistics', {}).get('languages', {})\\n        \\n        # Find main entry points\\n        entry_points = []\\n        main_classes = []\\n        main_functions = []\\n        \\n        for file_data in repo_analysis.get('files', []):\\n            if file_data.get('file_type') == 'code':\\n                elements = file_data.get('elements', [])\\n                \\n                # Look for main functions or entry points\\n                for element in elements:\\n                    if element['name'].lower() in ['main', 'run', 'start', 'init']:\\n                        entry_points.append({\\n                            'name': element['name'],\\n                            'file': file_data['file_path'],\\n                            'signature': element.get('signature', ''),\\n                            'type': element['type']\\n                        })\\n                    \\n                    if element['type'] == 'class' and len(element.get('name', '')) > 3:\\n                        main_classes.append({\\n                            'name': element['name'],\\n                            'file': file_data['file_path'],\\n                            'signature': element.get('signature', ''),\\n                            'docstring': element.get('docstring', '')\\n                        })\\n                    \\n                    if element['type'] == 'function' and element.get('docstring'):\\n                        main_functions.append({\\n                            'name': element['name'],\\n                            'file': file_data['file_path'],\\n                            'signature': element.get('signature', ''),\\n                            'docstring': element.get('docstring', '')\\n                        })\\n        \\n        # Build context\\n        context = []\\n        context.append(f\\\"Repository: {repo_name}\\\")\\n        context.append(f\\\"Languages: {', '.join(languages.keys())}\\\")\\n        \\n        if entry_points:\\n            context.append(\\\"\\\\nEntry points:\\\")\\n            for ep in entry_points[:5]:\\n                context.append(f\\\"- {ep['name']} in {ep['file']}\\\")\\n        \\n        if main_classes:\\n            context.append(\\\"\\\\nMain classes:\\\")\\n            for cls in main_classes[:5]:\\n                context.append(f\\\"- {cls['name']} in {cls['file']}\\\")\\n        \\n        if main_functions:\\n            context.append(\\\"\\\\nKey functions:\\\")\\n            for func in main_functions[:5]:\\n                context.append(f\\\"- {func['name']} in {func['file']}: {func['docstring'][:50]}...\\\")\\n        \\n        context_str = '\\\\n'.join(context)\\n        \\n        prompt = f\\\"\\\"\\\"Generate practical usage examples and tutorials for this project:\\n\\n{context_str}\\n\\nPlease provide:\\n1. Quick start example\\n2. Basic usage patterns\\n3. Common use cases with code examples\\n4. Integration examples\\n5. Configuration examples\\n6. Troubleshooting common issues\\n\\nInclude actual code snippets with explanations. Format with proper Markdown and code blocks.\\\"\\\"\\\"\\n\\n        try:\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\n        except Exception as e:\\n            return f\\\"# Usage Examples\\\\n\\\\nError generating examples: {str(e)}\\\"\\n    \\n    def generate_table_of_contents(self, documentation: Dict[str, str]) -> str:\\n        \\\"\\\"\\\"Generate table of contents for all documentation.\\\"\\\"\\\"\\n        toc_content = \\\"# Table of Contents\\\\n\\\\n\\\"\\n        toc_content += \\\"This repository contains the following documentation:\\\\n\\\\n\\\"\\n        \\n        # Main documentation\\n        main_docs = ['README.md', 'ARCHITECTURE.md', 'EXAMPLES.md']\\n        for doc in main_docs:\\n            if doc in documentation:\\n                toc_content += f\\\"- [{doc}](./{doc})\\\\n\\\"\\n        \\n        # API documentation\\n        api_docs = [k for k in documentation.keys() if k.startswith('api/')]\\n        if api_docs:\\n            toc_content += \\\"\\\\n## API Documentation\\\\n\\\\n\\\"\\n            for doc in sorted(api_docs):\\n                file_name = Path(doc).stem\\n                toc_content += f\\\"- [{file_name}](./{doc})\\\\n\\\"\\n        \\n        toc_content += f\\\"\\\\n---\\\\n\\\\n*Documentation generated automatically from codebase analysis.*\\\"\\n        \\n        return toc_content\\n    \\n    def update_existing_docs(self, repo_path: str, analysis: Dict[str, Any]) -> Dict[str, str]:\\n        \\\"\\\"\\\"Update existing documentation files with new analysis.\\\"\\\"\\\"\\n        repo_path = Path(repo_path)\\n        updates = {}\\n        \\n        # Check for existing README\\n        readme_path = repo_path / 'README.md'\\n        if readme_path.exists():\\n            with open(readme_path, 'r', encoding='utf-8') as f:\\n                existing_readme = f.read()\\n            \\n            # Generate enhancement suggestions\\n            prompt = f\\\"\\\"\\\"Analyze this existing README and suggest improvements based on the codebase analysis:\\n\\nCurrent README:\\n{existing_readme[:2000]}...\\n\\nCodebase info:\\n- Files: {analysis.get('statistics', {}).get('total_files', 0)}\\n- Languages: {', '.join(analysis.get('statistics', {}).get('languages', {}).keys())}\\n- Key components: {len(analysis.get('files', []))} files analyzed\\n\\nSuggest specific improvements while preserving the existing structure and content.\\\"\\\"\\\"\\n\\n            try:\\n                suggestions = self.ollama_client.generate(prompt, temperature=0.3)\\n                updates['README_suggestions.md'] = suggestions\\n            except Exception as e:\\n                updates['README_suggestions.md'] = f\\\"Error generating suggestions: {str(e)}\\\"\\n        \\n        return updates\\n\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n      \"file_type\": \"code\",\n      \"language\": \"python\",\n      \"imports\": [\n        \"argparse\",\n        \"asyncio\",\n        \"sys\",\n        \"pathlib.Path\",\n        \"typing.Optional\",\n        \"config.settings\",\n        \"repository_analyzer.RepositoryAnalyzer\",\n        \"ollama_client.OllamaClient\",\n        \"vector_store.VectorStore\",\n        \"rag_system.RAGSystem\",\n        \"documentation_generator.DocumentationBuilder\",\n        \"documentation_generator.DocumentationConfig\",\n        \"api.main\"\n      ],\n      \"elements\": [\n        {\n          \"name\": \"LocalDeepWiki\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 21,\n          \"line_end\": 254,\n          \"docstring\": \"Main class for Local DeepWiki functionality.\",\n          \"signature\": \"class LocalDeepWiki\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"LocalDeepWiki.__init__\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 24,\n          \"line_end\": 30,\n          \"docstring\": \"Initialize LocalDeepWiki with all components.\",\n          \"signature\": \"def __init__(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"LocalDeepWiki.check_prerequisites\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 32,\n          \"line_end\": 65,\n          \"docstring\": \"Check if all prerequisites are met.\",\n          \"signature\": \"def check_prerequisites(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"LocalDeepWiki.analyze_repository\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 67,\n          \"line_end\": 104,\n          \"docstring\": \"Analyze a repository and add it to the vector store.\",\n          \"signature\": \"def analyze_repository(self, repo_path, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"LocalDeepWiki.query_repository\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 106,\n          \"line_end\": 129,\n          \"docstring\": \"Query a repository using the RAG system.\",\n          \"signature\": \"def query_repository(self, query, repo_name, stream)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"LocalDeepWiki.interactive_chat\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 131,\n          \"line_end\": 164,\n          \"docstring\": \"Start an interactive chat session.\",\n          \"signature\": \"def interactive_chat(self, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"LocalDeepWiki.generate_documentation\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 166,\n          \"line_end\": 199,\n          \"docstring\": \"Generate documentation for a repository.\",\n          \"signature\": \"def generate_documentation(self, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"LocalDeepWiki.list_repositories\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 201,\n          \"line_end\": 231,\n          \"docstring\": \"List all analyzed repositories.\",\n          \"signature\": \"def list_repositories(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"LocalDeepWiki.show_stats\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 233,\n          \"line_end\": 254,\n          \"docstring\": \"Show system statistics.\",\n          \"signature\": \"def show_stats(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"main\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 256,\n          \"line_end\": 342,\n          \"docstring\": \"Main CLI interface.\",\n          \"signature\": \"def main()\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"__init__\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 24,\n          \"line_end\": 30,\n          \"docstring\": \"Initialize LocalDeepWiki with all components.\",\n          \"signature\": \"def __init__(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"check_prerequisites\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 32,\n          \"line_end\": 65,\n          \"docstring\": \"Check if all prerequisites are met.\",\n          \"signature\": \"def check_prerequisites(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"analyze_repository\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 67,\n          \"line_end\": 104,\n          \"docstring\": \"Analyze a repository and add it to the vector store.\",\n          \"signature\": \"def analyze_repository(self, repo_path, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"query_repository\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 106,\n          \"line_end\": 129,\n          \"docstring\": \"Query a repository using the RAG system.\",\n          \"signature\": \"def query_repository(self, query, repo_name, stream)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"interactive_chat\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 131,\n          \"line_end\": 164,\n          \"docstring\": \"Start an interactive chat session.\",\n          \"signature\": \"def interactive_chat(self, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"generate_documentation\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 166,\n          \"line_end\": 199,\n          \"docstring\": \"Generate documentation for a repository.\",\n          \"signature\": \"def generate_documentation(self, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"list_repositories\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 201,\n          \"line_end\": 231,\n          \"docstring\": \"List all analyzed repositories.\",\n          \"signature\": \"def list_repositories(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"show_stats\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\main.py\",\n          \"line_start\": 233,\n          \"line_end\": 254,\n          \"docstring\": \"Show system statistics.\",\n          \"signature\": \"def show_stats(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        }\n      ],\n      \"summary\": null,\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\nLocal DeepWiki - Main entry point and CLI interface.\\n\\nA local implementation of DeepWiki using Ollama for LLM inference.\\n\\\"\\\"\\\"\\n\\nimport argparse\\nimport asyncio\\nimport sys\\nfrom pathlib import Path\\nfrom typing import Optional\\n\\nfrom config import settings\\nfrom repository_analyzer import RepositoryAnalyzer\\nfrom ollama_client import OllamaClient\\nfrom vector_store import VectorStore\\nfrom rag_system import RAGSystem\\nfrom documentation_generator import DocumentationBuilder, DocumentationConfig\\n\\nclass LocalDeepWiki:\\n    \\\"\\\"\\\"Main class for Local DeepWiki functionality.\\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        \\\"\\\"\\\"Initialize LocalDeepWiki with all components.\\\"\\\"\\\"\\n        self.ollama_client = OllamaClient()\\n        self.vector_store = VectorStore()\\n        self.rag_system = RAGSystem(self.vector_store, self.ollama_client)\\n        self.repository_analyzer = RepositoryAnalyzer()\\n        self.documentation_builder = DocumentationBuilder(self.ollama_client)\\n    \\n    def check_prerequisites(self) -> bool:\\n        \\\"\\\"\\\"Check if all prerequisites are met.\\\"\\\"\\\"\\n        print(\\\"Checking prerequisites...\\\")\\n        \\n        # Check Ollama\\n        if not self.ollama_client.is_available():\\n            print(\\\"X Ollama server is not available at\\\", settings.OLLAMA_BASE_URL)\\n            print(\\\"Please start Ollama first:\\\")\\n            print(\\\"  ollama serve\\\")\\n            return False\\n        \\n        print(\\\"OK Ollama server is available\\\")\\n        \\n        # Check model\\n        models = self.ollama_client.list_models()\\n        model_names = [model['name'] for model in models]\\n        \\n        if settings.OLLAMA_MODEL not in model_names:\\n            print(f\\\"X Model '{settings.OLLAMA_MODEL}' is not available\\\")\\n            print(\\\"Available models:\\\", model_names)\\n            print(f\\\"To download the model, run:\\\")\\n            print(f\\\"  ollama pull {settings.OLLAMA_MODEL}\\\")\\n            return False\\n        \\n        print(f\\\"OK Model '{settings.OLLAMA_MODEL}' is available\\\")\\n        \\n        # Check embedding model\\n        if settings.OLLAMA_EMBEDDING_MODEL not in model_names:\\n            print(f\\\"! Embedding model '{settings.OLLAMA_EMBEDDING_MODEL}' not found\\\")\\n            print(\\\"Will use fallback embedding model\\\")\\n        else:\\n            print(f\\\"OK Embedding model '{settings.OLLAMA_EMBEDDING_MODEL}' is available\\\")\\n        \\n        return True\\n    \\n    def analyze_repository(self, repo_path: str, repo_name: Optional[str] = None) -> bool:\\n        \\\"\\\"\\\"Analyze a repository and add it to the vector store.\\\"\\\"\\\"\\n        repo_path = Path(repo_path).resolve()\\n        \\n        if not repo_path.exists():\\n            print(f\\\"X Repository path does not exist: {repo_path}\\\")\\n            return False\\n        \\n        repo_name = repo_name or repo_path.name\\n        print(f\\\"* Analyzing repository: {repo_name}\\\")\\n        print(f\\\"   Path: {repo_path}\\\")\\n        \\n        try:\\n            # Analyze repository structure\\n            print(\\\"   Parsing files and extracting structure...\\\")\\n            analysis = self.repository_analyzer.analyze_repository(str(repo_path))\\n            analysis['repo_name'] = repo_name\\n            \\n            # Save analysis\\n            analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\"{repo_name}_analysis.json\\\"\\n            self.repository_analyzer.save_analysis(analysis, str(analysis_path))\\n            print(f\\\"   Analysis saved to: {analysis_path}\\\")\\n            \\n            # Add to vector store\\n            print(\\\"   Adding to vector store...\\\")\\n            chunks_added = self.vector_store.add_repository(analysis)\\n            \\n            print(f\\\"OK Repository analysis complete!\\\")\\n            print(f\\\"   Files analyzed: {analysis['statistics']['total_files']}\\\")\\n            print(f\\\"   Code files: {analysis['statistics']['code_files']}\\\")\\n            print(f\\\"   Languages: {', '.join(analysis['statistics']['languages'].keys())}\\\")\\n            print(f\\\"   Chunks added to vector store: {chunks_added}\\\")\\n            \\n            return True\\n            \\n        except Exception as e:\\n            print(f\\\"X Error analyzing repository: {e}\\\")\\n            return False\\n    \\n    def query_repository(self, query: str, repo_name: Optional[str] = None, stream: bool = True):\\n        \\\"\\\"\\\"Query a repository using the RAG system.\\\"\\\"\\\"\\n        print(f\\\"? Query: {query}\\\")\\n        if repo_name:\\n            print(f\\\"   Repository: {repo_name}\\\")\\n        \\n        try:\\n            result = self.rag_system.query(query, repo_name=repo_name, stream=False)\\n            \\n            if result['context']:\\n                print(\\\"\\\\n> Response:\\\")\\n                print(result['response'])\\n                \\n                if result['sources']:\\n                    print(\\\"\\\\n* Sources:\\\")\\n                    for i, source in enumerate(result['sources'], 1):\\n                        print(f\\\"   {i}. {source.get('file_path', 'Unknown')}\\\")\\n                        if source.get('element_name'):\\n                            print(f\\\"      Element: {source['element_name']}\\\")\\n            else:\\n                print(\\\"X No relevant context found for your query.\\\")\\n                \\n        except Exception as e:\\n            print(f\\\"X Error processing query: {e}\\\")\\n    \\n    def interactive_chat(self, repo_name: Optional[str] = None):\\n        \\\"\\\"\\\"Start an interactive chat session.\\\"\\\"\\\"\\n        print(\\\"* Interactive Chat Mode\\\")\\n        print(\\\"Type 'quit' or 'exit' to end the session\\\")\\n        if repo_name:\\n            print(f\\\"Querying repository: {repo_name}\\\")\\n        print(\\\"-\\\" * 50)\\n        \\n        messages = []\\n        \\n        while True:\\n            try:\\n                user_input = input(\\\"\\\\nYou: \\\").strip()\\n                \\n                if user_input.lower() in ['quit', 'exit', 'q']:\\n                    print(\\\"Goodbye!\\\")\\n                    break\\n                \\n                if not user_input:\\n                    continue\\n                \\n                messages.append({\\\"role\\\": \\\"user\\\", \\\"content\\\": user_input})\\n                \\n                print(\\\"\\\\nAssistant: \\\", end=\\\"\\\", flush=True)\\n                response = self.rag_system.chat_with_repo(messages, repo_name)\\n                print(response)\\n                \\n                messages.append({\\\"role\\\": \\\"assistant\\\", \\\"content\\\": response})\\n                \\n            except KeyboardInterrupt:\\n                print(\\\"\\\\nGoodbye!\\\")\\n                break\\n            except Exception as e:\\n                print(f\\\"\\\\nX Error: {e}\\\")\\n    \\n    def generate_documentation(self, repo_name: str):\\n        \\\"\\\"\\\"Generate documentation for a repository.\\\"\\\"\\\"\\n        print(f\\\"* Generating documentation for: {repo_name}\\\")\\n        \\n        # Load analysis\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\"{repo_name}_analysis.json\\\"\\n        if not analysis_path.exists():\\n            print(f\\\"X Repository {repo_name} not found. Please analyze it first.\\\")\\n            return False\\n        \\n        try:\\n            analysis = self.repository_analyzer.load_analysis(str(analysis_path))\\n            \\n            config = DocumentationConfig(\\n                include_overview=True,\\n                include_api_docs=True,\\n                include_examples=True,\\n                include_architecture=True\\n            )\\n            \\n            docs = self.documentation_builder.generate_full_documentation(analysis, config)\\n            \\n            print(f\\\"OK Documentation generated!\\\")\\n            print(f\\\"   Files created: {len(docs)}\\\")\\n            print(f\\\"   Output directory: {Path(settings.DOCS_DIRECTORY) / repo_name}\\\")\\n            \\n            for doc_name in docs.keys():\\n                print(f\\\"   - {doc_name}\\\")\\n            \\n            return True\\n            \\n        except Exception as e:\\n            print(f\\\"X Error generating documentation: {e}\\\")\\n            return False\\n    \\n    def list_repositories(self):\\n        \\\"\\\"\\\"List all analyzed repositories.\\\"\\\"\\\"\\n        repos_dir = Path(settings.REPOS_DIRECTORY)\\n        \\n        if not repos_dir.exists():\\n            print(\\\"No repositories found.\\\")\\n            return\\n        \\n        analysis_files = list(repos_dir.glob(\\\"*_analysis.json\\\"))\\n        \\n        if not analysis_files:\\n            print(\\\"No repositories found.\\\")\\n            return\\n        \\n        print(\\\"* Analyzed Repositories:\\\")\\n        print(\\\"-\\\" * 50)\\n        \\n        for analysis_file in analysis_files:\\n            try:\\n                analysis = self.repository_analyzer.load_analysis(str(analysis_file))\\n                repo_name = analysis.get('repo_name', analysis_file.stem.replace('_analysis', ''))\\n                stats = analysis.get('statistics', {})\\n                \\n                print(f\\\"+ {repo_name}\\\")\\n                print(f\\\"   Path: {analysis.get('repo_path', 'Unknown')}\\\")\\n                print(f\\\"   Files: {stats.get('total_files', 0)} total, {stats.get('code_files', 0)} code\\\")\\n                print(f\\\"   Languages: {', '.join(stats.get('languages', {}).keys())}\\\")\\n                print()\\n                \\n            except Exception as e:\\n                print(f\\\"X Error loading {analysis_file}: {e}\\\")\\n    \\n    def show_stats(self):\\n        \\\"\\\"\\\"Show system statistics.\\\"\\\"\\\"\\n        print(\\\"* System Statistics\\\")\\n        print(\\\"-\\\" * 30)\\n        \\n        # Vector store stats\\n        vector_stats = self.vector_store.get_collection_stats()\\n        print(f\\\"Documents in vector store: {vector_stats.get('total_documents', 0)}\\\")\\n        \\n        # Repository count\\n        repos_dir = Path(settings.REPOS_DIRECTORY)\\n        repo_count = len(list(repos_dir.glob(\\\"*_analysis.json\\\"))) if repos_dir.exists() else 0\\n        print(f\\\"Analyzed repositories: {repo_count}\\\")\\n        \\n        # Generated docs count\\n        docs_dir = Path(settings.DOCS_DIRECTORY)\\n        doc_count = len(list(docs_dir.rglob(\\\"*.md\\\"))) if docs_dir.exists() else 0\\n        print(f\\\"Generated documentation files: {doc_count}\\\")\\n        \\n        # Ollama status\\n        print(f\\\"Ollama available: {'OK' if self.ollama_client.is_available() else 'X'}\\\")\\n        print(f\\\"Current model: {settings.OLLAMA_MODEL}\\\")\\n\\ndef main():\\n    \\\"\\\"\\\"Main CLI interface.\\\"\\\"\\\"\\n    parser = argparse.ArgumentParser(description=\\\"Local DeepWiki - Chat with your code repositories\\\")\\n    \\n    subparsers = parser.add_subparsers(dest='command', help='Available commands')\\n    \\n    # Check command\\n    subparsers.add_parser('check', help='Check system prerequisites')\\n    \\n    # Analyze command\\n    analyze_parser = subparsers.add_parser('analyze', help='Analyze a repository')\\n    analyze_parser.add_argument('repo_path', help='Path to the repository')\\n    analyze_parser.add_argument('--name', help='Custom name for the repository')\\n    \\n    # Query command\\n    query_parser = subparsers.add_parser('query', help='Query a repository')\\n    query_parser.add_argument('query', help='Your question or query')\\n    query_parser.add_argument('--repo', help='Repository name to query')\\n    \\n    # Chat command\\n    chat_parser = subparsers.add_parser('chat', help='Start interactive chat')\\n    chat_parser.add_argument('--repo', help='Repository name to chat with')\\n    \\n    # Docs command\\n    docs_parser = subparsers.add_parser('docs', help='Generate documentation')\\n    docs_parser.add_argument('repo_name', help='Repository name')\\n    \\n    # List command\\n    subparsers.add_parser('list', help='List analyzed repositories')\\n    \\n    # Stats command\\n    subparsers.add_parser('stats', help='Show system statistics')\\n    \\n    # Server command\\n    server_parser = subparsers.add_parser('server', help='Start web server')\\n    server_parser.add_argument('--host', default=settings.API_HOST, help='Host address')\\n    server_parser.add_argument('--port', type=int, default=settings.API_PORT, help='Port number')\\n    \\n    args = parser.parse_args()\\n    \\n    if not args.command:\\n        parser.print_help()\\n        return\\n    \\n    # Initialize LocalDeepWiki\\n    ldw = LocalDeepWiki()\\n    \\n    if args.command == 'check':\\n        if ldw.check_prerequisites():\\n            print(\\\"\\\\nOK All prerequisites are met! You're ready to use Local DeepWiki.\\\")\\n        else:\\n            print(\\\"\\\\nX Please fix the issues above before using Local DeepWiki.\\\")\\n            sys.exit(1)\\n    \\n    elif args.command == 'analyze':\\n        if not ldw.check_prerequisites():\\n            sys.exit(1)\\n        ldw.analyze_repository(args.repo_path, args.name)\\n    \\n    elif args.command == 'query':\\n        if not ldw.check_prerequisites():\\n            sys.exit(1)\\n        ldw.query_repository(args.query, args.repo)\\n    \\n    elif args.command == 'chat':\\n        if not ldw.check_prerequisites():\\n            sys.exit(1)\\n        ldw.interactive_chat(args.repo)\\n    \\n    elif args.command == 'docs':\\n        if not ldw.check_prerequisites():\\n            sys.exit(1)\\n        ldw.generate_documentation(args.repo_name)\\n    \\n    elif args.command == 'list':\\n        ldw.list_repositories()\\n    \\n    elif args.command == 'stats':\\n        ldw.show_stats()\\n    \\n    elif args.command == 'server':\\n        if not ldw.check_prerequisites():\\n            sys.exit(1)\\n        \\n        # Import and run the API server\\n        from api import main as run_server\\n        run_server()\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\\n\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n      \"file_type\": \"code\",\n      \"language\": \"python\",\n      \"imports\": [\n        \"json\",\n        \"requests\",\n        \"asyncio\",\n        \"aiohttp\",\n        \"typing.Dict\",\n        \"typing.List\",\n        \"typing.Any\",\n        \"typing.Optional\",\n        \"typing.AsyncGenerator\",\n        \"config.settings\"\n      ],\n      \"elements\": [\n        {\n          \"name\": \"OllamaClient\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 10,\n          \"line_end\": 231,\n          \"docstring\": \"Client for interacting with Ollama local LLM server.\",\n          \"signature\": \"class OllamaClient\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"OllamaClient.__init__\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 13,\n          \"line_end\": 16,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self, base_url, model)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"OllamaClient.is_available\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 18,\n          \"line_end\": 24,\n          \"docstring\": \"Check if Ollama server is available.\",\n          \"signature\": \"def is_available(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"OllamaClient.list_models\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 26,\n          \"line_end\": 34,\n          \"docstring\": \"List available models.\",\n          \"signature\": \"def list_models(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"OllamaClient.pull_model\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 36,\n          \"line_end\": 57,\n          \"docstring\": \"Pull a model if not already available.\",\n          \"signature\": \"def pull_model(self, model_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"OllamaClient.generate\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 59,\n          \"line_end\": 80,\n          \"docstring\": \"Generate text using Ollama.\",\n          \"signature\": \"def generate(self, prompt, model)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"OllamaClient.get_embeddings\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 141,\n          \"line_end\": 160,\n          \"docstring\": \"Get embeddings for text.\",\n          \"signature\": \"def get_embeddings(self, text, model)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"OllamaClient.chat\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 185,\n          \"line_end\": 206,\n          \"docstring\": \"Chat completion using Ollama.\",\n          \"signature\": \"def chat(self, messages, model)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationGenerator\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 233,\n          \"line_end\": 352,\n          \"docstring\": \"Generate documentation using Ollama.\",\n          \"signature\": \"class DocumentationGenerator\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationGenerator.__init__\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 236,\n          \"line_end\": 237,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self, ollama_client)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationGenerator.generate_file_documentation\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 239,\n          \"line_end\": 295,\n          \"docstring\": \"Generate documentation for a single file.\",\n          \"signature\": \"def generate_file_documentation(self, file_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"DocumentationGenerator.generate_repository_overview\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 297,\n          \"line_end\": 352,\n          \"docstring\": \"Generate high-level repository documentation.\",\n          \"signature\": \"def generate_repository_overview(self, repo_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"__init__\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 13,\n          \"line_end\": 16,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self, base_url, model)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"is_available\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 18,\n          \"line_end\": 24,\n          \"docstring\": \"Check if Ollama server is available.\",\n          \"signature\": \"def is_available(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"list_models\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 26,\n          \"line_end\": 34,\n          \"docstring\": \"List available models.\",\n          \"signature\": \"def list_models(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"pull_model\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 36,\n          \"line_end\": 57,\n          \"docstring\": \"Pull a model if not already available.\",\n          \"signature\": \"def pull_model(self, model_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"generate\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 59,\n          \"line_end\": 80,\n          \"docstring\": \"Generate text using Ollama.\",\n          \"signature\": \"def generate(self, prompt, model)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"get_embeddings\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 141,\n          \"line_end\": 160,\n          \"docstring\": \"Get embeddings for text.\",\n          \"signature\": \"def get_embeddings(self, text, model)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"chat\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 185,\n          \"line_end\": 206,\n          \"docstring\": \"Chat completion using Ollama.\",\n          \"signature\": \"def chat(self, messages, model)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"__init__\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 236,\n          \"line_end\": 237,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self, ollama_client)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"generate_file_documentation\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 239,\n          \"line_end\": 295,\n          \"docstring\": \"Generate documentation for a single file.\",\n          \"signature\": \"def generate_file_documentation(self, file_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"generate_repository_overview\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\ollama_client.py\",\n          \"line_start\": 297,\n          \"line_end\": 352,\n          \"docstring\": \"Generate high-level repository documentation.\",\n          \"signature\": \"def generate_repository_overview(self, repo_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        }\n      ],\n      \"summary\": null,\n      \"content\": \"\\\"\\\"\\\"Ollama client for local LLM inference.\\\"\\\"\\\"\\n\\nimport json\\nimport requests\\nimport asyncio\\nimport aiohttp\\nfrom typing import Dict, List, Any, Optional, AsyncGenerator\\nfrom config import settings\\n\\nclass OllamaClient:\\n    \\\"\\\"\\\"Client for interacting with Ollama local LLM server.\\\"\\\"\\\"\\n    \\n    def __init__(self, base_url: str = None, model: str = None):\\n        self.base_url = base_url or settings.OLLAMA_BASE_URL\\n        self.model = model or settings.OLLAMA_MODEL\\n        self.embedding_model = settings.OLLAMA_EMBEDDING_MODEL\\n        \\n    def is_available(self) -> bool:\\n        \\\"\\\"\\\"Check if Ollama server is available.\\\"\\\"\\\"\\n        try:\\n            response = requests.get(f\\\"{self.base_url}/api/tags\\\", timeout=5)\\n            return response.status_code == 200\\n        except:\\n            return False\\n    \\n    def list_models(self) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"List available models.\\\"\\\"\\\"\\n        try:\\n            response = requests.get(f\\\"{self.base_url}/api/tags\\\")\\n            response.raise_for_status()\\n            return response.json().get('models', [])\\n        except Exception as e:\\n            print(f\\\"Error listing models: {e}\\\")\\n            return []\\n    \\n    def pull_model(self, model_name: str) -> bool:\\n        \\\"\\\"\\\"Pull a model if not already available.\\\"\\\"\\\"\\n        try:\\n            response = requests.post(\\n                f\\\"{self.base_url}/api/pull\\\",\\n                json={\\\"name\\\": model_name},\\n                stream=True\\n            )\\n            \\n            for line in response.iter_lines():\\n                if line:\\n                    data = json.loads(line)\\n                    if data.get('status'):\\n                        print(f\\\"Pulling {model_name}: {data['status']}\\\")\\n                    if data.get('error'):\\n                        print(f\\\"Error: {data['error']}\\\")\\n                        return False\\n            \\n            return True\\n        except Exception as e:\\n            print(f\\\"Error pulling model {model_name}: {e}\\\")\\n            return False\\n    \\n    def generate(self, prompt: str, model: str = None, **kwargs) -> str:\\n        \\\"\\\"\\\"Generate text using Ollama.\\\"\\\"\\\"\\n        model = model or self.model\\n        \\n        payload = {\\n            \\\"model\\\": model,\\n            \\\"prompt\\\": prompt,\\n            \\\"stream\\\": False,\\n            **kwargs\\n        }\\n        \\n        try:\\n            response = requests.post(\\n                f\\\"{self.base_url}/api/generate\\\",\\n                json=payload,\\n                timeout=120\\n            )\\n            response.raise_for_status()\\n            return response.json()['response']\\n        except Exception as e:\\n            print(f\\\"Error generating text: {e}\\\")\\n            raise\\n    \\n    async def generate_async(self, prompt: str, model: str = None, **kwargs) -> str:\\n        \\\"\\\"\\\"Generate text asynchronously.\\\"\\\"\\\"\\n        model = model or self.model\\n        \\n        payload = {\\n            \\\"model\\\": model,\\n            \\\"prompt\\\": prompt,\\n            \\\"stream\\\": False,\\n            **kwargs\\n        }\\n        \\n        async with aiohttp.ClientSession() as session:\\n            try:\\n                async with session.post(\\n                    f\\\"{self.base_url}/api/generate\\\",\\n                    json=payload,\\n                    timeout=aiohttp.ClientTimeout(total=120)\\n                ) as response:\\n                    response.raise_for_status()\\n                    result = await response.json()\\n                    return result['response']\\n            except Exception as e:\\n                print(f\\\"Error generating text: {e}\\\")\\n                raise\\n    \\n    async def generate_stream(self, prompt: str, model: str = None, **kwargs) -> AsyncGenerator[str, None]:\\n        \\\"\\\"\\\"Generate text with streaming response.\\\"\\\"\\\"\\n        model = model or self.model\\n        \\n        payload = {\\n            \\\"model\\\": model,\\n            \\\"prompt\\\": prompt,\\n            \\\"stream\\\": True,\\n            **kwargs\\n        }\\n        \\n        async with aiohttp.ClientSession() as session:\\n            try:\\n                async with session.post(\\n                    f\\\"{self.base_url}/api/generate\\\",\\n                    json=payload,\\n                    timeout=aiohttp.ClientTimeout(total=None)\\n                ) as response:\\n                    response.raise_for_status()\\n                    \\n                    async for line in response.content:\\n                        if line:\\n                            try:\\n                                data = json.loads(line)\\n                                if 'response' in data:\\n                                    yield data['response']\\n                                if data.get('done', False):\\n                                    break\\n                            except json.JSONDecodeError:\\n                                continue\\n            except Exception as e:\\n                print(f\\\"Error in streaming generation: {e}\\\")\\n                raise\\n    \\n    def get_embeddings(self, text: str, model: str = None) -> List[float]:\\n        \\\"\\\"\\\"Get embeddings for text.\\\"\\\"\\\"\\n        model = model or self.embedding_model\\n        \\n        payload = {\\n            \\\"model\\\": model,\\n            \\\"prompt\\\": text\\n        }\\n        \\n        try:\\n            response = requests.post(\\n                f\\\"{self.base_url}/api/embeddings\\\",\\n                json=payload,\\n                timeout=60\\n            )\\n            response.raise_for_status()\\n            return response.json()['embedding']\\n        except Exception as e:\\n            print(f\\\"Error getting embeddings: {e}\\\")\\n            raise\\n    \\n    async def get_embeddings_async(self, text: str, model: str = None) -> List[float]:\\n        \\\"\\\"\\\"Get embeddings asynchronously.\\\"\\\"\\\"\\n        model = model or self.embedding_model\\n        \\n        payload = {\\n            \\\"model\\\": model,\\n            \\\"prompt\\\": text\\n        }\\n        \\n        async with aiohttp.ClientSession() as session:\\n            try:\\n                async with session.post(\\n                    f\\\"{self.base_url}/api/embeddings\\\",\\n                    json=payload,\\n                    timeout=aiohttp.ClientTimeout(total=60)\\n                ) as response:\\n                    response.raise_for_status()\\n                    result = await response.json()\\n                    return result['embedding']\\n            except Exception as e:\\n                print(f\\\"Error getting embeddings: {e}\\\")\\n                raise\\n    \\n    def chat(self, messages: List[Dict[str, str]], model: str = None, **kwargs) -> str:\\n        \\\"\\\"\\\"Chat completion using Ollama.\\\"\\\"\\\"\\n        model = model or self.model\\n        \\n        payload = {\\n            \\\"model\\\": model,\\n            \\\"messages\\\": messages,\\n            \\\"stream\\\": False,\\n            **kwargs\\n        }\\n        \\n        try:\\n            response = requests.post(\\n                f\\\"{self.base_url}/api/chat\\\",\\n                json=payload,\\n                timeout=120\\n            )\\n            response.raise_for_status()\\n            return response.json()['message']['content']\\n        except Exception as e:\\n            print(f\\\"Error in chat completion: {e}\\\")\\n            raise\\n    \\n    async def chat_async(self, messages: List[Dict[str, str]], model: str = None, **kwargs) -> str:\\n        \\\"\\\"\\\"Chat completion asynchronously.\\\"\\\"\\\"\\n        model = model or self.model\\n        \\n        payload = {\\n            \\\"model\\\": model,\\n            \\\"messages\\\": messages,\\n            \\\"stream\\\": False,\\n            **kwargs\\n        }\\n        \\n        async with aiohttp.ClientSession() as session:\\n            try:\\n                async with session.post(\\n                    f\\\"{self.base_url}/api/chat\\\",\\n                    json=payload,\\n                    timeout=aiohttp.ClientTimeout(total=120)\\n                ) as response:\\n                    response.raise_for_status()\\n                    result = await response.json()\\n                    return result['message']['content']\\n            except Exception as e:\\n                print(f\\\"Error in chat completion: {e}\\\")\\n                raise\\n\\nclass DocumentationGenerator:\\n    \\\"\\\"\\\"Generate documentation using Ollama.\\\"\\\"\\\"\\n    \\n    def __init__(self, ollama_client: OllamaClient):\\n        self.client = ollama_client\\n    \\n    def generate_file_documentation(self, file_analysis: Dict[str, Any]) -> str:\\n        \\\"\\\"\\\"Generate documentation for a single file.\\\"\\\"\\\"\\n        \\n        # Build context from file analysis\\n        context = []\\n        context.append(f\\\"File: {file_analysis['file_path']}\\\")\\n        context.append(f\\\"Language: {file_analysis.get('language', 'Unknown')}\\\")\\n        \\n        if file_analysis.get('imports'):\\n            context.append(f\\\"Imports: {', '.join(file_analysis['imports'][:10])}\\\")\\n        \\n        # Add code elements\\n        elements_summary = []\\n        for element in file_analysis.get('elements', []):\\n            elem_type = element['type']\\n            name = element['name']\\n            signature = element.get('signature', '')\\n            docstring = element.get('docstring', '')\\n            \\n            elem_desc = f\\\"{elem_type}: {name}\\\"\\n            if signature:\\n                elem_desc += f\\\" - {signature}\\\"\\n            if docstring:\\n                elem_desc += f\\\" - {docstring[:100]}...\\\"\\n            \\n            elements_summary.append(elem_desc)\\n        \\n        if elements_summary:\\n            context.append(\\\"Code Elements:\\\")\\n            context.extend(elements_summary[:15])  # Limit to prevent prompt overflow\\n        \\n        # Add file content preview\\n        content = file_analysis.get('content', '')\\n        if content:\\n            content_preview = content[:2000] + \\\"...\\\" if len(content) > 2000 else content\\n            context.append(f\\\"Content Preview:\\\\n```\\\\n{content_preview}\\\\n```\\\")\\n        \\n        context_str = \\\"\\\\n\\\".join(context)\\n        \\n        prompt = f\\\"\\\"\\\"Analyze the following code file and generate comprehensive documentation in Markdown format.\\n\\n{context_str}\\n\\nPlease provide:\\n1. A brief overview of what this file does\\n2. Main components and their purposes\\n3. Key functions/classes with descriptions\\n4. Usage examples if applicable\\n5. Dependencies and relationships\\n\\nFormat the output as clean Markdown with appropriate headers and code blocks.\\\"\\\"\\\"\\n\\n        try:\\n            return self.client.generate(prompt, temperature=0.3, max_tokens=2000)\\n        except Exception as e:\\n            print(f\\\"Error generating documentation for {file_analysis['file_path']}: {e}\\\")\\n            return f\\\"# {file_analysis['file_path']}\\\\n\\\\nError generating documentation: {str(e)}\\\"\\n    \\n    def generate_repository_overview(self, repo_analysis: Dict[str, Any]) -> str:\\n        \\\"\\\"\\\"Generate high-level repository documentation.\\\"\\\"\\\"\\n        \\n        stats = repo_analysis.get('statistics', {})\\n        structure = repo_analysis.get('structure', {})\\n        \\n        context = []\\n        context.append(f\\\"Repository: {repo_analysis.get('repo_name', 'Unknown')}\\\")\\n        context.append(f\\\"Total Files: {stats.get('total_files', 0)}\\\")\\n        context.append(f\\\"Code Files: {stats.get('code_files', 0)}\\\")\\n        context.append(f\\\"Documentation Files: {stats.get('doc_files', 0)}\\\")\\n        context.append(f\\\"Total Lines: {stats.get('total_lines', 0)}\\\")\\n        \\n        if stats.get('languages'):\\n            langs = list(stats['languages'].keys())\\n            context.append(f\\\"Languages: {', '.join(langs)}\\\")\\n        \\n        # Add git info if available\\n        git_info = repo_analysis.get('git_info')\\n        if git_info:\\n            context.append(f\\\"Current Branch: {git_info.get('current_branch', 'Unknown')}\\\")\\n            if git_info.get('last_commit'):\\n                commit = git_info['last_commit']\\n                context.append(f\\\"Last Commit: {commit.get('message', '')[:100]}\\\")\\n        \\n        # Add main files/directories\\n        main_files = []\\n        for file_data in repo_analysis.get('files', [])[:10]:\\n            if file_data.get('file_type') == 'documentation':\\n                main_files.append(file_data['file_path'])\\n        \\n        if main_files:\\n            context.append(f\\\"Key Documentation: {', '.join(main_files)}\\\")\\n        \\n        context_str = \\\"\\\\n\\\".join(context)\\n        \\n        prompt = f\\\"\\\"\\\"Analyze this code repository and generate a comprehensive overview documentation in Markdown format.\\n\\nRepository Information:\\n{context_str}\\n\\nPlease provide:\\n1. Project overview and purpose\\n2. Architecture and structure\\n3. Key components and modules\\n4. Getting started guide\\n5. Development setup instructions\\n6. Main features and capabilities\\n\\nFormat as professional README-style documentation with proper Markdown structure.\\\"\\\"\\\"\\n\\n        try:\\n            return self.client.generate(prompt, temperature=0.3, max_tokens=3000)\\n        except Exception as e:\\n            print(f\\\"Error generating repository overview: {e}\\\")\\n            return f\\\"# Repository Overview\\\\n\\\\nError generating overview: {str(e)}\\\"\\n\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n      \"file_type\": \"code\",\n      \"language\": \"python\",\n      \"imports\": [\n        \"json\",\n        \"typing.List\",\n        \"typing.Dict\",\n        \"typing.Any\",\n        \"typing.Optional\",\n        \"typing.Tuple\",\n        \"dataclasses.dataclass\",\n        \"ollama_client.OllamaClient\",\n        \"vector_store.VectorStore\"\n      ],\n      \"elements\": [\n        {\n          \"name\": \"RAGContext\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 10,\n          \"line_end\": 15,\n          \"docstring\": \"Context information for RAG system.\",\n          \"signature\": \"class RAGContext\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 17,\n          \"line_end\": 329,\n          \"docstring\": \"Retrieval-Augmented Generation system.\",\n          \"signature\": \"class RAGSystem\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem.__init__\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 20,\n          \"line_end\": 62,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self, vector_store, ollama_client)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem.determine_query_type\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 64,\n          \"line_end\": 75,\n          \"docstring\": \"Determine the type of query to select appropriate prompt.\",\n          \"signature\": \"def determine_query_type(self, query)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem.retrieve_context\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 77,\n          \"line_end\": 79,\n          \"docstring\": \"Retrieve relevant context for the query.\",\n          \"signature\": \"def retrieve_context(self, query, n_results, filter_metadata)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem.build_context_text\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 81,\n          \"line_end\": 110,\n          \"docstring\": \"Build context text from retrieved chunks.\",\n          \"signature\": \"def build_context_text(self, retrieved_chunks, max_context_length)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem.generate_response\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 112,\n          \"line_end\": 133,\n          \"docstring\": \"Generate response using RAG context.\",\n          \"signature\": \"def generate_response(self, query, context, stream)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem.query\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 135,\n          \"line_end\": 191,\n          \"docstring\": \"Main query interface for RAG system.\",\n          \"signature\": \"def query(self, query, repo_name, file_path, n_results, stream)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem.explain_code\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 193,\n          \"line_end\": 214,\n          \"docstring\": \"Explain a specific code snippet.\",\n          \"signature\": \"def explain_code(self, code, language, context)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem.suggest_improvements\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 216,\n          \"line_end\": 237,\n          \"docstring\": \"Suggest improvements for code.\",\n          \"signature\": \"def suggest_improvements(self, code, language)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem.search_similar_code\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 239,\n          \"line_end\": 248,\n          \"docstring\": \"Find similar code in the repository.\",\n          \"signature\": \"def search_similar_code(self, code_snippet, language, n_results)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem.get_file_summary\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 250,\n          \"line_end\": 282,\n          \"docstring\": \"Get a summary of a specific file.\",\n          \"signature\": \"def get_file_summary(self, file_path, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem.get_repository_overview\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 284,\n          \"line_end\": 295,\n          \"docstring\": \"Get an overview of the repository.\",\n          \"signature\": \"def get_repository_overview(self, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RAGSystem.chat_with_repo\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 297,\n          \"line_end\": 329,\n          \"docstring\": \"Chat interface for conversational interaction with repository.\",\n          \"signature\": \"def chat_with_repo(self, messages, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"__init__\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 20,\n          \"line_end\": 62,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self, vector_store, ollama_client)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"determine_query_type\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 64,\n          \"line_end\": 75,\n          \"docstring\": \"Determine the type of query to select appropriate prompt.\",\n          \"signature\": \"def determine_query_type(self, query)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"retrieve_context\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 77,\n          \"line_end\": 79,\n          \"docstring\": \"Retrieve relevant context for the query.\",\n          \"signature\": \"def retrieve_context(self, query, n_results, filter_metadata)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"build_context_text\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 81,\n          \"line_end\": 110,\n          \"docstring\": \"Build context text from retrieved chunks.\",\n          \"signature\": \"def build_context_text(self, retrieved_chunks, max_context_length)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"generate_response\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 112,\n          \"line_end\": 133,\n          \"docstring\": \"Generate response using RAG context.\",\n          \"signature\": \"def generate_response(self, query, context, stream)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"query\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 135,\n          \"line_end\": 191,\n          \"docstring\": \"Main query interface for RAG system.\",\n          \"signature\": \"def query(self, query, repo_name, file_path, n_results, stream)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"explain_code\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 193,\n          \"line_end\": 214,\n          \"docstring\": \"Explain a specific code snippet.\",\n          \"signature\": \"def explain_code(self, code, language, context)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"suggest_improvements\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 216,\n          \"line_end\": 237,\n          \"docstring\": \"Suggest improvements for code.\",\n          \"signature\": \"def suggest_improvements(self, code, language)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"search_similar_code\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 239,\n          \"line_end\": 248,\n          \"docstring\": \"Find similar code in the repository.\",\n          \"signature\": \"def search_similar_code(self, code_snippet, language, n_results)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"get_file_summary\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 250,\n          \"line_end\": 282,\n          \"docstring\": \"Get a summary of a specific file.\",\n          \"signature\": \"def get_file_summary(self, file_path, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"get_repository_overview\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 284,\n          \"line_end\": 295,\n          \"docstring\": \"Get an overview of the repository.\",\n          \"signature\": \"def get_repository_overview(self, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"chat_with_repo\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\rag_system.py\",\n          \"line_start\": 297,\n          \"line_end\": 329,\n          \"docstring\": \"Chat interface for conversational interaction with repository.\",\n          \"signature\": \"def chat_with_repo(self, messages, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        }\n      ],\n      \"summary\": null,\n      \"content\": \"\\\"\\\"\\\"RAG (Retrieval-Augmented Generation) system for context-aware responses.\\\"\\\"\\\"\\n\\nimport json\\nfrom typing import List, Dict, Any, Optional, Tuple\\nfrom dataclasses import dataclass\\nfrom ollama_client import OllamaClient\\nfrom vector_store import VectorStore\\n\\n@dataclass\\nclass RAGContext:\\n    \\\"\\\"\\\"Context information for RAG system.\\\"\\\"\\\"\\n    query: str\\n    retrieved_chunks: List[Dict[str, Any]]\\n    context_text: str\\n    metadata: Dict[str, Any]\\n\\nclass RAGSystem:\\n    \\\"\\\"\\\"Retrieval-Augmented Generation system.\\\"\\\"\\\"\\n    \\n    def __init__(self, vector_store: VectorStore, ollama_client: OllamaClient):\\n        self.vector_store = vector_store\\n        self.ollama_client = ollama_client\\n        \\n        # System prompts for different types of queries\\n        self.system_prompts = {\\n            'code_explanation': \\\"\\\"\\\"You are an expert code analyst. Your task is to explain code clearly and concisely based on the provided context. \\n\\nFocus on:\\n- What the code does\\n- How it works\\n- Key components and their relationships\\n- Usage examples when relevant\\n- Best practices and potential improvements\\n\\nBe accurate and reference the specific code provided in the context.\\\"\\\"\\\",\\n\\n            'general_question': \\\"\\\"\\\"You are a helpful assistant that answers questions about codebases and documentation. \\n\\nUse the provided context to give accurate, helpful answers. If the context doesn't contain enough information to answer fully, say so and provide what information you can from the context.\\n\\nBe concise but thorough, and always ground your answers in the provided context.\\\"\\\"\\\",\\n\\n            'documentation': \\\"\\\"\\\"You are a technical documentation expert. Generate clear, well-structured documentation based on the provided code and context.\\n\\nFocus on:\\n- Clear explanations of functionality\\n- Proper formatting with headers and code blocks\\n- Usage examples and best practices\\n- Integration with other parts of the system\\n\\nUse proper Markdown formatting.\\\"\\\"\\\",\\n\\n            'troubleshooting': \\\"\\\"\\\"You are a debugging expert. Help identify issues, suggest solutions, and provide troubleshooting guidance based on the code context.\\n\\nFocus on:\\n- Identifying potential problems\\n- Suggesting specific solutions\\n- Explaining the reasoning behind recommendations\\n- Providing preventive measures\\n\\nBe practical and actionable in your suggestions.\\\"\\\"\\\"\\n        }\\n    \\n    def determine_query_type(self, query: str) -> str:\\n        \\\"\\\"\\\"Determine the type of query to select appropriate prompt.\\\"\\\"\\\"\\n        query_lower = query.lower()\\n        \\n        if any(word in query_lower for word in ['how does', 'what does', 'explain', 'how to']):\\n            return 'code_explanation'\\n        elif any(word in query_lower for word in ['document', 'generate docs', 'create documentation']):\\n            return 'documentation'\\n        elif any(word in query_lower for word in ['error', 'bug', 'fix', 'problem', 'issue', 'debug']):\\n            return 'troubleshooting'\\n        else:\\n            return 'general_question'\\n    \\n    def retrieve_context(self, query: str, n_results: int = 5, filter_metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"Retrieve relevant context for the query.\\\"\\\"\\\"\\n        return self.vector_store.search(query, n_results, filter_metadata)\\n    \\n    def build_context_text(self, retrieved_chunks: List[Dict[str, Any]], max_context_length: int = 4000) -> str:\\n        \\\"\\\"\\\"Build context text from retrieved chunks.\\\"\\\"\\\"\\n        context_parts = []\\n        current_length = 0\\n        \\n        for chunk in retrieved_chunks:\\n            text = chunk['text']\\n            metadata = chunk.get('metadata', {})\\n            \\n            # Add metadata header for context\\n            header = \\\"\\\"\\n            if metadata.get('file_path'):\\n                header += f\\\"File: {metadata['file_path']}\\\\n\\\"\\n            if metadata.get('element_name'):\\n                header += f\\\"Element: {metadata['element_name']} ({metadata.get('element_type', 'unknown')})\\\\n\\\"\\n            if metadata.get('type'):\\n                header += f\\\"Type: {metadata['type']}\\\\n\\\"\\n            \\n            chunk_text = header + \\\"\\\\n\\\" + text + \\\"\\\\n\\\" + \\\"=\\\"*50 + \\\"\\\\n\\\"\\n            \\n            # Check if adding this chunk would exceed max length\\n            if current_length + len(chunk_text) > max_context_length:\\n                if not context_parts:  # If first chunk is too long, truncate it\\n                    context_parts.append(chunk_text[:max_context_length])\\n                break\\n            \\n            context_parts.append(chunk_text)\\n            current_length += len(chunk_text)\\n        \\n        return \\\"\\\\n\\\".join(context_parts)\\n    \\n    def generate_response(self, query: str, context: RAGContext, stream: bool = False) -> str:\\n        \\\"\\\"\\\"Generate response using RAG context.\\\"\\\"\\\"\\n        query_type = self.determine_query_type(query)\\n        system_prompt = self.system_prompts.get(query_type, self.system_prompts['general_question'])\\n        \\n        # Build the full prompt\\n        full_prompt = f\\\"\\\"\\\"{system_prompt}\\n\\nCONTEXT:\\n{context.context_text}\\n\\nUSER QUERY: {query}\\n\\nPlease provide a helpful response based on the context above. If the context doesn't contain sufficient information, clearly state what information is missing.\\\"\\\"\\\"\\n\\n        try:\\n            if stream:\\n                return self.ollama_client.generate_stream(full_prompt, temperature=0.3)\\n            else:\\n                return self.ollama_client.generate(full_prompt, temperature=0.3)\\n        except Exception as e:\\n            return f\\\"Error generating response: {str(e)}\\\"\\n    \\n    def query(self, \\n              query: str, \\n              repo_name: str = None, \\n              file_path: str = None,\\n              n_results: int = 5,\\n              stream: bool = False) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Main query interface for RAG system.\\\"\\\"\\\"\\n        \\n        # Build filter for specific repository or file\\n        filter_metadata = {}\\n        if repo_name:\\n            filter_metadata['repo_name'] = repo_name\\n        if file_path:\\n            filter_metadata['file_path'] = file_path\\n        \\n        # Retrieve relevant context\\n        retrieved_chunks = self.retrieve_context(query, n_results, filter_metadata or None)\\n        \\n        if not retrieved_chunks:\\n            return {\\n                'response': f\\\"No relevant context found for query: {query}\\\",\\n                'context': None,\\n                'sources': []\\n            }\\n        \\n        # Build context\\n        context_text = self.build_context_text(retrieved_chunks)\\n        context = RAGContext(\\n            query=query,\\n            retrieved_chunks=retrieved_chunks,\\n            context_text=context_text,\\n            metadata={'repo_name': repo_name, 'file_path': file_path}\\n        )\\n        \\n        # Generate response\\n        response = self.generate_response(query, context, stream)\\n        \\n        # Extract sources\\n        sources = []\\n        for chunk in retrieved_chunks:\\n            metadata = chunk.get('metadata', {})\\n            source = {\\n                'file_path': metadata.get('file_path'),\\n                'element_name': metadata.get('element_name'),\\n                'type': metadata.get('type'),\\n                'distance': chunk.get('distance', 0)\\n            }\\n            # Remove None values\\n            source = {k: v for k, v in source.items() if v is not None}\\n            if source and source not in sources:\\n                sources.append(source)\\n        \\n        return {\\n            'response': response,\\n            'context': context,\\n            'sources': sources[:5]  # Limit to top 5 sources\\n        }\\n    \\n    def explain_code(self, code: str, language: str = None, context: str = None) -> str:\\n        \\\"\\\"\\\"Explain a specific code snippet.\\\"\\\"\\\"\\n        prompt = f\\\"\\\"\\\"Explain the following code clearly and concisely:\\n\\nLanguage: {language or 'Unknown'}\\n{f'Context: {context}' if context else ''}\\n\\nCode:\\n```{language or ''}\\n{code}\\n```\\n\\nPlease explain:\\n1. What this code does\\n2. How it works\\n3. Key components and their purpose\\n4. Any notable patterns or techniques used\\\"\\\"\\\"\\n\\n        try:\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\n        except Exception as e:\\n            return f\\\"Error explaining code: {str(e)}\\\"\\n    \\n    def suggest_improvements(self, code: str, language: str = None) -> str:\\n        \\\"\\\"\\\"Suggest improvements for code.\\\"\\\"\\\"\\n        prompt = f\\\"\\\"\\\"Analyze the following code and suggest improvements:\\n\\nLanguage: {language or 'Unknown'}\\n\\nCode:\\n```{language or ''}\\n{code}\\n```\\n\\nPlease provide:\\n1. Code quality assessment\\n2. Potential improvements\\n3. Best practices recommendations\\n4. Performance optimizations if applicable\\n5. Security considerations if relevant\\\"\\\"\\\"\\n\\n        try:\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\n        except Exception as e:\\n            return f\\\"Error suggesting improvements: {str(e)}\\\"\\n    \\n    def search_similar_code(self, code_snippet: str, language: str = None, n_results: int = 3) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"Find similar code in the repository.\\\"\\\"\\\"\\n        # Create a search query from the code\\n        query = f\\\"code similar to: {code_snippet[:200]}...\\\"\\n        \\n        filter_metadata = {}\\n        if language:\\n            filter_metadata['language'] = language\\n        \\n        return self.retrieve_context(query, n_results, filter_metadata or None)\\n    \\n    def get_file_summary(self, file_path: str, repo_name: str = None) -> str:\\n        \\\"\\\"\\\"Get a summary of a specific file.\\\"\\\"\\\"\\n        filter_metadata = {'file_path': file_path}\\n        if repo_name:\\n            filter_metadata['repo_name'] = repo_name\\n        \\n        # Get file overview chunk\\n        chunks = self.vector_store.search(\\n            f\\\"file overview {file_path}\\\", \\n            n_results=1, \\n            filter_metadata=filter_metadata\\n        )\\n        \\n        if not chunks:\\n            return f\\\"No information found for file: {file_path}\\\"\\n        \\n        chunk = chunks[0]\\n        context_text = chunk['text']\\n        \\n        prompt = f\\\"\\\"\\\"Provide a concise summary of this file:\\n\\n{context_text}\\n\\nSummary should include:\\n- Purpose of the file\\n- Main components\\n- Key functionality\\n- Dependencies\\\"\\\"\\\"\\n\\n        try:\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\n        except Exception as e:\\n            return f\\\"Error generating file summary: {str(e)}\\\"\\n    \\n    def get_repository_overview(self, repo_name: str) -> str:\\n        \\\"\\\"\\\"Get an overview of the repository.\\\"\\\"\\\"\\n        chunks = self.vector_store.search(\\n            f\\\"repository overview {repo_name}\\\",\\n            n_results=1,\\n            filter_metadata={'repo_name': repo_name, 'type': 'repository_overview'}\\n        )\\n        \\n        if not chunks:\\n            return f\\\"No overview found for repository: {repo_name}\\\"\\n        \\n        return chunks[0]['text']\\n    \\n    def chat_with_repo(self, messages: List[Dict[str, str]], repo_name: str = None) -> str:\\n        \\\"\\\"\\\"Chat interface for conversational interaction with repository.\\\"\\\"\\\"\\n        if not messages:\\n            return \\\"No messages provided\\\"\\n        \\n        # Get the latest user message\\n        latest_message = messages[-1]['content']\\n        \\n        # Get context for the latest query\\n        result = self.query(latest_message, repo_name=repo_name, stream=False)\\n        \\n        # Build conversation context\\n        conversation_context = \\\"\\\\n\\\".join([\\n            f\\\"{msg['role']}: {msg['content']}\\\" \\n            for msg in messages[:-1]  # Exclude the latest message\\n        ])\\n        \\n        # Enhanced prompt with conversation history\\n        prompt = f\\\"\\\"\\\"You are having a conversation about a codebase. Here's the conversation history:\\n\\n{conversation_context}\\n\\nCurrent context from the codebase:\\n{result['context'].context_text if result['context'] else 'No relevant context found'}\\n\\nCurrent question: {latest_message}\\n\\nPlease provide a helpful response that considers both the conversation history and the current context.\\\"\\\"\\\"\\n\\n        try:\\n            return self.ollama_client.generate(prompt, temperature=0.4)\\n        except Exception as e:\\n            return f\\\"Error in chat response: {str(e)}\\\"\\n\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\README.md\",\n      \"file_type\": \"documentation\",\n      \"language\": null,\n      \"imports\": [],\n      \"elements\": [],\n      \"summary\": null,\n      \"content\": \"# Local DeepWiki\\n\\nA local implementation of DeepWiki that allows you to chat with your code repositories using Ollama and local LLMs. This system provides repository analysis, documentation generation, and conversational AI capabilities - all running locally on your machine.\\n\\n## Features\\n\\n- ðŸ” **Repository Analysis**: Automatically parse and understand code structure\\n- ðŸ¤– **Local LLM Integration**: Uses Ollama for privacy-focused AI inference\\n- ðŸ“š **Documentation Generation**: Create comprehensive docs from your codebase\\n- ðŸ’¬ **Interactive Chat**: Ask questions about your code in natural language\\n- ðŸ”Ž **Semantic Search**: Find relevant code and documentation quickly\\n- ðŸŒ **Web Interface**: Clean, modern UI for easy interaction\\n- ðŸ“– **RAG System**: Context-aware responses grounded in your actual code\\n\\n## Prerequisites\\n\\n1. **Python 3.8+**\\n2. **Ollama** - Download from [ollama.ai](https://ollama.ai)\\n3. **Git** (optional, for repository information)\\n\\n## Installation\\n\\n1. **Clone this repository:**\\n```bash\\ngit clone <repository-url>\\ncd local_deepwiki\\n```\\n\\n2. **Install Python dependencies:**\\n```bash\\npip install -r requirements.txt\\n```\\n\\n3. **Install and start Ollama:**\\n```bash\\n# Install Ollama (see https://ollama.ai for platform-specific instructions)\\n\\n# Start Ollama server\\nollama serve\\n\\n# Pull required models (in another terminal)\\nollama pull llama2          # Main language model\\nollama pull nomic-embed-text  # Embedding model (optional)\\n```\\n\\n4. **Check prerequisites:**\\n```bash\\npython main.py check\\n```\\n\\n## Quick Start\\n\\n### 1. Analyze a Repository\\n\\n```bash\\n# Analyze your current directory\\npython main.py analyze .\\n\\n# Analyze a specific repository\\npython main.py analyze /path/to/your/repo --name my-project\\n\\n# Analyze with custom name\\npython main.py analyze ~/projects/my-app --name my-awesome-app\\n```\\n\\n### 2. Chat with Your Code\\n\\n```bash\\n# Start interactive chat\\npython main.py chat\\n\\n# Chat with specific repository\\npython main.py chat --repo my-project\\n```\\n\\n### 3. Query Your Repository\\n\\n```bash\\n# Ask a specific question\\npython main.py query \\\"How does user authentication work?\\\" --repo my-project\\n\\n# Query without specifying repository (searches all)\\npython main.py query \\\"Show me the main entry point\\\"\\n```\\n\\n### 4. Generate Documentation\\n\\n```bash\\n# Generate comprehensive documentation\\npython main.py docs my-project\\n```\\n\\n### 5. Web Interface\\n\\n```bash\\n# Start the web server\\npython main.py server\\n\\n# Or with custom host/port\\npython main.py server --host 127.0.0.1 --port 8080\\n```\\n\\nThen open http://localhost:8000 in your browser.\\n\\n## Configuration\\n\\nCreate a `.env` file to customize settings:\\n\\n```env\\n# Ollama Configuration\\nOLLAMA_BASE_URL=http://localhost:11434\\nOLLAMA_MODEL=llama2\\nOLLAMA_EMBEDDING_MODEL=nomic-embed-text\\n\\n# API Configuration\\nAPI_HOST=0.0.0.0\\nAPI_PORT=8000\\n\\n# Storage Configuration\\nCHROMA_PERSIST_DIRECTORY=./data/chroma_db\\nREPOS_DIRECTORY=./data/repos\\nDOCS_DIRECTORY=./data/generated_docs\\n\\n# Processing Configuration\\nMAX_CHUNK_SIZE=2000\\nCHUNK_OVERLAP=200\\nMAX_CONTEXT_LENGTH=4000\\n```\\n\\n## Supported Languages\\n\\nThe system can analyze and understand code in:\\n\\n- Python (.py)\\n- JavaScript/TypeScript (.js, .ts, .jsx, .tsx)\\n- Java (.java)\\n- C/C++ (.c, .cpp, .h)\\n- C# (.cs)\\n- PHP (.php)\\n- Ruby (.rb)\\n- Go (.go)\\n- Rust (.rs)\\n- Swift (.swift)\\n- Kotlin (.kt)\\n- Scala (.scala)\\n- And more...\\n\\nPlus documentation files:\\n- Markdown (.md)\\n- reStructuredText (.rst)\\n- Plain text (.txt)\\n\\n## CLI Commands\\n\\n### Repository Management\\n```bash\\n# List analyzed repositories\\npython main.py list\\n\\n# Show system statistics\\npython main.py stats\\n```\\n\\n### Analysis and Documentation\\n```bash\\n# Analyze repository\\npython main.py analyze <path> [--name <name>]\\n\\n# Generate documentation\\npython main.py docs <repo-name>\\n```\\n\\n### Querying\\n```bash\\n# One-time query\\npython main.py query \\\"<question>\\\" [--repo <name>]\\n\\n# Interactive chat\\npython main.py chat [--repo <name>]\\n```\\n\\n### Web Server\\n```bash\\n# Start web interface\\npython main.py server [--host <host>] [--port <port>]\\n```\\n\\n## API Endpoints\\n\\nWhen running the web server, these endpoints are available:\\n\\n### Health & System\\n- `GET /health` - System health check\\n- `GET /stats` - System statistics\\n- `GET /models` - List available Ollama models\\n\\n### Repository Management\\n- `POST /repositories/analyze` - Analyze repository\\n- `GET /repositories` - List repositories\\n- `DELETE /repositories/{name}` - Delete repository\\n\\n### Querying\\n- `POST /query` - Query with RAG system\\n- `POST /chat` - Chat interface\\n- `POST /explain` - Explain code snippet\\n- `POST /improve` - Suggest code improvements\\n\\n### Documentation\\n- `POST /repositories/{name}/generate-docs` - Generate docs\\n- `GET /repositories/{name}/docs` - List generated docs\\n- `GET /repositories/{name}/docs/{path}` - Get specific doc\\n\\n### Search\\n- `GET /search` - Search all repositories\\n- `GET /repositories/{name}/search` - Search specific repository\\n\\n## How It Works\\n\\n1. **Repository Analysis**: The system parses your codebase, extracting:\\n   - File structure and organization\\n   - Functions, classes, and their relationships\\n   - Import dependencies\\n   - Documentation and comments\\n   - Git information (if available)\\n\\n2. **Vector Embeddings**: Code and documentation are chunked and converted to embeddings using:\\n   - Ollama embedding models (preferred)\\n   - Sentence Transformers (fallback)\\n   - ChromaDB for efficient storage and retrieval\\n\\n3. **RAG System**: When you ask questions:\\n   - Your query is embedded and matched against the codebase\\n   - Relevant code snippets and documentation are retrieved\\n   - Context is provided to the LLM for accurate, grounded responses\\n\\n4. **Documentation Generation**: Using the analyzed structure:\\n   - README files with project overviews\\n   - API documentation for each file\\n   - Architecture documentation\\n   - Usage examples and tutorials\\n\\n## Example Queries\\n\\nHere are some example questions you can ask:\\n\\n### Code Understanding\\n- \\\"How does user authentication work in this project?\\\"\\n- \\\"What is the main entry point of the application?\\\"\\n- \\\"Show me all the API endpoints\\\"\\n- \\\"How is data validation handled?\\\"\\n\\n### Architecture Questions\\n- \\\"What's the overall architecture of this system?\\\"\\n- \\\"How do the different modules interact?\\\"\\n- \\\"What design patterns are used?\\\"\\n- \\\"What are the main dependencies?\\\"\\n\\n### Implementation Details\\n- \\\"How is error handling implemented?\\\"\\n- \\\"Where is the database connection configured?\\\"\\n- \\\"How are user permissions checked?\\\"\\n- \\\"What testing framework is used?\\\"\\n\\n### Documentation\\n- \\\"Generate API documentation for the user service\\\"\\n- \\\"Create a getting started guide\\\"\\n- \\\"Explain the deployment process\\\"\\n\\n## Troubleshooting\\n\\n### Ollama Issues\\n```bash\\n# Check if Ollama is running\\ncurl http://localhost:11434/api/tags\\n\\n# Pull required models\\nollama pull llama2\\nollama pull nomic-embed-text\\n\\n# Check model availability\\nollama list\\n```\\n\\n### Common Problems\\n\\n1. **\\\"Ollama server not available\\\"**\\n   - Make sure Ollama is installed and running (`ollama serve`)\\n   - Check the OLLAMA_BASE_URL in your configuration\\n\\n2. **\\\"Model not found\\\"**\\n   - Pull the required model: `ollama pull llama2`\\n   - Update OLLAMA_MODEL in configuration if using a different model\\n\\n3. **\\\"No relevant context found\\\"**\\n   - Make sure the repository has been analyzed\\n   - Try rephrasing your question\\n   - Check that the repository contains relevant code\\n\\n4. **Slow responses**\\n   - Consider using a smaller, faster model (e.g., `llama2:7b`)\\n   - Reduce MAX_CONTEXT_LENGTH in configuration\\n   - Use more specific queries\\n\\n### Performance Tips\\n\\n1. **Model Selection**: \\n   - Use `codellama` for better code understanding\\n   - Use `llama2:7b` for faster responses\\n   - Use `mistral` for a good balance\\n\\n2. **Configuration Tuning**:\\n   - Adjust MAX_CHUNK_SIZE for your hardware\\n   - Reduce MAX_CONTEXT_LENGTH for faster responses\\n   - Increase CHUNK_OVERLAP for better context\\n\\n3. **Repository Size**:\\n   - Large repositories may take time to analyze\\n   - Consider analyzing specific directories for faster results\\n   - Use .gitignore patterns to exclude unnecessary files\\n\\n## Contributing\\n\\n1. Fork the repository\\n2. Create a feature branch\\n3. Make your changes\\n4. Add tests if applicable\\n5. Submit a pull request\\n\\n## License\\n\\nThis project is licensed under the MIT License - see the LICENSE file for details.\\n\\n## Acknowledgments\\n\\n- [Ollama](https://ollama.ai) for local LLM inference\\n- [ChromaDB](https://www.trychroma.com/) for vector storage\\n- [LangChain](https://langchain.com/) for RAG implementation\\n- [FastAPI](https://fastapi.tiangolo.com/) for the web API\\n- [Vue.js](https://vuejs.org/) for the web interface\\n\\n## Roadmap\\n\\n- [ ] Support for more programming languages\\n- [ ] Advanced code analysis (call graphs, dependency analysis)\\n- [ ] Integration with popular IDEs\\n- [ ] Multi-repository projects support\\n- [ ] Custom model fine-tuning\\n- [ ] Collaborative features\\n- [ ] Plugin system for extensibility\\n\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n      \"file_type\": \"code\",\n      \"language\": \"python\",\n      \"imports\": [\n        \"os\",\n        \"ast\",\n        \"re\",\n        \"json\",\n        \"pathlib.Path\",\n        \"typing.Dict\",\n        \"typing.List\",\n        \"typing.Any\",\n        \"typing.Optional\",\n        \"typing.Tuple\",\n        \"dataclasses.dataclass\",\n        \"dataclasses.asdict\",\n        \"git\",\n        \"config.settings\"\n      ],\n      \"elements\": [\n        {\n          \"name\": \"CodeElement\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 14,\n          \"line_end\": 28,\n          \"docstring\": \"Represents a code element (function, class, etc.).\",\n          \"signature\": \"class CodeElement\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"CodeElement.__post_init__\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 26,\n          \"line_end\": 28,\n          \"docstring\": null,\n          \"signature\": \"def __post_init__(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"FileAnalysis\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 31,\n          \"line_end\": 45,\n          \"docstring\": \"Analysis results for a single file.\",\n          \"signature\": \"class FileAnalysis\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"FileAnalysis.__post_init__\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 41,\n          \"line_end\": 45,\n          \"docstring\": null,\n          \"signature\": \"def __post_init__(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 47,\n          \"line_end\": 348,\n          \"docstring\": \"Analyzes code repositories to extract structure and content.\",\n          \"signature\": \"class RepositoryAnalyzer\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer.__init__\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 50,\n          \"line_end\": 69,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer.analyze_repository\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 71,\n          \"line_end\": 132,\n          \"docstring\": \"Analyze an entire repository.\",\n          \"signature\": \"def analyze_repository(self, repo_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer.analyze_file\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 134,\n          \"line_end\": 170,\n          \"docstring\": \"Analyze a single file.\",\n          \"signature\": \"def analyze_file(self, file_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer._analyze_python_file\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 172,\n          \"line_end\": 230,\n          \"docstring\": \"Analyze Python file for structure.\",\n          \"signature\": \"def _analyze_python_file(self, analysis, content)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer._analyze_js_ts_file\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 232,\n          \"line_end\": 285,\n          \"docstring\": \"Analyze JavaScript/TypeScript file for structure.\",\n          \"signature\": \"def _analyze_js_ts_file(self, analysis, content)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer._get_function_args\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 287,\n          \"line_end\": 292,\n          \"docstring\": \"Extract function arguments as string.\",\n          \"signature\": \"def _get_function_args(self, node)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer._get_files_to_analyze\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 294,\n          \"line_end\": 307,\n          \"docstring\": \"Get list of files to analyze, respecting ignore patterns.\",\n          \"signature\": \"def _get_files_to_analyze(self, repo_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer._should_ignore_dir\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 309,\n          \"line_end\": 311,\n          \"docstring\": \"Check if directory should be ignored.\",\n          \"signature\": \"def _should_ignore_dir(self, dirname)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer._should_analyze_file\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 313,\n          \"line_end\": 316,\n          \"docstring\": \"Check if file should be analyzed.\",\n          \"signature\": \"def _should_analyze_file(self, file_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer._build_directory_structure\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 318,\n          \"line_end\": 338,\n          \"docstring\": \"Build a tree representation of the directory structure.\",\n          \"signature\": \"def _build_directory_structure(self, repo_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer.save_analysis\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 340,\n          \"line_end\": 343,\n          \"docstring\": \"Save analysis results to JSON file.\",\n          \"signature\": \"def save_analysis(self, analysis, output_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"RepositoryAnalyzer.load_analysis\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 345,\n          \"line_end\": 348,\n          \"docstring\": \"Load analysis results from JSON file.\",\n          \"signature\": \"def load_analysis(self, input_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"__post_init__\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 26,\n          \"line_end\": 28,\n          \"docstring\": null,\n          \"signature\": \"def __post_init__(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"__post_init__\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 41,\n          \"line_end\": 45,\n          \"docstring\": null,\n          \"signature\": \"def __post_init__(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"__init__\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 50,\n          \"line_end\": 69,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"analyze_repository\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 71,\n          \"line_end\": 132,\n          \"docstring\": \"Analyze an entire repository.\",\n          \"signature\": \"def analyze_repository(self, repo_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"analyze_file\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 134,\n          \"line_end\": 170,\n          \"docstring\": \"Analyze a single file.\",\n          \"signature\": \"def analyze_file(self, file_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"_analyze_python_file\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 172,\n          \"line_end\": 230,\n          \"docstring\": \"Analyze Python file for structure.\",\n          \"signature\": \"def _analyze_python_file(self, analysis, content)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"_analyze_js_ts_file\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 232,\n          \"line_end\": 285,\n          \"docstring\": \"Analyze JavaScript/TypeScript file for structure.\",\n          \"signature\": \"def _analyze_js_ts_file(self, analysis, content)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"_get_function_args\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 287,\n          \"line_end\": 292,\n          \"docstring\": \"Extract function arguments as string.\",\n          \"signature\": \"def _get_function_args(self, node)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"_get_files_to_analyze\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 294,\n          \"line_end\": 307,\n          \"docstring\": \"Get list of files to analyze, respecting ignore patterns.\",\n          \"signature\": \"def _get_files_to_analyze(self, repo_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"_should_ignore_dir\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 309,\n          \"line_end\": 311,\n          \"docstring\": \"Check if directory should be ignored.\",\n          \"signature\": \"def _should_ignore_dir(self, dirname)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"_should_analyze_file\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 313,\n          \"line_end\": 316,\n          \"docstring\": \"Check if file should be analyzed.\",\n          \"signature\": \"def _should_analyze_file(self, file_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"_build_directory_structure\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 318,\n          \"line_end\": 338,\n          \"docstring\": \"Build a tree representation of the directory structure.\",\n          \"signature\": \"def _build_directory_structure(self, repo_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"save_analysis\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 340,\n          \"line_end\": 343,\n          \"docstring\": \"Save analysis results to JSON file.\",\n          \"signature\": \"def save_analysis(self, analysis, output_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"load_analysis\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 345,\n          \"line_end\": 348,\n          \"docstring\": \"Load analysis results from JSON file.\",\n          \"signature\": \"def load_analysis(self, input_path)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"build_tree\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\repository_analyzer.py\",\n          \"line_start\": 320,\n          \"line_end\": 336,\n          \"docstring\": null,\n          \"signature\": \"def build_tree(path)\",\n          \"content\": null,\n          \"dependencies\": []\n        }\n      ],\n      \"summary\": null,\n      \"content\": \"\\\"\\\"\\\"Repository analysis module for extracting code structure and content.\\\"\\\"\\\"\\n\\nimport os\\nimport ast\\nimport re\\nimport json\\nfrom pathlib import Path\\nfrom typing import Dict, List, Any, Optional, Tuple\\nfrom dataclasses import dataclass, asdict\\nimport git\\nfrom config import settings\\n\\n@dataclass\\nclass CodeElement:\\n    \\\"\\\"\\\"Represents a code element (function, class, etc.).\\\"\\\"\\\"\\n    name: str\\n    type: str  # 'function', 'class', 'method', 'variable'\\n    file_path: str\\n    line_start: int\\n    line_end: int\\n    docstring: Optional[str] = None\\n    signature: Optional[str] = None\\n    content: Optional[str] = None\\n    dependencies: List[str] = None\\n    \\n    def __post_init__(self):\\n        if self.dependencies is None:\\n            self.dependencies = []\\n\\n@dataclass\\nclass FileAnalysis:\\n    \\\"\\\"\\\"Analysis results for a single file.\\\"\\\"\\\"\\n    file_path: str\\n    file_type: str  # 'code', 'documentation', 'config'\\n    language: Optional[str] = None\\n    imports: List[str] = None\\n    elements: List[CodeElement] = None\\n    summary: Optional[str] = None\\n    content: Optional[str] = None\\n    \\n    def __post_init__(self):\\n        if self.imports is None:\\n            self.imports = []\\n        if self.elements is None:\\n            self.elements = []\\n\\nclass RepositoryAnalyzer:\\n    \\\"\\\"\\\"Analyzes code repositories to extract structure and content.\\\"\\\"\\\"\\n    \\n    def __init__(self):\\n        self.supported_languages = {\\n            '.py': 'python',\\n            '.js': 'javascript', \\n            '.ts': 'typescript',\\n            '.jsx': 'javascript',\\n            '.tsx': 'typescript',\\n            '.java': 'java',\\n            '.cpp': 'cpp',\\n            '.c': 'c',\\n            '.h': 'c',\\n            '.cs': 'csharp',\\n            '.php': 'php',\\n            '.rb': 'ruby',\\n            '.go': 'go',\\n            '.rs': 'rust',\\n            '.swift': 'swift',\\n            '.kt': 'kotlin',\\n            '.scala': 'scala'\\n        }\\n    \\n    def analyze_repository(self, repo_path: str) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Analyze an entire repository.\\\"\\\"\\\"\\n        repo_path = Path(repo_path)\\n        \\n        if not repo_path.exists():\\n            raise ValueError(f\\\"Repository path does not exist: {repo_path}\\\")\\n        \\n        analysis = {\\n            'repo_path': str(repo_path),\\n            'repo_name': repo_path.name,\\n            'files': [],\\n            'structure': {},\\n            'statistics': {\\n                'total_files': 0,\\n                'code_files': 0,\\n                'doc_files': 0,\\n                'languages': {},\\n                'total_lines': 0\\n            }\\n        }\\n        \\n        # Get git info if available\\n        try:\\n            repo = git.Repo(repo_path)\\n            analysis['git_info'] = {\\n                'remote_url': repo.remotes.origin.url if repo.remotes else None,\\n                'current_branch': repo.active_branch.name,\\n                'last_commit': {\\n                    'hash': repo.head.commit.hexsha[:8],\\n                    'message': repo.head.commit.message.strip(),\\n                    'author': str(repo.head.commit.author),\\n                    'date': repo.head.commit.committed_datetime.isoformat()\\n                }\\n            }\\n        except:\\n            analysis['git_info'] = None\\n        \\n        # Analyze files\\n        for file_path in self._get_files_to_analyze(repo_path):\\n            file_analysis = self.analyze_file(file_path)\\n            if file_analysis:\\n                analysis['files'].append(asdict(file_analysis))\\n                \\n                # Update statistics\\n                analysis['statistics']['total_files'] += 1\\n                if file_analysis.file_type == 'code':\\n                    analysis['statistics']['code_files'] += 1\\n                    if file_analysis.language:\\n                        lang = file_analysis.language\\n                        analysis['statistics']['languages'][lang] = \\\\\\n                            analysis['statistics']['languages'].get(lang, 0) + 1\\n                elif file_analysis.file_type == 'documentation':\\n                    analysis['statistics']['doc_files'] += 1\\n                \\n                # Count lines\\n                if file_analysis.content:\\n                    analysis['statistics']['total_lines'] += len(file_analysis.content.split('\\\\n'))\\n        \\n        # Build directory structure\\n        analysis['structure'] = self._build_directory_structure(repo_path)\\n        \\n        return analysis\\n    \\n    def analyze_file(self, file_path: Path) -> Optional[FileAnalysis]:\\n        \\\"\\\"\\\"Analyze a single file.\\\"\\\"\\\"\\n        try:\\n            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\\n                content = f.read()\\n        except Exception as e:\\n            print(f\\\"Error reading file {file_path}: {e}\\\")\\n            return None\\n        \\n        file_ext = file_path.suffix.lower()\\n        relative_path = str(file_path)\\n        \\n        # Determine file type and language\\n        if file_ext in settings.CODE_EXTENSIONS:\\n            file_type = 'code'\\n            language = self.supported_languages.get(file_ext)\\n        elif file_ext in settings.DOC_EXTENSIONS:\\n            file_type = 'documentation'\\n            language = None\\n        else:\\n            file_type = 'config'\\n            language = None\\n        \\n        analysis = FileAnalysis(\\n            file_path=relative_path,\\n            file_type=file_type,\\n            language=language,\\n            content=content\\n        )\\n        \\n        # Language-specific analysis\\n        if language == 'python':\\n            self._analyze_python_file(analysis, content)\\n        elif language in ['javascript', 'typescript']:\\n            self._analyze_js_ts_file(analysis, content)\\n        \\n        return analysis\\n    \\n    def _analyze_python_file(self, analysis: FileAnalysis, content: str):\\n        \\\"\\\"\\\"Analyze Python file for structure.\\\"\\\"\\\"\\n        try:\\n            tree = ast.parse(content)\\n            \\n            # Extract imports\\n            for node in ast.walk(tree):\\n                if isinstance(node, ast.Import):\\n                    for alias in node.names:\\n                        analysis.imports.append(alias.name)\\n                elif isinstance(node, ast.ImportFrom):\\n                    module = node.module or ''\\n                    for alias in node.names:\\n                        analysis.imports.append(f\\\"{module}.{alias.name}\\\")\\n            \\n            # Extract classes and functions\\n            for node in ast.walk(tree):\\n                if isinstance(node, ast.ClassDef):\\n                    element = CodeElement(\\n                        name=node.name,\\n                        type='class',\\n                        file_path=analysis.file_path,\\n                        line_start=node.lineno,\\n                        line_end=getattr(node, 'end_lineno', node.lineno),\\n                        docstring=ast.get_docstring(node),\\n                        signature=f\\\"class {node.name}\\\"\\n                    )\\n                    analysis.elements.append(element)\\n                    \\n                    # Extract methods\\n                    for item in node.body:\\n                        if isinstance(item, ast.FunctionDef):\\n                            method = CodeElement(\\n                                name=f\\\"{node.name}.{item.name}\\\",\\n                                type='method',\\n                                file_path=analysis.file_path,\\n                                line_start=item.lineno,\\n                                line_end=getattr(item, 'end_lineno', item.lineno),\\n                                docstring=ast.get_docstring(item),\\n                                signature=f\\\"def {item.name}({self._get_function_args(item)})\\\"\\n                            )\\n                            analysis.elements.append(method)\\n                \\n                elif isinstance(node, ast.FunctionDef):\\n                    # Only top-level functions (not methods)\\n                    if isinstance(getattr(node, 'parent', None), ast.Module) or not hasattr(node, 'parent'):\\n                        element = CodeElement(\\n                            name=node.name,\\n                            type='function',\\n                            file_path=analysis.file_path,\\n                            line_start=node.lineno,\\n                            line_end=getattr(node, 'end_lineno', node.lineno),\\n                            docstring=ast.get_docstring(node),\\n                            signature=f\\\"def {node.name}({self._get_function_args(node)})\\\"\\n                        )\\n                        analysis.elements.append(element)\\n                        \\n        except SyntaxError as e:\\n            print(f\\\"Syntax error in {analysis.file_path}: {e}\\\")\\n    \\n    def _analyze_js_ts_file(self, analysis: FileAnalysis, content: str):\\n        \\\"\\\"\\\"Analyze JavaScript/TypeScript file for structure.\\\"\\\"\\\"\\n        lines = content.split('\\\\n')\\n        \\n        # Extract imports (simple regex-based approach)\\n        import_patterns = [\\n            r'import\\\\s+.*?\\\\s+from\\\\s+[\\\\'\\\"]([^\\\\'\\\"]+)[\\\\'\\\"]',\\n            r'const\\\\s+.*?\\\\s*=\\\\s*require\\\\([\\\\'\\\"]([^\\\\'\\\"]+)[\\\\'\\\"]\\\\)',\\n            r'import\\\\s*\\\\(\\\\s*[\\\\'\\\"]([^\\\\'\\\"]+)[\\\\'\\\"]\\\\s*\\\\)'\\n        ]\\n        \\n        for line in lines:\\n            for pattern in import_patterns:\\n                matches = re.findall(pattern, line)\\n                analysis.imports.extend(matches)\\n        \\n        # Extract functions and classes (basic regex patterns)\\n        function_patterns = [\\n            r'function\\\\s+(\\\\w+)\\\\s*\\\\(',\\n            r'const\\\\s+(\\\\w+)\\\\s*=\\\\s*\\\\(',\\n            r'(\\\\w+)\\\\s*:\\\\s*function\\\\s*\\\\(',\\n            r'(\\\\w+)\\\\s*\\\\([^)]*\\\\)\\\\s*=>',\\n            r'async\\\\s+function\\\\s+(\\\\w+)\\\\s*\\\\('\\n        ]\\n        \\n        class_pattern = r'class\\\\s+(\\\\w+)'\\n        \\n        for i, line in enumerate(lines, 1):\\n            # Find classes\\n            class_match = re.search(class_pattern, line)\\n            if class_match:\\n                element = CodeElement(\\n                    name=class_match.group(1),\\n                    type='class',\\n                    file_path=analysis.file_path,\\n                    line_start=i,\\n                    line_end=i,  # We'd need more sophisticated parsing to find end\\n                    signature=line.strip()\\n                )\\n                analysis.elements.append(element)\\n            \\n            # Find functions\\n            for pattern in function_patterns:\\n                func_match = re.search(pattern, line)\\n                if func_match:\\n                    element = CodeElement(\\n                        name=func_match.group(1),\\n                        type='function',\\n                        file_path=analysis.file_path,\\n                        line_start=i,\\n                        line_end=i,\\n                        signature=line.strip()\\n                    )\\n                    analysis.elements.append(element)\\n    \\n    def _get_function_args(self, node: ast.FunctionDef) -> str:\\n        \\\"\\\"\\\"Extract function arguments as string.\\\"\\\"\\\"\\n        args = []\\n        for arg in node.args.args:\\n            args.append(arg.arg)\\n        return ', '.join(args)\\n    \\n    def _get_files_to_analyze(self, repo_path: Path) -> List[Path]:\\n        \\\"\\\"\\\"Get list of files to analyze, respecting ignore patterns.\\\"\\\"\\\"\\n        files = []\\n        \\n        for root, dirs, filenames in os.walk(repo_path):\\n            # Remove ignored directories\\n            dirs[:] = [d for d in dirs if not self._should_ignore_dir(d)]\\n            \\n            for filename in filenames:\\n                file_path = Path(root) / filename\\n                if self._should_analyze_file(file_path):\\n                    files.append(file_path)\\n        \\n        return files\\n    \\n    def _should_ignore_dir(self, dirname: str) -> bool:\\n        \\\"\\\"\\\"Check if directory should be ignored.\\\"\\\"\\\"\\n        return dirname in settings.IGNORED_DIRS or dirname.startswith('.')\\n    \\n    def _should_analyze_file(self, file_path: Path) -> bool:\\n        \\\"\\\"\\\"Check if file should be analyzed.\\\"\\\"\\\"\\n        ext = file_path.suffix.lower()\\n        return ext in settings.CODE_EXTENSIONS or ext in settings.DOC_EXTENSIONS\\n    \\n    def _build_directory_structure(self, repo_path: Path) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Build a tree representation of the directory structure.\\\"\\\"\\\"\\n        def build_tree(path: Path) -> Dict[str, Any]:\\n            tree = {'name': path.name, 'type': 'directory', 'children': []}\\n            \\n            try:\\n                for item in sorted(path.iterdir()):\\n                    if item.is_dir() and not self._should_ignore_dir(item.name):\\n                        tree['children'].append(build_tree(item))\\n                    elif item.is_file() and self._should_analyze_file(item):\\n                        tree['children'].append({\\n                            'name': item.name,\\n                            'type': 'file',\\n                            'path': str(item.relative_to(repo_path))\\n                        })\\n            except PermissionError:\\n                pass\\n            \\n            return tree\\n        \\n        return build_tree(repo_path)\\n\\n    def save_analysis(self, analysis: Dict[str, Any], output_path: str):\\n        \\\"\\\"\\\"Save analysis results to JSON file.\\\"\\\"\\\"\\n        with open(output_path, 'w', encoding='utf-8') as f:\\n            json.dump(analysis, f, indent=2, ensure_ascii=False)\\n    \\n    def load_analysis(self, input_path: str) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Load analysis results from JSON file.\\\"\\\"\\\"\\n        with open(input_path, 'r', encoding='utf-8') as f:\\n            return json.load(f)\\n\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\requirements.txt\",\n      \"file_type\": \"documentation\",\n      \"language\": null,\n      \"imports\": [],\n      \"elements\": [],\n      \"summary\": null,\n      \"content\": \"ollama>=0.2.0\\nlangchain>=0.1.0\\nlangchain-community>=0.0.20\\nchromadb>=0.4.0\\nsentence-transformers>=2.2.2\\nfastapi>=0.104.0\\nuvicorn>=0.24.0\\npydantic>=2.5.0\\npython-multipart>=0.0.6\\ngitpython>=3.1.40\\npathspec>=0.12.0\\ntiktoken>=0.5.0\\njinja2>=3.1.0\\nmarkdown>=3.5.0\\nbeautifulsoup4>=4.12.0\\ntree-sitter>=0.20.0\\ntree-sitter-python>=0.20.0\\ntree-sitter-javascript>=0.20.0\\ntree-sitter-typescript>=0.20.0\\naiofiles>=23.2.0\\nwatchdog>=3.0.0\\n\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n      \"file_type\": \"code\",\n      \"language\": \"python\",\n      \"imports\": [\n        \"os\",\n        \"hashlib\",\n        \"json\",\n        \"pathlib.Path\",\n        \"typing.List\",\n        \"typing.Dict\",\n        \"typing.Any\",\n        \"typing.Optional\",\n        \"typing.Tuple\",\n        \"chromadb\",\n        \"chromadb.config.Settings\",\n        \"sentence_transformers.SentenceTransformer\",\n        \"tiktoken\",\n        \"config.settings\",\n        \"ollama_client.OllamaClient\"\n      ],\n      \"elements\": [\n        {\n          \"name\": \"TextChunker\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 15,\n          \"line_end\": 188,\n          \"docstring\": \"Utility class for chunking text into manageable pieces.\",\n          \"signature\": \"class TextChunker\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"TextChunker.__init__\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 18,\n          \"line_end\": 26,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self, max_chunk_size, overlap)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"TextChunker.count_tokens\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 28,\n          \"line_end\": 34,\n          \"docstring\": \"Count tokens in text.\",\n          \"signature\": \"def count_tokens(self, text)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"TextChunker.chunk_text\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 36,\n          \"line_end\": 113,\n          \"docstring\": \"Split text into chunks with metadata.\",\n          \"signature\": \"def chunk_text(self, text, metadata)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"TextChunker.chunk_code_file\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 115,\n          \"line_end\": 188,\n          \"docstring\": \"Chunk code file based on structure.\",\n          \"signature\": \"def chunk_code_file(self, content, file_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"VectorStore\",\n          \"type\": \"class\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 190,\n          \"line_end\": 411,\n          \"docstring\": \"Vector store for embeddings using ChromaDB and local embeddings.\",\n          \"signature\": \"class VectorStore\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"VectorStore.__init__\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 193,\n          \"line_end\": 219,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self, persist_directory, collection_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"VectorStore.get_embedding\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 221,\n          \"line_end\": 238,\n          \"docstring\": \"Get embedding for text using available models.\",\n          \"signature\": \"def get_embedding(self, text)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"VectorStore.add_repository\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 240,\n          \"line_end\": 270,\n          \"docstring\": \"Add entire repository to vector store.\",\n          \"signature\": \"def add_repository(self, repo_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"VectorStore.add_file_analysis\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 272,\n          \"line_end\": 295,\n          \"docstring\": \"Add file analysis to vector store.\",\n          \"signature\": \"def add_file_analysis(self, file_analysis, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"VectorStore.add_document\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 297,\n          \"line_end\": 300,\n          \"docstring\": \"Add a single document to vector store.\",\n          \"signature\": \"def add_document(self, text, metadata)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"VectorStore.add_chunks\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 302,\n          \"line_end\": 348,\n          \"docstring\": \"Add multiple chunks to vector store.\",\n          \"signature\": \"def add_chunks(self, chunks)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"VectorStore.search\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 350,\n          \"line_end\": 379,\n          \"docstring\": \"Search vector store for relevant documents.\",\n          \"signature\": \"def search(self, query, n_results, filter_metadata)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"VectorStore.get_collection_stats\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 381,\n          \"line_end\": 391,\n          \"docstring\": \"Get statistics about the collection.\",\n          \"signature\": \"def get_collection_stats(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"VectorStore.clear_collection\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 393,\n          \"line_end\": 400,\n          \"docstring\": \"Clear all documents from collection.\",\n          \"signature\": \"def clear_collection(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"VectorStore.delete_repository\",\n          \"type\": \"method\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 402,\n          \"line_end\": 411,\n          \"docstring\": \"Delete all documents from a specific repository.\",\n          \"signature\": \"def delete_repository(self, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"__init__\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 18,\n          \"line_end\": 26,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self, max_chunk_size, overlap)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"count_tokens\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 28,\n          \"line_end\": 34,\n          \"docstring\": \"Count tokens in text.\",\n          \"signature\": \"def count_tokens(self, text)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"chunk_text\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 36,\n          \"line_end\": 113,\n          \"docstring\": \"Split text into chunks with metadata.\",\n          \"signature\": \"def chunk_text(self, text, metadata)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"chunk_code_file\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 115,\n          \"line_end\": 188,\n          \"docstring\": \"Chunk code file based on structure.\",\n          \"signature\": \"def chunk_code_file(self, content, file_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"__init__\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 193,\n          \"line_end\": 219,\n          \"docstring\": null,\n          \"signature\": \"def __init__(self, persist_directory, collection_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"get_embedding\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 221,\n          \"line_end\": 238,\n          \"docstring\": \"Get embedding for text using available models.\",\n          \"signature\": \"def get_embedding(self, text)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"add_repository\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 240,\n          \"line_end\": 270,\n          \"docstring\": \"Add entire repository to vector store.\",\n          \"signature\": \"def add_repository(self, repo_analysis)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"add_file_analysis\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 272,\n          \"line_end\": 295,\n          \"docstring\": \"Add file analysis to vector store.\",\n          \"signature\": \"def add_file_analysis(self, file_analysis, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"add_document\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 297,\n          \"line_end\": 300,\n          \"docstring\": \"Add a single document to vector store.\",\n          \"signature\": \"def add_document(self, text, metadata)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"add_chunks\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 302,\n          \"line_end\": 348,\n          \"docstring\": \"Add multiple chunks to vector store.\",\n          \"signature\": \"def add_chunks(self, chunks)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"search\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 350,\n          \"line_end\": 379,\n          \"docstring\": \"Search vector store for relevant documents.\",\n          \"signature\": \"def search(self, query, n_results, filter_metadata)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"get_collection_stats\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 381,\n          \"line_end\": 391,\n          \"docstring\": \"Get statistics about the collection.\",\n          \"signature\": \"def get_collection_stats(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"clear_collection\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 393,\n          \"line_end\": 400,\n          \"docstring\": \"Clear all documents from collection.\",\n          \"signature\": \"def clear_collection(self)\",\n          \"content\": null,\n          \"dependencies\": []\n        },\n        {\n          \"name\": \"delete_repository\",\n          \"type\": \"function\",\n          \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\vector_store.py\",\n          \"line_start\": 402,\n          \"line_end\": 411,\n          \"docstring\": \"Delete all documents from a specific repository.\",\n          \"signature\": \"def delete_repository(self, repo_name)\",\n          \"content\": null,\n          \"dependencies\": []\n        }\n      ],\n      \"summary\": null,\n      \"content\": \"\\\"\\\"\\\"Vector embedding and storage system using ChromaDB.\\\"\\\"\\\"\\n\\nimport os\\nimport hashlib\\nimport json\\nfrom pathlib import Path\\nfrom typing import List, Dict, Any, Optional, Tuple\\nimport chromadb\\nfrom chromadb.config import Settings\\nfrom sentence_transformers import SentenceTransformer\\nimport tiktoken\\nfrom config import settings\\nfrom ollama_client import OllamaClient\\n\\nclass TextChunker:\\n    \\\"\\\"\\\"Utility class for chunking text into manageable pieces.\\\"\\\"\\\"\\n    \\n    def __init__(self, max_chunk_size: int = None, overlap: int = None):\\n        self.max_chunk_size = max_chunk_size or settings.MAX_CHUNK_SIZE\\n        self.overlap = overlap or settings.CHUNK_OVERLAP\\n        \\n        # Initialize tokenizer for accurate token counting\\n        try:\\n            self.tokenizer = tiktoken.get_encoding(\\\"cl100k_base\\\")\\n        except:\\n            self.tokenizer = None\\n    \\n    def count_tokens(self, text: str) -> int:\\n        \\\"\\\"\\\"Count tokens in text.\\\"\\\"\\\"\\n        if self.tokenizer:\\n            return len(self.tokenizer.encode(text))\\n        else:\\n            # Rough approximation: 1 token â‰ˆ 4 characters\\n            return len(text) // 4\\n    \\n    def chunk_text(self, text: str, metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"Split text into chunks with metadata.\\\"\\\"\\\"\\n        if metadata is None:\\n            metadata = {}\\n        \\n        chunks = []\\n        \\n        # Split by paragraphs first\\n        paragraphs = text.split('\\\\n\\\\n')\\n        current_chunk = \\\"\\\"\\n        current_tokens = 0\\n        \\n        for para in paragraphs:\\n            para_tokens = self.count_tokens(para)\\n            \\n            # If single paragraph exceeds max size, split it further\\n            if para_tokens > self.max_chunk_size:\\n                # Save current chunk if not empty\\n                if current_chunk.strip():\\n                    chunks.append({\\n                        'text': current_chunk.strip(),\\n                        'tokens': current_tokens,\\n                        **metadata\\n                    })\\n                    current_chunk = \\\"\\\"\\n                    current_tokens = 0\\n                \\n                # Split large paragraph by sentences\\n                sentences = para.split('. ')\\n                for sentence in sentences:\\n                    sentence_tokens = self.count_tokens(sentence)\\n                    \\n                    if current_tokens + sentence_tokens > self.max_chunk_size:\\n                        if current_chunk.strip():\\n                            chunks.append({\\n                                'text': current_chunk.strip(),\\n                                'tokens': current_tokens,\\n                                **metadata\\n                            })\\n                        current_chunk = sentence\\n                        current_tokens = sentence_tokens\\n                    else:\\n                        current_chunk += (\\\". \\\" if current_chunk else \\\"\\\") + sentence\\n                        current_tokens += sentence_tokens\\n            \\n            # Normal paragraph processing\\n            elif current_tokens + para_tokens > self.max_chunk_size:\\n                # Save current chunk\\n                if current_chunk.strip():\\n                    chunks.append({\\n                        'text': current_chunk.strip(),\\n                        'tokens': current_tokens,\\n                        **metadata\\n                    })\\n                \\n                # Start new chunk with overlap\\n                if self.overlap > 0 and chunks:\\n                    # Get last few words for overlap\\n                    last_chunk_words = current_chunk.split()\\n                    overlap_words = last_chunk_words[-self.overlap:] if len(last_chunk_words) > self.overlap else last_chunk_words\\n                    current_chunk = \\\" \\\".join(overlap_words) + \\\"\\\\n\\\\n\\\" + para\\n                else:\\n                    current_chunk = para\\n                \\n                current_tokens = self.count_tokens(current_chunk)\\n            else:\\n                current_chunk += (\\\"\\\\n\\\\n\\\" if current_chunk else \\\"\\\") + para\\n                current_tokens += para_tokens\\n        \\n        # Add final chunk\\n        if current_chunk.strip():\\n            chunks.append({\\n                'text': current_chunk.strip(),\\n                'tokens': current_tokens,\\n                **metadata\\n            })\\n        \\n        return chunks\\n    \\n    def chunk_code_file(self, content: str, file_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"Chunk code file based on structure.\\\"\\\"\\\"\\n        chunks = []\\n        \\n        # Create chunk for file overview\\n        overview_text = f\\\"File: {file_analysis['file_path']}\\\\n\\\"\\n        overview_text += f\\\"Language: {file_analysis.get('language', 'Unknown')}\\\\n\\\"\\n        \\n        if file_analysis.get('imports'):\\n            overview_text += f\\\"Imports: {', '.join(file_analysis['imports'])}\\\\n\\\"\\n        \\n        # Add summary of elements\\n        elements = file_analysis.get('elements', [])\\n        if elements:\\n            overview_text += \\\"\\\\nCode Elements:\\\\n\\\"\\n            for element in elements:\\n                overview_text += f\\\"- {element['type']}: {element['name']}\\\\n\\\"\\n                if element.get('docstring'):\\n                    overview_text += f\\\"  {element['docstring'][:100]}...\\\\n\\\"\\n        \\n        chunks.append({\\n            'text': overview_text,\\n            'type': 'file_overview',\\n            'file_path': file_analysis['file_path'],\\n            'language': file_analysis.get('language'),\\n            'source': 'code_analysis'\\n        })\\n        \\n        # Create chunks for individual code elements\\n        lines = content.split('\\\\n')\\n        for element in elements:\\n            start_line = element.get('line_start', 1) - 1  # Convert to 0-based\\n            end_line = element.get('line_end', len(lines))\\n            \\n            if start_line < len(lines):\\n                element_content = '\\\\n'.join(lines[start_line:min(end_line, len(lines))])\\n                \\n                element_text = f\\\"Element: {element['name']} ({element['type']})\\\\n\\\"\\n                element_text += f\\\"File: {file_analysis['file_path']}\\\\n\\\"\\n                \\n                if element.get('signature'):\\n                    element_text += f\\\"Signature: {element['signature']}\\\\n\\\"\\n                \\n                if element.get('docstring'):\\n                    element_text += f\\\"Documentation: {element['docstring']}\\\\n\\\"\\n                \\n                element_text += f\\\"\\\\nCode:\\\\n```{file_analysis.get('language', '')}\\\\n{element_content}\\\\n```\\\"\\n                \\n                chunks.append({\\n                    'text': element_text,\\n                    'type': 'code_element',\\n                    'element_type': element['type'],\\n                    'element_name': element['name'],\\n                    'file_path': file_analysis['file_path'],\\n                    'language': file_analysis.get('language'),\\n                    'line_start': element.get('line_start'),\\n                    'line_end': element.get('line_end'),\\n                    'source': 'code_analysis'\\n                })\\n        \\n        # If no elements found, chunk the entire file content\\n        if not elements and content.strip():\\n            file_chunks = self.chunk_text(\\n                content, \\n                {\\n                    'type': 'file_content',\\n                    'file_path': file_analysis['file_path'],\\n                    'language': file_analysis.get('language'),\\n                    'source': 'file_content'\\n                }\\n            )\\n            chunks.extend(file_chunks)\\n        \\n        return chunks\\n\\nclass VectorStore:\\n    \\\"\\\"\\\"Vector store for embeddings using ChromaDB and local embeddings.\\\"\\\"\\\"\\n    \\n    def __init__(self, persist_directory: str = None, collection_name: str = None):\\n        self.persist_directory = persist_directory or settings.CHROMA_PERSIST_DIRECTORY\\n        self.collection_name = collection_name or settings.COLLECTION_NAME\\n        \\n        # Initialize ChromaDB\\n        self.client = chromadb.PersistentClient(\\n            path=self.persist_directory,\\n            settings=Settings(anonymized_telemetry=False)\\n        )\\n        \\n        # Get or create collection\\n        try:\\n            self.collection = self.client.get_collection(name=self.collection_name)\\n        except:\\n            self.collection = self.client.create_collection(name=self.collection_name)\\n        \\n        # Initialize embedding models\\n        self.ollama_client = OllamaClient()\\n        \\n        # Fallback to sentence transformers if Ollama embeddings fail\\n        try:\\n            self.sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')\\n        except:\\n            print(\\\"Warning: Could not load sentence transformer model\\\")\\n            self.sentence_transformer = None\\n        \\n        self.chunker = TextChunker()\\n    \\n    def get_embedding(self, text: str) -> List[float]:\\n        \\\"\\\"\\\"Get embedding for text using available models.\\\"\\\"\\\"\\n        # Try Ollama first\\n        if self.ollama_client.is_available():\\n            try:\\n                return self.ollama_client.get_embeddings(text)\\n            except Exception as e:\\n                print(f\\\"Ollama embedding failed: {e}\\\")\\n        \\n        # Fallback to sentence transformer\\n        if self.sentence_transformer:\\n            try:\\n                embedding = self.sentence_transformer.encode(text)\\n                return embedding.tolist()\\n            except Exception as e:\\n                print(f\\\"Sentence transformer embedding failed: {e}\\\")\\n        \\n        raise Exception(\\\"No embedding model available\\\")\\n    \\n    def add_repository(self, repo_analysis: Dict[str, Any]) -> int:\\n        \\\"\\\"\\\"Add entire repository to vector store.\\\"\\\"\\\"\\n        repo_name = repo_analysis.get('repo_name', 'unknown')\\n        total_chunks = 0\\n        \\n        # Add repository overview\\n        if repo_analysis.get('files'):\\n            overview_text = f\\\"Repository: {repo_name}\\\\n\\\"\\n            overview_text += f\\\"Total files: {repo_analysis['statistics']['total_files']}\\\\n\\\"\\n            overview_text += f\\\"Languages: {', '.join(repo_analysis['statistics']['languages'].keys())}\\\\n\\\"\\n            \\n            # Add file list\\n            overview_text += \\\"\\\\nFiles:\\\\n\\\"\\n            for file_data in repo_analysis['files'][:20]:  # Limit to first 20 files\\n                overview_text += f\\\"- {file_data['file_path']}\\\\n\\\"\\n            \\n            total_chunks += self.add_document(\\n                overview_text,\\n                {\\n                    'type': 'repository_overview',\\n                    'repo_name': repo_name,\\n                    'source': 'repository_analysis'\\n                }\\n            )\\n        \\n        # Add individual files\\n        for file_data in repo_analysis.get('files', []):\\n            file_chunks = self.add_file_analysis(file_data, repo_name)\\n            total_chunks += file_chunks\\n        \\n        return total_chunks\\n    \\n    def add_file_analysis(self, file_analysis: Dict[str, Any], repo_name: str = None) -> int:\\n        \\\"\\\"\\\"Add file analysis to vector store.\\\"\\\"\\\"\\n        if file_analysis.get('file_type') == 'code':\\n            chunks = self.chunker.chunk_code_file(\\n                file_analysis.get('content', ''), \\n                file_analysis\\n            )\\n        else:\\n            # Regular text chunking for documentation files\\n            chunks = self.chunker.chunk_text(\\n                file_analysis.get('content', ''),\\n                {\\n                    'type': 'documentation',\\n                    'file_path': file_analysis['file_path'],\\n                    'source': 'file_content'\\n                }\\n            )\\n        \\n        # Add repository name to all chunks\\n        for chunk in chunks:\\n            if repo_name:\\n                chunk['repo_name'] = repo_name\\n        \\n        return self.add_chunks(chunks)\\n    \\n    def add_document(self, text: str, metadata: Dict[str, Any]) -> int:\\n        \\\"\\\"\\\"Add a single document to vector store.\\\"\\\"\\\"\\n        chunks = self.chunker.chunk_text(text, metadata)\\n        return self.add_chunks(chunks)\\n    \\n    def add_chunks(self, chunks: List[Dict[str, Any]]) -> int:\\n        \\\"\\\"\\\"Add multiple chunks to vector store.\\\"\\\"\\\"\\n        if not chunks:\\n            return 0\\n        \\n        documents = []\\n        metadatas = []\\n        ids = []\\n        embeddings = []\\n        \\n        for i, chunk in enumerate(chunks):\\n            text = chunk['text']\\n            \\n            # Create unique ID\\n            chunk_id = hashlib.md5(text.encode()).hexdigest()\\n            \\n            # Prepare metadata (remove 'text' key)\\n            metadata = {k: v for k, v in chunk.items() if k != 'text'}\\n            \\n            try:\\n                # Get embedding\\n                embedding = self.get_embedding(text)\\n                \\n                documents.append(text)\\n                metadatas.append(metadata)\\n                ids.append(chunk_id)\\n                embeddings.append(embedding)\\n                \\n            except Exception as e:\\n                print(f\\\"Error processing chunk {i}: {e}\\\")\\n                continue\\n        \\n        if documents:\\n            try:\\n                self.collection.add(\\n                    documents=documents,\\n                    metadatas=metadatas,\\n                    ids=ids,\\n                    embeddings=embeddings\\n                )\\n                print(f\\\"Added {len(documents)} chunks to vector store\\\")\\n                return len(documents)\\n            except Exception as e:\\n                print(f\\\"Error adding to vector store: {e}\\\")\\n                return 0\\n        \\n        return 0\\n    \\n    def search(self, query: str, n_results: int = 5, filter_metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"Search vector store for relevant documents.\\\"\\\"\\\"\\n        try:\\n            query_embedding = self.get_embedding(query)\\n            \\n            search_kwargs = {\\n                'query_embeddings': [query_embedding],\\n                'n_results': n_results\\n            }\\n            \\n            if filter_metadata:\\n                search_kwargs['where'] = filter_metadata\\n            \\n            results = self.collection.query(**search_kwargs)\\n            \\n            # Format results\\n            formatted_results = []\\n            for i in range(len(results['documents'][0])):\\n                formatted_results.append({\\n                    'text': results['documents'][0][i],\\n                    'metadata': results['metadatas'][0][i],\\n                    'distance': results['distances'][0][i],\\n                    'id': results['ids'][0][i]\\n                })\\n            \\n            return formatted_results\\n            \\n        except Exception as e:\\n            print(f\\\"Error searching vector store: {e}\\\")\\n            return []\\n    \\n    def get_collection_stats(self) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Get statistics about the collection.\\\"\\\"\\\"\\n        try:\\n            count = self.collection.count()\\n            return {\\n                'total_documents': count,\\n                'collection_name': self.collection_name\\n            }\\n        except Exception as e:\\n            print(f\\\"Error getting collection stats: {e}\\\")\\n            return {'total_documents': 0, 'collection_name': self.collection_name}\\n    \\n    def clear_collection(self):\\n        \\\"\\\"\\\"Clear all documents from collection.\\\"\\\"\\\"\\n        try:\\n            self.client.delete_collection(name=self.collection_name)\\n            self.collection = self.client.create_collection(name=self.collection_name)\\n            print(\\\"Collection cleared successfully\\\")\\n        except Exception as e:\\n            print(f\\\"Error clearing collection: {e}\\\")\\n    \\n    def delete_repository(self, repo_name: str):\\n        \\\"\\\"\\\"Delete all documents from a specific repository.\\\"\\\"\\\"\\n        try:\\n            # Get all documents with repo_name\\n            results = self.collection.get(where={\\\"repo_name\\\": repo_name})\\n            if results['ids']:\\n                self.collection.delete(ids=results['ids'])\\n                print(f\\\"Deleted {len(results['ids'])} documents for repository {repo_name}\\\")\\n        except Exception as e:\\n            print(f\\\"Error deleting repository {repo_name}: {e}\\\")\\n\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\data\\\\repos\\\\wikillm_analysis.json\",\n      \"file_type\": \"code\",\n      \"language\": null,\n      \"imports\": [],\n      \"elements\": [],\n      \"summary\": null,\n      \"content\": \"{\\n  \\\"repo_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\",\\n  \\\"repo_name\\\": \\\"wikillm\\\",\\n  \\\"files\\\": [\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\api.py\\\",\\n      \\\"file_type\\\": \\\"code\\\",\\n      \\\"language\\\": \\\"python\\\",\\n      \\\"imports\\\": [\\n        \\\"asyncio\\\",\\n        \\\"json\\\",\\n        \\\"traceback\\\",\\n        \\\"pathlib.Path\\\",\\n        \\\"typing.Dict\\\",\\n        \\\"typing.List\\\",\\n        \\\"typing.Any\\\",\\n        \\\"typing.Optional\\\",\\n        \\\"fastapi.FastAPI\\\",\\n        \\\"fastapi.HTTPException\\\",\\n        \\\"fastapi.BackgroundTasks\\\",\\n        \\\"fastapi.UploadFile\\\",\\n        \\\"fastapi.File\\\",\\n        \\\"fastapi.middleware.cors.CORSMiddleware\\\",\\n        \\\"fastapi.responses.StreamingResponse\\\",\\n        \\\"fastapi.responses.JSONResponse\\\",\\n        \\\"fastapi.staticfiles.StaticFiles\\\",\\n        \\\"pydantic.BaseModel\\\",\\n        \\\"uvicorn\\\",\\n        \\\"config.settings\\\",\\n        \\\"repository_analyzer.RepositoryAnalyzer\\\",\\n        \\\"ollama_client.OllamaClient\\\",\\n        \\\"vector_store.VectorStore\\\",\\n        \\\"rag_system.RAGSystem\\\",\\n        \\\"documentation_generator.DocumentationBuilder\\\",\\n        \\\"documentation_generator.DocumentationConfig\\\"\\n      ],\\n      \\\"elements\\\": [\\n        {\\n          \\\"name\\\": \\\"QueryRequest\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\api.py\\\",\\n          \\\"line_start\\\": 23,\\n          \\\"line_end\\\": 27,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"class QueryRequest\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"ChatMessage\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\api.py\\\",\\n          \\\"line_start\\\": 29,\\n          \\\"line_end\\\": 31,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"class ChatMessage\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"ChatRequest\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\api.py\\\",\\n          \\\"line_start\\\": 33,\\n          \\\"line_end\\\": 35,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"class ChatRequest\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryRequest\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\api.py\\\",\\n          \\\"line_start\\\": 37,\\n          \\\"line_end\\\": 39,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"class RepositoryRequest\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"ExplainCodeRequest\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\api.py\\\",\\n          \\\"line_start\\\": 41,\\n          \\\"line_end\\\": 44,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"class ExplainCodeRequest\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationRequest\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\api.py\\\",\\n          \\\"line_start\\\": 46,\\n          \\\"line_end\\\": 51,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"class DocumentationRequest\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"main\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\api.py\\\",\\n          \\\"line_start\\\": 422,\\n          \\\"line_end\\\": 438,\\n          \\\"docstring\\\": \\\"Main function to run the API server.\\\",\\n          \\\"signature\\\": \\\"def main()\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        }\\n      ],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"FastAPI server for Local DeepWiki.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport asyncio\\\\nimport json\\\\nimport traceback\\\\nfrom pathlib import Path\\\\nfrom typing import Dict, List, Any, Optional\\\\nfrom fastapi import FastAPI, HTTPException, BackgroundTasks, UploadFile, File\\\\nfrom fastapi.middleware.cors import CORSMiddleware\\\\nfrom fastapi.responses import StreamingResponse, JSONResponse\\\\nfrom fastapi.staticfiles import StaticFiles\\\\nfrom pydantic import BaseModel\\\\nimport uvicorn\\\\n\\\\nfrom config import settings\\\\nfrom repository_analyzer import RepositoryAnalyzer\\\\nfrom ollama_client import OllamaClient\\\\nfrom vector_store import VectorStore\\\\nfrom rag_system import RAGSystem\\\\nfrom documentation_generator import DocumentationBuilder, DocumentationConfig\\\\n\\\\n# Pydantic models for API\\\\nclass QueryRequest(BaseModel):\\\\n    query: str\\\\n    repo_name: Optional[str] = None\\\\n    file_path: Optional[str] = None\\\\n    stream: Optional[bool] = False\\\\n\\\\nclass ChatMessage(BaseModel):\\\\n    role: str  # 'user' or 'assistant'\\\\n    content: str\\\\n\\\\nclass ChatRequest(BaseModel):\\\\n    messages: List[ChatMessage]\\\\n    repo_name: Optional[str] = None\\\\n\\\\nclass RepositoryRequest(BaseModel):\\\\n    repo_path: str\\\\n    repo_name: Optional[str] = None\\\\n\\\\nclass ExplainCodeRequest(BaseModel):\\\\n    code: str\\\\n    language: Optional[str] = None\\\\n    context: Optional[str] = None\\\\n\\\\nclass DocumentationRequest(BaseModel):\\\\n    repo_name: str\\\\n    include_overview: bool = True\\\\n    include_api_docs: bool = True\\\\n    include_examples: bool = True\\\\n    include_architecture: bool = True\\\\n\\\\n# Global instances\\\\napp = FastAPI(title=\\\\\\\"Local DeepWiki\\\\\\\", version=\\\\\\\"1.0.0\\\\\\\")\\\\nollama_client = OllamaClient()\\\\nvector_store = VectorStore()\\\\nrag_system = RAGSystem(vector_store, ollama_client)\\\\nrepository_analyzer = RepositoryAnalyzer()\\\\ndocumentation_builder = DocumentationBuilder(ollama_client)\\\\n\\\\n# Add CORS middleware\\\\napp.add_middleware(\\\\n    CORSMiddleware,\\\\n    allow_origins=[\\\\\\\"*\\\\\\\"],\\\\n    allow_credentials=True,\\\\n    allow_methods=[\\\\\\\"*\\\\\\\"],\\\\n    allow_headers=[\\\\\\\"*\\\\\\\"],\\\\n)\\\\n\\\\n# Health check endpoints\\\\n@app.get(\\\\\\\"/health\\\\\\\")\\\\nasync def health_check():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Health check endpoint.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    ollama_available = ollama_client.is_available()\\\\n    vector_stats = vector_store.get_collection_stats()\\\\n    \\\\n    return {\\\\n        \\\\\\\"status\\\\\\\": \\\\\\\"healthy\\\\\\\",\\\\n        \\\\\\\"ollama_available\\\\\\\": ollama_available,\\\\n        \\\\\\\"ollama_url\\\\\\\": settings.OLLAMA_BASE_URL,\\\\n        \\\\\\\"ollama_model\\\\\\\": settings.OLLAMA_MODEL,\\\\n        \\\\\\\"vector_store\\\\\\\": vector_stats\\\\n    }\\\\n\\\\n@app.get(\\\\\\\"/models\\\\\\\")\\\\nasync def list_models():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"List available Ollama models.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        models = ollama_client.list_models()\\\\n        return {\\\\\\\"models\\\\\\\": models}\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error listing models: {str(e)}\\\\\\\")\\\\n\\\\n# Repository management endpoints\\\\n@app.post(\\\\\\\"/repositories/analyze\\\\\\\")\\\\nasync def analyze_repository(request: RepositoryRequest, background_tasks: BackgroundTasks):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Analyze a repository and add it to the vector store.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    repo_path = Path(request.repo_path)\\\\n    \\\\n    if not repo_path.exists():\\\\n        raise HTTPException(status_code=404, detail=f\\\\\\\"Repository path not found: {repo_path}\\\\\\\")\\\\n    \\\\n    repo_name = request.repo_name or repo_path.name\\\\n    \\\\n    try:\\\\n        # Start analysis in background\\\\n        background_tasks.add_task(analyze_repository_task, str(repo_path), repo_name)\\\\n        \\\\n        return {\\\\n            \\\\\\\"message\\\\\\\": f\\\\\\\"Repository analysis started for {repo_name}\\\\\\\",\\\\n            \\\\\\\"repo_name\\\\\\\": repo_name,\\\\n            \\\\\\\"repo_path\\\\\\\": str(repo_path)\\\\n        }\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error starting analysis: {str(e)}\\\\\\\")\\\\n\\\\nasync def analyze_repository_task(repo_path: str, repo_name: str):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Background task to analyze repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        print(f\\\\\\\"Starting analysis of {repo_name} at {repo_path}\\\\\\\")\\\\n        \\\\n        # Analyze repository\\\\n        analysis = repository_analyzer.analyze_repository(repo_path)\\\\n        analysis['repo_name'] = repo_name\\\\n        \\\\n        # Save analysis\\\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\"{repo_name}_analysis.json\\\\\\\"\\\\n        repository_analyzer.save_analysis(analysis, str(analysis_path))\\\\n        \\\\n        # Add to vector store\\\\n        chunks_added = vector_store.add_repository(analysis)\\\\n        \\\\n        print(f\\\\\\\"Analysis complete for {repo_name}: {chunks_added} chunks added to vector store\\\\\\\")\\\\n        \\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Error in repository analysis task: {str(e)}\\\\\\\")\\\\n        traceback.print_exc()\\\\n\\\\n@app.get(\\\\\\\"/repositories\\\\\\\")\\\\nasync def list_repositories():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"List analyzed repositories.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    repos = []\\\\n    repos_dir = Path(settings.REPOS_DIRECTORY)\\\\n    \\\\n    if repos_dir.exists():\\\\n        for analysis_file in repos_dir.glob(\\\\\\\"*_analysis.json\\\\\\\"):\\\\n            try:\\\\n                analysis = repository_analyzer.load_analysis(str(analysis_file))\\\\n                repos.append({\\\\n                    \\\\\\\"name\\\\\\\": analysis.get('repo_name', analysis_file.stem.replace('_analysis', '')),\\\\n                    \\\\\\\"path\\\\\\\": analysis.get('repo_path', ''),\\\\n                    \\\\\\\"files\\\\\\\": analysis.get('statistics', {}).get('total_files', 0),\\\\n                    \\\\\\\"languages\\\\\\\": list(analysis.get('statistics', {}).get('languages', {}).keys())\\\\n                })\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"Error loading analysis from {analysis_file}: {e}\\\\\\\")\\\\n    \\\\n    return {\\\\\\\"repositories\\\\\\\": repos}\\\\n\\\\n@app.delete(\\\\\\\"/repositories/{repo_name}\\\\\\\")\\\\nasync def delete_repository(repo_name: str):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Delete repository from vector store.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        vector_store.delete_repository(repo_name)\\\\n        \\\\n        # Also delete analysis file\\\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\"{repo_name}_analysis.json\\\\\\\"\\\\n        if analysis_path.exists():\\\\n            analysis_path.unlink()\\\\n        \\\\n        return {\\\\\\\"message\\\\\\\": f\\\\\\\"Repository {repo_name} deleted successfully\\\\\\\"}\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error deleting repository: {str(e)}\\\\\\\")\\\\n\\\\n# Query endpoints\\\\n@app.post(\\\\\\\"/query\\\\\\\")\\\\nasync def query_repository(request: QueryRequest):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Query repository using RAG system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        if request.stream:\\\\n            # Return streaming response\\\\n            return StreamingResponse(\\\\n                stream_query_response(request),\\\\n                media_type=\\\\\\\"text/plain\\\\\\\"\\\\n            )\\\\n        else:\\\\n            # Return complete response\\\\n            result = rag_system.query(\\\\n                request.query,\\\\n                repo_name=request.repo_name,\\\\n                file_path=request.file_path,\\\\n                stream=False\\\\n            )\\\\n            return result\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error processing query: {str(e)}\\\\\\\")\\\\n\\\\nasync def stream_query_response(request: QueryRequest):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Stream query response for real-time updates.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        # Get context first\\\\n        filter_metadata = {}\\\\n        if request.repo_name:\\\\n            filter_metadata['repo_name'] = request.repo_name\\\\n        if request.file_path:\\\\n            filter_metadata['file_path'] = request.file_path\\\\n        \\\\n        retrieved_chunks = rag_system.retrieve_context(\\\\n            request.query, \\\\n            n_results=5, \\\\n            filter_metadata=filter_metadata or None\\\\n        )\\\\n        \\\\n        if not retrieved_chunks:\\\\n            yield \\\\\\\"No relevant context found for query.\\\\\\\\n\\\\\\\"\\\\n            return\\\\n        \\\\n        context_text = rag_system.build_context_text(retrieved_chunks)\\\\n        \\\\n        # Build prompt\\\\n        system_prompt = rag_system.system_prompts['general_question']\\\\n        full_prompt = f\\\\\\\"\\\\\\\"\\\\\\\"{system_prompt}\\\\n\\\\nCONTEXT:\\\\n{context_text}\\\\n\\\\nUSER QUERY: {request.query}\\\\n\\\\nPlease provide a helpful response based on the context above.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        # Stream response\\\\n        async for chunk in ollama_client.generate_stream(full_prompt, temperature=0.3):\\\\n            yield chunk\\\\n            \\\\n    except Exception as e:\\\\n        yield f\\\\\\\"Error: {str(e)}\\\\\\\\n\\\\\\\"\\\\n\\\\n@app.post(\\\\\\\"/chat\\\\\\\")\\\\nasync def chat_with_repository(request: ChatRequest):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Chat interface for conversational interaction.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        messages = [{\\\\\\\"role\\\\\\\": msg.role, \\\\\\\"content\\\\\\\": msg.content} for msg in request.messages]\\\\n        response = rag_system.chat_with_repo(messages, request.repo_name)\\\\n        \\\\n        return {\\\\n            \\\\\\\"response\\\\\\\": response,\\\\n            \\\\\\\"repo_name\\\\\\\": request.repo_name\\\\n        }\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error in chat: {str(e)}\\\\\\\")\\\\n\\\\n@app.post(\\\\\\\"/explain\\\\\\\")\\\\nasync def explain_code(request: ExplainCodeRequest):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Explain code snippet.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        explanation = rag_system.explain_code(\\\\n            request.code,\\\\n            request.language,\\\\n            request.context\\\\n        )\\\\n        return {\\\\\\\"explanation\\\\\\\": explanation}\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error explaining code: {str(e)}\\\\\\\")\\\\n\\\\n@app.post(\\\\\\\"/improve\\\\\\\")\\\\nasync def suggest_improvements(request: ExplainCodeRequest):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Suggest code improvements.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        suggestions = rag_system.suggest_improvements(\\\\n            request.code,\\\\n            request.language\\\\n        )\\\\n        return {\\\\\\\"suggestions\\\\\\\": suggestions}\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error suggesting improvements: {str(e)}\\\\\\\")\\\\n\\\\n@app.get(\\\\\\\"/repositories/{repo_name}/overview\\\\\\\")\\\\nasync def get_repository_overview(repo_name: str):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Get repository overview.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        overview = rag_system.get_repository_overview(repo_name)\\\\n        return {\\\\\\\"overview\\\\\\\": overview, \\\\\\\"repo_name\\\\\\\": repo_name}\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error getting overview: {str(e)}\\\\\\\")\\\\n\\\\n@app.get(\\\\\\\"/repositories/{repo_name}/files/{file_path:path}/summary\\\\\\\")\\\\nasync def get_file_summary(repo_name: str, file_path: str):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Get file summary.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        summary = rag_system.get_file_summary(file_path, repo_name)\\\\n        return {\\\\\\\"summary\\\\\\\": summary, \\\\\\\"file_path\\\\\\\": file_path, \\\\\\\"repo_name\\\\\\\": repo_name}\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error getting file summary: {str(e)}\\\\\\\")\\\\n\\\\n# Documentation endpoints\\\\n@app.post(\\\\\\\"/repositories/{repo_name}/generate-docs\\\\\\\")\\\\nasync def generate_documentation(repo_name: str, request: DocumentationRequest, background_tasks: BackgroundTasks):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Generate comprehensive documentation for repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        # Load repository analysis\\\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\"{repo_name}_analysis.json\\\\\\\"\\\\n        if not analysis_path.exists():\\\\n            raise HTTPException(status_code=404, detail=f\\\\\\\"Repository {repo_name} not found. Please analyze it first.\\\\\\\")\\\\n        \\\\n        analysis = repository_analyzer.load_analysis(str(analysis_path))\\\\n        \\\\n        config = DocumentationConfig(\\\\n            include_overview=request.include_overview,\\\\n            include_api_docs=request.include_api_docs,\\\\n            include_examples=request.include_examples,\\\\n            include_architecture=request.include_architecture\\\\n        )\\\\n        \\\\n        # Start documentation generation in background\\\\n        background_tasks.add_task(generate_docs_task, analysis, config, repo_name)\\\\n        \\\\n        return {\\\\n            \\\\\\\"message\\\\\\\": f\\\\\\\"Documentation generation started for {repo_name}\\\\\\\",\\\\n            \\\\\\\"repo_name\\\\\\\": repo_name\\\\n        }\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error starting documentation generation: {str(e)}\\\\\\\")\\\\n\\\\nasync def generate_docs_task(analysis: Dict[str, Any], config: DocumentationConfig, repo_name: str):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Background task to generate documentation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        print(f\\\\\\\"Starting documentation generation for {repo_name}\\\\\\\")\\\\n        docs = documentation_builder.generate_full_documentation(analysis, config)\\\\n        print(f\\\\\\\"Documentation generation complete for {repo_name}: {len(docs)} files generated\\\\\\\")\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Error in documentation generation task: {str(e)}\\\\\\\")\\\\n        traceback.print_exc()\\\\n\\\\n@app.get(\\\\\\\"/repositories/{repo_name}/docs\\\\\\\")\\\\nasync def list_generated_docs(repo_name: str):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"List generated documentation files.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    docs_dir = Path(settings.DOCS_DIRECTORY) / repo_name\\\\n    \\\\n    if not docs_dir.exists():\\\\n        return {\\\\\\\"documents\\\\\\\": []}\\\\n    \\\\n    docs = []\\\\n    for doc_file in docs_dir.rglob(\\\\\\\"*.md\\\\\\\"):\\\\n        relative_path = doc_file.relative_to(docs_dir)\\\\n        docs.append({\\\\n            \\\\\\\"name\\\\\\\": doc_file.name,\\\\n            \\\\\\\"path\\\\\\\": str(relative_path),\\\\n            \\\\\\\"size\\\\\\\": doc_file.stat().st_size\\\\n        })\\\\n    \\\\n    return {\\\\\\\"documents\\\\\\\": docs}\\\\n\\\\n@app.get(\\\\\\\"/repositories/{repo_name}/docs/{doc_path:path}\\\\\\\")\\\\nasync def get_documentation(repo_name: str, doc_path: str):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Get specific documentation file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    doc_file = Path(settings.DOCS_DIRECTORY) / repo_name / doc_path\\\\n    \\\\n    if not doc_file.exists():\\\\n        raise HTTPException(status_code=404, detail=\\\\\\\"Documentation file not found\\\\\\\")\\\\n    \\\\n    try:\\\\n        with open(doc_file, 'r', encoding='utf-8') as f:\\\\n            content = f.read()\\\\n        \\\\n        return {\\\\n            \\\\\\\"content\\\\\\\": content,\\\\n            \\\\\\\"path\\\\\\\": doc_path,\\\\n            \\\\\\\"repo_name\\\\\\\": repo_name\\\\n        }\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error reading documentation: {str(e)}\\\\\\\")\\\\n\\\\n# Search endpoints\\\\n@app.get(\\\\\\\"/search\\\\\\\")\\\\nasync def search_all_repositories(q: str, limit: int = 10):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Search across all repositories.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        results = vector_store.search(q, n_results=limit)\\\\n        return {\\\\\\\"results\\\\\\\": results, \\\\\\\"query\\\\\\\": q}\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error searching: {str(e)}\\\\\\\")\\\\n\\\\n@app.get(\\\\\\\"/repositories/{repo_name}/search\\\\\\\")\\\\nasync def search_repository(repo_name: str, q: str, limit: int = 10):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Search within specific repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        results = vector_store.search(\\\\n            q, \\\\n            n_results=limit, \\\\n            filter_metadata={\\\\\\\"repo_name\\\\\\\": repo_name}\\\\n        )\\\\n        return {\\\\\\\"results\\\\\\\": results, \\\\\\\"query\\\\\\\": q, \\\\\\\"repo_name\\\\\\\": repo_name}\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error searching repository: {str(e)}\\\\\\\")\\\\n\\\\n# Statistics endpoint\\\\n@app.get(\\\\\\\"/stats\\\\\\\")\\\\nasync def get_system_stats():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Get system statistics.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        vector_stats = vector_store.get_collection_stats()\\\\n        \\\\n        # Count repositories\\\\n        repos_dir = Path(settings.REPOS_DIRECTORY)\\\\n        repo_count = len(list(repos_dir.glob(\\\\\\\"*_analysis.json\\\\\\\"))) if repos_dir.exists() else 0\\\\n        \\\\n        # Count generated docs\\\\n        docs_dir = Path(settings.DOCS_DIRECTORY)\\\\n        doc_count = len(list(docs_dir.rglob(\\\\\\\"*.md\\\\\\\"))) if docs_dir.exists() else 0\\\\n        \\\\n        return {\\\\n            \\\\\\\"repositories\\\\\\\": repo_count,\\\\n            \\\\\\\"documents_in_vector_store\\\\\\\": vector_stats.get('total_documents', 0),\\\\n            \\\\\\\"generated_docs\\\\\\\": doc_count,\\\\n            \\\\\\\"ollama_available\\\\\\\": ollama_client.is_available(),\\\\n            \\\\\\\"ollama_model\\\\\\\": settings.OLLAMA_MODEL\\\\n        }\\\\n    except Exception as e:\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\"Error getting stats: {str(e)}\\\\\\\")\\\\n\\\\n# Main function to run the server\\\\ndef main():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Main function to run the API server.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    print(f\\\\\\\"Starting Local DeepWiki server on {settings.API_HOST}:{settings.API_PORT}\\\\\\\")\\\\n    print(f\\\\\\\"Ollama URL: {settings.OLLAMA_BASE_URL}\\\\\\\")\\\\n    print(f\\\\\\\"Model: {settings.OLLAMA_MODEL}\\\\\\\")\\\\n    \\\\n    # Check Ollama availability\\\\n    if not ollama_client.is_available():\\\\n        print(\\\\\\\"WARNING: Ollama server not available. Please start Ollama first.\\\\\\\")\\\\n        print(\\\\\\\"Run: ollama serve\\\\\\\")\\\\n    \\\\n    uvicorn.run(\\\\n        \\\\\\\"api:app\\\\\\\",\\\\n        host=settings.API_HOST,\\\\n        port=settings.API_PORT,\\\\n        reload=True\\\\n    )\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\config.py\\\",\\n      \\\"file_type\\\": \\\"code\\\",\\n      \\\"language\\\": \\\"python\\\",\\n      \\\"imports\\\": [\\n        \\\"os\\\",\\n        \\\"pathlib.Path\\\",\\n        \\\"typing.List\\\",\\n        \\\"typing.Dict\\\",\\n        \\\"typing.Any\\\",\\n        \\\"pydantic_settings.BaseSettings\\\"\\n      ],\\n      \\\"elements\\\": [\\n        {\\n          \\\"name\\\": \\\"Settings\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\config.py\\\",\\n          \\\"line_start\\\": 8,\\n          \\\"line_end\\\": 53,\\n          \\\"docstring\\\": \\\"Application settings.\\\",\\n          \\\"signature\\\": \\\"class Settings\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"Config\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\config.py\\\",\\n          \\\"line_start\\\": 52,\\n          \\\"line_end\\\": 53,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"class Config\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        }\\n      ],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Configuration settings for Local DeepWiki.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport os\\\\nfrom pathlib import Path\\\\nfrom typing import List, Dict, Any\\\\nfrom pydantic_settings import BaseSettings\\\\n\\\\nclass Settings(BaseSettings):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Application settings.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    # Ollama settings\\\\n    OLLAMA_BASE_URL: str = \\\\\\\"http://localhost:11434\\\\\\\"\\\\n    OLLAMA_MODEL: str = \\\\\\\"deepseek-coder:6.7b\\\\\\\"  # Using available code-focused model\\\\n    OLLAMA_EMBEDDING_MODEL: str = \\\\\\\"nomic-embed-text:latest\\\\\\\"\\\\n    \\\\n    # Vector database settings\\\\n    CHROMA_PERSIST_DIRECTORY: str = \\\\\\\"./data/chroma_db\\\\\\\"\\\\n    COLLECTION_NAME: str = \\\\\\\"codebase_docs\\\\\\\"\\\\n    \\\\n    # Repository settings\\\\n    REPOS_DIRECTORY: str = \\\\\\\"./data/repos\\\\\\\"\\\\n    DOCS_DIRECTORY: str = \\\\\\\"./data/generated_docs\\\\\\\"\\\\n    \\\\n    # Generation settings\\\\n    MAX_CHUNK_SIZE: int = 2000\\\\n    CHUNK_OVERLAP: int = 200\\\\n    MAX_CONTEXT_LENGTH: int = 4000\\\\n    \\\\n    # API settings\\\\n    API_HOST: str = \\\\\\\"0.0.0.0\\\\\\\"\\\\n    API_PORT: int = 8000\\\\n    \\\\n    # Supported file extensions\\\\n    CODE_EXTENSIONS: List[str] = [\\\\n        \\\\\\\".py\\\\\\\", \\\\\\\".js\\\\\\\", \\\\\\\".ts\\\\\\\", \\\\\\\".jsx\\\\\\\", \\\\\\\".tsx\\\\\\\", \\\\\\\".java\\\\\\\", \\\\\\\".cpp\\\\\\\", \\\\\\\".c\\\\\\\", \\\\\\\".h\\\\\\\",\\\\n        \\\\\\\".cs\\\\\\\", \\\\\\\".php\\\\\\\", \\\\\\\".rb\\\\\\\", \\\\\\\".go\\\\\\\", \\\\\\\".rs\\\\\\\", \\\\\\\".swift\\\\\\\", \\\\\\\".kt\\\\\\\", \\\\\\\".scala\\\\\\\",\\\\n        \\\\\\\".r\\\\\\\", \\\\\\\".sql\\\\\\\", \\\\\\\".sh\\\\\\\", \\\\\\\".yaml\\\\\\\", \\\\\\\".yml\\\\\\\", \\\\\\\".json\\\\\\\", \\\\\\\".xml\\\\\\\", \\\\\\\".html\\\\\\\",\\\\n        \\\\\\\".css\\\\\\\", \\\\\\\".scss\\\\\\\", \\\\\\\".less\\\\\\\", \\\\\\\".vue\\\\\\\", \\\\\\\".svelte\\\\\\\"\\\\n    ]\\\\n    \\\\n    DOC_EXTENSIONS: List[str] = [\\\\\\\".md\\\\\\\", \\\\\\\".rst\\\\\\\", \\\\\\\".txt\\\\\\\", \\\\\\\".adoc\\\\\\\"]\\\\n    \\\\n    # Ignored directories\\\\n    IGNORED_DIRS: List[str] = [\\\\n        \\\\\\\".git\\\\\\\", \\\\\\\".svn\\\\\\\", \\\\\\\".hg\\\\\\\", \\\\\\\"__pycache__\\\\\\\", \\\\\\\".pytest_cache\\\\\\\",\\\\n        \\\\\\\"node_modules\\\\\\\", \\\\\\\".npm\\\\\\\", \\\\\\\".yarn\\\\\\\", \\\\\\\"bower_components\\\\\\\",\\\\n        \\\\\\\".venv\\\\\\\", \\\\\\\"venv\\\\\\\", \\\\\\\"env\\\\\\\", \\\\\\\".env\\\\\\\", \\\\\\\"virtualenv\\\\\\\",\\\\n        \\\\\\\"dist\\\\\\\", \\\\\\\"build\\\\\\\", \\\\\\\"target\\\\\\\", \\\\\\\"bin\\\\\\\", \\\\\\\"obj\\\\\\\",\\\\n        \\\\\\\".idea\\\\\\\", \\\\\\\".vscode\\\\\\\", \\\\\\\".vs\\\\\\\", \\\\\\\"*.egg-info\\\\\\\"\\\\n    ]\\\\n    \\\\n    class Config:\\\\n        env_file = \\\\\\\".env\\\\\\\"\\\\n\\\\n# Global settings instance\\\\nsettings = Settings()\\\\n\\\\n# Ensure data directories exist\\\\nPath(settings.CHROMA_PERSIST_DIRECTORY).mkdir(parents=True, exist_ok=True)\\\\nPath(settings.REPOS_DIRECTORY).mkdir(parents=True, exist_ok=True)\\\\nPath(settings.DOCS_DIRECTORY).mkdir(parents=True, exist_ok=True)\\\\n\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\DEVELOPMENT.md\\\",\\n      \\\"file_type\\\": \\\"documentation\\\",\\n      \\\"language\\\": null,\\n      \\\"imports\\\": [],\\n      \\\"elements\\\": [],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"# Development Guide\\\\n\\\\n## Setting up the development environment\\\\n\\\\n1. Install Python 3.8+\\\\n2. Install dependencies: `pip install -r requirements.txt`\\\\n3. Install and start Ollama\\\\n4. Pull required models: `ollama pull deepseek-coder:6.7b`\\\\n\\\\n## Running the system\\\\n\\\\n### Analyze a repository\\\\n```bash\\\\npython main.py analyze . --name myproject\\\\n```\\\\n\\\\n### Query the repository\\\\n```bash\\\\npython main.py query \\\\\\\"How does authentication work?\\\\\\\" --repo myproject\\\\n```\\\\n\\\\n### Start the API server\\\\n```bash\\\\npython main.py server\\\\n```\\\\n\\\\n## Key Components\\\\n\\\\n- **config.py**: Configuration settings\\\\n- **repository_analyzer.py**: Code parsing and analysis\\\\n- **vector_store.py**: ChromaDB integration\\\\n- **rag_system.py**: RAG implementation\\\\n- **api.py**: FastAPI server\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n      \\\"file_type\\\": \\\"code\\\",\\n      \\\"language\\\": \\\"python\\\",\\n      \\\"imports\\\": [\\n        \\\"os\\\",\\n        \\\"json\\\",\\n        \\\"pathlib.Path\\\",\\n        \\\"typing.Dict\\\",\\n        \\\"typing.List\\\",\\n        \\\"typing.Any\\\",\\n        \\\"typing.Optional\\\",\\n        \\\"dataclasses.dataclass\\\",\\n        \\\"markdown\\\",\\n        \\\"jinja2.Template\\\",\\n        \\\"ollama_client.OllamaClient\\\",\\n        \\\"ollama_client.DocumentationGenerator\\\",\\n        \\\"repository_analyzer.RepositoryAnalyzer\\\",\\n        \\\"config.settings\\\"\\n      ],\\n      \\\"elements\\\": [\\n        {\\n          \\\"name\\\": \\\"DocumentationConfig\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 15,\\n          \\\"line_end\\\": 22,\\n          \\\"docstring\\\": \\\"Configuration for documentation generation.\\\",\\n          \\\"signature\\\": \\\"class DocumentationConfig\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationBuilder\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 24,\\n          \\\"line_end\\\": 502,\\n          \\\"docstring\\\": \\\"Build comprehensive documentation from repository analysis.\\\",\\n          \\\"signature\\\": \\\"class DocumentationBuilder\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationBuilder.__init__\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 27,\\n          \\\"line_end\\\": 94,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self, ollama_client)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationBuilder.generate_full_documentation\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 96,\\n          \\\"line_end\\\": 161,\\n          \\\"docstring\\\": \\\"Generate complete documentation for a repository.\\\",\\n          \\\"signature\\\": \\\"def generate_full_documentation(self, repo_analysis, config, output_dir)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationBuilder.generate_repository_readme\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 163,\\n          \\\"line_end\\\": 224,\\n          \\\"docstring\\\": \\\"Generate main repository README.\\\",\\n          \\\"signature\\\": \\\"def generate_repository_readme(self, repo_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationBuilder.generate_file_api_docs\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 226,\\n          \\\"line_end\\\": 303,\\n          \\\"docstring\\\": \\\"Generate API documentation for a single file.\\\",\\n          \\\"signature\\\": \\\"def generate_file_api_docs(self, file_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationBuilder.generate_architecture_docs\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 305,\\n          \\\"line_end\\\": 366,\\n          \\\"docstring\\\": \\\"Generate architecture documentation.\\\",\\n          \\\"signature\\\": \\\"def generate_architecture_docs(self, repo_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationBuilder.generate_examples_docs\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 368,\\n          \\\"line_end\\\": 447,\\n          \\\"docstring\\\": \\\"Generate usage examples documentation.\\\",\\n          \\\"signature\\\": \\\"def generate_examples_docs(self, repo_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationBuilder.generate_table_of_contents\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 449,\\n          \\\"line_end\\\": 470,\\n          \\\"docstring\\\": \\\"Generate table of contents for all documentation.\\\",\\n          \\\"signature\\\": \\\"def generate_table_of_contents(self, documentation)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationBuilder.update_existing_docs\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 472,\\n          \\\"line_end\\\": 502,\\n          \\\"docstring\\\": \\\"Update existing documentation files with new analysis.\\\",\\n          \\\"signature\\\": \\\"def update_existing_docs(self, repo_path, analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"__init__\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 27,\\n          \\\"line_end\\\": 94,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self, ollama_client)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"generate_full_documentation\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 96,\\n          \\\"line_end\\\": 161,\\n          \\\"docstring\\\": \\\"Generate complete documentation for a repository.\\\",\\n          \\\"signature\\\": \\\"def generate_full_documentation(self, repo_analysis, config, output_dir)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"generate_repository_readme\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 163,\\n          \\\"line_end\\\": 224,\\n          \\\"docstring\\\": \\\"Generate main repository README.\\\",\\n          \\\"signature\\\": \\\"def generate_repository_readme(self, repo_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"generate_file_api_docs\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 226,\\n          \\\"line_end\\\": 303,\\n          \\\"docstring\\\": \\\"Generate API documentation for a single file.\\\",\\n          \\\"signature\\\": \\\"def generate_file_api_docs(self, file_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"generate_architecture_docs\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 305,\\n          \\\"line_end\\\": 366,\\n          \\\"docstring\\\": \\\"Generate architecture documentation.\\\",\\n          \\\"signature\\\": \\\"def generate_architecture_docs(self, repo_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"generate_examples_docs\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 368,\\n          \\\"line_end\\\": 447,\\n          \\\"docstring\\\": \\\"Generate usage examples documentation.\\\",\\n          \\\"signature\\\": \\\"def generate_examples_docs(self, repo_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"generate_table_of_contents\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 449,\\n          \\\"line_end\\\": 470,\\n          \\\"docstring\\\": \\\"Generate table of contents for all documentation.\\\",\\n          \\\"signature\\\": \\\"def generate_table_of_contents(self, documentation)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"update_existing_docs\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\documentation_generator.py\\\",\\n          \\\"line_start\\\": 472,\\n          \\\"line_end\\\": 502,\\n          \\\"docstring\\\": \\\"Update existing documentation files with new analysis.\\\",\\n          \\\"signature\\\": \\\"def update_existing_docs(self, repo_path, analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        }\\n      ],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Documentation generation system using local LLMs.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport os\\\\nimport json\\\\nfrom pathlib import Path\\\\nfrom typing import Dict, List, Any, Optional\\\\nfrom dataclasses import dataclass\\\\nimport markdown\\\\nfrom jinja2 import Template\\\\nfrom ollama_client import OllamaClient, DocumentationGenerator\\\\nfrom repository_analyzer import RepositoryAnalyzer\\\\nfrom config import settings\\\\n\\\\n@dataclass\\\\nclass DocumentationConfig:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Configuration for documentation generation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    include_overview: bool = True\\\\n    include_api_docs: bool = True\\\\n    include_examples: bool = True\\\\n    include_architecture: bool = True\\\\n    output_format: str = 'markdown'  # 'markdown', 'html'\\\\n    template_style: str = 'default'  # 'default', 'minimal', 'detailed'\\\\n\\\\nclass DocumentationBuilder:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Build comprehensive documentation from repository analysis.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    def __init__(self, ollama_client: OllamaClient):\\\\n        self.ollama_client = ollama_client\\\\n        self.doc_generator = DocumentationGenerator(ollama_client)\\\\n        \\\\n        # Documentation templates\\\\n        self.templates = {\\\\n            'repository_readme': \\\\\\\"\\\\\\\"\\\\\\\"# {{ repo_name }}\\\\n\\\\n{{ overview }}\\\\n\\\\n## Architecture\\\\n\\\\n{{ architecture }}\\\\n\\\\n## Getting Started\\\\n\\\\n{{ getting_started }}\\\\n\\\\n## API Documentation\\\\n\\\\n{{ api_docs }}\\\\n\\\\n## Examples\\\\n\\\\n{{ examples }}\\\\n\\\\n## Contributing\\\\n\\\\n{{ contributing }}\\\\n\\\\n\\\\\\\"\\\\\\\"\\\\\\\",\\\\n            \\\\n            'api_reference': \\\\\\\"\\\\\\\"\\\\\\\"# API Reference - {{ file_name }}\\\\n\\\\n{{ file_overview }}\\\\n\\\\n## Classes\\\\n\\\\n{{ classes }}\\\\n\\\\n## Functions\\\\n\\\\n{{ functions }}\\\\n\\\\n## Constants\\\\n\\\\n{{ constants }}\\\\n\\\\n\\\\\\\"\\\\\\\"\\\\\\\",\\\\n            \\\\n            'module_docs': \\\\\\\"\\\\\\\"\\\\\\\"# {{ module_name }}\\\\n\\\\n{{ description }}\\\\n\\\\n## Usage\\\\n\\\\n{{ usage }}\\\\n\\\\n## Implementation Details\\\\n\\\\n{{ implementation }}\\\\n\\\\n## Dependencies\\\\n\\\\n{{ dependencies }}\\\\n\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        }\\\\n    \\\\n    def generate_full_documentation(self, \\\\n                                  repo_analysis: Dict[str, Any], \\\\n                                  config: DocumentationConfig = None,\\\\n                                  output_dir: str = None) -> Dict[str, str]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate complete documentation for a repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        \\\\n        if config is None:\\\\n            config = DocumentationConfig()\\\\n        \\\\n        if output_dir is None:\\\\n            output_dir = settings.DOCS_DIRECTORY\\\\n        \\\\n        output_dir = Path(output_dir)\\\\n        repo_name = repo_analysis.get('repo_name', 'unknown')\\\\n        repo_output_dir = output_dir / repo_name\\\\n        repo_output_dir.mkdir(parents=True, exist_ok=True)\\\\n        \\\\n        documentation = {}\\\\n        \\\\n        # Generate main README\\\\n        if config.include_overview:\\\\n            readme_content = self.generate_repository_readme(repo_analysis)\\\\n            readme_path = repo_output_dir / 'README.md'\\\\n            with open(readme_path, 'w', encoding='utf-8') as f:\\\\n                f.write(readme_content)\\\\n            documentation['README.md'] = readme_content\\\\n        \\\\n        # Generate API documentation for each file\\\\n        if config.include_api_docs:\\\\n            api_dir = repo_output_dir / 'api'\\\\n            api_dir.mkdir(exist_ok=True)\\\\n            \\\\n            for file_data in repo_analysis.get('files', []):\\\\n                if file_data.get('file_type') == 'code':\\\\n                    api_doc = self.generate_file_api_docs(file_data)\\\\n                    file_name = Path(file_data['file_path']).stem\\\\n                    api_file_path = api_dir / f\\\\\\\"{file_name}.md\\\\\\\"\\\\n                    \\\\n                    with open(api_file_path, 'w', encoding='utf-8') as f:\\\\n                        f.write(api_doc)\\\\n                    documentation[f'api/{file_name}.md'] = api_doc\\\\n        \\\\n        # Generate architecture documentation\\\\n        if config.include_architecture:\\\\n            arch_doc = self.generate_architecture_docs(repo_analysis)\\\\n            arch_path = repo_output_dir / 'ARCHITECTURE.md'\\\\n            with open(arch_path, 'w', encoding='utf-8') as f:\\\\n                f.write(arch_doc)\\\\n            documentation['ARCHITECTURE.md'] = arch_doc\\\\n        \\\\n        # Generate examples\\\\n        if config.include_examples:\\\\n            examples_doc = self.generate_examples_docs(repo_analysis)\\\\n            examples_path = repo_output_dir / 'EXAMPLES.md'\\\\n            with open(examples_path, 'w', encoding='utf-8') as f:\\\\n                f.write(examples_doc)\\\\n            documentation['EXAMPLES.md'] = examples_doc\\\\n        \\\\n        # Generate table of contents\\\\n        toc = self.generate_table_of_contents(documentation)\\\\n        toc_path = repo_output_dir / 'TABLE_OF_CONTENTS.md'\\\\n        with open(toc_path, 'w', encoding='utf-8') as f:\\\\n            f.write(toc)\\\\n        documentation['TABLE_OF_CONTENTS.md'] = toc\\\\n        \\\\n        return documentation\\\\n    \\\\n    def generate_repository_readme(self, repo_analysis: Dict[str, Any]) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate main repository README.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        repo_name = repo_analysis.get('repo_name', 'Repository')\\\\n        stats = repo_analysis.get('statistics', {})\\\\n        \\\\n        # Build context for LLM\\\\n        context = []\\\\n        context.append(f\\\\\\\"Repository: {repo_name}\\\\\\\")\\\\n        context.append(f\\\\\\\"Total files: {stats.get('total_files', 0)}\\\\\\\")\\\\n        context.append(f\\\\\\\"Code files: {stats.get('code_files', 0)}\\\\\\\")\\\\n        context.append(f\\\\\\\"Languages: {', '.join(stats.get('languages', {}).keys())}\\\\\\\")\\\\n        \\\\n        # Add git information\\\\n        git_info = repo_analysis.get('git_info')\\\\n        if git_info:\\\\n            context.append(f\\\\\\\"Current branch: {git_info.get('current_branch', 'main')}\\\\\\\")\\\\n            if git_info.get('last_commit'):\\\\n                commit = git_info['last_commit']\\\\n                context.append(f\\\\\\\"Last commit: {commit.get('message', '')[:100]}\\\\\\\")\\\\n        \\\\n        # Add file structure overview\\\\n        main_files = []\\\\n        config_files = []\\\\n        doc_files = []\\\\n        \\\\n        for file_data in repo_analysis.get('files', []):\\\\n            file_path = file_data['file_path']\\\\n            if any(name in file_path.lower() for name in ['readme', 'license', 'changelog']):\\\\n                doc_files.append(file_path)\\\\n            elif any(ext in file_path.lower() for ext in ['.json', '.yaml', '.yml', '.toml', '.ini']):\\\\n                config_files.append(file_path)\\\\n            elif file_data.get('file_type') == 'code':\\\\n                main_files.append(file_path)\\\\n        \\\\n        context.append(f\\\\\\\"Main code files: {', '.join(main_files[:10])}\\\\\\\")\\\\n        if config_files:\\\\n            context.append(f\\\\\\\"Configuration files: {', '.join(config_files[:5])}\\\\\\\")\\\\n        if doc_files:\\\\n            context.append(f\\\\\\\"Documentation files: {', '.join(doc_files)}\\\\\\\")\\\\n        \\\\n        context_str = '\\\\\\\\n'.join(context)\\\\n        \\\\n        prompt = f\\\\\\\"\\\\\\\"\\\\\\\"Generate a comprehensive README.md for this repository based on the following information:\\\\n\\\\n{context_str}\\\\n\\\\nPlease include:\\\\n1. Project title and brief description\\\\n2. Features and capabilities\\\\n3. Installation instructions\\\\n4. Quick start guide\\\\n5. Usage examples\\\\n6. Project structure overview\\\\n7. Contributing guidelines\\\\n8. License information\\\\n\\\\nMake it professional and well-formatted with proper Markdown syntax.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        try:\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\n        except Exception as e:\\\\n            return f\\\\\\\"# {repo_name}\\\\\\\\n\\\\\\\\nError generating README: {str(e)}\\\\\\\"\\\\n    \\\\n    def generate_file_api_docs(self, file_analysis: Dict[str, Any]) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate API documentation for a single file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        file_path = file_analysis['file_path']\\\\n        language = file_analysis.get('language', 'Unknown')\\\\n        elements = file_analysis.get('elements', [])\\\\n        \\\\n        # Group elements by type\\\\n        classes = [e for e in elements if e['type'] == 'class']\\\\n        functions = [e for e in elements if e['type'] in ['function', 'method']]\\\\n        \\\\n        doc_content = f\\\\\\\"# API Reference - {Path(file_path).name}\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n        doc_content += f\\\\\\\"**File**: `{file_path}`  \\\\\\\\n\\\\\\\"\\\\n        doc_content += f\\\\\\\"**Language**: {language}\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n        \\\\n        # File overview\\\\n        overview_prompt = f\\\\\\\"\\\\\\\"\\\\\\\"Provide a brief overview of this {language} file:\\\\n\\\\nFile: {file_path}\\\\nElements: {len(elements)} total ({len(classes)} classes, {len(functions)} functions)\\\\n\\\\nContent preview:\\\\n{file_analysis.get('content', '')[:1000]}...\\\\n\\\\nWrite a 2-3 sentence overview of what this file does.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        try:\\\\n            overview = self.ollama_client.generate(overview_prompt, temperature=0.3)\\\\n            doc_content += f\\\\\\\"## Overview\\\\\\\\n\\\\\\\\n{overview}\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n        except:\\\\n            doc_content += f\\\\\\\"## Overview\\\\\\\\n\\\\\\\\nThis file contains {len(elements)} code elements.\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n        \\\\n        # Document classes\\\\n        if classes:\\\\n            doc_content += \\\\\\\"## Classes\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n            for cls in classes:\\\\n                doc_content += f\\\\\\\"### {cls['name']}\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n                if cls.get('docstring'):\\\\n                    doc_content += f\\\\\\\"{cls['docstring']}\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n                \\\\n                # Get methods for this class\\\\n                class_methods = [e for e in elements if e['type'] == 'method' and e['name'].startswith(f\\\\\\\"{cls['name']}.\\\\\\\")]\\\\n                if class_methods:\\\\n                    doc_content += \\\\\\\"#### Methods\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n                    for method in class_methods:\\\\n                        method_name = method['name'].split('.')[-1]\\\\n                        doc_content += f\\\\\\\"- **{method_name}**\\\\\\\"\\\\n                        if method.get('signature'):\\\\n                            doc_content += f\\\\\\\": `{method['signature']}`\\\\\\\"\\\\n                        if method.get('docstring'):\\\\n                            doc_content += f\\\\\\\" - {method['docstring'][:100]}...\\\\\\\"\\\\n                        doc_content += \\\\\\\"\\\\\\\\n\\\\\\\"\\\\n                    doc_content += \\\\\\\"\\\\\\\\n\\\\\\\"\\\\n        \\\\n        # Document functions\\\\n        if functions:\\\\n            doc_content += \\\\\\\"## Functions\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n            for func in functions:\\\\n                if func['type'] == 'method':\\\\n                    continue  # Skip methods (already documented with classes)\\\\n                \\\\n                doc_content += f\\\\\\\"### {func['name']}\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n                if func.get('signature'):\\\\n                    doc_content += f\\\\\\\"```{language}\\\\\\\\n{func['signature']}\\\\\\\\n```\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n                if func.get('docstring'):\\\\n                    doc_content += f\\\\\\\"{func['docstring']}\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n        \\\\n        # Add imports if available\\\\n        imports = file_analysis.get('imports', [])\\\\n        if imports:\\\\n            doc_content += \\\\\\\"## Dependencies\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n            doc_content += \\\\\\\"This file imports:\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n            for imp in imports[:10]:  # Limit to first 10 imports\\\\n                doc_content += f\\\\\\\"- `{imp}`\\\\\\\\n\\\\\\\"\\\\n            if len(imports) > 10:\\\\n                doc_content += f\\\\\\\"- ... and {len(imports) - 10} more\\\\\\\\n\\\\\\\"\\\\n            doc_content += \\\\\\\"\\\\\\\\n\\\\\\\"\\\\n        \\\\n        return doc_content\\\\n    \\\\n    def generate_architecture_docs(self, repo_analysis: Dict[str, Any]) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate architecture documentation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        repo_name = repo_analysis.get('repo_name', 'Repository')\\\\n        stats = repo_analysis.get('statistics', {})\\\\n        \\\\n        # Analyze project structure\\\\n        languages = stats.get('languages', {})\\\\n        files = repo_analysis.get('files', [])\\\\n        \\\\n        # Group files by directory\\\\n        directories = {}\\\\n        for file_data in files:\\\\n            dir_path = str(Path(file_data['file_path']).parent)\\\\n            if dir_path not in directories:\\\\n                directories[dir_path] = []\\\\n            directories[dir_path].append(file_data)\\\\n        \\\\n        # Build context for architecture analysis\\\\n        context = []\\\\n        context.append(f\\\\\\\"Repository: {repo_name}\\\\\\\")\\\\n        context.append(f\\\\\\\"Languages: {', '.join(languages.keys())}\\\\\\\")\\\\n        context.append(f\\\\\\\"Total files: {stats.get('total_files', 0)}\\\\\\\")\\\\n        \\\\n        context.append(\\\\\\\"\\\\\\\\nDirectory structure:\\\\\\\")\\\\n        for dir_path, dir_files in sorted(directories.items())[:15]:  # Limit directories\\\\n            file_count = len(dir_files)\\\\n            main_types = set()\\\\n            for f in dir_files:\\\\n                if f.get('language'):\\\\n                    main_types.add(f['language'])\\\\n            context.append(f\\\\\\\"- {dir_path}: {file_count} files ({', '.join(main_types)})\\\\\\\")\\\\n        \\\\n        # Add key files analysis\\\\n        key_files = []\\\\n        for file_data in files:\\\\n            if any(keyword in file_data['file_path'].lower() for keyword in ['main', 'app', 'index', '__init__', 'server', 'client']):\\\\n                key_files.append(file_data['file_path'])\\\\n        \\\\n        if key_files:\\\\n            context.append(f\\\\\\\"\\\\\\\\nKey files: {', '.join(key_files[:10])}\\\\\\\")\\\\n        \\\\n        context_str = '\\\\\\\\n'.join(context)\\\\n        \\\\n        prompt = f\\\\\\\"\\\\\\\"\\\\\\\"Analyze the architecture of this project and generate comprehensive architecture documentation:\\\\n\\\\n{context_str}\\\\n\\\\nPlease provide:\\\\n1. High-level architecture overview\\\\n2. Component breakdown and relationships\\\\n3. Data flow and system interactions\\\\n4. Design patterns used\\\\n5. Technology stack analysis\\\\n6. Scalability considerations\\\\n7. Deployment architecture\\\\n\\\\nFormat as professional technical documentation with proper Markdown structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        try:\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\n        except Exception as e:\\\\n            return f\\\\\\\"# Architecture Documentation\\\\\\\\n\\\\\\\\nError generating architecture docs: {str(e)}\\\\\\\"\\\\n    \\\\n    def generate_examples_docs(self, repo_analysis: Dict[str, Any]) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate usage examples documentation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        repo_name = repo_analysis.get('repo_name', 'Repository')\\\\n        languages = repo_analysis.get('statistics', {}).get('languages', {})\\\\n        \\\\n        # Find main entry points\\\\n        entry_points = []\\\\n        main_classes = []\\\\n        main_functions = []\\\\n        \\\\n        for file_data in repo_analysis.get('files', []):\\\\n            if file_data.get('file_type') == 'code':\\\\n                elements = file_data.get('elements', [])\\\\n                \\\\n                # Look for main functions or entry points\\\\n                for element in elements:\\\\n                    if element['name'].lower() in ['main', 'run', 'start', 'init']:\\\\n                        entry_points.append({\\\\n                            'name': element['name'],\\\\n                            'file': file_data['file_path'],\\\\n                            'signature': element.get('signature', ''),\\\\n                            'type': element['type']\\\\n                        })\\\\n                    \\\\n                    if element['type'] == 'class' and len(element.get('name', '')) > 3:\\\\n                        main_classes.append({\\\\n                            'name': element['name'],\\\\n                            'file': file_data['file_path'],\\\\n                            'signature': element.get('signature', ''),\\\\n                            'docstring': element.get('docstring', '')\\\\n                        })\\\\n                    \\\\n                    if element['type'] == 'function' and element.get('docstring'):\\\\n                        main_functions.append({\\\\n                            'name': element['name'],\\\\n                            'file': file_data['file_path'],\\\\n                            'signature': element.get('signature', ''),\\\\n                            'docstring': element.get('docstring', '')\\\\n                        })\\\\n        \\\\n        # Build context\\\\n        context = []\\\\n        context.append(f\\\\\\\"Repository: {repo_name}\\\\\\\")\\\\n        context.append(f\\\\\\\"Languages: {', '.join(languages.keys())}\\\\\\\")\\\\n        \\\\n        if entry_points:\\\\n            context.append(\\\\\\\"\\\\\\\\nEntry points:\\\\\\\")\\\\n            for ep in entry_points[:5]:\\\\n                context.append(f\\\\\\\"- {ep['name']} in {ep['file']}\\\\\\\")\\\\n        \\\\n        if main_classes:\\\\n            context.append(\\\\\\\"\\\\\\\\nMain classes:\\\\\\\")\\\\n            for cls in main_classes[:5]:\\\\n                context.append(f\\\\\\\"- {cls['name']} in {cls['file']}\\\\\\\")\\\\n        \\\\n        if main_functions:\\\\n            context.append(\\\\\\\"\\\\\\\\nKey functions:\\\\\\\")\\\\n            for func in main_functions[:5]:\\\\n                context.append(f\\\\\\\"- {func['name']} in {func['file']}: {func['docstring'][:50]}...\\\\\\\")\\\\n        \\\\n        context_str = '\\\\\\\\n'.join(context)\\\\n        \\\\n        prompt = f\\\\\\\"\\\\\\\"\\\\\\\"Generate practical usage examples and tutorials for this project:\\\\n\\\\n{context_str}\\\\n\\\\nPlease provide:\\\\n1. Quick start example\\\\n2. Basic usage patterns\\\\n3. Common use cases with code examples\\\\n4. Integration examples\\\\n5. Configuration examples\\\\n6. Troubleshooting common issues\\\\n\\\\nInclude actual code snippets with explanations. Format with proper Markdown and code blocks.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        try:\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\n        except Exception as e:\\\\n            return f\\\\\\\"# Usage Examples\\\\\\\\n\\\\\\\\nError generating examples: {str(e)}\\\\\\\"\\\\n    \\\\n    def generate_table_of_contents(self, documentation: Dict[str, str]) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate table of contents for all documentation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        toc_content = \\\\\\\"# Table of Contents\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n        toc_content += \\\\\\\"This repository contains the following documentation:\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n        \\\\n        # Main documentation\\\\n        main_docs = ['README.md', 'ARCHITECTURE.md', 'EXAMPLES.md']\\\\n        for doc in main_docs:\\\\n            if doc in documentation:\\\\n                toc_content += f\\\\\\\"- [{doc}](./{doc})\\\\\\\\n\\\\\\\"\\\\n        \\\\n        # API documentation\\\\n        api_docs = [k for k in documentation.keys() if k.startswith('api/')]\\\\n        if api_docs:\\\\n            toc_content += \\\\\\\"\\\\\\\\n## API Documentation\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n            for doc in sorted(api_docs):\\\\n                file_name = Path(doc).stem\\\\n                toc_content += f\\\\\\\"- [{file_name}](./{doc})\\\\\\\\n\\\\\\\"\\\\n        \\\\n        toc_content += f\\\\\\\"\\\\\\\\n---\\\\\\\\n\\\\\\\\n*Documentation generated automatically from codebase analysis.*\\\\\\\"\\\\n        \\\\n        return toc_content\\\\n    \\\\n    def update_existing_docs(self, repo_path: str, analysis: Dict[str, Any]) -> Dict[str, str]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Update existing documentation files with new analysis.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        repo_path = Path(repo_path)\\\\n        updates = {}\\\\n        \\\\n        # Check for existing README\\\\n        readme_path = repo_path / 'README.md'\\\\n        if readme_path.exists():\\\\n            with open(readme_path, 'r', encoding='utf-8') as f:\\\\n                existing_readme = f.read()\\\\n            \\\\n            # Generate enhancement suggestions\\\\n            prompt = f\\\\\\\"\\\\\\\"\\\\\\\"Analyze this existing README and suggest improvements based on the codebase analysis:\\\\n\\\\nCurrent README:\\\\n{existing_readme[:2000]}...\\\\n\\\\nCodebase info:\\\\n- Files: {analysis.get('statistics', {}).get('total_files', 0)}\\\\n- Languages: {', '.join(analysis.get('statistics', {}).get('languages', {}).keys())}\\\\n- Key components: {len(analysis.get('files', []))} files analyzed\\\\n\\\\nSuggest specific improvements while preserving the existing structure and content.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n            try:\\\\n                suggestions = self.ollama_client.generate(prompt, temperature=0.3)\\\\n                updates['README_suggestions.md'] = suggestions\\\\n            except Exception as e:\\\\n                updates['README_suggestions.md'] = f\\\\\\\"Error generating suggestions: {str(e)}\\\\\\\"\\\\n        \\\\n        return updates\\\\n\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n      \\\"file_type\\\": \\\"code\\\",\\n      \\\"language\\\": \\\"python\\\",\\n      \\\"imports\\\": [\\n        \\\"argparse\\\",\\n        \\\"asyncio\\\",\\n        \\\"sys\\\",\\n        \\\"pathlib.Path\\\",\\n        \\\"typing.Optional\\\",\\n        \\\"config.settings\\\",\\n        \\\"repository_analyzer.RepositoryAnalyzer\\\",\\n        \\\"ollama_client.OllamaClient\\\",\\n        \\\"vector_store.VectorStore\\\",\\n        \\\"rag_system.RAGSystem\\\",\\n        \\\"documentation_generator.DocumentationBuilder\\\",\\n        \\\"documentation_generator.DocumentationConfig\\\",\\n        \\\"api.main\\\"\\n      ],\\n      \\\"elements\\\": [\\n        {\\n          \\\"name\\\": \\\"LocalDeepWiki\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 21,\\n          \\\"line_end\\\": 254,\\n          \\\"docstring\\\": \\\"Main class for Local DeepWiki functionality.\\\",\\n          \\\"signature\\\": \\\"class LocalDeepWiki\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"LocalDeepWiki.__init__\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 24,\\n          \\\"line_end\\\": 30,\\n          \\\"docstring\\\": \\\"Initialize LocalDeepWiki with all components.\\\",\\n          \\\"signature\\\": \\\"def __init__(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"LocalDeepWiki.check_prerequisites\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 32,\\n          \\\"line_end\\\": 65,\\n          \\\"docstring\\\": \\\"Check if all prerequisites are met.\\\",\\n          \\\"signature\\\": \\\"def check_prerequisites(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"LocalDeepWiki.analyze_repository\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 67,\\n          \\\"line_end\\\": 104,\\n          \\\"docstring\\\": \\\"Analyze a repository and add it to the vector store.\\\",\\n          \\\"signature\\\": \\\"def analyze_repository(self, repo_path, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"LocalDeepWiki.query_repository\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 106,\\n          \\\"line_end\\\": 129,\\n          \\\"docstring\\\": \\\"Query a repository using the RAG system.\\\",\\n          \\\"signature\\\": \\\"def query_repository(self, query, repo_name, stream)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"LocalDeepWiki.interactive_chat\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 131,\\n          \\\"line_end\\\": 164,\\n          \\\"docstring\\\": \\\"Start an interactive chat session.\\\",\\n          \\\"signature\\\": \\\"def interactive_chat(self, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"LocalDeepWiki.generate_documentation\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 166,\\n          \\\"line_end\\\": 199,\\n          \\\"docstring\\\": \\\"Generate documentation for a repository.\\\",\\n          \\\"signature\\\": \\\"def generate_documentation(self, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"LocalDeepWiki.list_repositories\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 201,\\n          \\\"line_end\\\": 231,\\n          \\\"docstring\\\": \\\"List all analyzed repositories.\\\",\\n          \\\"signature\\\": \\\"def list_repositories(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"LocalDeepWiki.show_stats\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 233,\\n          \\\"line_end\\\": 254,\\n          \\\"docstring\\\": \\\"Show system statistics.\\\",\\n          \\\"signature\\\": \\\"def show_stats(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"main\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 256,\\n          \\\"line_end\\\": 342,\\n          \\\"docstring\\\": \\\"Main CLI interface.\\\",\\n          \\\"signature\\\": \\\"def main()\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"__init__\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 24,\\n          \\\"line_end\\\": 30,\\n          \\\"docstring\\\": \\\"Initialize LocalDeepWiki with all components.\\\",\\n          \\\"signature\\\": \\\"def __init__(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"check_prerequisites\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 32,\\n          \\\"line_end\\\": 65,\\n          \\\"docstring\\\": \\\"Check if all prerequisites are met.\\\",\\n          \\\"signature\\\": \\\"def check_prerequisites(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"analyze_repository\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 67,\\n          \\\"line_end\\\": 104,\\n          \\\"docstring\\\": \\\"Analyze a repository and add it to the vector store.\\\",\\n          \\\"signature\\\": \\\"def analyze_repository(self, repo_path, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"query_repository\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 106,\\n          \\\"line_end\\\": 129,\\n          \\\"docstring\\\": \\\"Query a repository using the RAG system.\\\",\\n          \\\"signature\\\": \\\"def query_repository(self, query, repo_name, stream)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"interactive_chat\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 131,\\n          \\\"line_end\\\": 164,\\n          \\\"docstring\\\": \\\"Start an interactive chat session.\\\",\\n          \\\"signature\\\": \\\"def interactive_chat(self, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"generate_documentation\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 166,\\n          \\\"line_end\\\": 199,\\n          \\\"docstring\\\": \\\"Generate documentation for a repository.\\\",\\n          \\\"signature\\\": \\\"def generate_documentation(self, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"list_repositories\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 201,\\n          \\\"line_end\\\": 231,\\n          \\\"docstring\\\": \\\"List all analyzed repositories.\\\",\\n          \\\"signature\\\": \\\"def list_repositories(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"show_stats\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\main.py\\\",\\n          \\\"line_start\\\": 233,\\n          \\\"line_end\\\": 254,\\n          \\\"docstring\\\": \\\"Show system statistics.\\\",\\n          \\\"signature\\\": \\\"def show_stats(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        }\\n      ],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nLocal DeepWiki - Main entry point and CLI interface.\\\\n\\\\nA local implementation of DeepWiki using Ollama for LLM inference.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport argparse\\\\nimport asyncio\\\\nimport sys\\\\nfrom pathlib import Path\\\\nfrom typing import Optional\\\\n\\\\nfrom config import settings\\\\nfrom repository_analyzer import RepositoryAnalyzer\\\\nfrom ollama_client import OllamaClient\\\\nfrom vector_store import VectorStore\\\\nfrom rag_system import RAGSystem\\\\nfrom documentation_generator import DocumentationBuilder, DocumentationConfig\\\\n\\\\nclass LocalDeepWiki:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Main class for Local DeepWiki functionality.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    def __init__(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Initialize LocalDeepWiki with all components.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.ollama_client = OllamaClient()\\\\n        self.vector_store = VectorStore()\\\\n        self.rag_system = RAGSystem(self.vector_store, self.ollama_client)\\\\n        self.repository_analyzer = RepositoryAnalyzer()\\\\n        self.documentation_builder = DocumentationBuilder(self.ollama_client)\\\\n    \\\\n    def check_prerequisites(self) -> bool:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Check if all prerequisites are met.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        print(\\\\\\\"Checking prerequisites...\\\\\\\")\\\\n        \\\\n        # Check Ollama\\\\n        if not self.ollama_client.is_available():\\\\n            print(\\\\\\\"X Ollama server is not available at\\\\\\\", settings.OLLAMA_BASE_URL)\\\\n            print(\\\\\\\"Please start Ollama first:\\\\\\\")\\\\n            print(\\\\\\\"  ollama serve\\\\\\\")\\\\n            return False\\\\n        \\\\n        print(\\\\\\\"OK Ollama server is available\\\\\\\")\\\\n        \\\\n        # Check model\\\\n        models = self.ollama_client.list_models()\\\\n        model_names = [model['name'] for model in models]\\\\n        \\\\n        if settings.OLLAMA_MODEL not in model_names:\\\\n            print(f\\\\\\\"X Model '{settings.OLLAMA_MODEL}' is not available\\\\\\\")\\\\n            print(\\\\\\\"Available models:\\\\\\\", model_names)\\\\n            print(f\\\\\\\"To download the model, run:\\\\\\\")\\\\n            print(f\\\\\\\"  ollama pull {settings.OLLAMA_MODEL}\\\\\\\")\\\\n            return False\\\\n        \\\\n        print(f\\\\\\\"OK Model '{settings.OLLAMA_MODEL}' is available\\\\\\\")\\\\n        \\\\n        # Check embedding model\\\\n        if settings.OLLAMA_EMBEDDING_MODEL not in model_names:\\\\n            print(f\\\\\\\"! Embedding model '{settings.OLLAMA_EMBEDDING_MODEL}' not found\\\\\\\")\\\\n            print(\\\\\\\"Will use fallback embedding model\\\\\\\")\\\\n        else:\\\\n            print(f\\\\\\\"OK Embedding model '{settings.OLLAMA_EMBEDDING_MODEL}' is available\\\\\\\")\\\\n        \\\\n        return True\\\\n    \\\\n    def analyze_repository(self, repo_path: str, repo_name: Optional[str] = None) -> bool:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Analyze a repository and add it to the vector store.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        repo_path = Path(repo_path).resolve()\\\\n        \\\\n        if not repo_path.exists():\\\\n            print(f\\\\\\\"X Repository path does not exist: {repo_path}\\\\\\\")\\\\n            return False\\\\n        \\\\n        repo_name = repo_name or repo_path.name\\\\n        print(f\\\\\\\"* Analyzing repository: {repo_name}\\\\\\\")\\\\n        print(f\\\\\\\"   Path: {repo_path}\\\\\\\")\\\\n        \\\\n        try:\\\\n            # Analyze repository structure\\\\n            print(\\\\\\\"   Parsing files and extracting structure...\\\\\\\")\\\\n            analysis = self.repository_analyzer.analyze_repository(str(repo_path))\\\\n            analysis['repo_name'] = repo_name\\\\n            \\\\n            # Save analysis\\\\n            analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\"{repo_name}_analysis.json\\\\\\\"\\\\n            self.repository_analyzer.save_analysis(analysis, str(analysis_path))\\\\n            print(f\\\\\\\"   Analysis saved to: {analysis_path}\\\\\\\")\\\\n            \\\\n            # Add to vector store\\\\n            print(\\\\\\\"   Adding to vector store...\\\\\\\")\\\\n            chunks_added = self.vector_store.add_repository(analysis)\\\\n            \\\\n            print(f\\\\\\\"OK Repository analysis complete!\\\\\\\")\\\\n            print(f\\\\\\\"   Files analyzed: {analysis['statistics']['total_files']}\\\\\\\")\\\\n            print(f\\\\\\\"   Code files: {analysis['statistics']['code_files']}\\\\\\\")\\\\n            print(f\\\\\\\"   Languages: {', '.join(analysis['statistics']['languages'].keys())}\\\\\\\")\\\\n            print(f\\\\\\\"   Chunks added to vector store: {chunks_added}\\\\\\\")\\\\n            \\\\n            return True\\\\n            \\\\n        except Exception as e:\\\\n            print(f\\\\\\\"X Error analyzing repository: {e}\\\\\\\")\\\\n            return False\\\\n    \\\\n    def query_repository(self, query: str, repo_name: Optional[str] = None, stream: bool = True):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Query a repository using the RAG system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        print(f\\\\\\\"? Query: {query}\\\\\\\")\\\\n        if repo_name:\\\\n            print(f\\\\\\\"   Repository: {repo_name}\\\\\\\")\\\\n        \\\\n        try:\\\\n            result = self.rag_system.query(query, repo_name=repo_name, stream=False)\\\\n            \\\\n            if result['context']:\\\\n                print(\\\\\\\"\\\\\\\\n> Response:\\\\\\\")\\\\n                print(result['response'])\\\\n                \\\\n                if result['sources']:\\\\n                    print(\\\\\\\"\\\\\\\\n* Sources:\\\\\\\")\\\\n                    for i, source in enumerate(result['sources'], 1):\\\\n                        print(f\\\\\\\"   {i}. {source.get('file_path', 'Unknown')}\\\\\\\")\\\\n                        if source.get('element_name'):\\\\n                            print(f\\\\\\\"      Element: {source['element_name']}\\\\\\\")\\\\n            else:\\\\n                print(\\\\\\\"X No relevant context found for your query.\\\\\\\")\\\\n                \\\\n        except Exception as e:\\\\n            print(f\\\\\\\"X Error processing query: {e}\\\\\\\")\\\\n    \\\\n    def interactive_chat(self, repo_name: Optional[str] = None):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Start an interactive chat session.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        print(\\\\\\\"* Interactive Chat Mode\\\\\\\")\\\\n        print(\\\\\\\"Type 'quit' or 'exit' to end the session\\\\\\\")\\\\n        if repo_name:\\\\n            print(f\\\\\\\"Querying repository: {repo_name}\\\\\\\")\\\\n        print(\\\\\\\"-\\\\\\\" * 50)\\\\n        \\\\n        messages = []\\\\n        \\\\n        while True:\\\\n            try:\\\\n                user_input = input(\\\\\\\"\\\\\\\\nYou: \\\\\\\").strip()\\\\n                \\\\n                if user_input.lower() in ['quit', 'exit', 'q']:\\\\n                    print(\\\\\\\"Goodbye!\\\\\\\")\\\\n                    break\\\\n                \\\\n                if not user_input:\\\\n                    continue\\\\n                \\\\n                messages.append({\\\\\\\"role\\\\\\\": \\\\\\\"user\\\\\\\", \\\\\\\"content\\\\\\\": user_input})\\\\n                \\\\n                print(\\\\\\\"\\\\\\\\nAssistant: \\\\\\\", end=\\\\\\\"\\\\\\\", flush=True)\\\\n                response = self.rag_system.chat_with_repo(messages, repo_name)\\\\n                print(response)\\\\n                \\\\n                messages.append({\\\\\\\"role\\\\\\\": \\\\\\\"assistant\\\\\\\", \\\\\\\"content\\\\\\\": response})\\\\n                \\\\n            except KeyboardInterrupt:\\\\n                print(\\\\\\\"\\\\\\\\nGoodbye!\\\\\\\")\\\\n                break\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"\\\\\\\\nX Error: {e}\\\\\\\")\\\\n    \\\\n    def generate_documentation(self, repo_name: str):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate documentation for a repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        print(f\\\\\\\"* Generating documentation for: {repo_name}\\\\\\\")\\\\n        \\\\n        # Load analysis\\\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\"{repo_name}_analysis.json\\\\\\\"\\\\n        if not analysis_path.exists():\\\\n            print(f\\\\\\\"X Repository {repo_name} not found. Please analyze it first.\\\\\\\")\\\\n            return False\\\\n        \\\\n        try:\\\\n            analysis = self.repository_analyzer.load_analysis(str(analysis_path))\\\\n            \\\\n            config = DocumentationConfig(\\\\n                include_overview=True,\\\\n                include_api_docs=True,\\\\n                include_examples=True,\\\\n                include_architecture=True\\\\n            )\\\\n            \\\\n            docs = self.documentation_builder.generate_full_documentation(analysis, config)\\\\n            \\\\n            print(f\\\\\\\"OK Documentation generated!\\\\\\\")\\\\n            print(f\\\\\\\"   Files created: {len(docs)}\\\\\\\")\\\\n            print(f\\\\\\\"   Output directory: {Path(settings.DOCS_DIRECTORY) / repo_name}\\\\\\\")\\\\n            \\\\n            for doc_name in docs.keys():\\\\n                print(f\\\\\\\"   - {doc_name}\\\\\\\")\\\\n            \\\\n            return True\\\\n            \\\\n        except Exception as e:\\\\n            print(f\\\\\\\"X Error generating documentation: {e}\\\\\\\")\\\\n            return False\\\\n    \\\\n    def list_repositories(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"List all analyzed repositories.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        repos_dir = Path(settings.REPOS_DIRECTORY)\\\\n        \\\\n        if not repos_dir.exists():\\\\n            print(\\\\\\\"No repositories found.\\\\\\\")\\\\n            return\\\\n        \\\\n        analysis_files = list(repos_dir.glob(\\\\\\\"*_analysis.json\\\\\\\"))\\\\n        \\\\n        if not analysis_files:\\\\n            print(\\\\\\\"No repositories found.\\\\\\\")\\\\n            return\\\\n        \\\\n        print(\\\\\\\"* Analyzed Repositories:\\\\\\\")\\\\n        print(\\\\\\\"-\\\\\\\" * 50)\\\\n        \\\\n        for analysis_file in analysis_files:\\\\n            try:\\\\n                analysis = self.repository_analyzer.load_analysis(str(analysis_file))\\\\n                repo_name = analysis.get('repo_name', analysis_file.stem.replace('_analysis', ''))\\\\n                stats = analysis.get('statistics', {})\\\\n                \\\\n                print(f\\\\\\\"+ {repo_name}\\\\\\\")\\\\n                print(f\\\\\\\"   Path: {analysis.get('repo_path', 'Unknown')}\\\\\\\")\\\\n                print(f\\\\\\\"   Files: {stats.get('total_files', 0)} total, {stats.get('code_files', 0)} code\\\\\\\")\\\\n                print(f\\\\\\\"   Languages: {', '.join(stats.get('languages', {}).keys())}\\\\\\\")\\\\n                print()\\\\n                \\\\n            except Exception as e:\\\\n                print(f\\\\\\\"X Error loading {analysis_file}: {e}\\\\\\\")\\\\n    \\\\n    def show_stats(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Show system statistics.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        print(\\\\\\\"* System Statistics\\\\\\\")\\\\n        print(\\\\\\\"-\\\\\\\" * 30)\\\\n        \\\\n        # Vector store stats\\\\n        vector_stats = self.vector_store.get_collection_stats()\\\\n        print(f\\\\\\\"Documents in vector store: {vector_stats.get('total_documents', 0)}\\\\\\\")\\\\n        \\\\n        # Repository count\\\\n        repos_dir = Path(settings.REPOS_DIRECTORY)\\\\n        repo_count = len(list(repos_dir.glob(\\\\\\\"*_analysis.json\\\\\\\"))) if repos_dir.exists() else 0\\\\n        print(f\\\\\\\"Analyzed repositories: {repo_count}\\\\\\\")\\\\n        \\\\n        # Generated docs count\\\\n        docs_dir = Path(settings.DOCS_DIRECTORY)\\\\n        doc_count = len(list(docs_dir.rglob(\\\\\\\"*.md\\\\\\\"))) if docs_dir.exists() else 0\\\\n        print(f\\\\\\\"Generated documentation files: {doc_count}\\\\\\\")\\\\n        \\\\n        # Ollama status\\\\n        print(f\\\\\\\"Ollama available: {'OK' if self.ollama_client.is_available() else 'X'}\\\\\\\")\\\\n        print(f\\\\\\\"Current model: {settings.OLLAMA_MODEL}\\\\\\\")\\\\n\\\\ndef main():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Main CLI interface.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    parser = argparse.ArgumentParser(description=\\\\\\\"Local DeepWiki - Chat with your code repositories\\\\\\\")\\\\n    \\\\n    subparsers = parser.add_subparsers(dest='command', help='Available commands')\\\\n    \\\\n    # Check command\\\\n    subparsers.add_parser('check', help='Check system prerequisites')\\\\n    \\\\n    # Analyze command\\\\n    analyze_parser = subparsers.add_parser('analyze', help='Analyze a repository')\\\\n    analyze_parser.add_argument('repo_path', help='Path to the repository')\\\\n    analyze_parser.add_argument('--name', help='Custom name for the repository')\\\\n    \\\\n    # Query command\\\\n    query_parser = subparsers.add_parser('query', help='Query a repository')\\\\n    query_parser.add_argument('query', help='Your question or query')\\\\n    query_parser.add_argument('--repo', help='Repository name to query')\\\\n    \\\\n    # Chat command\\\\n    chat_parser = subparsers.add_parser('chat', help='Start interactive chat')\\\\n    chat_parser.add_argument('--repo', help='Repository name to chat with')\\\\n    \\\\n    # Docs command\\\\n    docs_parser = subparsers.add_parser('docs', help='Generate documentation')\\\\n    docs_parser.add_argument('repo_name', help='Repository name')\\\\n    \\\\n    # List command\\\\n    subparsers.add_parser('list', help='List analyzed repositories')\\\\n    \\\\n    # Stats command\\\\n    subparsers.add_parser('stats', help='Show system statistics')\\\\n    \\\\n    # Server command\\\\n    server_parser = subparsers.add_parser('server', help='Start web server')\\\\n    server_parser.add_argument('--host', default=settings.API_HOST, help='Host address')\\\\n    server_parser.add_argument('--port', type=int, default=settings.API_PORT, help='Port number')\\\\n    \\\\n    args = parser.parse_args()\\\\n    \\\\n    if not args.command:\\\\n        parser.print_help()\\\\n        return\\\\n    \\\\n    # Initialize LocalDeepWiki\\\\n    ldw = LocalDeepWiki()\\\\n    \\\\n    if args.command == 'check':\\\\n        if ldw.check_prerequisites():\\\\n            print(\\\\\\\"\\\\\\\\nOK All prerequisites are met! You're ready to use Local DeepWiki.\\\\\\\")\\\\n        else:\\\\n            print(\\\\\\\"\\\\\\\\nX Please fix the issues above before using Local DeepWiki.\\\\\\\")\\\\n            sys.exit(1)\\\\n    \\\\n    elif args.command == 'analyze':\\\\n        if not ldw.check_prerequisites():\\\\n            sys.exit(1)\\\\n        ldw.analyze_repository(args.repo_path, args.name)\\\\n    \\\\n    elif args.command == 'query':\\\\n        if not ldw.check_prerequisites():\\\\n            sys.exit(1)\\\\n        ldw.query_repository(args.query, args.repo)\\\\n    \\\\n    elif args.command == 'chat':\\\\n        if not ldw.check_prerequisites():\\\\n            sys.exit(1)\\\\n        ldw.interactive_chat(args.repo)\\\\n    \\\\n    elif args.command == 'docs':\\\\n        if not ldw.check_prerequisites():\\\\n            sys.exit(1)\\\\n        ldw.generate_documentation(args.repo_name)\\\\n    \\\\n    elif args.command == 'list':\\\\n        ldw.list_repositories()\\\\n    \\\\n    elif args.command == 'stats':\\\\n        ldw.show_stats()\\\\n    \\\\n    elif args.command == 'server':\\\\n        if not ldw.check_prerequisites():\\\\n            sys.exit(1)\\\\n        \\\\n        # Import and run the API server\\\\n        from api import main as run_server\\\\n        run_server()\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\\n\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n      \\\"file_type\\\": \\\"code\\\",\\n      \\\"language\\\": \\\"python\\\",\\n      \\\"imports\\\": [\\n        \\\"json\\\",\\n        \\\"requests\\\",\\n        \\\"asyncio\\\",\\n        \\\"aiohttp\\\",\\n        \\\"typing.Dict\\\",\\n        \\\"typing.List\\\",\\n        \\\"typing.Any\\\",\\n        \\\"typing.Optional\\\",\\n        \\\"typing.AsyncGenerator\\\",\\n        \\\"config.settings\\\"\\n      ],\\n      \\\"elements\\\": [\\n        {\\n          \\\"name\\\": \\\"OllamaClient\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 10,\\n          \\\"line_end\\\": 231,\\n          \\\"docstring\\\": \\\"Client for interacting with Ollama local LLM server.\\\",\\n          \\\"signature\\\": \\\"class OllamaClient\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"OllamaClient.__init__\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 13,\\n          \\\"line_end\\\": 16,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self, base_url, model)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"OllamaClient.is_available\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 18,\\n          \\\"line_end\\\": 24,\\n          \\\"docstring\\\": \\\"Check if Ollama server is available.\\\",\\n          \\\"signature\\\": \\\"def is_available(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"OllamaClient.list_models\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 26,\\n          \\\"line_end\\\": 34,\\n          \\\"docstring\\\": \\\"List available models.\\\",\\n          \\\"signature\\\": \\\"def list_models(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"OllamaClient.pull_model\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 36,\\n          \\\"line_end\\\": 57,\\n          \\\"docstring\\\": \\\"Pull a model if not already available.\\\",\\n          \\\"signature\\\": \\\"def pull_model(self, model_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"OllamaClient.generate\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 59,\\n          \\\"line_end\\\": 80,\\n          \\\"docstring\\\": \\\"Generate text using Ollama.\\\",\\n          \\\"signature\\\": \\\"def generate(self, prompt, model)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"OllamaClient.get_embeddings\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 141,\\n          \\\"line_end\\\": 160,\\n          \\\"docstring\\\": \\\"Get embeddings for text.\\\",\\n          \\\"signature\\\": \\\"def get_embeddings(self, text, model)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"OllamaClient.chat\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 185,\\n          \\\"line_end\\\": 206,\\n          \\\"docstring\\\": \\\"Chat completion using Ollama.\\\",\\n          \\\"signature\\\": \\\"def chat(self, messages, model)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationGenerator\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 233,\\n          \\\"line_end\\\": 352,\\n          \\\"docstring\\\": \\\"Generate documentation using Ollama.\\\",\\n          \\\"signature\\\": \\\"class DocumentationGenerator\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationGenerator.__init__\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 236,\\n          \\\"line_end\\\": 237,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self, ollama_client)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationGenerator.generate_file_documentation\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 239,\\n          \\\"line_end\\\": 295,\\n          \\\"docstring\\\": \\\"Generate documentation for a single file.\\\",\\n          \\\"signature\\\": \\\"def generate_file_documentation(self, file_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"DocumentationGenerator.generate_repository_overview\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 297,\\n          \\\"line_end\\\": 352,\\n          \\\"docstring\\\": \\\"Generate high-level repository documentation.\\\",\\n          \\\"signature\\\": \\\"def generate_repository_overview(self, repo_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"__init__\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 13,\\n          \\\"line_end\\\": 16,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self, base_url, model)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"is_available\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 18,\\n          \\\"line_end\\\": 24,\\n          \\\"docstring\\\": \\\"Check if Ollama server is available.\\\",\\n          \\\"signature\\\": \\\"def is_available(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"list_models\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 26,\\n          \\\"line_end\\\": 34,\\n          \\\"docstring\\\": \\\"List available models.\\\",\\n          \\\"signature\\\": \\\"def list_models(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"pull_model\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 36,\\n          \\\"line_end\\\": 57,\\n          \\\"docstring\\\": \\\"Pull a model if not already available.\\\",\\n          \\\"signature\\\": \\\"def pull_model(self, model_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"generate\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 59,\\n          \\\"line_end\\\": 80,\\n          \\\"docstring\\\": \\\"Generate text using Ollama.\\\",\\n          \\\"signature\\\": \\\"def generate(self, prompt, model)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"get_embeddings\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 141,\\n          \\\"line_end\\\": 160,\\n          \\\"docstring\\\": \\\"Get embeddings for text.\\\",\\n          \\\"signature\\\": \\\"def get_embeddings(self, text, model)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"chat\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 185,\\n          \\\"line_end\\\": 206,\\n          \\\"docstring\\\": \\\"Chat completion using Ollama.\\\",\\n          \\\"signature\\\": \\\"def chat(self, messages, model)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"__init__\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 236,\\n          \\\"line_end\\\": 237,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self, ollama_client)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"generate_file_documentation\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 239,\\n          \\\"line_end\\\": 295,\\n          \\\"docstring\\\": \\\"Generate documentation for a single file.\\\",\\n          \\\"signature\\\": \\\"def generate_file_documentation(self, file_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"generate_repository_overview\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\ollama_client.py\\\",\\n          \\\"line_start\\\": 297,\\n          \\\"line_end\\\": 352,\\n          \\\"docstring\\\": \\\"Generate high-level repository documentation.\\\",\\n          \\\"signature\\\": \\\"def generate_repository_overview(self, repo_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        }\\n      ],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Ollama client for local LLM inference.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport json\\\\nimport requests\\\\nimport asyncio\\\\nimport aiohttp\\\\nfrom typing import Dict, List, Any, Optional, AsyncGenerator\\\\nfrom config import settings\\\\n\\\\nclass OllamaClient:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Client for interacting with Ollama local LLM server.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    def __init__(self, base_url: str = None, model: str = None):\\\\n        self.base_url = base_url or settings.OLLAMA_BASE_URL\\\\n        self.model = model or settings.OLLAMA_MODEL\\\\n        self.embedding_model = settings.OLLAMA_EMBEDDING_MODEL\\\\n        \\\\n    def is_available(self) -> bool:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Check if Ollama server is available.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            response = requests.get(f\\\\\\\"{self.base_url}/api/tags\\\\\\\", timeout=5)\\\\n            return response.status_code == 200\\\\n        except:\\\\n            return False\\\\n    \\\\n    def list_models(self) -> List[Dict[str, Any]]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"List available models.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            response = requests.get(f\\\\\\\"{self.base_url}/api/tags\\\\\\\")\\\\n            response.raise_for_status()\\\\n            return response.json().get('models', [])\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error listing models: {e}\\\\\\\")\\\\n            return []\\\\n    \\\\n    def pull_model(self, model_name: str) -> bool:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Pull a model if not already available.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            response = requests.post(\\\\n                f\\\\\\\"{self.base_url}/api/pull\\\\\\\",\\\\n                json={\\\\\\\"name\\\\\\\": model_name},\\\\n                stream=True\\\\n            )\\\\n            \\\\n            for line in response.iter_lines():\\\\n                if line:\\\\n                    data = json.loads(line)\\\\n                    if data.get('status'):\\\\n                        print(f\\\\\\\"Pulling {model_name}: {data['status']}\\\\\\\")\\\\n                    if data.get('error'):\\\\n                        print(f\\\\\\\"Error: {data['error']}\\\\\\\")\\\\n                        return False\\\\n            \\\\n            return True\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error pulling model {model_name}: {e}\\\\\\\")\\\\n            return False\\\\n    \\\\n    def generate(self, prompt: str, model: str = None, **kwargs) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate text using Ollama.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        model = model or self.model\\\\n        \\\\n        payload = {\\\\n            \\\\\\\"model\\\\\\\": model,\\\\n            \\\\\\\"prompt\\\\\\\": prompt,\\\\n            \\\\\\\"stream\\\\\\\": False,\\\\n            **kwargs\\\\n        }\\\\n        \\\\n        try:\\\\n            response = requests.post(\\\\n                f\\\\\\\"{self.base_url}/api/generate\\\\\\\",\\\\n                json=payload,\\\\n                timeout=120\\\\n            )\\\\n            response.raise_for_status()\\\\n            return response.json()['response']\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error generating text: {e}\\\\\\\")\\\\n            raise\\\\n    \\\\n    async def generate_async(self, prompt: str, model: str = None, **kwargs) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate text asynchronously.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        model = model or self.model\\\\n        \\\\n        payload = {\\\\n            \\\\\\\"model\\\\\\\": model,\\\\n            \\\\\\\"prompt\\\\\\\": prompt,\\\\n            \\\\\\\"stream\\\\\\\": False,\\\\n            **kwargs\\\\n        }\\\\n        \\\\n        async with aiohttp.ClientSession() as session:\\\\n            try:\\\\n                async with session.post(\\\\n                    f\\\\\\\"{self.base_url}/api/generate\\\\\\\",\\\\n                    json=payload,\\\\n                    timeout=aiohttp.ClientTimeout(total=120)\\\\n                ) as response:\\\\n                    response.raise_for_status()\\\\n                    result = await response.json()\\\\n                    return result['response']\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"Error generating text: {e}\\\\\\\")\\\\n                raise\\\\n    \\\\n    async def generate_stream(self, prompt: str, model: str = None, **kwargs) -> AsyncGenerator[str, None]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate text with streaming response.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        model = model or self.model\\\\n        \\\\n        payload = {\\\\n            \\\\\\\"model\\\\\\\": model,\\\\n            \\\\\\\"prompt\\\\\\\": prompt,\\\\n            \\\\\\\"stream\\\\\\\": True,\\\\n            **kwargs\\\\n        }\\\\n        \\\\n        async with aiohttp.ClientSession() as session:\\\\n            try:\\\\n                async with session.post(\\\\n                    f\\\\\\\"{self.base_url}/api/generate\\\\\\\",\\\\n                    json=payload,\\\\n                    timeout=aiohttp.ClientTimeout(total=None)\\\\n                ) as response:\\\\n                    response.raise_for_status()\\\\n                    \\\\n                    async for line in response.content:\\\\n                        if line:\\\\n                            try:\\\\n                                data = json.loads(line)\\\\n                                if 'response' in data:\\\\n                                    yield data['response']\\\\n                                if data.get('done', False):\\\\n                                    break\\\\n                            except json.JSONDecodeError:\\\\n                                continue\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"Error in streaming generation: {e}\\\\\\\")\\\\n                raise\\\\n    \\\\n    def get_embeddings(self, text: str, model: str = None) -> List[float]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get embeddings for text.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        model = model or self.embedding_model\\\\n        \\\\n        payload = {\\\\n            \\\\\\\"model\\\\\\\": model,\\\\n            \\\\\\\"prompt\\\\\\\": text\\\\n        }\\\\n        \\\\n        try:\\\\n            response = requests.post(\\\\n                f\\\\\\\"{self.base_url}/api/embeddings\\\\\\\",\\\\n                json=payload,\\\\n                timeout=60\\\\n            )\\\\n            response.raise_for_status()\\\\n            return response.json()['embedding']\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error getting embeddings: {e}\\\\\\\")\\\\n            raise\\\\n    \\\\n    async def get_embeddings_async(self, text: str, model: str = None) -> List[float]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get embeddings asynchronously.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        model = model or self.embedding_model\\\\n        \\\\n        payload = {\\\\n            \\\\\\\"model\\\\\\\": model,\\\\n            \\\\\\\"prompt\\\\\\\": text\\\\n        }\\\\n        \\\\n        async with aiohttp.ClientSession() as session:\\\\n            try:\\\\n                async with session.post(\\\\n                    f\\\\\\\"{self.base_url}/api/embeddings\\\\\\\",\\\\n                    json=payload,\\\\n                    timeout=aiohttp.ClientTimeout(total=60)\\\\n                ) as response:\\\\n                    response.raise_for_status()\\\\n                    result = await response.json()\\\\n                    return result['embedding']\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"Error getting embeddings: {e}\\\\\\\")\\\\n                raise\\\\n    \\\\n    def chat(self, messages: List[Dict[str, str]], model: str = None, **kwargs) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Chat completion using Ollama.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        model = model or self.model\\\\n        \\\\n        payload = {\\\\n            \\\\\\\"model\\\\\\\": model,\\\\n            \\\\\\\"messages\\\\\\\": messages,\\\\n            \\\\\\\"stream\\\\\\\": False,\\\\n            **kwargs\\\\n        }\\\\n        \\\\n        try:\\\\n            response = requests.post(\\\\n                f\\\\\\\"{self.base_url}/api/chat\\\\\\\",\\\\n                json=payload,\\\\n                timeout=120\\\\n            )\\\\n            response.raise_for_status()\\\\n            return response.json()['message']['content']\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error in chat completion: {e}\\\\\\\")\\\\n            raise\\\\n    \\\\n    async def chat_async(self, messages: List[Dict[str, str]], model: str = None, **kwargs) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Chat completion asynchronously.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        model = model or self.model\\\\n        \\\\n        payload = {\\\\n            \\\\\\\"model\\\\\\\": model,\\\\n            \\\\\\\"messages\\\\\\\": messages,\\\\n            \\\\\\\"stream\\\\\\\": False,\\\\n            **kwargs\\\\n        }\\\\n        \\\\n        async with aiohttp.ClientSession() as session:\\\\n            try:\\\\n                async with session.post(\\\\n                    f\\\\\\\"{self.base_url}/api/chat\\\\\\\",\\\\n                    json=payload,\\\\n                    timeout=aiohttp.ClientTimeout(total=120)\\\\n                ) as response:\\\\n                    response.raise_for_status()\\\\n                    result = await response.json()\\\\n                    return result['message']['content']\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"Error in chat completion: {e}\\\\\\\")\\\\n                raise\\\\n\\\\nclass DocumentationGenerator:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Generate documentation using Ollama.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    def __init__(self, ollama_client: OllamaClient):\\\\n        self.client = ollama_client\\\\n    \\\\n    def generate_file_documentation(self, file_analysis: Dict[str, Any]) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate documentation for a single file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        \\\\n        # Build context from file analysis\\\\n        context = []\\\\n        context.append(f\\\\\\\"File: {file_analysis['file_path']}\\\\\\\")\\\\n        context.append(f\\\\\\\"Language: {file_analysis.get('language', 'Unknown')}\\\\\\\")\\\\n        \\\\n        if file_analysis.get('imports'):\\\\n            context.append(f\\\\\\\"Imports: {', '.join(file_analysis['imports'][:10])}\\\\\\\")\\\\n        \\\\n        # Add code elements\\\\n        elements_summary = []\\\\n        for element in file_analysis.get('elements', []):\\\\n            elem_type = element['type']\\\\n            name = element['name']\\\\n            signature = element.get('signature', '')\\\\n            docstring = element.get('docstring', '')\\\\n            \\\\n            elem_desc = f\\\\\\\"{elem_type}: {name}\\\\\\\"\\\\n            if signature:\\\\n                elem_desc += f\\\\\\\" - {signature}\\\\\\\"\\\\n            if docstring:\\\\n                elem_desc += f\\\\\\\" - {docstring[:100]}...\\\\\\\"\\\\n            \\\\n            elements_summary.append(elem_desc)\\\\n        \\\\n        if elements_summary:\\\\n            context.append(\\\\\\\"Code Elements:\\\\\\\")\\\\n            context.extend(elements_summary[:15])  # Limit to prevent prompt overflow\\\\n        \\\\n        # Add file content preview\\\\n        content = file_analysis.get('content', '')\\\\n        if content:\\\\n            content_preview = content[:2000] + \\\\\\\"...\\\\\\\" if len(content) > 2000 else content\\\\n            context.append(f\\\\\\\"Content Preview:\\\\\\\\n```\\\\\\\\n{content_preview}\\\\\\\\n```\\\\\\\")\\\\n        \\\\n        context_str = \\\\\\\"\\\\\\\\n\\\\\\\".join(context)\\\\n        \\\\n        prompt = f\\\\\\\"\\\\\\\"\\\\\\\"Analyze the following code file and generate comprehensive documentation in Markdown format.\\\\n\\\\n{context_str}\\\\n\\\\nPlease provide:\\\\n1. A brief overview of what this file does\\\\n2. Main components and their purposes\\\\n3. Key functions/classes with descriptions\\\\n4. Usage examples if applicable\\\\n5. Dependencies and relationships\\\\n\\\\nFormat the output as clean Markdown with appropriate headers and code blocks.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        try:\\\\n            return self.client.generate(prompt, temperature=0.3, max_tokens=2000)\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error generating documentation for {file_analysis['file_path']}: {e}\\\\\\\")\\\\n            return f\\\\\\\"# {file_analysis['file_path']}\\\\\\\\n\\\\\\\\nError generating documentation: {str(e)}\\\\\\\"\\\\n    \\\\n    def generate_repository_overview(self, repo_analysis: Dict[str, Any]) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate high-level repository documentation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        \\\\n        stats = repo_analysis.get('statistics', {})\\\\n        structure = repo_analysis.get('structure', {})\\\\n        \\\\n        context = []\\\\n        context.append(f\\\\\\\"Repository: {repo_analysis.get('repo_name', 'Unknown')}\\\\\\\")\\\\n        context.append(f\\\\\\\"Total Files: {stats.get('total_files', 0)}\\\\\\\")\\\\n        context.append(f\\\\\\\"Code Files: {stats.get('code_files', 0)}\\\\\\\")\\\\n        context.append(f\\\\\\\"Documentation Files: {stats.get('doc_files', 0)}\\\\\\\")\\\\n        context.append(f\\\\\\\"Total Lines: {stats.get('total_lines', 0)}\\\\\\\")\\\\n        \\\\n        if stats.get('languages'):\\\\n            langs = list(stats['languages'].keys())\\\\n            context.append(f\\\\\\\"Languages: {', '.join(langs)}\\\\\\\")\\\\n        \\\\n        # Add git info if available\\\\n        git_info = repo_analysis.get('git_info')\\\\n        if git_info:\\\\n            context.append(f\\\\\\\"Current Branch: {git_info.get('current_branch', 'Unknown')}\\\\\\\")\\\\n            if git_info.get('last_commit'):\\\\n                commit = git_info['last_commit']\\\\n                context.append(f\\\\\\\"Last Commit: {commit.get('message', '')[:100]}\\\\\\\")\\\\n        \\\\n        # Add main files/directories\\\\n        main_files = []\\\\n        for file_data in repo_analysis.get('files', [])[:10]:\\\\n            if file_data.get('file_type') == 'documentation':\\\\n                main_files.append(file_data['file_path'])\\\\n        \\\\n        if main_files:\\\\n            context.append(f\\\\\\\"Key Documentation: {', '.join(main_files)}\\\\\\\")\\\\n        \\\\n        context_str = \\\\\\\"\\\\\\\\n\\\\\\\".join(context)\\\\n        \\\\n        prompt = f\\\\\\\"\\\\\\\"\\\\\\\"Analyze this code repository and generate a comprehensive overview documentation in Markdown format.\\\\n\\\\nRepository Information:\\\\n{context_str}\\\\n\\\\nPlease provide:\\\\n1. Project overview and purpose\\\\n2. Architecture and structure\\\\n3. Key components and modules\\\\n4. Getting started guide\\\\n5. Development setup instructions\\\\n6. Main features and capabilities\\\\n\\\\nFormat as professional README-style documentation with proper Markdown structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        try:\\\\n            return self.client.generate(prompt, temperature=0.3, max_tokens=3000)\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error generating repository overview: {e}\\\\\\\")\\\\n            return f\\\\\\\"# Repository Overview\\\\\\\\n\\\\\\\\nError generating overview: {str(e)}\\\\\\\"\\\\n\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n      \\\"file_type\\\": \\\"code\\\",\\n      \\\"language\\\": \\\"python\\\",\\n      \\\"imports\\\": [\\n        \\\"json\\\",\\n        \\\"typing.List\\\",\\n        \\\"typing.Dict\\\",\\n        \\\"typing.Any\\\",\\n        \\\"typing.Optional\\\",\\n        \\\"typing.Tuple\\\",\\n        \\\"dataclasses.dataclass\\\",\\n        \\\"ollama_client.OllamaClient\\\",\\n        \\\"vector_store.VectorStore\\\"\\n      ],\\n      \\\"elements\\\": [\\n        {\\n          \\\"name\\\": \\\"RAGContext\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 10,\\n          \\\"line_end\\\": 15,\\n          \\\"docstring\\\": \\\"Context information for RAG system.\\\",\\n          \\\"signature\\\": \\\"class RAGContext\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 17,\\n          \\\"line_end\\\": 329,\\n          \\\"docstring\\\": \\\"Retrieval-Augmented Generation system.\\\",\\n          \\\"signature\\\": \\\"class RAGSystem\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem.__init__\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 20,\\n          \\\"line_end\\\": 62,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self, vector_store, ollama_client)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem.determine_query_type\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 64,\\n          \\\"line_end\\\": 75,\\n          \\\"docstring\\\": \\\"Determine the type of query to select appropriate prompt.\\\",\\n          \\\"signature\\\": \\\"def determine_query_type(self, query)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem.retrieve_context\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 77,\\n          \\\"line_end\\\": 79,\\n          \\\"docstring\\\": \\\"Retrieve relevant context for the query.\\\",\\n          \\\"signature\\\": \\\"def retrieve_context(self, query, n_results, filter_metadata)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem.build_context_text\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 81,\\n          \\\"line_end\\\": 110,\\n          \\\"docstring\\\": \\\"Build context text from retrieved chunks.\\\",\\n          \\\"signature\\\": \\\"def build_context_text(self, retrieved_chunks, max_context_length)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem.generate_response\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 112,\\n          \\\"line_end\\\": 133,\\n          \\\"docstring\\\": \\\"Generate response using RAG context.\\\",\\n          \\\"signature\\\": \\\"def generate_response(self, query, context, stream)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem.query\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 135,\\n          \\\"line_end\\\": 191,\\n          \\\"docstring\\\": \\\"Main query interface for RAG system.\\\",\\n          \\\"signature\\\": \\\"def query(self, query, repo_name, file_path, n_results, stream)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem.explain_code\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 193,\\n          \\\"line_end\\\": 214,\\n          \\\"docstring\\\": \\\"Explain a specific code snippet.\\\",\\n          \\\"signature\\\": \\\"def explain_code(self, code, language, context)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem.suggest_improvements\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 216,\\n          \\\"line_end\\\": 237,\\n          \\\"docstring\\\": \\\"Suggest improvements for code.\\\",\\n          \\\"signature\\\": \\\"def suggest_improvements(self, code, language)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem.search_similar_code\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 239,\\n          \\\"line_end\\\": 248,\\n          \\\"docstring\\\": \\\"Find similar code in the repository.\\\",\\n          \\\"signature\\\": \\\"def search_similar_code(self, code_snippet, language, n_results)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem.get_file_summary\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 250,\\n          \\\"line_end\\\": 282,\\n          \\\"docstring\\\": \\\"Get a summary of a specific file.\\\",\\n          \\\"signature\\\": \\\"def get_file_summary(self, file_path, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem.get_repository_overview\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 284,\\n          \\\"line_end\\\": 295,\\n          \\\"docstring\\\": \\\"Get an overview of the repository.\\\",\\n          \\\"signature\\\": \\\"def get_repository_overview(self, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RAGSystem.chat_with_repo\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 297,\\n          \\\"line_end\\\": 329,\\n          \\\"docstring\\\": \\\"Chat interface for conversational interaction with repository.\\\",\\n          \\\"signature\\\": \\\"def chat_with_repo(self, messages, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"__init__\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 20,\\n          \\\"line_end\\\": 62,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self, vector_store, ollama_client)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"determine_query_type\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 64,\\n          \\\"line_end\\\": 75,\\n          \\\"docstring\\\": \\\"Determine the type of query to select appropriate prompt.\\\",\\n          \\\"signature\\\": \\\"def determine_query_type(self, query)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"retrieve_context\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 77,\\n          \\\"line_end\\\": 79,\\n          \\\"docstring\\\": \\\"Retrieve relevant context for the query.\\\",\\n          \\\"signature\\\": \\\"def retrieve_context(self, query, n_results, filter_metadata)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"build_context_text\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 81,\\n          \\\"line_end\\\": 110,\\n          \\\"docstring\\\": \\\"Build context text from retrieved chunks.\\\",\\n          \\\"signature\\\": \\\"def build_context_text(self, retrieved_chunks, max_context_length)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"generate_response\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 112,\\n          \\\"line_end\\\": 133,\\n          \\\"docstring\\\": \\\"Generate response using RAG context.\\\",\\n          \\\"signature\\\": \\\"def generate_response(self, query, context, stream)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"query\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 135,\\n          \\\"line_end\\\": 191,\\n          \\\"docstring\\\": \\\"Main query interface for RAG system.\\\",\\n          \\\"signature\\\": \\\"def query(self, query, repo_name, file_path, n_results, stream)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"explain_code\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 193,\\n          \\\"line_end\\\": 214,\\n          \\\"docstring\\\": \\\"Explain a specific code snippet.\\\",\\n          \\\"signature\\\": \\\"def explain_code(self, code, language, context)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"suggest_improvements\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 216,\\n          \\\"line_end\\\": 237,\\n          \\\"docstring\\\": \\\"Suggest improvements for code.\\\",\\n          \\\"signature\\\": \\\"def suggest_improvements(self, code, language)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"search_similar_code\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 239,\\n          \\\"line_end\\\": 248,\\n          \\\"docstring\\\": \\\"Find similar code in the repository.\\\",\\n          \\\"signature\\\": \\\"def search_similar_code(self, code_snippet, language, n_results)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"get_file_summary\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 250,\\n          \\\"line_end\\\": 282,\\n          \\\"docstring\\\": \\\"Get a summary of a specific file.\\\",\\n          \\\"signature\\\": \\\"def get_file_summary(self, file_path, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"get_repository_overview\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 284,\\n          \\\"line_end\\\": 295,\\n          \\\"docstring\\\": \\\"Get an overview of the repository.\\\",\\n          \\\"signature\\\": \\\"def get_repository_overview(self, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"chat_with_repo\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\rag_system.py\\\",\\n          \\\"line_start\\\": 297,\\n          \\\"line_end\\\": 329,\\n          \\\"docstring\\\": \\\"Chat interface for conversational interaction with repository.\\\",\\n          \\\"signature\\\": \\\"def chat_with_repo(self, messages, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        }\\n      ],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"RAG (Retrieval-Augmented Generation) system for context-aware responses.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport json\\\\nfrom typing import List, Dict, Any, Optional, Tuple\\\\nfrom dataclasses import dataclass\\\\nfrom ollama_client import OllamaClient\\\\nfrom vector_store import VectorStore\\\\n\\\\n@dataclass\\\\nclass RAGContext:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Context information for RAG system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    query: str\\\\n    retrieved_chunks: List[Dict[str, Any]]\\\\n    context_text: str\\\\n    metadata: Dict[str, Any]\\\\n\\\\nclass RAGSystem:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Retrieval-Augmented Generation system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    def __init__(self, vector_store: VectorStore, ollama_client: OllamaClient):\\\\n        self.vector_store = vector_store\\\\n        self.ollama_client = ollama_client\\\\n        \\\\n        # System prompts for different types of queries\\\\n        self.system_prompts = {\\\\n            'code_explanation': \\\\\\\"\\\\\\\"\\\\\\\"You are an expert code analyst. Your task is to explain code clearly and concisely based on the provided context. \\\\n\\\\nFocus on:\\\\n- What the code does\\\\n- How it works\\\\n- Key components and their relationships\\\\n- Usage examples when relevant\\\\n- Best practices and potential improvements\\\\n\\\\nBe accurate and reference the specific code provided in the context.\\\\\\\"\\\\\\\"\\\\\\\",\\\\n\\\\n            'general_question': \\\\\\\"\\\\\\\"\\\\\\\"You are a helpful assistant that answers questions about codebases and documentation. \\\\n\\\\nUse the provided context to give accurate, helpful answers. If the context doesn't contain enough information to answer fully, say so and provide what information you can from the context.\\\\n\\\\nBe concise but thorough, and always ground your answers in the provided context.\\\\\\\"\\\\\\\"\\\\\\\",\\\\n\\\\n            'documentation': \\\\\\\"\\\\\\\"\\\\\\\"You are a technical documentation expert. Generate clear, well-structured documentation based on the provided code and context.\\\\n\\\\nFocus on:\\\\n- Clear explanations of functionality\\\\n- Proper formatting with headers and code blocks\\\\n- Usage examples and best practices\\\\n- Integration with other parts of the system\\\\n\\\\nUse proper Markdown formatting.\\\\\\\"\\\\\\\"\\\\\\\",\\\\n\\\\n            'troubleshooting': \\\\\\\"\\\\\\\"\\\\\\\"You are a debugging expert. Help identify issues, suggest solutions, and provide troubleshooting guidance based on the code context.\\\\n\\\\nFocus on:\\\\n- Identifying potential problems\\\\n- Suggesting specific solutions\\\\n- Explaining the reasoning behind recommendations\\\\n- Providing preventive measures\\\\n\\\\nBe practical and actionable in your suggestions.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        }\\\\n    \\\\n    def determine_query_type(self, query: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Determine the type of query to select appropriate prompt.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        query_lower = query.lower()\\\\n        \\\\n        if any(word in query_lower for word in ['how does', 'what does', 'explain', 'how to']):\\\\n            return 'code_explanation'\\\\n        elif any(word in query_lower for word in ['document', 'generate docs', 'create documentation']):\\\\n            return 'documentation'\\\\n        elif any(word in query_lower for word in ['error', 'bug', 'fix', 'problem', 'issue', 'debug']):\\\\n            return 'troubleshooting'\\\\n        else:\\\\n            return 'general_question'\\\\n    \\\\n    def retrieve_context(self, query: str, n_results: int = 5, filter_metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Retrieve relevant context for the query.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return self.vector_store.search(query, n_results, filter_metadata)\\\\n    \\\\n    def build_context_text(self, retrieved_chunks: List[Dict[str, Any]], max_context_length: int = 4000) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Build context text from retrieved chunks.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        context_parts = []\\\\n        current_length = 0\\\\n        \\\\n        for chunk in retrieved_chunks:\\\\n            text = chunk['text']\\\\n            metadata = chunk.get('metadata', {})\\\\n            \\\\n            # Add metadata header for context\\\\n            header = \\\\\\\"\\\\\\\"\\\\n            if metadata.get('file_path'):\\\\n                header += f\\\\\\\"File: {metadata['file_path']}\\\\\\\\n\\\\\\\"\\\\n            if metadata.get('element_name'):\\\\n                header += f\\\\\\\"Element: {metadata['element_name']} ({metadata.get('element_type', 'unknown')})\\\\\\\\n\\\\\\\"\\\\n            if metadata.get('type'):\\\\n                header += f\\\\\\\"Type: {metadata['type']}\\\\\\\\n\\\\\\\"\\\\n            \\\\n            chunk_text = header + \\\\\\\"\\\\\\\\n\\\\\\\" + text + \\\\\\\"\\\\\\\\n\\\\\\\" + \\\\\\\"=\\\\\\\"*50 + \\\\\\\"\\\\\\\\n\\\\\\\"\\\\n            \\\\n            # Check if adding this chunk would exceed max length\\\\n            if current_length + len(chunk_text) > max_context_length:\\\\n                if not context_parts:  # If first chunk is too long, truncate it\\\\n                    context_parts.append(chunk_text[:max_context_length])\\\\n                break\\\\n            \\\\n            context_parts.append(chunk_text)\\\\n            current_length += len(chunk_text)\\\\n        \\\\n        return \\\\\\\"\\\\\\\\n\\\\\\\".join(context_parts)\\\\n    \\\\n    def generate_response(self, query: str, context: RAGContext, stream: bool = False) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate response using RAG context.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        query_type = self.determine_query_type(query)\\\\n        system_prompt = self.system_prompts.get(query_type, self.system_prompts['general_question'])\\\\n        \\\\n        # Build the full prompt\\\\n        full_prompt = f\\\\\\\"\\\\\\\"\\\\\\\"{system_prompt}\\\\n\\\\nCONTEXT:\\\\n{context.context_text}\\\\n\\\\nUSER QUERY: {query}\\\\n\\\\nPlease provide a helpful response based on the context above. If the context doesn't contain sufficient information, clearly state what information is missing.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        try:\\\\n            if stream:\\\\n                return self.ollama_client.generate_stream(full_prompt, temperature=0.3)\\\\n            else:\\\\n                return self.ollama_client.generate(full_prompt, temperature=0.3)\\\\n        except Exception as e:\\\\n            return f\\\\\\\"Error generating response: {str(e)}\\\\\\\"\\\\n    \\\\n    def query(self, \\\\n              query: str, \\\\n              repo_name: str = None, \\\\n              file_path: str = None,\\\\n              n_results: int = 5,\\\\n              stream: bool = False) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Main query interface for RAG system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        \\\\n        # Build filter for specific repository or file\\\\n        filter_metadata = {}\\\\n        if repo_name:\\\\n            filter_metadata['repo_name'] = repo_name\\\\n        if file_path:\\\\n            filter_metadata['file_path'] = file_path\\\\n        \\\\n        # Retrieve relevant context\\\\n        retrieved_chunks = self.retrieve_context(query, n_results, filter_metadata or None)\\\\n        \\\\n        if not retrieved_chunks:\\\\n            return {\\\\n                'response': f\\\\\\\"No relevant context found for query: {query}\\\\\\\",\\\\n                'context': None,\\\\n                'sources': []\\\\n            }\\\\n        \\\\n        # Build context\\\\n        context_text = self.build_context_text(retrieved_chunks)\\\\n        context = RAGContext(\\\\n            query=query,\\\\n            retrieved_chunks=retrieved_chunks,\\\\n            context_text=context_text,\\\\n            metadata={'repo_name': repo_name, 'file_path': file_path}\\\\n        )\\\\n        \\\\n        # Generate response\\\\n        response = self.generate_response(query, context, stream)\\\\n        \\\\n        # Extract sources\\\\n        sources = []\\\\n        for chunk in retrieved_chunks:\\\\n            metadata = chunk.get('metadata', {})\\\\n            source = {\\\\n                'file_path': metadata.get('file_path'),\\\\n                'element_name': metadata.get('element_name'),\\\\n                'type': metadata.get('type'),\\\\n                'distance': chunk.get('distance', 0)\\\\n            }\\\\n            # Remove None values\\\\n            source = {k: v for k, v in source.items() if v is not None}\\\\n            if source and source not in sources:\\\\n                sources.append(source)\\\\n        \\\\n        return {\\\\n            'response': response,\\\\n            'context': context,\\\\n            'sources': sources[:5]  # Limit to top 5 sources\\\\n        }\\\\n    \\\\n    def explain_code(self, code: str, language: str = None, context: str = None) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Explain a specific code snippet.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        prompt = f\\\\\\\"\\\\\\\"\\\\\\\"Explain the following code clearly and concisely:\\\\n\\\\nLanguage: {language or 'Unknown'}\\\\n{f'Context: {context}' if context else ''}\\\\n\\\\nCode:\\\\n```{language or ''}\\\\n{code}\\\\n```\\\\n\\\\nPlease explain:\\\\n1. What this code does\\\\n2. How it works\\\\n3. Key components and their purpose\\\\n4. Any notable patterns or techniques used\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        try:\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\n        except Exception as e:\\\\n            return f\\\\\\\"Error explaining code: {str(e)}\\\\\\\"\\\\n    \\\\n    def suggest_improvements(self, code: str, language: str = None) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Suggest improvements for code.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        prompt = f\\\\\\\"\\\\\\\"\\\\\\\"Analyze the following code and suggest improvements:\\\\n\\\\nLanguage: {language or 'Unknown'}\\\\n\\\\nCode:\\\\n```{language or ''}\\\\n{code}\\\\n```\\\\n\\\\nPlease provide:\\\\n1. Code quality assessment\\\\n2. Potential improvements\\\\n3. Best practices recommendations\\\\n4. Performance optimizations if applicable\\\\n5. Security considerations if relevant\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        try:\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\n        except Exception as e:\\\\n            return f\\\\\\\"Error suggesting improvements: {str(e)}\\\\\\\"\\\\n    \\\\n    def search_similar_code(self, code_snippet: str, language: str = None, n_results: int = 3) -> List[Dict[str, Any]]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Find similar code in the repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Create a search query from the code\\\\n        query = f\\\\\\\"code similar to: {code_snippet[:200]}...\\\\\\\"\\\\n        \\\\n        filter_metadata = {}\\\\n        if language:\\\\n            filter_metadata['language'] = language\\\\n        \\\\n        return self.retrieve_context(query, n_results, filter_metadata or None)\\\\n    \\\\n    def get_file_summary(self, file_path: str, repo_name: str = None) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get a summary of a specific file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        filter_metadata = {'file_path': file_path}\\\\n        if repo_name:\\\\n            filter_metadata['repo_name'] = repo_name\\\\n        \\\\n        # Get file overview chunk\\\\n        chunks = self.vector_store.search(\\\\n            f\\\\\\\"file overview {file_path}\\\\\\\", \\\\n            n_results=1, \\\\n            filter_metadata=filter_metadata\\\\n        )\\\\n        \\\\n        if not chunks:\\\\n            return f\\\\\\\"No information found for file: {file_path}\\\\\\\"\\\\n        \\\\n        chunk = chunks[0]\\\\n        context_text = chunk['text']\\\\n        \\\\n        prompt = f\\\\\\\"\\\\\\\"\\\\\\\"Provide a concise summary of this file:\\\\n\\\\n{context_text}\\\\n\\\\nSummary should include:\\\\n- Purpose of the file\\\\n- Main components\\\\n- Key functionality\\\\n- Dependencies\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        try:\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\n        except Exception as e:\\\\n            return f\\\\\\\"Error generating file summary: {str(e)}\\\\\\\"\\\\n    \\\\n    def get_repository_overview(self, repo_name: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get an overview of the repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        chunks = self.vector_store.search(\\\\n            f\\\\\\\"repository overview {repo_name}\\\\\\\",\\\\n            n_results=1,\\\\n            filter_metadata={'repo_name': repo_name, 'type': 'repository_overview'}\\\\n        )\\\\n        \\\\n        if not chunks:\\\\n            return f\\\\\\\"No overview found for repository: {repo_name}\\\\\\\"\\\\n        \\\\n        return chunks[0]['text']\\\\n    \\\\n    def chat_with_repo(self, messages: List[Dict[str, str]], repo_name: str = None) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Chat interface for conversational interaction with repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not messages:\\\\n            return \\\\\\\"No messages provided\\\\\\\"\\\\n        \\\\n        # Get the latest user message\\\\n        latest_message = messages[-1]['content']\\\\n        \\\\n        # Get context for the latest query\\\\n        result = self.query(latest_message, repo_name=repo_name, stream=False)\\\\n        \\\\n        # Build conversation context\\\\n        conversation_context = \\\\\\\"\\\\\\\\n\\\\\\\".join([\\\\n            f\\\\\\\"{msg['role']}: {msg['content']}\\\\\\\" \\\\n            for msg in messages[:-1]  # Exclude the latest message\\\\n        ])\\\\n        \\\\n        # Enhanced prompt with conversation history\\\\n        prompt = f\\\\\\\"\\\\\\\"\\\\\\\"You are having a conversation about a codebase. Here's the conversation history:\\\\n\\\\n{conversation_context}\\\\n\\\\nCurrent context from the codebase:\\\\n{result['context'].context_text if result['context'] else 'No relevant context found'}\\\\n\\\\nCurrent question: {latest_message}\\\\n\\\\nPlease provide a helpful response that considers both the conversation history and the current context.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        try:\\\\n            return self.ollama_client.generate(prompt, temperature=0.4)\\\\n        except Exception as e:\\\\n            return f\\\\\\\"Error in chat response: {str(e)}\\\\\\\"\\\\n\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\README.md\\\",\\n      \\\"file_type\\\": \\\"documentation\\\",\\n      \\\"language\\\": null,\\n      \\\"imports\\\": [],\\n      \\\"elements\\\": [],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"# Local DeepWiki\\\\n\\\\nA local implementation of DeepWiki that allows you to chat with your code repositories using Ollama and local LLMs. This system provides repository analysis, documentation generation, and conversational AI capabilities - all running locally on your machine.\\\\n\\\\n## Features\\\\n\\\\n- ðŸ” **Repository Analysis**: Automatically parse and understand code structure\\\\n- ðŸ¤– **Local LLM Integration**: Uses Ollama for privacy-focused AI inference\\\\n- ðŸ“š **Documentation Generation**: Create comprehensive docs from your codebase\\\\n- ðŸ’¬ **Interactive Chat**: Ask questions about your code in natural language\\\\n- ðŸ”Ž **Semantic Search**: Find relevant code and documentation quickly\\\\n- ðŸŒ **Web Interface**: Clean, modern UI for easy interaction\\\\n- ðŸ“– **RAG System**: Context-aware responses grounded in your actual code\\\\n\\\\n## Prerequisites\\\\n\\\\n1. **Python 3.8+**\\\\n2. **Ollama** - Download from [ollama.ai](https://ollama.ai)\\\\n3. **Git** (optional, for repository information)\\\\n\\\\n## Installation\\\\n\\\\n1. **Clone this repository:**\\\\n```bash\\\\ngit clone <repository-url>\\\\ncd local_deepwiki\\\\n```\\\\n\\\\n2. **Install Python dependencies:**\\\\n```bash\\\\npip install -r requirements.txt\\\\n```\\\\n\\\\n3. **Install and start Ollama:**\\\\n```bash\\\\n# Install Ollama (see https://ollama.ai for platform-specific instructions)\\\\n\\\\n# Start Ollama server\\\\nollama serve\\\\n\\\\n# Pull required models (in another terminal)\\\\nollama pull llama2          # Main language model\\\\nollama pull nomic-embed-text  # Embedding model (optional)\\\\n```\\\\n\\\\n4. **Check prerequisites:**\\\\n```bash\\\\npython main.py check\\\\n```\\\\n\\\\n## Quick Start\\\\n\\\\n### 1. Analyze a Repository\\\\n\\\\n```bash\\\\n# Analyze your current directory\\\\npython main.py analyze .\\\\n\\\\n# Analyze a specific repository\\\\npython main.py analyze /path/to/your/repo --name my-project\\\\n\\\\n# Analyze with custom name\\\\npython main.py analyze ~/projects/my-app --name my-awesome-app\\\\n```\\\\n\\\\n### 2. Chat with Your Code\\\\n\\\\n```bash\\\\n# Start interactive chat\\\\npython main.py chat\\\\n\\\\n# Chat with specific repository\\\\npython main.py chat --repo my-project\\\\n```\\\\n\\\\n### 3. Query Your Repository\\\\n\\\\n```bash\\\\n# Ask a specific question\\\\npython main.py query \\\\\\\"How does user authentication work?\\\\\\\" --repo my-project\\\\n\\\\n# Query without specifying repository (searches all)\\\\npython main.py query \\\\\\\"Show me the main entry point\\\\\\\"\\\\n```\\\\n\\\\n### 4. Generate Documentation\\\\n\\\\n```bash\\\\n# Generate comprehensive documentation\\\\npython main.py docs my-project\\\\n```\\\\n\\\\n### 5. Web Interface\\\\n\\\\n```bash\\\\n# Start the web server\\\\npython main.py server\\\\n\\\\n# Or with custom host/port\\\\npython main.py server --host 127.0.0.1 --port 8080\\\\n```\\\\n\\\\nThen open http://localhost:8000 in your browser.\\\\n\\\\n## Configuration\\\\n\\\\nCreate a `.env` file to customize settings:\\\\n\\\\n```env\\\\n# Ollama Configuration\\\\nOLLAMA_BASE_URL=http://localhost:11434\\\\nOLLAMA_MODEL=llama2\\\\nOLLAMA_EMBEDDING_MODEL=nomic-embed-text\\\\n\\\\n# API Configuration\\\\nAPI_HOST=0.0.0.0\\\\nAPI_PORT=8000\\\\n\\\\n# Storage Configuration\\\\nCHROMA_PERSIST_DIRECTORY=./data/chroma_db\\\\nREPOS_DIRECTORY=./data/repos\\\\nDOCS_DIRECTORY=./data/generated_docs\\\\n\\\\n# Processing Configuration\\\\nMAX_CHUNK_SIZE=2000\\\\nCHUNK_OVERLAP=200\\\\nMAX_CONTEXT_LENGTH=4000\\\\n```\\\\n\\\\n## Supported Languages\\\\n\\\\nThe system can analyze and understand code in:\\\\n\\\\n- Python (.py)\\\\n- JavaScript/TypeScript (.js, .ts, .jsx, .tsx)\\\\n- Java (.java)\\\\n- C/C++ (.c, .cpp, .h)\\\\n- C# (.cs)\\\\n- PHP (.php)\\\\n- Ruby (.rb)\\\\n- Go (.go)\\\\n- Rust (.rs)\\\\n- Swift (.swift)\\\\n- Kotlin (.kt)\\\\n- Scala (.scala)\\\\n- And more...\\\\n\\\\nPlus documentation files:\\\\n- Markdown (.md)\\\\n- reStructuredText (.rst)\\\\n- Plain text (.txt)\\\\n\\\\n## CLI Commands\\\\n\\\\n### Repository Management\\\\n```bash\\\\n# List analyzed repositories\\\\npython main.py list\\\\n\\\\n# Show system statistics\\\\npython main.py stats\\\\n```\\\\n\\\\n### Analysis and Documentation\\\\n```bash\\\\n# Analyze repository\\\\npython main.py analyze <path> [--name <name>]\\\\n\\\\n# Generate documentation\\\\npython main.py docs <repo-name>\\\\n```\\\\n\\\\n### Querying\\\\n```bash\\\\n# One-time query\\\\npython main.py query \\\\\\\"<question>\\\\\\\" [--repo <name>]\\\\n\\\\n# Interactive chat\\\\npython main.py chat [--repo <name>]\\\\n```\\\\n\\\\n### Web Server\\\\n```bash\\\\n# Start web interface\\\\npython main.py server [--host <host>] [--port <port>]\\\\n```\\\\n\\\\n## API Endpoints\\\\n\\\\nWhen running the web server, these endpoints are available:\\\\n\\\\n### Health & System\\\\n- `GET /health` - System health check\\\\n- `GET /stats` - System statistics\\\\n- `GET /models` - List available Ollama models\\\\n\\\\n### Repository Management\\\\n- `POST /repositories/analyze` - Analyze repository\\\\n- `GET /repositories` - List repositories\\\\n- `DELETE /repositories/{name}` - Delete repository\\\\n\\\\n### Querying\\\\n- `POST /query` - Query with RAG system\\\\n- `POST /chat` - Chat interface\\\\n- `POST /explain` - Explain code snippet\\\\n- `POST /improve` - Suggest code improvements\\\\n\\\\n### Documentation\\\\n- `POST /repositories/{name}/generate-docs` - Generate docs\\\\n- `GET /repositories/{name}/docs` - List generated docs\\\\n- `GET /repositories/{name}/docs/{path}` - Get specific doc\\\\n\\\\n### Search\\\\n- `GET /search` - Search all repositories\\\\n- `GET /repositories/{name}/search` - Search specific repository\\\\n\\\\n## How It Works\\\\n\\\\n1. **Repository Analysis**: The system parses your codebase, extracting:\\\\n   - File structure and organization\\\\n   - Functions, classes, and their relationships\\\\n   - Import dependencies\\\\n   - Documentation and comments\\\\n   - Git information (if available)\\\\n\\\\n2. **Vector Embeddings**: Code and documentation are chunked and converted to embeddings using:\\\\n   - Ollama embedding models (preferred)\\\\n   - Sentence Transformers (fallback)\\\\n   - ChromaDB for efficient storage and retrieval\\\\n\\\\n3. **RAG System**: When you ask questions:\\\\n   - Your query is embedded and matched against the codebase\\\\n   - Relevant code snippets and documentation are retrieved\\\\n   - Context is provided to the LLM for accurate, grounded responses\\\\n\\\\n4. **Documentation Generation**: Using the analyzed structure:\\\\n   - README files with project overviews\\\\n   - API documentation for each file\\\\n   - Architecture documentation\\\\n   - Usage examples and tutorials\\\\n\\\\n## Example Queries\\\\n\\\\nHere are some example questions you can ask:\\\\n\\\\n### Code Understanding\\\\n- \\\\\\\"How does user authentication work in this project?\\\\\\\"\\\\n- \\\\\\\"What is the main entry point of the application?\\\\\\\"\\\\n- \\\\\\\"Show me all the API endpoints\\\\\\\"\\\\n- \\\\\\\"How is data validation handled?\\\\\\\"\\\\n\\\\n### Architecture Questions\\\\n- \\\\\\\"What's the overall architecture of this system?\\\\\\\"\\\\n- \\\\\\\"How do the different modules interact?\\\\\\\"\\\\n- \\\\\\\"What design patterns are used?\\\\\\\"\\\\n- \\\\\\\"What are the main dependencies?\\\\\\\"\\\\n\\\\n### Implementation Details\\\\n- \\\\\\\"How is error handling implemented?\\\\\\\"\\\\n- \\\\\\\"Where is the database connection configured?\\\\\\\"\\\\n- \\\\\\\"How are user permissions checked?\\\\\\\"\\\\n- \\\\\\\"What testing framework is used?\\\\\\\"\\\\n\\\\n### Documentation\\\\n- \\\\\\\"Generate API documentation for the user service\\\\\\\"\\\\n- \\\\\\\"Create a getting started guide\\\\\\\"\\\\n- \\\\\\\"Explain the deployment process\\\\\\\"\\\\n\\\\n## Troubleshooting\\\\n\\\\n### Ollama Issues\\\\n```bash\\\\n# Check if Ollama is running\\\\ncurl http://localhost:11434/api/tags\\\\n\\\\n# Pull required models\\\\nollama pull llama2\\\\nollama pull nomic-embed-text\\\\n\\\\n# Check model availability\\\\nollama list\\\\n```\\\\n\\\\n### Common Problems\\\\n\\\\n1. **\\\\\\\"Ollama server not available\\\\\\\"**\\\\n   - Make sure Ollama is installed and running (`ollama serve`)\\\\n   - Check the OLLAMA_BASE_URL in your configuration\\\\n\\\\n2. **\\\\\\\"Model not found\\\\\\\"**\\\\n   - Pull the required model: `ollama pull llama2`\\\\n   - Update OLLAMA_MODEL in configuration if using a different model\\\\n\\\\n3. **\\\\\\\"No relevant context found\\\\\\\"**\\\\n   - Make sure the repository has been analyzed\\\\n   - Try rephrasing your question\\\\n   - Check that the repository contains relevant code\\\\n\\\\n4. **Slow responses**\\\\n   - Consider using a smaller, faster model (e.g., `llama2:7b`)\\\\n   - Reduce MAX_CONTEXT_LENGTH in configuration\\\\n   - Use more specific queries\\\\n\\\\n### Performance Tips\\\\n\\\\n1. **Model Selection**: \\\\n   - Use `codellama` for better code understanding\\\\n   - Use `llama2:7b` for faster responses\\\\n   - Use `mistral` for a good balance\\\\n\\\\n2. **Configuration Tuning**:\\\\n   - Adjust MAX_CHUNK_SIZE for your hardware\\\\n   - Reduce MAX_CONTEXT_LENGTH for faster responses\\\\n   - Increase CHUNK_OVERLAP for better context\\\\n\\\\n3. **Repository Size**:\\\\n   - Large repositories may take time to analyze\\\\n   - Consider analyzing specific directories for faster results\\\\n   - Use .gitignore patterns to exclude unnecessary files\\\\n\\\\n## Contributing\\\\n\\\\n1. Fork the repository\\\\n2. Create a feature branch\\\\n3. Make your changes\\\\n4. Add tests if applicable\\\\n5. Submit a pull request\\\\n\\\\n## License\\\\n\\\\nThis project is licensed under the MIT License - see the LICENSE file for details.\\\\n\\\\n## Acknowledgments\\\\n\\\\n- [Ollama](https://ollama.ai) for local LLM inference\\\\n- [ChromaDB](https://www.trychroma.com/) for vector storage\\\\n- [LangChain](https://langchain.com/) for RAG implementation\\\\n- [FastAPI](https://fastapi.tiangolo.com/) for the web API\\\\n- [Vue.js](https://vuejs.org/) for the web interface\\\\n\\\\n## Roadmap\\\\n\\\\n- [ ] Support for more programming languages\\\\n- [ ] Advanced code analysis (call graphs, dependency analysis)\\\\n- [ ] Integration with popular IDEs\\\\n- [ ] Multi-repository projects support\\\\n- [ ] Custom model fine-tuning\\\\n- [ ] Collaborative features\\\\n- [ ] Plugin system for extensibility\\\\n\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n      \\\"file_type\\\": \\\"code\\\",\\n      \\\"language\\\": \\\"python\\\",\\n      \\\"imports\\\": [\\n        \\\"os\\\",\\n        \\\"ast\\\",\\n        \\\"re\\\",\\n        \\\"json\\\",\\n        \\\"pathlib.Path\\\",\\n        \\\"typing.Dict\\\",\\n        \\\"typing.List\\\",\\n        \\\"typing.Any\\\",\\n        \\\"typing.Optional\\\",\\n        \\\"typing.Tuple\\\",\\n        \\\"dataclasses.dataclass\\\",\\n        \\\"dataclasses.asdict\\\",\\n        \\\"git\\\",\\n        \\\"config.settings\\\"\\n      ],\\n      \\\"elements\\\": [\\n        {\\n          \\\"name\\\": \\\"CodeElement\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 14,\\n          \\\"line_end\\\": 28,\\n          \\\"docstring\\\": \\\"Represents a code element (function, class, etc.).\\\",\\n          \\\"signature\\\": \\\"class CodeElement\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"CodeElement.__post_init__\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 26,\\n          \\\"line_end\\\": 28,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __post_init__(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"FileAnalysis\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 31,\\n          \\\"line_end\\\": 45,\\n          \\\"docstring\\\": \\\"Analysis results for a single file.\\\",\\n          \\\"signature\\\": \\\"class FileAnalysis\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"FileAnalysis.__post_init__\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 41,\\n          \\\"line_end\\\": 45,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __post_init__(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 47,\\n          \\\"line_end\\\": 348,\\n          \\\"docstring\\\": \\\"Analyzes code repositories to extract structure and content.\\\",\\n          \\\"signature\\\": \\\"class RepositoryAnalyzer\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer.__init__\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 50,\\n          \\\"line_end\\\": 69,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer.analyze_repository\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 71,\\n          \\\"line_end\\\": 132,\\n          \\\"docstring\\\": \\\"Analyze an entire repository.\\\",\\n          \\\"signature\\\": \\\"def analyze_repository(self, repo_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer.analyze_file\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 134,\\n          \\\"line_end\\\": 170,\\n          \\\"docstring\\\": \\\"Analyze a single file.\\\",\\n          \\\"signature\\\": \\\"def analyze_file(self, file_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer._analyze_python_file\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 172,\\n          \\\"line_end\\\": 230,\\n          \\\"docstring\\\": \\\"Analyze Python file for structure.\\\",\\n          \\\"signature\\\": \\\"def _analyze_python_file(self, analysis, content)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer._analyze_js_ts_file\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 232,\\n          \\\"line_end\\\": 285,\\n          \\\"docstring\\\": \\\"Analyze JavaScript/TypeScript file for structure.\\\",\\n          \\\"signature\\\": \\\"def _analyze_js_ts_file(self, analysis, content)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer._get_function_args\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 287,\\n          \\\"line_end\\\": 292,\\n          \\\"docstring\\\": \\\"Extract function arguments as string.\\\",\\n          \\\"signature\\\": \\\"def _get_function_args(self, node)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer._get_files_to_analyze\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 294,\\n          \\\"line_end\\\": 307,\\n          \\\"docstring\\\": \\\"Get list of files to analyze, respecting ignore patterns.\\\",\\n          \\\"signature\\\": \\\"def _get_files_to_analyze(self, repo_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer._should_ignore_dir\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 309,\\n          \\\"line_end\\\": 311,\\n          \\\"docstring\\\": \\\"Check if directory should be ignored.\\\",\\n          \\\"signature\\\": \\\"def _should_ignore_dir(self, dirname)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer._should_analyze_file\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 313,\\n          \\\"line_end\\\": 316,\\n          \\\"docstring\\\": \\\"Check if file should be analyzed.\\\",\\n          \\\"signature\\\": \\\"def _should_analyze_file(self, file_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer._build_directory_structure\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 318,\\n          \\\"line_end\\\": 338,\\n          \\\"docstring\\\": \\\"Build a tree representation of the directory structure.\\\",\\n          \\\"signature\\\": \\\"def _build_directory_structure(self, repo_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer.save_analysis\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 340,\\n          \\\"line_end\\\": 343,\\n          \\\"docstring\\\": \\\"Save analysis results to JSON file.\\\",\\n          \\\"signature\\\": \\\"def save_analysis(self, analysis, output_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"RepositoryAnalyzer.load_analysis\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 345,\\n          \\\"line_end\\\": 348,\\n          \\\"docstring\\\": \\\"Load analysis results from JSON file.\\\",\\n          \\\"signature\\\": \\\"def load_analysis(self, input_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"__post_init__\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 26,\\n          \\\"line_end\\\": 28,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __post_init__(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"__post_init__\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 41,\\n          \\\"line_end\\\": 45,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __post_init__(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"__init__\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 50,\\n          \\\"line_end\\\": 69,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"analyze_repository\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 71,\\n          \\\"line_end\\\": 132,\\n          \\\"docstring\\\": \\\"Analyze an entire repository.\\\",\\n          \\\"signature\\\": \\\"def analyze_repository(self, repo_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"analyze_file\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 134,\\n          \\\"line_end\\\": 170,\\n          \\\"docstring\\\": \\\"Analyze a single file.\\\",\\n          \\\"signature\\\": \\\"def analyze_file(self, file_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"_analyze_python_file\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 172,\\n          \\\"line_end\\\": 230,\\n          \\\"docstring\\\": \\\"Analyze Python file for structure.\\\",\\n          \\\"signature\\\": \\\"def _analyze_python_file(self, analysis, content)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"_analyze_js_ts_file\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 232,\\n          \\\"line_end\\\": 285,\\n          \\\"docstring\\\": \\\"Analyze JavaScript/TypeScript file for structure.\\\",\\n          \\\"signature\\\": \\\"def _analyze_js_ts_file(self, analysis, content)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"_get_function_args\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 287,\\n          \\\"line_end\\\": 292,\\n          \\\"docstring\\\": \\\"Extract function arguments as string.\\\",\\n          \\\"signature\\\": \\\"def _get_function_args(self, node)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"_get_files_to_analyze\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 294,\\n          \\\"line_end\\\": 307,\\n          \\\"docstring\\\": \\\"Get list of files to analyze, respecting ignore patterns.\\\",\\n          \\\"signature\\\": \\\"def _get_files_to_analyze(self, repo_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"_should_ignore_dir\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 309,\\n          \\\"line_end\\\": 311,\\n          \\\"docstring\\\": \\\"Check if directory should be ignored.\\\",\\n          \\\"signature\\\": \\\"def _should_ignore_dir(self, dirname)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"_should_analyze_file\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 313,\\n          \\\"line_end\\\": 316,\\n          \\\"docstring\\\": \\\"Check if file should be analyzed.\\\",\\n          \\\"signature\\\": \\\"def _should_analyze_file(self, file_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"_build_directory_structure\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 318,\\n          \\\"line_end\\\": 338,\\n          \\\"docstring\\\": \\\"Build a tree representation of the directory structure.\\\",\\n          \\\"signature\\\": \\\"def _build_directory_structure(self, repo_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"save_analysis\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 340,\\n          \\\"line_end\\\": 343,\\n          \\\"docstring\\\": \\\"Save analysis results to JSON file.\\\",\\n          \\\"signature\\\": \\\"def save_analysis(self, analysis, output_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"load_analysis\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 345,\\n          \\\"line_end\\\": 348,\\n          \\\"docstring\\\": \\\"Load analysis results from JSON file.\\\",\\n          \\\"signature\\\": \\\"def load_analysis(self, input_path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"build_tree\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\repository_analyzer.py\\\",\\n          \\\"line_start\\\": 320,\\n          \\\"line_end\\\": 336,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def build_tree(path)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        }\\n      ],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Repository analysis module for extracting code structure and content.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport os\\\\nimport ast\\\\nimport re\\\\nimport json\\\\nfrom pathlib import Path\\\\nfrom typing import Dict, List, Any, Optional, Tuple\\\\nfrom dataclasses import dataclass, asdict\\\\nimport git\\\\nfrom config import settings\\\\n\\\\n@dataclass\\\\nclass CodeElement:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Represents a code element (function, class, etc.).\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    name: str\\\\n    type: str  # 'function', 'class', 'method', 'variable'\\\\n    file_path: str\\\\n    line_start: int\\\\n    line_end: int\\\\n    docstring: Optional[str] = None\\\\n    signature: Optional[str] = None\\\\n    content: Optional[str] = None\\\\n    dependencies: List[str] = None\\\\n    \\\\n    def __post_init__(self):\\\\n        if self.dependencies is None:\\\\n            self.dependencies = []\\\\n\\\\n@dataclass\\\\nclass FileAnalysis:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Analysis results for a single file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    file_path: str\\\\n    file_type: str  # 'code', 'documentation', 'config'\\\\n    language: Optional[str] = None\\\\n    imports: List[str] = None\\\\n    elements: List[CodeElement] = None\\\\n    summary: Optional[str] = None\\\\n    content: Optional[str] = None\\\\n    \\\\n    def __post_init__(self):\\\\n        if self.imports is None:\\\\n            self.imports = []\\\\n        if self.elements is None:\\\\n            self.elements = []\\\\n\\\\nclass RepositoryAnalyzer:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Analyzes code repositories to extract structure and content.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    def __init__(self):\\\\n        self.supported_languages = {\\\\n            '.py': 'python',\\\\n            '.js': 'javascript', \\\\n            '.ts': 'typescript',\\\\n            '.jsx': 'javascript',\\\\n            '.tsx': 'typescript',\\\\n            '.java': 'java',\\\\n            '.cpp': 'cpp',\\\\n            '.c': 'c',\\\\n            '.h': 'c',\\\\n            '.cs': 'csharp',\\\\n            '.php': 'php',\\\\n            '.rb': 'ruby',\\\\n            '.go': 'go',\\\\n            '.rs': 'rust',\\\\n            '.swift': 'swift',\\\\n            '.kt': 'kotlin',\\\\n            '.scala': 'scala'\\\\n        }\\\\n    \\\\n    def analyze_repository(self, repo_path: str) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Analyze an entire repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        repo_path = Path(repo_path)\\\\n        \\\\n        if not repo_path.exists():\\\\n            raise ValueError(f\\\\\\\"Repository path does not exist: {repo_path}\\\\\\\")\\\\n        \\\\n        analysis = {\\\\n            'repo_path': str(repo_path),\\\\n            'repo_name': repo_path.name,\\\\n            'files': [],\\\\n            'structure': {},\\\\n            'statistics': {\\\\n                'total_files': 0,\\\\n                'code_files': 0,\\\\n                'doc_files': 0,\\\\n                'languages': {},\\\\n                'total_lines': 0\\\\n            }\\\\n        }\\\\n        \\\\n        # Get git info if available\\\\n        try:\\\\n            repo = git.Repo(repo_path)\\\\n            analysis['git_info'] = {\\\\n                'remote_url': repo.remotes.origin.url if repo.remotes else None,\\\\n                'current_branch': repo.active_branch.name,\\\\n                'last_commit': {\\\\n                    'hash': repo.head.commit.hexsha[:8],\\\\n                    'message': repo.head.commit.message.strip(),\\\\n                    'author': str(repo.head.commit.author),\\\\n                    'date': repo.head.commit.committed_datetime.isoformat()\\\\n                }\\\\n            }\\\\n        except:\\\\n            analysis['git_info'] = None\\\\n        \\\\n        # Analyze files\\\\n        for file_path in self._get_files_to_analyze(repo_path):\\\\n            file_analysis = self.analyze_file(file_path)\\\\n            if file_analysis:\\\\n                analysis['files'].append(asdict(file_analysis))\\\\n                \\\\n                # Update statistics\\\\n                analysis['statistics']['total_files'] += 1\\\\n                if file_analysis.file_type == 'code':\\\\n                    analysis['statistics']['code_files'] += 1\\\\n                    if file_analysis.language:\\\\n                        lang = file_analysis.language\\\\n                        analysis['statistics']['languages'][lang] = \\\\\\\\\\\\n                            analysis['statistics']['languages'].get(lang, 0) + 1\\\\n                elif file_analysis.file_type == 'documentation':\\\\n                    analysis['statistics']['doc_files'] += 1\\\\n                \\\\n                # Count lines\\\\n                if file_analysis.content:\\\\n                    analysis['statistics']['total_lines'] += len(file_analysis.content.split('\\\\\\\\n'))\\\\n        \\\\n        # Build directory structure\\\\n        analysis['structure'] = self._build_directory_structure(repo_path)\\\\n        \\\\n        return analysis\\\\n    \\\\n    def analyze_file(self, file_path: Path) -> Optional[FileAnalysis]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Analyze a single file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\\\\n                content = f.read()\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error reading file {file_path}: {e}\\\\\\\")\\\\n            return None\\\\n        \\\\n        file_ext = file_path.suffix.lower()\\\\n        relative_path = str(file_path)\\\\n        \\\\n        # Determine file type and language\\\\n        if file_ext in settings.CODE_EXTENSIONS:\\\\n            file_type = 'code'\\\\n            language = self.supported_languages.get(file_ext)\\\\n        elif file_ext in settings.DOC_EXTENSIONS:\\\\n            file_type = 'documentation'\\\\n            language = None\\\\n        else:\\\\n            file_type = 'config'\\\\n            language = None\\\\n        \\\\n        analysis = FileAnalysis(\\\\n            file_path=relative_path,\\\\n            file_type=file_type,\\\\n            language=language,\\\\n            content=content\\\\n        )\\\\n        \\\\n        # Language-specific analysis\\\\n        if language == 'python':\\\\n            self._analyze_python_file(analysis, content)\\\\n        elif language in ['javascript', 'typescript']:\\\\n            self._analyze_js_ts_file(analysis, content)\\\\n        \\\\n        return analysis\\\\n    \\\\n    def _analyze_python_file(self, analysis: FileAnalysis, content: str):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Analyze Python file for structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            tree = ast.parse(content)\\\\n            \\\\n            # Extract imports\\\\n            for node in ast.walk(tree):\\\\n                if isinstance(node, ast.Import):\\\\n                    for alias in node.names:\\\\n                        analysis.imports.append(alias.name)\\\\n                elif isinstance(node, ast.ImportFrom):\\\\n                    module = node.module or ''\\\\n                    for alias in node.names:\\\\n                        analysis.imports.append(f\\\\\\\"{module}.{alias.name}\\\\\\\")\\\\n            \\\\n            # Extract classes and functions\\\\n            for node in ast.walk(tree):\\\\n                if isinstance(node, ast.ClassDef):\\\\n                    element = CodeElement(\\\\n                        name=node.name,\\\\n                        type='class',\\\\n                        file_path=analysis.file_path,\\\\n                        line_start=node.lineno,\\\\n                        line_end=getattr(node, 'end_lineno', node.lineno),\\\\n                        docstring=ast.get_docstring(node),\\\\n                        signature=f\\\\\\\"class {node.name}\\\\\\\"\\\\n                    )\\\\n                    analysis.elements.append(element)\\\\n                    \\\\n                    # Extract methods\\\\n                    for item in node.body:\\\\n                        if isinstance(item, ast.FunctionDef):\\\\n                            method = CodeElement(\\\\n                                name=f\\\\\\\"{node.name}.{item.name}\\\\\\\",\\\\n                                type='method',\\\\n                                file_path=analysis.file_path,\\\\n                                line_start=item.lineno,\\\\n                                line_end=getattr(item, 'end_lineno', item.lineno),\\\\n                                docstring=ast.get_docstring(item),\\\\n                                signature=f\\\\\\\"def {item.name}({self._get_function_args(item)})\\\\\\\"\\\\n                            )\\\\n                            analysis.elements.append(method)\\\\n                \\\\n                elif isinstance(node, ast.FunctionDef):\\\\n                    # Only top-level functions (not methods)\\\\n                    if isinstance(getattr(node, 'parent', None), ast.Module) or not hasattr(node, 'parent'):\\\\n                        element = CodeElement(\\\\n                            name=node.name,\\\\n                            type='function',\\\\n                            file_path=analysis.file_path,\\\\n                            line_start=node.lineno,\\\\n                            line_end=getattr(node, 'end_lineno', node.lineno),\\\\n                            docstring=ast.get_docstring(node),\\\\n                            signature=f\\\\\\\"def {node.name}({self._get_function_args(node)})\\\\\\\"\\\\n                        )\\\\n                        analysis.elements.append(element)\\\\n                        \\\\n        except SyntaxError as e:\\\\n            print(f\\\\\\\"Syntax error in {analysis.file_path}: {e}\\\\\\\")\\\\n    \\\\n    def _analyze_js_ts_file(self, analysis: FileAnalysis, content: str):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Analyze JavaScript/TypeScript file for structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        lines = content.split('\\\\\\\\n')\\\\n        \\\\n        # Extract imports (simple regex-based approach)\\\\n        import_patterns = [\\\\n            r'import\\\\\\\\s+.*?\\\\\\\\s+from\\\\\\\\s+[\\\\\\\\'\\\\\\\"]([^\\\\\\\\'\\\\\\\"]+)[\\\\\\\\'\\\\\\\"]',\\\\n            r'const\\\\\\\\s+.*?\\\\\\\\s*=\\\\\\\\s*require\\\\\\\\([\\\\\\\\'\\\\\\\"]([^\\\\\\\\'\\\\\\\"]+)[\\\\\\\\'\\\\\\\"]\\\\\\\\)',\\\\n            r'import\\\\\\\\s*\\\\\\\\(\\\\\\\\s*[\\\\\\\\'\\\\\\\"]([^\\\\\\\\'\\\\\\\"]+)[\\\\\\\\'\\\\\\\"]\\\\\\\\s*\\\\\\\\)'\\\\n        ]\\\\n        \\\\n        for line in lines:\\\\n            for pattern in import_patterns:\\\\n                matches = re.findall(pattern, line)\\\\n                analysis.imports.extend(matches)\\\\n        \\\\n        # Extract functions and classes (basic regex patterns)\\\\n        function_patterns = [\\\\n            r'function\\\\\\\\s+(\\\\\\\\w+)\\\\\\\\s*\\\\\\\\(',\\\\n            r'const\\\\\\\\s+(\\\\\\\\w+)\\\\\\\\s*=\\\\\\\\s*\\\\\\\\(',\\\\n            r'(\\\\\\\\w+)\\\\\\\\s*:\\\\\\\\s*function\\\\\\\\s*\\\\\\\\(',\\\\n            r'(\\\\\\\\w+)\\\\\\\\s*\\\\\\\\([^)]*\\\\\\\\)\\\\\\\\s*=>',\\\\n            r'async\\\\\\\\s+function\\\\\\\\s+(\\\\\\\\w+)\\\\\\\\s*\\\\\\\\('\\\\n        ]\\\\n        \\\\n        class_pattern = r'class\\\\\\\\s+(\\\\\\\\w+)'\\\\n        \\\\n        for i, line in enumerate(lines, 1):\\\\n            # Find classes\\\\n            class_match = re.search(class_pattern, line)\\\\n            if class_match:\\\\n                element = CodeElement(\\\\n                    name=class_match.group(1),\\\\n                    type='class',\\\\n                    file_path=analysis.file_path,\\\\n                    line_start=i,\\\\n                    line_end=i,  # We'd need more sophisticated parsing to find end\\\\n                    signature=line.strip()\\\\n                )\\\\n                analysis.elements.append(element)\\\\n            \\\\n            # Find functions\\\\n            for pattern in function_patterns:\\\\n                func_match = re.search(pattern, line)\\\\n                if func_match:\\\\n                    element = CodeElement(\\\\n                        name=func_match.group(1),\\\\n                        type='function',\\\\n                        file_path=analysis.file_path,\\\\n                        line_start=i,\\\\n                        line_end=i,\\\\n                        signature=line.strip()\\\\n                    )\\\\n                    analysis.elements.append(element)\\\\n    \\\\n    def _get_function_args(self, node: ast.FunctionDef) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Extract function arguments as string.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        args = []\\\\n        for arg in node.args.args:\\\\n            args.append(arg.arg)\\\\n        return ', '.join(args)\\\\n    \\\\n    def _get_files_to_analyze(self, repo_path: Path) -> List[Path]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get list of files to analyze, respecting ignore patterns.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        files = []\\\\n        \\\\n        for root, dirs, filenames in os.walk(repo_path):\\\\n            # Remove ignored directories\\\\n            dirs[:] = [d for d in dirs if not self._should_ignore_dir(d)]\\\\n            \\\\n            for filename in filenames:\\\\n                file_path = Path(root) / filename\\\\n                if self._should_analyze_file(file_path):\\\\n                    files.append(file_path)\\\\n        \\\\n        return files\\\\n    \\\\n    def _should_ignore_dir(self, dirname: str) -> bool:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Check if directory should be ignored.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return dirname in settings.IGNORED_DIRS or dirname.startswith('.')\\\\n    \\\\n    def _should_analyze_file(self, file_path: Path) -> bool:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Check if file should be analyzed.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        ext = file_path.suffix.lower()\\\\n        return ext in settings.CODE_EXTENSIONS or ext in settings.DOC_EXTENSIONS\\\\n    \\\\n    def _build_directory_structure(self, repo_path: Path) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Build a tree representation of the directory structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        def build_tree(path: Path) -> Dict[str, Any]:\\\\n            tree = {'name': path.name, 'type': 'directory', 'children': []}\\\\n            \\\\n            try:\\\\n                for item in sorted(path.iterdir()):\\\\n                    if item.is_dir() and not self._should_ignore_dir(item.name):\\\\n                        tree['children'].append(build_tree(item))\\\\n                    elif item.is_file() and self._should_analyze_file(item):\\\\n                        tree['children'].append({\\\\n                            'name': item.name,\\\\n                            'type': 'file',\\\\n                            'path': str(item.relative_to(repo_path))\\\\n                        })\\\\n            except PermissionError:\\\\n                pass\\\\n            \\\\n            return tree\\\\n        \\\\n        return build_tree(repo_path)\\\\n\\\\n    def save_analysis(self, analysis: Dict[str, Any], output_path: str):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Save analysis results to JSON file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        with open(output_path, 'w', encoding='utf-8') as f:\\\\n            json.dump(analysis, f, indent=2, ensure_ascii=False)\\\\n    \\\\n    def load_analysis(self, input_path: str) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Load analysis results from JSON file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        with open(input_path, 'r', encoding='utf-8') as f:\\\\n            return json.load(f)\\\\n\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\requirements.txt\\\",\\n      \\\"file_type\\\": \\\"documentation\\\",\\n      \\\"language\\\": null,\\n      \\\"imports\\\": [],\\n      \\\"elements\\\": [],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"ollama>=0.2.0\\\\nlangchain>=0.1.0\\\\nlangchain-community>=0.0.20\\\\nchromadb>=0.4.0\\\\nsentence-transformers>=2.2.2\\\\nfastapi>=0.104.0\\\\nuvicorn>=0.24.0\\\\npydantic>=2.5.0\\\\npython-multipart>=0.0.6\\\\ngitpython>=3.1.40\\\\npathspec>=0.12.0\\\\ntiktoken>=0.5.0\\\\njinja2>=3.1.0\\\\nmarkdown>=3.5.0\\\\nbeautifulsoup4>=4.12.0\\\\ntree-sitter>=0.20.0\\\\ntree-sitter-python>=0.20.0\\\\ntree-sitter-javascript>=0.20.0\\\\ntree-sitter-typescript>=0.20.0\\\\naiofiles>=23.2.0\\\\nwatchdog>=3.0.0\\\\n\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n      \\\"file_type\\\": \\\"code\\\",\\n      \\\"language\\\": \\\"python\\\",\\n      \\\"imports\\\": [\\n        \\\"os\\\",\\n        \\\"hashlib\\\",\\n        \\\"json\\\",\\n        \\\"pathlib.Path\\\",\\n        \\\"typing.List\\\",\\n        \\\"typing.Dict\\\",\\n        \\\"typing.Any\\\",\\n        \\\"typing.Optional\\\",\\n        \\\"typing.Tuple\\\",\\n        \\\"chromadb\\\",\\n        \\\"chromadb.config.Settings\\\",\\n        \\\"sentence_transformers.SentenceTransformer\\\",\\n        \\\"tiktoken\\\",\\n        \\\"config.settings\\\",\\n        \\\"ollama_client.OllamaClient\\\"\\n      ],\\n      \\\"elements\\\": [\\n        {\\n          \\\"name\\\": \\\"TextChunker\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 15,\\n          \\\"line_end\\\": 188,\\n          \\\"docstring\\\": \\\"Utility class for chunking text into manageable pieces.\\\",\\n          \\\"signature\\\": \\\"class TextChunker\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"TextChunker.__init__\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 18,\\n          \\\"line_end\\\": 26,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self, max_chunk_size, overlap)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"TextChunker.count_tokens\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 28,\\n          \\\"line_end\\\": 34,\\n          \\\"docstring\\\": \\\"Count tokens in text.\\\",\\n          \\\"signature\\\": \\\"def count_tokens(self, text)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"TextChunker.chunk_text\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 36,\\n          \\\"line_end\\\": 113,\\n          \\\"docstring\\\": \\\"Split text into chunks with metadata.\\\",\\n          \\\"signature\\\": \\\"def chunk_text(self, text, metadata)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"TextChunker.chunk_code_file\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 115,\\n          \\\"line_end\\\": 188,\\n          \\\"docstring\\\": \\\"Chunk code file based on structure.\\\",\\n          \\\"signature\\\": \\\"def chunk_code_file(self, content, file_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"VectorStore\\\",\\n          \\\"type\\\": \\\"class\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 190,\\n          \\\"line_end\\\": 411,\\n          \\\"docstring\\\": \\\"Vector store for embeddings using ChromaDB and local embeddings.\\\",\\n          \\\"signature\\\": \\\"class VectorStore\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"VectorStore.__init__\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 193,\\n          \\\"line_end\\\": 219,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self, persist_directory, collection_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"VectorStore.get_embedding\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 221,\\n          \\\"line_end\\\": 238,\\n          \\\"docstring\\\": \\\"Get embedding for text using available models.\\\",\\n          \\\"signature\\\": \\\"def get_embedding(self, text)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"VectorStore.add_repository\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 240,\\n          \\\"line_end\\\": 270,\\n          \\\"docstring\\\": \\\"Add entire repository to vector store.\\\",\\n          \\\"signature\\\": \\\"def add_repository(self, repo_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"VectorStore.add_file_analysis\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 272,\\n          \\\"line_end\\\": 295,\\n          \\\"docstring\\\": \\\"Add file analysis to vector store.\\\",\\n          \\\"signature\\\": \\\"def add_file_analysis(self, file_analysis, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"VectorStore.add_document\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 297,\\n          \\\"line_end\\\": 300,\\n          \\\"docstring\\\": \\\"Add a single document to vector store.\\\",\\n          \\\"signature\\\": \\\"def add_document(self, text, metadata)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"VectorStore.add_chunks\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 302,\\n          \\\"line_end\\\": 348,\\n          \\\"docstring\\\": \\\"Add multiple chunks to vector store.\\\",\\n          \\\"signature\\\": \\\"def add_chunks(self, chunks)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"VectorStore.search\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 350,\\n          \\\"line_end\\\": 379,\\n          \\\"docstring\\\": \\\"Search vector store for relevant documents.\\\",\\n          \\\"signature\\\": \\\"def search(self, query, n_results, filter_metadata)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"VectorStore.get_collection_stats\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 381,\\n          \\\"line_end\\\": 391,\\n          \\\"docstring\\\": \\\"Get statistics about the collection.\\\",\\n          \\\"signature\\\": \\\"def get_collection_stats(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"VectorStore.clear_collection\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 393,\\n          \\\"line_end\\\": 400,\\n          \\\"docstring\\\": \\\"Clear all documents from collection.\\\",\\n          \\\"signature\\\": \\\"def clear_collection(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"VectorStore.delete_repository\\\",\\n          \\\"type\\\": \\\"method\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 402,\\n          \\\"line_end\\\": 411,\\n          \\\"docstring\\\": \\\"Delete all documents from a specific repository.\\\",\\n          \\\"signature\\\": \\\"def delete_repository(self, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"__init__\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 18,\\n          \\\"line_end\\\": 26,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self, max_chunk_size, overlap)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"count_tokens\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 28,\\n          \\\"line_end\\\": 34,\\n          \\\"docstring\\\": \\\"Count tokens in text.\\\",\\n          \\\"signature\\\": \\\"def count_tokens(self, text)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"chunk_text\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 36,\\n          \\\"line_end\\\": 113,\\n          \\\"docstring\\\": \\\"Split text into chunks with metadata.\\\",\\n          \\\"signature\\\": \\\"def chunk_text(self, text, metadata)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"chunk_code_file\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 115,\\n          \\\"line_end\\\": 188,\\n          \\\"docstring\\\": \\\"Chunk code file based on structure.\\\",\\n          \\\"signature\\\": \\\"def chunk_code_file(self, content, file_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"__init__\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 193,\\n          \\\"line_end\\\": 219,\\n          \\\"docstring\\\": null,\\n          \\\"signature\\\": \\\"def __init__(self, persist_directory, collection_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"get_embedding\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 221,\\n          \\\"line_end\\\": 238,\\n          \\\"docstring\\\": \\\"Get embedding for text using available models.\\\",\\n          \\\"signature\\\": \\\"def get_embedding(self, text)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"add_repository\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 240,\\n          \\\"line_end\\\": 270,\\n          \\\"docstring\\\": \\\"Add entire repository to vector store.\\\",\\n          \\\"signature\\\": \\\"def add_repository(self, repo_analysis)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"add_file_analysis\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 272,\\n          \\\"line_end\\\": 295,\\n          \\\"docstring\\\": \\\"Add file analysis to vector store.\\\",\\n          \\\"signature\\\": \\\"def add_file_analysis(self, file_analysis, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"add_document\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 297,\\n          \\\"line_end\\\": 300,\\n          \\\"docstring\\\": \\\"Add a single document to vector store.\\\",\\n          \\\"signature\\\": \\\"def add_document(self, text, metadata)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"add_chunks\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 302,\\n          \\\"line_end\\\": 348,\\n          \\\"docstring\\\": \\\"Add multiple chunks to vector store.\\\",\\n          \\\"signature\\\": \\\"def add_chunks(self, chunks)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"search\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 350,\\n          \\\"line_end\\\": 379,\\n          \\\"docstring\\\": \\\"Search vector store for relevant documents.\\\",\\n          \\\"signature\\\": \\\"def search(self, query, n_results, filter_metadata)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"get_collection_stats\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 381,\\n          \\\"line_end\\\": 391,\\n          \\\"docstring\\\": \\\"Get statistics about the collection.\\\",\\n          \\\"signature\\\": \\\"def get_collection_stats(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"clear_collection\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 393,\\n          \\\"line_end\\\": 400,\\n          \\\"docstring\\\": \\\"Clear all documents from collection.\\\",\\n          \\\"signature\\\": \\\"def clear_collection(self)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        },\\n        {\\n          \\\"name\\\": \\\"delete_repository\\\",\\n          \\\"type\\\": \\\"function\\\",\\n          \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\vector_store.py\\\",\\n          \\\"line_start\\\": 402,\\n          \\\"line_end\\\": 411,\\n          \\\"docstring\\\": \\\"Delete all documents from a specific repository.\\\",\\n          \\\"signature\\\": \\\"def delete_repository(self, repo_name)\\\",\\n          \\\"content\\\": null,\\n          \\\"dependencies\\\": []\\n        }\\n      ],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"Vector embedding and storage system using ChromaDB.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport os\\\\nimport hashlib\\\\nimport json\\\\nfrom pathlib import Path\\\\nfrom typing import List, Dict, Any, Optional, Tuple\\\\nimport chromadb\\\\nfrom chromadb.config import Settings\\\\nfrom sentence_transformers import SentenceTransformer\\\\nimport tiktoken\\\\nfrom config import settings\\\\nfrom ollama_client import OllamaClient\\\\n\\\\nclass TextChunker:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Utility class for chunking text into manageable pieces.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    def __init__(self, max_chunk_size: int = None, overlap: int = None):\\\\n        self.max_chunk_size = max_chunk_size or settings.MAX_CHUNK_SIZE\\\\n        self.overlap = overlap or settings.CHUNK_OVERLAP\\\\n        \\\\n        # Initialize tokenizer for accurate token counting\\\\n        try:\\\\n            self.tokenizer = tiktoken.get_encoding(\\\\\\\"cl100k_base\\\\\\\")\\\\n        except:\\\\n            self.tokenizer = None\\\\n    \\\\n    def count_tokens(self, text: str) -> int:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Count tokens in text.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if self.tokenizer:\\\\n            return len(self.tokenizer.encode(text))\\\\n        else:\\\\n            # Rough approximation: 1 token â‰ˆ 4 characters\\\\n            return len(text) // 4\\\\n    \\\\n    def chunk_text(self, text: str, metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Split text into chunks with metadata.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if metadata is None:\\\\n            metadata = {}\\\\n        \\\\n        chunks = []\\\\n        \\\\n        # Split by paragraphs first\\\\n        paragraphs = text.split('\\\\\\\\n\\\\\\\\n')\\\\n        current_chunk = \\\\\\\"\\\\\\\"\\\\n        current_tokens = 0\\\\n        \\\\n        for para in paragraphs:\\\\n            para_tokens = self.count_tokens(para)\\\\n            \\\\n            # If single paragraph exceeds max size, split it further\\\\n            if para_tokens > self.max_chunk_size:\\\\n                # Save current chunk if not empty\\\\n                if current_chunk.strip():\\\\n                    chunks.append({\\\\n                        'text': current_chunk.strip(),\\\\n                        'tokens': current_tokens,\\\\n                        **metadata\\\\n                    })\\\\n                    current_chunk = \\\\\\\"\\\\\\\"\\\\n                    current_tokens = 0\\\\n                \\\\n                # Split large paragraph by sentences\\\\n                sentences = para.split('. ')\\\\n                for sentence in sentences:\\\\n                    sentence_tokens = self.count_tokens(sentence)\\\\n                    \\\\n                    if current_tokens + sentence_tokens > self.max_chunk_size:\\\\n                        if current_chunk.strip():\\\\n                            chunks.append({\\\\n                                'text': current_chunk.strip(),\\\\n                                'tokens': current_tokens,\\\\n                                **metadata\\\\n                            })\\\\n                        current_chunk = sentence\\\\n                        current_tokens = sentence_tokens\\\\n                    else:\\\\n                        current_chunk += (\\\\\\\". \\\\\\\" if current_chunk else \\\\\\\"\\\\\\\") + sentence\\\\n                        current_tokens += sentence_tokens\\\\n            \\\\n            # Normal paragraph processing\\\\n            elif current_tokens + para_tokens > self.max_chunk_size:\\\\n                # Save current chunk\\\\n                if current_chunk.strip():\\\\n                    chunks.append({\\\\n                        'text': current_chunk.strip(),\\\\n                        'tokens': current_tokens,\\\\n                        **metadata\\\\n                    })\\\\n                \\\\n                # Start new chunk with overlap\\\\n                if self.overlap > 0 and chunks:\\\\n                    # Get last few words for overlap\\\\n                    last_chunk_words = current_chunk.split()\\\\n                    overlap_words = last_chunk_words[-self.overlap:] if len(last_chunk_words) > self.overlap else last_chunk_words\\\\n                    current_chunk = \\\\\\\" \\\\\\\".join(overlap_words) + \\\\\\\"\\\\\\\\n\\\\\\\\n\\\\\\\" + para\\\\n                else:\\\\n                    current_chunk = para\\\\n                \\\\n                current_tokens = self.count_tokens(current_chunk)\\\\n            else:\\\\n                current_chunk += (\\\\\\\"\\\\\\\\n\\\\\\\\n\\\\\\\" if current_chunk else \\\\\\\"\\\\\\\") + para\\\\n                current_tokens += para_tokens\\\\n        \\\\n        # Add final chunk\\\\n        if current_chunk.strip():\\\\n            chunks.append({\\\\n                'text': current_chunk.strip(),\\\\n                'tokens': current_tokens,\\\\n                **metadata\\\\n            })\\\\n        \\\\n        return chunks\\\\n    \\\\n    def chunk_code_file(self, content: str, file_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Chunk code file based on structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        chunks = []\\\\n        \\\\n        # Create chunk for file overview\\\\n        overview_text = f\\\\\\\"File: {file_analysis['file_path']}\\\\\\\\n\\\\\\\"\\\\n        overview_text += f\\\\\\\"Language: {file_analysis.get('language', 'Unknown')}\\\\\\\\n\\\\\\\"\\\\n        \\\\n        if file_analysis.get('imports'):\\\\n            overview_text += f\\\\\\\"Imports: {', '.join(file_analysis['imports'])}\\\\\\\\n\\\\\\\"\\\\n        \\\\n        # Add summary of elements\\\\n        elements = file_analysis.get('elements', [])\\\\n        if elements:\\\\n            overview_text += \\\\\\\"\\\\\\\\nCode Elements:\\\\\\\\n\\\\\\\"\\\\n            for element in elements:\\\\n                overview_text += f\\\\\\\"- {element['type']}: {element['name']}\\\\\\\\n\\\\\\\"\\\\n                if element.get('docstring'):\\\\n                    overview_text += f\\\\\\\"  {element['docstring'][:100]}...\\\\\\\\n\\\\\\\"\\\\n        \\\\n        chunks.append({\\\\n            'text': overview_text,\\\\n            'type': 'file_overview',\\\\n            'file_path': file_analysis['file_path'],\\\\n            'language': file_analysis.get('language'),\\\\n            'source': 'code_analysis'\\\\n        })\\\\n        \\\\n        # Create chunks for individual code elements\\\\n        lines = content.split('\\\\\\\\n')\\\\n        for element in elements:\\\\n            start_line = element.get('line_start', 1) - 1  # Convert to 0-based\\\\n            end_line = element.get('line_end', len(lines))\\\\n            \\\\n            if start_line < len(lines):\\\\n                element_content = '\\\\\\\\n'.join(lines[start_line:min(end_line, len(lines))])\\\\n                \\\\n                element_text = f\\\\\\\"Element: {element['name']} ({element['type']})\\\\\\\\n\\\\\\\"\\\\n                element_text += f\\\\\\\"File: {file_analysis['file_path']}\\\\\\\\n\\\\\\\"\\\\n                \\\\n                if element.get('signature'):\\\\n                    element_text += f\\\\\\\"Signature: {element['signature']}\\\\\\\\n\\\\\\\"\\\\n                \\\\n                if element.get('docstring'):\\\\n                    element_text += f\\\\\\\"Documentation: {element['docstring']}\\\\\\\\n\\\\\\\"\\\\n                \\\\n                element_text += f\\\\\\\"\\\\\\\\nCode:\\\\\\\\n```{file_analysis.get('language', '')}\\\\\\\\n{element_content}\\\\\\\\n```\\\\\\\"\\\\n                \\\\n                chunks.append({\\\\n                    'text': element_text,\\\\n                    'type': 'code_element',\\\\n                    'element_type': element['type'],\\\\n                    'element_name': element['name'],\\\\n                    'file_path': file_analysis['file_path'],\\\\n                    'language': file_analysis.get('language'),\\\\n                    'line_start': element.get('line_start'),\\\\n                    'line_end': element.get('line_end'),\\\\n                    'source': 'code_analysis'\\\\n                })\\\\n        \\\\n        # If no elements found, chunk the entire file content\\\\n        if not elements and content.strip():\\\\n            file_chunks = self.chunk_text(\\\\n                content, \\\\n                {\\\\n                    'type': 'file_content',\\\\n                    'file_path': file_analysis['file_path'],\\\\n                    'language': file_analysis.get('language'),\\\\n                    'source': 'file_content'\\\\n                }\\\\n            )\\\\n            chunks.extend(file_chunks)\\\\n        \\\\n        return chunks\\\\n\\\\nclass VectorStore:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Vector store for embeddings using ChromaDB and local embeddings.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    \\\\n    def __init__(self, persist_directory: str = None, collection_name: str = None):\\\\n        self.persist_directory = persist_directory or settings.CHROMA_PERSIST_DIRECTORY\\\\n        self.collection_name = collection_name or settings.COLLECTION_NAME\\\\n        \\\\n        # Initialize ChromaDB\\\\n        self.client = chromadb.PersistentClient(\\\\n            path=self.persist_directory,\\\\n            settings=Settings(anonymized_telemetry=False)\\\\n        )\\\\n        \\\\n        # Get or create collection\\\\n        try:\\\\n            self.collection = self.client.get_collection(name=self.collection_name)\\\\n        except:\\\\n            self.collection = self.client.create_collection(name=self.collection_name)\\\\n        \\\\n        # Initialize embedding models\\\\n        self.ollama_client = OllamaClient()\\\\n        \\\\n        # Fallback to sentence transformers if Ollama embeddings fail\\\\n        try:\\\\n            self.sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')\\\\n        except:\\\\n            print(\\\\\\\"Warning: Could not load sentence transformer model\\\\\\\")\\\\n            self.sentence_transformer = None\\\\n        \\\\n        self.chunker = TextChunker()\\\\n    \\\\n    def get_embedding(self, text: str) -> List[float]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get embedding for text using available models.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Try Ollama first\\\\n        if self.ollama_client.is_available():\\\\n            try:\\\\n                return self.ollama_client.get_embeddings(text)\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"Ollama embedding failed: {e}\\\\\\\")\\\\n        \\\\n        # Fallback to sentence transformer\\\\n        if self.sentence_transformer:\\\\n            try:\\\\n                embedding = self.sentence_transformer.encode(text)\\\\n                return embedding.tolist()\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"Sentence transformer embedding failed: {e}\\\\\\\")\\\\n        \\\\n        raise Exception(\\\\\\\"No embedding model available\\\\\\\")\\\\n    \\\\n    def add_repository(self, repo_analysis: Dict[str, Any]) -> int:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Add entire repository to vector store.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        repo_name = repo_analysis.get('repo_name', 'unknown')\\\\n        total_chunks = 0\\\\n        \\\\n        # Add repository overview\\\\n        if repo_analysis.get('files'):\\\\n            overview_text = f\\\\\\\"Repository: {repo_name}\\\\\\\\n\\\\\\\"\\\\n            overview_text += f\\\\\\\"Total files: {repo_analysis['statistics']['total_files']}\\\\\\\\n\\\\\\\"\\\\n            overview_text += f\\\\\\\"Languages: {', '.join(repo_analysis['statistics']['languages'].keys())}\\\\\\\\n\\\\\\\"\\\\n            \\\\n            # Add file list\\\\n            overview_text += \\\\\\\"\\\\\\\\nFiles:\\\\\\\\n\\\\\\\"\\\\n            for file_data in repo_analysis['files'][:20]:  # Limit to first 20 files\\\\n                overview_text += f\\\\\\\"- {file_data['file_path']}\\\\\\\\n\\\\\\\"\\\\n            \\\\n            total_chunks += self.add_document(\\\\n                overview_text,\\\\n                {\\\\n                    'type': 'repository_overview',\\\\n                    'repo_name': repo_name,\\\\n                    'source': 'repository_analysis'\\\\n                }\\\\n            )\\\\n        \\\\n        # Add individual files\\\\n        for file_data in repo_analysis.get('files', []):\\\\n            file_chunks = self.add_file_analysis(file_data, repo_name)\\\\n            total_chunks += file_chunks\\\\n        \\\\n        return total_chunks\\\\n    \\\\n    def add_file_analysis(self, file_analysis: Dict[str, Any], repo_name: str = None) -> int:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Add file analysis to vector store.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if file_analysis.get('file_type') == 'code':\\\\n            chunks = self.chunker.chunk_code_file(\\\\n                file_analysis.get('content', ''), \\\\n                file_analysis\\\\n            )\\\\n        else:\\\\n            # Regular text chunking for documentation files\\\\n            chunks = self.chunker.chunk_text(\\\\n                file_analysis.get('content', ''),\\\\n                {\\\\n                    'type': 'documentation',\\\\n                    'file_path': file_analysis['file_path'],\\\\n                    'source': 'file_content'\\\\n                }\\\\n            )\\\\n        \\\\n        # Add repository name to all chunks\\\\n        for chunk in chunks:\\\\n            if repo_name:\\\\n                chunk['repo_name'] = repo_name\\\\n        \\\\n        return self.add_chunks(chunks)\\\\n    \\\\n    def add_document(self, text: str, metadata: Dict[str, Any]) -> int:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Add a single document to vector store.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        chunks = self.chunker.chunk_text(text, metadata)\\\\n        return self.add_chunks(chunks)\\\\n    \\\\n    def add_chunks(self, chunks: List[Dict[str, Any]]) -> int:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Add multiple chunks to vector store.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not chunks:\\\\n            return 0\\\\n        \\\\n        documents = []\\\\n        metadatas = []\\\\n        ids = []\\\\n        embeddings = []\\\\n        \\\\n        for i, chunk in enumerate(chunks):\\\\n            text = chunk['text']\\\\n            \\\\n            # Create unique ID\\\\n            chunk_id = hashlib.md5(text.encode()).hexdigest()\\\\n            \\\\n            # Prepare metadata (remove 'text' key)\\\\n            metadata = {k: v for k, v in chunk.items() if k != 'text'}\\\\n            \\\\n            try:\\\\n                # Get embedding\\\\n                embedding = self.get_embedding(text)\\\\n                \\\\n                documents.append(text)\\\\n                metadatas.append(metadata)\\\\n                ids.append(chunk_id)\\\\n                embeddings.append(embedding)\\\\n                \\\\n            except Exception as e:\\\\n                print(f\\\\\\\"Error processing chunk {i}: {e}\\\\\\\")\\\\n                continue\\\\n        \\\\n        if documents:\\\\n            try:\\\\n                self.collection.add(\\\\n                    documents=documents,\\\\n                    metadatas=metadatas,\\\\n                    ids=ids,\\\\n                    embeddings=embeddings\\\\n                )\\\\n                print(f\\\\\\\"Added {len(documents)} chunks to vector store\\\\\\\")\\\\n                return len(documents)\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"Error adding to vector store: {e}\\\\\\\")\\\\n                return 0\\\\n        \\\\n        return 0\\\\n    \\\\n    def search(self, query: str, n_results: int = 5, filter_metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Search vector store for relevant documents.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            query_embedding = self.get_embedding(query)\\\\n            \\\\n            search_kwargs = {\\\\n                'query_embeddings': [query_embedding],\\\\n                'n_results': n_results\\\\n            }\\\\n            \\\\n            if filter_metadata:\\\\n                search_kwargs['where'] = filter_metadata\\\\n            \\\\n            results = self.collection.query(**search_kwargs)\\\\n            \\\\n            # Format results\\\\n            formatted_results = []\\\\n            for i in range(len(results['documents'][0])):\\\\n                formatted_results.append({\\\\n                    'text': results['documents'][0][i],\\\\n                    'metadata': results['metadatas'][0][i],\\\\n                    'distance': results['distances'][0][i],\\\\n                    'id': results['ids'][0][i]\\\\n                })\\\\n            \\\\n            return formatted_results\\\\n            \\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error searching vector store: {e}\\\\\\\")\\\\n            return []\\\\n    \\\\n    def get_collection_stats(self) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get statistics about the collection.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            count = self.collection.count()\\\\n            return {\\\\n                'total_documents': count,\\\\n                'collection_name': self.collection_name\\\\n            }\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error getting collection stats: {e}\\\\\\\")\\\\n            return {'total_documents': 0, 'collection_name': self.collection_name}\\\\n    \\\\n    def clear_collection(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Clear all documents from collection.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            self.client.delete_collection(name=self.collection_name)\\\\n            self.collection = self.client.create_collection(name=self.collection_name)\\\\n            print(\\\\\\\"Collection cleared successfully\\\\\\\")\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error clearing collection: {e}\\\\\\\")\\\\n    \\\\n    def delete_repository(self, repo_name: str):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Delete all documents from a specific repository.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            # Get all documents with repo_name\\\\n            results = self.collection.get(where={\\\\\\\"repo_name\\\\\\\": repo_name})\\\\n            if results['ids']:\\\\n                self.collection.delete(ids=results['ids'])\\\\n                print(f\\\\\\\"Deleted {len(results['ids'])} documents for repository {repo_name}\\\\\\\")\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error deleting repository {repo_name}: {e}\\\\\\\")\\\\n\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\data\\\\\\\\repos\\\\\\\\wikillm_analysis.json\\\",\\n      \\\"file_type\\\": \\\"code\\\",\\n      \\\"language\\\": null,\\n      \\\"imports\\\": [],\\n      \\\"elements\\\": [],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"{\\\\n  \\\\\\\"repo_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\",\\\\n  \\\\\\\"repo_name\\\\\\\": \\\\\\\"wikillm\\\\\\\",\\\\n  \\\\\\\"files\\\\\\\": [\\\\n    {\\\\n      \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\api.py\\\\\\\",\\\\n      \\\\\\\"file_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n      \\\\\\\"language\\\\\\\": \\\\\\\"python\\\\\\\",\\\\n      \\\\\\\"imports\\\\\\\": [\\\\n        \\\\\\\"asyncio\\\\\\\",\\\\n        \\\\\\\"json\\\\\\\",\\\\n        \\\\\\\"traceback\\\\\\\",\\\\n        \\\\\\\"pathlib.Path\\\\\\\",\\\\n        \\\\\\\"typing.Dict\\\\\\\",\\\\n        \\\\\\\"typing.List\\\\\\\",\\\\n        \\\\\\\"typing.Any\\\\\\\",\\\\n        \\\\\\\"typing.Optional\\\\\\\",\\\\n        \\\\\\\"fastapi.FastAPI\\\\\\\",\\\\n        \\\\\\\"fastapi.HTTPException\\\\\\\",\\\\n        \\\\\\\"fastapi.BackgroundTasks\\\\\\\",\\\\n        \\\\\\\"fastapi.UploadFile\\\\\\\",\\\\n        \\\\\\\"fastapi.File\\\\\\\",\\\\n        \\\\\\\"fastapi.middleware.cors.CORSMiddleware\\\\\\\",\\\\n        \\\\\\\"fastapi.responses.StreamingResponse\\\\\\\",\\\\n        \\\\\\\"fastapi.responses.JSONResponse\\\\\\\",\\\\n        \\\\\\\"fastapi.staticfiles.StaticFiles\\\\\\\",\\\\n        \\\\\\\"pydantic.BaseModel\\\\\\\",\\\\n        \\\\\\\"uvicorn\\\\\\\",\\\\n        \\\\\\\"config.settings\\\\\\\",\\\\n        \\\\\\\"repository_analyzer.RepositoryAnalyzer\\\\\\\",\\\\n        \\\\\\\"ollama_client.OllamaClient\\\\\\\",\\\\n        \\\\\\\"vector_store.VectorStore\\\\\\\",\\\\n        \\\\\\\"rag_system.RAGSystem\\\\\\\",\\\\n        \\\\\\\"documentation_generator.DocumentationBuilder\\\\\\\",\\\\n        \\\\\\\"documentation_generator.DocumentationConfig\\\\\\\"\\\\n      ],\\\\n      \\\\\\\"elements\\\\\\\": [\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"QueryRequest\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\api.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 23,\\\\n          \\\\\\\"line_end\\\\\\\": 27,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class QueryRequest\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"ChatMessage\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\api.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 29,\\\\n          \\\\\\\"line_end\\\\\\\": 31,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class ChatMessage\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"ChatRequest\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\api.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 33,\\\\n          \\\\\\\"line_end\\\\\\\": 35,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class ChatRequest\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryRequest\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\api.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 37,\\\\n          \\\\\\\"line_end\\\\\\\": 39,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class RepositoryRequest\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"ExplainCodeRequest\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\api.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 41,\\\\n          \\\\\\\"line_end\\\\\\\": 44,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class ExplainCodeRequest\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationRequest\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\api.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 46,\\\\n          \\\\\\\"line_end\\\\\\\": 51,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class DocumentationRequest\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"main\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\api.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 422,\\\\n          \\\\\\\"line_end\\\\\\\": 438,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Main function to run the API server.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def main()\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        }\\\\n      ],\\\\n      \\\\\\\"summary\\\\\\\": null,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"FastAPI server for Local DeepWiki.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport asyncio\\\\\\\\nimport json\\\\\\\\nimport traceback\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import Dict, List, Any, Optional\\\\\\\\nfrom fastapi import FastAPI, HTTPException, BackgroundTasks, UploadFile, File\\\\\\\\nfrom fastapi.middleware.cors import CORSMiddleware\\\\\\\\nfrom fastapi.responses import StreamingResponse, JSONResponse\\\\\\\\nfrom fastapi.staticfiles import StaticFiles\\\\\\\\nfrom pydantic import BaseModel\\\\\\\\nimport uvicorn\\\\\\\\n\\\\\\\\nfrom config import settings\\\\\\\\nfrom repository_analyzer import RepositoryAnalyzer\\\\\\\\nfrom ollama_client import OllamaClient\\\\\\\\nfrom vector_store import VectorStore\\\\\\\\nfrom rag_system import RAGSystem\\\\\\\\nfrom documentation_generator import DocumentationBuilder, DocumentationConfig\\\\\\\\n\\\\\\\\n# Pydantic models for API\\\\\\\\nclass QueryRequest(BaseModel):\\\\\\\\n    query: str\\\\\\\\n    repo_name: Optional[str] = None\\\\\\\\n    file_path: Optional[str] = None\\\\\\\\n    stream: Optional[bool] = False\\\\\\\\n\\\\\\\\nclass ChatMessage(BaseModel):\\\\\\\\n    role: str  # 'user' or 'assistant'\\\\\\\\n    content: str\\\\\\\\n\\\\\\\\nclass ChatRequest(BaseModel):\\\\\\\\n    messages: List[ChatMessage]\\\\\\\\n    repo_name: Optional[str] = None\\\\\\\\n\\\\\\\\nclass RepositoryRequest(BaseModel):\\\\\\\\n    repo_path: str\\\\\\\\n    repo_name: Optional[str] = None\\\\\\\\n\\\\\\\\nclass ExplainCodeRequest(BaseModel):\\\\\\\\n    code: str\\\\\\\\n    language: Optional[str] = None\\\\\\\\n    context: Optional[str] = None\\\\\\\\n\\\\\\\\nclass DocumentationRequest(BaseModel):\\\\\\\\n    repo_name: str\\\\\\\\n    include_overview: bool = True\\\\\\\\n    include_api_docs: bool = True\\\\\\\\n    include_examples: bool = True\\\\\\\\n    include_architecture: bool = True\\\\\\\\n\\\\\\\\n# Global instances\\\\\\\\napp = FastAPI(title=\\\\\\\\\\\\\\\"Local DeepWiki\\\\\\\\\\\\\\\", version=\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\")\\\\\\\\nollama_client = OllamaClient()\\\\\\\\nvector_store = VectorStore()\\\\\\\\nrag_system = RAGSystem(vector_store, ollama_client)\\\\\\\\nrepository_analyzer = RepositoryAnalyzer()\\\\\\\\ndocumentation_builder = DocumentationBuilder(ollama_client)\\\\\\\\n\\\\\\\\n# Add CORS middleware\\\\\\\\napp.add_middleware(\\\\\\\\n    CORSMiddleware,\\\\\\\\n    allow_origins=[\\\\\\\\\\\\\\\"*\\\\\\\\\\\\\\\"],\\\\\\\\n    allow_credentials=True,\\\\\\\\n    allow_methods=[\\\\\\\\\\\\\\\"*\\\\\\\\\\\\\\\"],\\\\\\\\n    allow_headers=[\\\\\\\\\\\\\\\"*\\\\\\\\\\\\\\\"],\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Health check endpoints\\\\\\\\n@app.get(\\\\\\\\\\\\\\\"/health\\\\\\\\\\\\\\\")\\\\\\\\nasync def health_check():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Health check endpoint.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    ollama_available = ollama_client.is_available()\\\\\\\\n    vector_stats = vector_store.get_collection_stats()\\\\\\\\n    \\\\\\\\n    return {\\\\\\\\n        \\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"healthy\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"ollama_available\\\\\\\\\\\\\\\": ollama_available,\\\\\\\\n        \\\\\\\\\\\\\\\"ollama_url\\\\\\\\\\\\\\\": settings.OLLAMA_BASE_URL,\\\\\\\\n        \\\\\\\\\\\\\\\"ollama_model\\\\\\\\\\\\\\\": settings.OLLAMA_MODEL,\\\\\\\\n        \\\\\\\\\\\\\\\"vector_store\\\\\\\\\\\\\\\": vector_stats\\\\\\\\n    }\\\\\\\\n\\\\\\\\n@app.get(\\\\\\\\\\\\\\\"/models\\\\\\\\\\\\\\\")\\\\\\\\nasync def list_models():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"List available Ollama models.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        models = ollama_client.list_models()\\\\\\\\n        return {\\\\\\\\\\\\\\\"models\\\\\\\\\\\\\\\": models}\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error listing models: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n# Repository management endpoints\\\\\\\\n@app.post(\\\\\\\\\\\\\\\"/repositories/analyze\\\\\\\\\\\\\\\")\\\\\\\\nasync def analyze_repository(request: RepositoryRequest, background_tasks: BackgroundTasks):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyze a repository and add it to the vector store.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    repo_path = Path(request.repo_path)\\\\\\\\n    \\\\\\\\n    if not repo_path.exists():\\\\\\\\n        raise HTTPException(status_code=404, detail=f\\\\\\\\\\\\\\\"Repository path not found: {repo_path}\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    repo_name = request.repo_name or repo_path.name\\\\\\\\n    \\\\\\\\n    try:\\\\\\\\n        # Start analysis in background\\\\\\\\n        background_tasks.add_task(analyze_repository_task, str(repo_path), repo_name)\\\\\\\\n        \\\\\\\\n        return {\\\\\\\\n            \\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\"Repository analysis started for {repo_name}\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\": repo_name,\\\\\\\\n            \\\\\\\\\\\\\\\"repo_path\\\\\\\\\\\\\\\": str(repo_path)\\\\\\\\n        }\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error starting analysis: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\nasync def analyze_repository_task(repo_path: str, repo_name: str):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Background task to analyze repository.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Starting analysis of {repo_name} at {repo_path}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Analyze repository\\\\\\\\n        analysis = repository_analyzer.analyze_repository(repo_path)\\\\\\\\n        analysis['repo_name'] = repo_name\\\\\\\\n        \\\\\\\\n        # Save analysis\\\\\\\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\\\\\\\\\"{repo_name}_analysis.json\\\\\\\\\\\\\\\"\\\\\\\\n        repository_analyzer.save_analysis(analysis, str(analysis_path))\\\\\\\\n        \\\\\\\\n        # Add to vector store\\\\\\\\n        chunks_added = vector_store.add_repository(analysis)\\\\\\\\n        \\\\\\\\n        print(f\\\\\\\\\\\\\\\"Analysis complete for {repo_name}: {chunks_added} chunks added to vector store\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n    except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Error in repository analysis task: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n        traceback.print_exc()\\\\\\\\n\\\\\\\\n@app.get(\\\\\\\\\\\\\\\"/repositories\\\\\\\\\\\\\\\")\\\\\\\\nasync def list_repositories():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"List analyzed repositories.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    repos = []\\\\\\\\n    repos_dir = Path(settings.REPOS_DIRECTORY)\\\\\\\\n    \\\\\\\\n    if repos_dir.exists():\\\\\\\\n        for analysis_file in repos_dir.glob(\\\\\\\\\\\\\\\"*_analysis.json\\\\\\\\\\\\\\\"):\\\\\\\\n            try:\\\\\\\\n                analysis = repository_analyzer.load_analysis(str(analysis_file))\\\\\\\\n                repos.append({\\\\\\\\n                    \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": analysis.get('repo_name', analysis_file.stem.replace('_analysis', '')),\\\\\\\\n                    \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": analysis.get('repo_path', ''),\\\\\\\\n                    \\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\": analysis.get('statistics', {}).get('total_files', 0),\\\\\\\\n                    \\\\\\\\\\\\\\\"languages\\\\\\\\\\\\\\\": list(analysis.get('statistics', {}).get('languages', {}).keys())\\\\\\\\n                })\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Error loading analysis from {analysis_file}: {e}\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    return {\\\\\\\\\\\\\\\"repositories\\\\\\\\\\\\\\\": repos}\\\\\\\\n\\\\\\\\n@app.delete(\\\\\\\\\\\\\\\"/repositories/{repo_name}\\\\\\\\\\\\\\\")\\\\\\\\nasync def delete_repository(repo_name: str):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Delete repository from vector store.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        vector_store.delete_repository(repo_name)\\\\\\\\n        \\\\\\\\n        # Also delete analysis file\\\\\\\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\\\\\\\\\"{repo_name}_analysis.json\\\\\\\\\\\\\\\"\\\\\\\\n        if analysis_path.exists():\\\\\\\\n            analysis_path.unlink()\\\\\\\\n        \\\\\\\\n        return {\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\"Repository {repo_name} deleted successfully\\\\\\\\\\\\\\\"}\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error deleting repository: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n# Query endpoints\\\\\\\\n@app.post(\\\\\\\\\\\\\\\"/query\\\\\\\\\\\\\\\")\\\\\\\\nasync def query_repository(request: QueryRequest):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Query repository using RAG system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        if request.stream:\\\\\\\\n            # Return streaming response\\\\\\\\n            return StreamingResponse(\\\\\\\\n                stream_query_response(request),\\\\\\\\n                media_type=\\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\"\\\\\\\\n            )\\\\\\\\n        else:\\\\\\\\n            # Return complete response\\\\\\\\n            result = rag_system.query(\\\\\\\\n                request.query,\\\\\\\\n                repo_name=request.repo_name,\\\\\\\\n                file_path=request.file_path,\\\\\\\\n                stream=False\\\\\\\\n            )\\\\\\\\n            return result\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error processing query: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\nasync def stream_query_response(request: QueryRequest):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Stream query response for real-time updates.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        # Get context first\\\\\\\\n        filter_metadata = {}\\\\\\\\n        if request.repo_name:\\\\\\\\n            filter_metadata['repo_name'] = request.repo_name\\\\\\\\n        if request.file_path:\\\\\\\\n            filter_metadata['file_path'] = request.file_path\\\\\\\\n        \\\\\\\\n        retrieved_chunks = rag_system.retrieve_context(\\\\\\\\n            request.query, \\\\\\\\n            n_results=5, \\\\\\\\n            filter_metadata=filter_metadata or None\\\\\\\\n        )\\\\\\\\n        \\\\\\\\n        if not retrieved_chunks:\\\\\\\\n            yield \\\\\\\\\\\\\\\"No relevant context found for query.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            return\\\\\\\\n        \\\\\\\\n        context_text = rag_system.build_context_text(retrieved_chunks)\\\\\\\\n        \\\\\\\\n        # Build prompt\\\\\\\\n        system_prompt = rag_system.system_prompts['general_question']\\\\\\\\n        full_prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"{system_prompt}\\\\\\\\n\\\\\\\\nCONTEXT:\\\\\\\\n{context_text}\\\\\\\\n\\\\\\\\nUSER QUERY: {request.query}\\\\\\\\n\\\\\\\\nPlease provide a helpful response based on the context above.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        # Stream response\\\\\\\\n        async for chunk in ollama_client.generate_stream(full_prompt, temperature=0.3):\\\\\\\\n            yield chunk\\\\\\\\n            \\\\\\\\n    except Exception as e:\\\\\\\\n        yield f\\\\\\\\\\\\\\\"Error: {str(e)}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n@app.post(\\\\\\\\\\\\\\\"/chat\\\\\\\\\\\\\\\")\\\\\\\\nasync def chat_with_repository(request: ChatRequest):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Chat interface for conversational interaction.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        messages = [{\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\": msg.role, \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": msg.content} for msg in request.messages]\\\\\\\\n        response = rag_system.chat_with_repo(messages, request.repo_name)\\\\\\\\n        \\\\\\\\n        return {\\\\\\\\n            \\\\\\\\\\\\\\\"response\\\\\\\\\\\\\\\": response,\\\\\\\\n            \\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\": request.repo_name\\\\\\\\n        }\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error in chat: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n@app.post(\\\\\\\\\\\\\\\"/explain\\\\\\\\\\\\\\\")\\\\\\\\nasync def explain_code(request: ExplainCodeRequest):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Explain code snippet.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        explanation = rag_system.explain_code(\\\\\\\\n            request.code,\\\\\\\\n            request.language,\\\\\\\\n            request.context\\\\\\\\n        )\\\\\\\\n        return {\\\\\\\\\\\\\\\"explanation\\\\\\\\\\\\\\\": explanation}\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error explaining code: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n@app.post(\\\\\\\\\\\\\\\"/improve\\\\\\\\\\\\\\\")\\\\\\\\nasync def suggest_improvements(request: ExplainCodeRequest):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Suggest code improvements.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        suggestions = rag_system.suggest_improvements(\\\\\\\\n            request.code,\\\\\\\\n            request.language\\\\\\\\n        )\\\\\\\\n        return {\\\\\\\\\\\\\\\"suggestions\\\\\\\\\\\\\\\": suggestions}\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error suggesting improvements: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n@app.get(\\\\\\\\\\\\\\\"/repositories/{repo_name}/overview\\\\\\\\\\\\\\\")\\\\\\\\nasync def get_repository_overview(repo_name: str):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get repository overview.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        overview = rag_system.get_repository_overview(repo_name)\\\\\\\\n        return {\\\\\\\\\\\\\\\"overview\\\\\\\\\\\\\\\": overview, \\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\": repo_name}\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error getting overview: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n@app.get(\\\\\\\\\\\\\\\"/repositories/{repo_name}/files/{file_path:path}/summary\\\\\\\\\\\\\\\")\\\\\\\\nasync def get_file_summary(repo_name: str, file_path: str):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get file summary.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        summary = rag_system.get_file_summary(file_path, repo_name)\\\\\\\\n        return {\\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": summary, \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": file_path, \\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\": repo_name}\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error getting file summary: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n# Documentation endpoints\\\\\\\\n@app.post(\\\\\\\\\\\\\\\"/repositories/{repo_name}/generate-docs\\\\\\\\\\\\\\\")\\\\\\\\nasync def generate_documentation(repo_name: str, request: DocumentationRequest, background_tasks: BackgroundTasks):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate comprehensive documentation for repository.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        # Load repository analysis\\\\\\\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\\\\\\\\\"{repo_name}_analysis.json\\\\\\\\\\\\\\\"\\\\\\\\n        if not analysis_path.exists():\\\\\\\\n            raise HTTPException(status_code=404, detail=f\\\\\\\\\\\\\\\"Repository {repo_name} not found. Please analyze it first.\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        analysis = repository_analyzer.load_analysis(str(analysis_path))\\\\\\\\n        \\\\\\\\n        config = DocumentationConfig(\\\\\\\\n            include_overview=request.include_overview,\\\\\\\\n            include_api_docs=request.include_api_docs,\\\\\\\\n            include_examples=request.include_examples,\\\\\\\\n            include_architecture=request.include_architecture\\\\\\\\n        )\\\\\\\\n        \\\\\\\\n        # Start documentation generation in background\\\\\\\\n        background_tasks.add_task(generate_docs_task, analysis, config, repo_name)\\\\\\\\n        \\\\\\\\n        return {\\\\\\\\n            \\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\"Documentation generation started for {repo_name}\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\": repo_name\\\\\\\\n        }\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error starting documentation generation: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\nasync def generate_docs_task(analysis: Dict[str, Any], config: DocumentationConfig, repo_name: str):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Background task to generate documentation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Starting documentation generation for {repo_name}\\\\\\\\\\\\\\\")\\\\\\\\n        docs = documentation_builder.generate_full_documentation(analysis, config)\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Documentation generation complete for {repo_name}: {len(docs)} files generated\\\\\\\\\\\\\\\")\\\\\\\\n    except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Error in documentation generation task: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n        traceback.print_exc()\\\\\\\\n\\\\\\\\n@app.get(\\\\\\\\\\\\\\\"/repositories/{repo_name}/docs\\\\\\\\\\\\\\\")\\\\\\\\nasync def list_generated_docs(repo_name: str):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"List generated documentation files.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    docs_dir = Path(settings.DOCS_DIRECTORY) / repo_name\\\\\\\\n    \\\\\\\\n    if not docs_dir.exists():\\\\\\\\n        return {\\\\\\\\\\\\\\\"documents\\\\\\\\\\\\\\\": []}\\\\\\\\n    \\\\\\\\n    docs = []\\\\\\\\n    for doc_file in docs_dir.rglob(\\\\\\\\\\\\\\\"*.md\\\\\\\\\\\\\\\"):\\\\\\\\n        relative_path = doc_file.relative_to(docs_dir)\\\\\\\\n        docs.append({\\\\\\\\n            \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": doc_file.name,\\\\\\\\n            \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": str(relative_path),\\\\\\\\n            \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": doc_file.stat().st_size\\\\\\\\n        })\\\\\\\\n    \\\\\\\\n    return {\\\\\\\\\\\\\\\"documents\\\\\\\\\\\\\\\": docs}\\\\\\\\n\\\\\\\\n@app.get(\\\\\\\\\\\\\\\"/repositories/{repo_name}/docs/{doc_path:path}\\\\\\\\\\\\\\\")\\\\\\\\nasync def get_documentation(repo_name: str, doc_path: str):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get specific documentation file.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    doc_file = Path(settings.DOCS_DIRECTORY) / repo_name / doc_path\\\\\\\\n    \\\\\\\\n    if not doc_file.exists():\\\\\\\\n        raise HTTPException(status_code=404, detail=\\\\\\\\\\\\\\\"Documentation file not found\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    try:\\\\\\\\n        with open(doc_file, 'r', encoding='utf-8') as f:\\\\\\\\n            content = f.read()\\\\\\\\n        \\\\\\\\n        return {\\\\\\\\n            \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": content,\\\\\\\\n            \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": doc_path,\\\\\\\\n            \\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\": repo_name\\\\\\\\n        }\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error reading documentation: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n# Search endpoints\\\\\\\\n@app.get(\\\\\\\\\\\\\\\"/search\\\\\\\\\\\\\\\")\\\\\\\\nasync def search_all_repositories(q: str, limit: int = 10):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Search across all repositories.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        results = vector_store.search(q, n_results=limit)\\\\\\\\n        return {\\\\\\\\\\\\\\\"results\\\\\\\\\\\\\\\": results, \\\\\\\\\\\\\\\"query\\\\\\\\\\\\\\\": q}\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error searching: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n@app.get(\\\\\\\\\\\\\\\"/repositories/{repo_name}/search\\\\\\\\\\\\\\\")\\\\\\\\nasync def search_repository(repo_name: str, q: str, limit: int = 10):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Search within specific repository.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        results = vector_store.search(\\\\\\\\n            q, \\\\\\\\n            n_results=limit, \\\\\\\\n            filter_metadata={\\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\": repo_name}\\\\\\\\n        )\\\\\\\\n        return {\\\\\\\\\\\\\\\"results\\\\\\\\\\\\\\\": results, \\\\\\\\\\\\\\\"query\\\\\\\\\\\\\\\": q, \\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\": repo_name}\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error searching repository: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n# Statistics endpoint\\\\\\\\n@app.get(\\\\\\\\\\\\\\\"/stats\\\\\\\\\\\\\\\")\\\\\\\\nasync def get_system_stats():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get system statistics.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        vector_stats = vector_store.get_collection_stats()\\\\\\\\n        \\\\\\\\n        # Count repositories\\\\\\\\n        repos_dir = Path(settings.REPOS_DIRECTORY)\\\\\\\\n        repo_count = len(list(repos_dir.glob(\\\\\\\\\\\\\\\"*_analysis.json\\\\\\\\\\\\\\\"))) if repos_dir.exists() else 0\\\\\\\\n        \\\\\\\\n        # Count generated docs\\\\\\\\n        docs_dir = Path(settings.DOCS_DIRECTORY)\\\\\\\\n        doc_count = len(list(docs_dir.rglob(\\\\\\\\\\\\\\\"*.md\\\\\\\\\\\\\\\"))) if docs_dir.exists() else 0\\\\\\\\n        \\\\\\\\n        return {\\\\\\\\n            \\\\\\\\\\\\\\\"repositories\\\\\\\\\\\\\\\": repo_count,\\\\\\\\n            \\\\\\\\\\\\\\\"documents_in_vector_store\\\\\\\\\\\\\\\": vector_stats.get('total_documents', 0),\\\\\\\\n            \\\\\\\\\\\\\\\"generated_docs\\\\\\\\\\\\\\\": doc_count,\\\\\\\\n            \\\\\\\\\\\\\\\"ollama_available\\\\\\\\\\\\\\\": ollama_client.is_available(),\\\\\\\\n            \\\\\\\\\\\\\\\"ollama_model\\\\\\\\\\\\\\\": settings.OLLAMA_MODEL\\\\\\\\n        }\\\\\\\\n    except Exception as e:\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\"Error getting stats: {str(e)}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n# Main function to run the server\\\\\\\\ndef main():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Main function to run the API server.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    print(f\\\\\\\\\\\\\\\"Starting Local DeepWiki server on {settings.API_HOST}:{settings.API_PORT}\\\\\\\\\\\\\\\")\\\\\\\\n    print(f\\\\\\\\\\\\\\\"Ollama URL: {settings.OLLAMA_BASE_URL}\\\\\\\\\\\\\\\")\\\\\\\\n    print(f\\\\\\\\\\\\\\\"Model: {settings.OLLAMA_MODEL}\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    # Check Ollama availability\\\\\\\\n    if not ollama_client.is_available():\\\\\\\\n        print(\\\\\\\\\\\\\\\"WARNING: Ollama server not available. Please start Ollama first.\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"Run: ollama serve\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    uvicorn.run(\\\\\\\\n        \\\\\\\\\\\\\\\"api:app\\\\\\\\\\\\\\\",\\\\\\\\n        host=settings.API_HOST,\\\\\\\\n        port=settings.API_PORT,\\\\\\\\n        reload=True\\\\\\\\n    )\\\\\\\\n\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n    main()\\\\\\\\n\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\config.py\\\\\\\",\\\\n      \\\\\\\"file_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n      \\\\\\\"language\\\\\\\": \\\\\\\"python\\\\\\\",\\\\n      \\\\\\\"imports\\\\\\\": [\\\\n        \\\\\\\"os\\\\\\\",\\\\n        \\\\\\\"pathlib.Path\\\\\\\",\\\\n        \\\\\\\"typing.List\\\\\\\",\\\\n        \\\\\\\"typing.Dict\\\\\\\",\\\\n        \\\\\\\"typing.Any\\\\\\\",\\\\n        \\\\\\\"pydantic_settings.BaseSettings\\\\\\\"\\\\n      ],\\\\n      \\\\\\\"elements\\\\\\\": [\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"Settings\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\config.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 8,\\\\n          \\\\\\\"line_end\\\\\\\": 53,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Application settings.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class Settings\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"Config\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\config.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 52,\\\\n          \\\\\\\"line_end\\\\\\\": 53,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class Config\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        }\\\\n      ],\\\\n      \\\\\\\"summary\\\\\\\": null,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Configuration settings for Local DeepWiki.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport os\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import List, Dict, Any\\\\\\\\nfrom pydantic_settings import BaseSettings\\\\\\\\n\\\\\\\\nclass Settings(BaseSettings):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Application settings.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    # Ollama settings\\\\\\\\n    OLLAMA_BASE_URL: str = \\\\\\\\\\\\\\\"http://localhost:11434\\\\\\\\\\\\\\\"\\\\\\\\n    OLLAMA_MODEL: str = \\\\\\\\\\\\\\\"deepseek-coder:6.7b\\\\\\\\\\\\\\\"  # Using available code-focused model\\\\\\\\n    OLLAMA_EMBEDDING_MODEL: str = \\\\\\\\\\\\\\\"nomic-embed-text\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    # Vector database settings\\\\\\\\n    CHROMA_PERSIST_DIRECTORY: str = \\\\\\\\\\\\\\\"./data/chroma_db\\\\\\\\\\\\\\\"\\\\\\\\n    COLLECTION_NAME: str = \\\\\\\\\\\\\\\"codebase_docs\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    # Repository settings\\\\\\\\n    REPOS_DIRECTORY: str = \\\\\\\\\\\\\\\"./data/repos\\\\\\\\\\\\\\\"\\\\\\\\n    DOCS_DIRECTORY: str = \\\\\\\\\\\\\\\"./data/generated_docs\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    # Generation settings\\\\\\\\n    MAX_CHUNK_SIZE: int = 2000\\\\\\\\n    CHUNK_OVERLAP: int = 200\\\\\\\\n    MAX_CONTEXT_LENGTH: int = 4000\\\\\\\\n    \\\\\\\\n    # API settings\\\\\\\\n    API_HOST: str = \\\\\\\\\\\\\\\"0.0.0.0\\\\\\\\\\\\\\\"\\\\\\\\n    API_PORT: int = 8000\\\\\\\\n    \\\\\\\\n    # Supported file extensions\\\\\\\\n    CODE_EXTENSIONS: List[str] = [\\\\\\\\n        \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".js\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".ts\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".jsx\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".tsx\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".java\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".cpp\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".c\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".h\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\".cs\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".php\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".rb\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".go\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".rs\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".swift\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".kt\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".scala\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\".r\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".sql\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".sh\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".yaml\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".yml\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".json\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".xml\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".html\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\".css\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".scss\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".less\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".vue\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".svelte\\\\\\\\\\\\\\\"\\\\\\\\n    ]\\\\\\\\n    \\\\\\\\n    DOC_EXTENSIONS: List[str] = [\\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".rst\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".txt\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".adoc\\\\\\\\\\\\\\\"]\\\\\\\\n    \\\\\\\\n    # Ignored directories\\\\\\\\n    IGNORED_DIRS: List[str] = [\\\\\\\\n        \\\\\\\\\\\\\\\".git\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".svn\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".hg\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"__pycache__\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".pytest_cache\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"node_modules\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".npm\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".yarn\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"bower_components\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\".venv\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"venv\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"env\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".env\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"virtualenv\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"dist\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"build\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"target\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"bin\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"obj\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\".idea\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".vscode\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".vs\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"*.egg-info\\\\\\\\\\\\\\\"\\\\\\\\n    ]\\\\\\\\n    \\\\\\\\n    class Config:\\\\\\\\n        env_file = \\\\\\\\\\\\\\\".env\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Global settings instance\\\\\\\\nsettings = Settings()\\\\\\\\n\\\\\\\\n# Ensure data directories exist\\\\\\\\nPath(settings.CHROMA_PERSIST_DIRECTORY).mkdir(parents=True, exist_ok=True)\\\\\\\\nPath(settings.REPOS_DIRECTORY).mkdir(parents=True, exist_ok=True)\\\\\\\\nPath(settings.DOCS_DIRECTORY).mkdir(parents=True, exist_ok=True)\\\\\\\\n\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n      \\\\\\\"file_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n      \\\\\\\"language\\\\\\\": \\\\\\\"python\\\\\\\",\\\\n      \\\\\\\"imports\\\\\\\": [\\\\n        \\\\\\\"os\\\\\\\",\\\\n        \\\\\\\"json\\\\\\\",\\\\n        \\\\\\\"pathlib.Path\\\\\\\",\\\\n        \\\\\\\"typing.Dict\\\\\\\",\\\\n        \\\\\\\"typing.List\\\\\\\",\\\\n        \\\\\\\"typing.Any\\\\\\\",\\\\n        \\\\\\\"typing.Optional\\\\\\\",\\\\n        \\\\\\\"dataclasses.dataclass\\\\\\\",\\\\n        \\\\\\\"markdown\\\\\\\",\\\\n        \\\\\\\"jinja2.Template\\\\\\\",\\\\n        \\\\\\\"ollama_client.OllamaClient\\\\\\\",\\\\n        \\\\\\\"ollama_client.DocumentationGenerator\\\\\\\",\\\\n        \\\\\\\"repository_analyzer.RepositoryAnalyzer\\\\\\\",\\\\n        \\\\\\\"config.settings\\\\\\\"\\\\n      ],\\\\n      \\\\\\\"elements\\\\\\\": [\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationConfig\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 15,\\\\n          \\\\\\\"line_end\\\\\\\": 22,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Configuration for documentation generation.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class DocumentationConfig\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationBuilder\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 24,\\\\n          \\\\\\\"line_end\\\\\\\": 502,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Build comprehensive documentation from repository analysis.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class DocumentationBuilder\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationBuilder.__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 27,\\\\n          \\\\\\\"line_end\\\\\\\": 94,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self, ollama_client)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationBuilder.generate_full_documentation\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 96,\\\\n          \\\\\\\"line_end\\\\\\\": 161,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate complete documentation for a repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_full_documentation(self, repo_analysis, config, output_dir)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationBuilder.generate_repository_readme\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 163,\\\\n          \\\\\\\"line_end\\\\\\\": 224,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate main repository README.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_repository_readme(self, repo_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationBuilder.generate_file_api_docs\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 226,\\\\n          \\\\\\\"line_end\\\\\\\": 303,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate API documentation for a single file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_file_api_docs(self, file_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationBuilder.generate_architecture_docs\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 305,\\\\n          \\\\\\\"line_end\\\\\\\": 366,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate architecture documentation.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_architecture_docs(self, repo_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationBuilder.generate_examples_docs\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 368,\\\\n          \\\\\\\"line_end\\\\\\\": 447,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate usage examples documentation.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_examples_docs(self, repo_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationBuilder.generate_table_of_contents\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 449,\\\\n          \\\\\\\"line_end\\\\\\\": 470,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate table of contents for all documentation.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_table_of_contents(self, documentation)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationBuilder.update_existing_docs\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 472,\\\\n          \\\\\\\"line_end\\\\\\\": 502,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Update existing documentation files with new analysis.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def update_existing_docs(self, repo_path, analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 27,\\\\n          \\\\\\\"line_end\\\\\\\": 94,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self, ollama_client)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"generate_full_documentation\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 96,\\\\n          \\\\\\\"line_end\\\\\\\": 161,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate complete documentation for a repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_full_documentation(self, repo_analysis, config, output_dir)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"generate_repository_readme\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 163,\\\\n          \\\\\\\"line_end\\\\\\\": 224,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate main repository README.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_repository_readme(self, repo_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"generate_file_api_docs\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 226,\\\\n          \\\\\\\"line_end\\\\\\\": 303,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate API documentation for a single file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_file_api_docs(self, file_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"generate_architecture_docs\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 305,\\\\n          \\\\\\\"line_end\\\\\\\": 366,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate architecture documentation.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_architecture_docs(self, repo_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"generate_examples_docs\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 368,\\\\n          \\\\\\\"line_end\\\\\\\": 447,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate usage examples documentation.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_examples_docs(self, repo_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"generate_table_of_contents\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 449,\\\\n          \\\\\\\"line_end\\\\\\\": 470,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate table of contents for all documentation.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_table_of_contents(self, documentation)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"update_existing_docs\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 472,\\\\n          \\\\\\\"line_end\\\\\\\": 502,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Update existing documentation files with new analysis.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def update_existing_docs(self, repo_path, analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        }\\\\n      ],\\\\n      \\\\\\\"summary\\\\\\\": null,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Documentation generation system using local LLMs.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport os\\\\\\\\nimport json\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import Dict, List, Any, Optional\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\nimport markdown\\\\\\\\nfrom jinja2 import Template\\\\\\\\nfrom ollama_client import OllamaClient, DocumentationGenerator\\\\\\\\nfrom repository_analyzer import RepositoryAnalyzer\\\\\\\\nfrom config import settings\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass DocumentationConfig:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Configuration for documentation generation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    include_overview: bool = True\\\\\\\\n    include_api_docs: bool = True\\\\\\\\n    include_examples: bool = True\\\\\\\\n    include_architecture: bool = True\\\\\\\\n    output_format: str = 'markdown'  # 'markdown', 'html'\\\\\\\\n    template_style: str = 'default'  # 'default', 'minimal', 'detailed'\\\\\\\\n\\\\\\\\nclass DocumentationBuilder:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Build comprehensive documentation from repository analysis.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def __init__(self, ollama_client: OllamaClient):\\\\\\\\n        self.ollama_client = ollama_client\\\\\\\\n        self.doc_generator = DocumentationGenerator(ollama_client)\\\\\\\\n        \\\\\\\\n        # Documentation templates\\\\\\\\n        self.templates = {\\\\\\\\n            'repository_readme': \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"# {{ repo_name }}\\\\\\\\n\\\\\\\\n{{ overview }}\\\\\\\\n\\\\\\\\n## Architecture\\\\\\\\n\\\\\\\\n{{ architecture }}\\\\\\\\n\\\\\\\\n## Getting Started\\\\\\\\n\\\\\\\\n{{ getting_started }}\\\\\\\\n\\\\\\\\n## API Documentation\\\\\\\\n\\\\\\\\n{{ api_docs }}\\\\\\\\n\\\\\\\\n## Examples\\\\\\\\n\\\\\\\\n{{ examples }}\\\\\\\\n\\\\\\\\n## Contributing\\\\\\\\n\\\\\\\\n{{ contributing }}\\\\\\\\n\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\n            'api_reference': \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"# API Reference - {{ file_name }}\\\\\\\\n\\\\\\\\n{{ file_overview }}\\\\\\\\n\\\\\\\\n## Classes\\\\\\\\n\\\\\\\\n{{ classes }}\\\\\\\\n\\\\\\\\n## Functions\\\\\\\\n\\\\\\\\n{{ functions }}\\\\\\\\n\\\\\\\\n## Constants\\\\\\\\n\\\\\\\\n{{ constants }}\\\\\\\\n\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\n            'module_docs': \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"# {{ module_name }}\\\\\\\\n\\\\\\\\n{{ description }}\\\\\\\\n\\\\\\\\n## Usage\\\\\\\\n\\\\\\\\n{{ usage }}\\\\\\\\n\\\\\\\\n## Implementation Details\\\\\\\\n\\\\\\\\n{{ implementation }}\\\\\\\\n\\\\\\\\n## Dependencies\\\\\\\\n\\\\\\\\n{{ dependencies }}\\\\\\\\n\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        }\\\\\\\\n    \\\\\\\\n    def generate_full_documentation(self, \\\\\\\\n                                  repo_analysis: Dict[str, Any], \\\\\\\\n                                  config: DocumentationConfig = None,\\\\\\\\n                                  output_dir: str = None) -> Dict[str, str]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate complete documentation for a repository.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        if config is None:\\\\\\\\n            config = DocumentationConfig()\\\\\\\\n        \\\\\\\\n        if output_dir is None:\\\\\\\\n            output_dir = settings.DOCS_DIRECTORY\\\\\\\\n        \\\\\\\\n        output_dir = Path(output_dir)\\\\\\\\n        repo_name = repo_analysis.get('repo_name', 'unknown')\\\\\\\\n        repo_output_dir = output_dir / repo_name\\\\\\\\n        repo_output_dir.mkdir(parents=True, exist_ok=True)\\\\\\\\n        \\\\\\\\n        documentation = {}\\\\\\\\n        \\\\\\\\n        # Generate main README\\\\\\\\n        if config.include_overview:\\\\\\\\n            readme_content = self.generate_repository_readme(repo_analysis)\\\\\\\\n            readme_path = repo_output_dir / 'README.md'\\\\\\\\n            with open(readme_path, 'w', encoding='utf-8') as f:\\\\\\\\n                f.write(readme_content)\\\\\\\\n            documentation['README.md'] = readme_content\\\\\\\\n        \\\\\\\\n        # Generate API documentation for each file\\\\\\\\n        if config.include_api_docs:\\\\\\\\n            api_dir = repo_output_dir / 'api'\\\\\\\\n            api_dir.mkdir(exist_ok=True)\\\\\\\\n            \\\\\\\\n            for file_data in repo_analysis.get('files', []):\\\\\\\\n                if file_data.get('file_type') == 'code':\\\\\\\\n                    api_doc = self.generate_file_api_docs(file_data)\\\\\\\\n                    file_name = Path(file_data['file_path']).stem\\\\\\\\n                    api_file_path = api_dir / f\\\\\\\\\\\\\\\"{file_name}.md\\\\\\\\\\\\\\\"\\\\\\\\n                    \\\\\\\\n                    with open(api_file_path, 'w', encoding='utf-8') as f:\\\\\\\\n                        f.write(api_doc)\\\\\\\\n                    documentation[f'api/{file_name}.md'] = api_doc\\\\\\\\n        \\\\\\\\n        # Generate architecture documentation\\\\\\\\n        if config.include_architecture:\\\\\\\\n            arch_doc = self.generate_architecture_docs(repo_analysis)\\\\\\\\n            arch_path = repo_output_dir / 'ARCHITECTURE.md'\\\\\\\\n            with open(arch_path, 'w', encoding='utf-8') as f:\\\\\\\\n                f.write(arch_doc)\\\\\\\\n            documentation['ARCHITECTURE.md'] = arch_doc\\\\\\\\n        \\\\\\\\n        # Generate examples\\\\\\\\n        if config.include_examples:\\\\\\\\n            examples_doc = self.generate_examples_docs(repo_analysis)\\\\\\\\n            examples_path = repo_output_dir / 'EXAMPLES.md'\\\\\\\\n            with open(examples_path, 'w', encoding='utf-8') as f:\\\\\\\\n                f.write(examples_doc)\\\\\\\\n            documentation['EXAMPLES.md'] = examples_doc\\\\\\\\n        \\\\\\\\n        # Generate table of contents\\\\\\\\n        toc = self.generate_table_of_contents(documentation)\\\\\\\\n        toc_path = repo_output_dir / 'TABLE_OF_CONTENTS.md'\\\\\\\\n        with open(toc_path, 'w', encoding='utf-8') as f:\\\\\\\\n            f.write(toc)\\\\\\\\n        documentation['TABLE_OF_CONTENTS.md'] = toc\\\\\\\\n        \\\\\\\\n        return documentation\\\\\\\\n    \\\\\\\\n    def generate_repository_readme(self, repo_analysis: Dict[str, Any]) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate main repository README.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        repo_name = repo_analysis.get('repo_name', 'Repository')\\\\\\\\n        stats = repo_analysis.get('statistics', {})\\\\\\\\n        \\\\\\\\n        # Build context for LLM\\\\\\\\n        context = []\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Repository: {repo_name}\\\\\\\\\\\\\\\")\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Total files: {stats.get('total_files', 0)}\\\\\\\\\\\\\\\")\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Code files: {stats.get('code_files', 0)}\\\\\\\\\\\\\\\")\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Languages: {', '.join(stats.get('languages', {}).keys())}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Add git information\\\\\\\\n        git_info = repo_analysis.get('git_info')\\\\\\\\n        if git_info:\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\"Current branch: {git_info.get('current_branch', 'main')}\\\\\\\\\\\\\\\")\\\\\\\\n            if git_info.get('last_commit'):\\\\\\\\n                commit = git_info['last_commit']\\\\\\\\n                context.append(f\\\\\\\\\\\\\\\"Last commit: {commit.get('message', '')[:100]}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Add file structure overview\\\\\\\\n        main_files = []\\\\\\\\n        config_files = []\\\\\\\\n        doc_files = []\\\\\\\\n        \\\\\\\\n        for file_data in repo_analysis.get('files', []):\\\\\\\\n            file_path = file_data['file_path']\\\\\\\\n            if any(name in file_path.lower() for name in ['readme', 'license', 'changelog']):\\\\\\\\n                doc_files.append(file_path)\\\\\\\\n            elif any(ext in file_path.lower() for ext in ['.json', '.yaml', '.yml', '.toml', '.ini']):\\\\\\\\n                config_files.append(file_path)\\\\\\\\n            elif file_data.get('file_type') == 'code':\\\\\\\\n                main_files.append(file_path)\\\\\\\\n        \\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Main code files: {', '.join(main_files[:10])}\\\\\\\\\\\\\\\")\\\\\\\\n        if config_files:\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\"Configuration files: {', '.join(config_files[:5])}\\\\\\\\\\\\\\\")\\\\\\\\n        if doc_files:\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\"Documentation files: {', '.join(doc_files)}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        context_str = '\\\\\\\\\\\\\\\\n'.join(context)\\\\\\\\n        \\\\\\\\n        prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate a comprehensive README.md for this repository based on the following information:\\\\\\\\n\\\\\\\\n{context_str}\\\\\\\\n\\\\\\\\nPlease include:\\\\\\\\n1. Project title and brief description\\\\\\\\n2. Features and capabilities\\\\\\\\n3. Installation instructions\\\\\\\\n4. Quick start guide\\\\\\\\n5. Usage examples\\\\\\\\n6. Project structure overview\\\\\\\\n7. Contributing guidelines\\\\\\\\n8. License information\\\\\\\\n\\\\\\\\nMake it professional and well-formatted with proper Markdown syntax.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\n        except Exception as e:\\\\\\\\n            return f\\\\\\\\\\\\\\\"# {repo_name}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nError generating README: {str(e)}\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def generate_file_api_docs(self, file_analysis: Dict[str, Any]) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate API documentation for a single file.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        file_path = file_analysis['file_path']\\\\\\\\n        language = file_analysis.get('language', 'Unknown')\\\\\\\\n        elements = file_analysis.get('elements', [])\\\\\\\\n        \\\\\\\\n        # Group elements by type\\\\\\\\n        classes = [e for e in elements if e['type'] == 'class']\\\\\\\\n        functions = [e for e in elements if e['type'] in ['function', 'method']]\\\\\\\\n        \\\\\\\\n        doc_content = f\\\\\\\\\\\\\\\"# API Reference - {Path(file_path).name}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        doc_content += f\\\\\\\\\\\\\\\"**File**: `{file_path}`  \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        doc_content += f\\\\\\\\\\\\\\\"**Language**: {language}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        # File overview\\\\\\\\n        overview_prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Provide a brief overview of this {language} file:\\\\\\\\n\\\\\\\\nFile: {file_path}\\\\\\\\nElements: {len(elements)} total ({len(classes)} classes, {len(functions)} functions)\\\\\\\\n\\\\\\\\nContent preview:\\\\\\\\n{file_analysis.get('content', '')[:1000]}...\\\\\\\\n\\\\\\\\nWrite a 2-3 sentence overview of what this file does.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            overview = self.ollama_client.generate(overview_prompt, temperature=0.3)\\\\\\\\n            doc_content += f\\\\\\\\\\\\\\\"## Overview\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{overview}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        except:\\\\\\\\n            doc_content += f\\\\\\\\\\\\\\\"## Overview\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis file contains {len(elements)} code elements.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        # Document classes\\\\\\\\n        if classes:\\\\\\\\n            doc_content += \\\\\\\\\\\\\\\"## Classes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            for cls in classes:\\\\\\\\n                doc_content += f\\\\\\\\\\\\\\\"### {cls['name']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n                if cls.get('docstring'):\\\\\\\\n                    doc_content += f\\\\\\\\\\\\\\\"{cls['docstring']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n                \\\\\\\\n                # Get methods for this class\\\\\\\\n                class_methods = [e for e in elements if e['type'] == 'method' and e['name'].startswith(f\\\\\\\\\\\\\\\"{cls['name']}.\\\\\\\\\\\\\\\")]\\\\\\\\n                if class_methods:\\\\\\\\n                    doc_content += \\\\\\\\\\\\\\\"#### Methods\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n                    for method in class_methods:\\\\\\\\n                        method_name = method['name'].split('.')[-1]\\\\\\\\n                        doc_content += f\\\\\\\\\\\\\\\"- **{method_name}**\\\\\\\\\\\\\\\"\\\\\\\\n                        if method.get('signature'):\\\\\\\\n                            doc_content += f\\\\\\\\\\\\\\\": `{method['signature']}`\\\\\\\\\\\\\\\"\\\\\\\\n                        if method.get('docstring'):\\\\\\\\n                            doc_content += f\\\\\\\\\\\\\\\" - {method['docstring'][:100]}...\\\\\\\\\\\\\\\"\\\\\\\\n                        doc_content += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n                    doc_content += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        # Document functions\\\\\\\\n        if functions:\\\\\\\\n            doc_content += \\\\\\\\\\\\\\\"## Functions\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            for func in functions:\\\\\\\\n                if func['type'] == 'method':\\\\\\\\n                    continue  # Skip methods (already documented with classes)\\\\\\\\n                \\\\\\\\n                doc_content += f\\\\\\\\\\\\\\\"### {func['name']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n                if func.get('signature'):\\\\\\\\n                    doc_content += f\\\\\\\\\\\\\\\"```{language}\\\\\\\\\\\\\\\\n{func['signature']}\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n                if func.get('docstring'):\\\\\\\\n                    doc_content += f\\\\\\\\\\\\\\\"{func['docstring']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        # Add imports if available\\\\\\\\n        imports = file_analysis.get('imports', [])\\\\\\\\n        if imports:\\\\\\\\n            doc_content += \\\\\\\\\\\\\\\"## Dependencies\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            doc_content += \\\\\\\\\\\\\\\"This file imports:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            for imp in imports[:10]:  # Limit to first 10 imports\\\\\\\\n                doc_content += f\\\\\\\\\\\\\\\"- `{imp}`\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            if len(imports) > 10:\\\\\\\\n                doc_content += f\\\\\\\\\\\\\\\"- ... and {len(imports) - 10} more\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            doc_content += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        return doc_content\\\\\\\\n    \\\\\\\\n    def generate_architecture_docs(self, repo_analysis: Dict[str, Any]) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate architecture documentation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        repo_name = repo_analysis.get('repo_name', 'Repository')\\\\\\\\n        stats = repo_analysis.get('statistics', {})\\\\\\\\n        \\\\\\\\n        # Analyze project structure\\\\\\\\n        languages = stats.get('languages', {})\\\\\\\\n        files = repo_analysis.get('files', [])\\\\\\\\n        \\\\\\\\n        # Group files by directory\\\\\\\\n        directories = {}\\\\\\\\n        for file_data in files:\\\\\\\\n            dir_path = str(Path(file_data['file_path']).parent)\\\\\\\\n            if dir_path not in directories:\\\\\\\\n                directories[dir_path] = []\\\\\\\\n            directories[dir_path].append(file_data)\\\\\\\\n        \\\\\\\\n        # Build context for architecture analysis\\\\\\\\n        context = []\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Repository: {repo_name}\\\\\\\\\\\\\\\")\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Languages: {', '.join(languages.keys())}\\\\\\\\\\\\\\\")\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Total files: {stats.get('total_files', 0)}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        context.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nDirectory structure:\\\\\\\\\\\\\\\")\\\\\\\\n        for dir_path, dir_files in sorted(directories.items())[:15]:  # Limit directories\\\\\\\\n            file_count = len(dir_files)\\\\\\\\n            main_types = set()\\\\\\\\n            for f in dir_files:\\\\\\\\n                if f.get('language'):\\\\\\\\n                    main_types.add(f['language'])\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\"- {dir_path}: {file_count} files ({', '.join(main_types)})\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Add key files analysis\\\\\\\\n        key_files = []\\\\\\\\n        for file_data in files:\\\\\\\\n            if any(keyword in file_data['file_path'].lower() for keyword in ['main', 'app', 'index', '__init__', 'server', 'client']):\\\\\\\\n                key_files.append(file_data['file_path'])\\\\\\\\n        \\\\\\\\n        if key_files:\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nKey files: {', '.join(key_files[:10])}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        context_str = '\\\\\\\\\\\\\\\\n'.join(context)\\\\\\\\n        \\\\\\\\n        prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyze the architecture of this project and generate comprehensive architecture documentation:\\\\\\\\n\\\\\\\\n{context_str}\\\\\\\\n\\\\\\\\nPlease provide:\\\\\\\\n1. High-level architecture overview\\\\\\\\n2. Component breakdown and relationships\\\\\\\\n3. Data flow and system interactions\\\\\\\\n4. Design patterns used\\\\\\\\n5. Technology stack analysis\\\\\\\\n6. Scalability considerations\\\\\\\\n7. Deployment architecture\\\\\\\\n\\\\\\\\nFormat as professional technical documentation with proper Markdown structure.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\n        except Exception as e:\\\\\\\\n            return f\\\\\\\\\\\\\\\"# Architecture Documentation\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nError generating architecture docs: {str(e)}\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def generate_examples_docs(self, repo_analysis: Dict[str, Any]) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate usage examples documentation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        repo_name = repo_analysis.get('repo_name', 'Repository')\\\\\\\\n        languages = repo_analysis.get('statistics', {}).get('languages', {})\\\\\\\\n        \\\\\\\\n        # Find main entry points\\\\\\\\n        entry_points = []\\\\\\\\n        main_classes = []\\\\\\\\n        main_functions = []\\\\\\\\n        \\\\\\\\n        for file_data in repo_analysis.get('files', []):\\\\\\\\n            if file_data.get('file_type') == 'code':\\\\\\\\n                elements = file_data.get('elements', [])\\\\\\\\n                \\\\\\\\n                # Look for main functions or entry points\\\\\\\\n                for element in elements:\\\\\\\\n                    if element['name'].lower() in ['main', 'run', 'start', 'init']:\\\\\\\\n                        entry_points.append({\\\\\\\\n                            'name': element['name'],\\\\\\\\n                            'file': file_data['file_path'],\\\\\\\\n                            'signature': element.get('signature', ''),\\\\\\\\n                            'type': element['type']\\\\\\\\n                        })\\\\\\\\n                    \\\\\\\\n                    if element['type'] == 'class' and len(element.get('name', '')) > 3:\\\\\\\\n                        main_classes.append({\\\\\\\\n                            'name': element['name'],\\\\\\\\n                            'file': file_data['file_path'],\\\\\\\\n                            'signature': element.get('signature', ''),\\\\\\\\n                            'docstring': element.get('docstring', '')\\\\\\\\n                        })\\\\\\\\n                    \\\\\\\\n                    if element['type'] == 'function' and element.get('docstring'):\\\\\\\\n                        main_functions.append({\\\\\\\\n                            'name': element['name'],\\\\\\\\n                            'file': file_data['file_path'],\\\\\\\\n                            'signature': element.get('signature', ''),\\\\\\\\n                            'docstring': element.get('docstring', '')\\\\\\\\n                        })\\\\\\\\n        \\\\\\\\n        # Build context\\\\\\\\n        context = []\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Repository: {repo_name}\\\\\\\\\\\\\\\")\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Languages: {', '.join(languages.keys())}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        if entry_points:\\\\\\\\n            context.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nEntry points:\\\\\\\\\\\\\\\")\\\\\\\\n            for ep in entry_points[:5]:\\\\\\\\n                context.append(f\\\\\\\\\\\\\\\"- {ep['name']} in {ep['file']}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        if main_classes:\\\\\\\\n            context.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nMain classes:\\\\\\\\\\\\\\\")\\\\\\\\n            for cls in main_classes[:5]:\\\\\\\\n                context.append(f\\\\\\\\\\\\\\\"- {cls['name']} in {cls['file']}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        if main_functions:\\\\\\\\n            context.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nKey functions:\\\\\\\\\\\\\\\")\\\\\\\\n            for func in main_functions[:5]:\\\\\\\\n                context.append(f\\\\\\\\\\\\\\\"- {func['name']} in {func['file']}: {func['docstring'][:50]}...\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        context_str = '\\\\\\\\\\\\\\\\n'.join(context)\\\\\\\\n        \\\\\\\\n        prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate practical usage examples and tutorials for this project:\\\\\\\\n\\\\\\\\n{context_str}\\\\\\\\n\\\\\\\\nPlease provide:\\\\\\\\n1. Quick start example\\\\\\\\n2. Basic usage patterns\\\\\\\\n3. Common use cases with code examples\\\\\\\\n4. Integration examples\\\\\\\\n5. Configuration examples\\\\\\\\n6. Troubleshooting common issues\\\\\\\\n\\\\\\\\nInclude actual code snippets with explanations. Format with proper Markdown and code blocks.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\n        except Exception as e:\\\\\\\\n            return f\\\\\\\\\\\\\\\"# Usage Examples\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nError generating examples: {str(e)}\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def generate_table_of_contents(self, documentation: Dict[str, str]) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate table of contents for all documentation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        toc_content = \\\\\\\\\\\\\\\"# Table of Contents\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        toc_content += \\\\\\\\\\\\\\\"This repository contains the following documentation:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        # Main documentation\\\\\\\\n        main_docs = ['README.md', 'ARCHITECTURE.md', 'EXAMPLES.md']\\\\\\\\n        for doc in main_docs:\\\\\\\\n            if doc in documentation:\\\\\\\\n                toc_content += f\\\\\\\\\\\\\\\"- [{doc}](./{doc})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        # API documentation\\\\\\\\n        api_docs = [k for k in documentation.keys() if k.startswith('api/')]\\\\\\\\n        if api_docs:\\\\\\\\n            toc_content += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n## API Documentation\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            for doc in sorted(api_docs):\\\\\\\\n                file_name = Path(doc).stem\\\\\\\\n                toc_content += f\\\\\\\\\\\\\\\"- [{file_name}](./{doc})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        toc_content += f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n*Documentation generated automatically from codebase analysis.*\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        return toc_content\\\\\\\\n    \\\\\\\\n    def update_existing_docs(self, repo_path: str, analysis: Dict[str, Any]) -> Dict[str, str]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Update existing documentation files with new analysis.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        repo_path = Path(repo_path)\\\\\\\\n        updates = {}\\\\\\\\n        \\\\\\\\n        # Check for existing README\\\\\\\\n        readme_path = repo_path / 'README.md'\\\\\\\\n        if readme_path.exists():\\\\\\\\n            with open(readme_path, 'r', encoding='utf-8') as f:\\\\\\\\n                existing_readme = f.read()\\\\\\\\n            \\\\\\\\n            # Generate enhancement suggestions\\\\\\\\n            prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyze this existing README and suggest improvements based on the codebase analysis:\\\\\\\\n\\\\\\\\nCurrent README:\\\\\\\\n{existing_readme[:2000]}...\\\\\\\\n\\\\\\\\nCodebase info:\\\\\\\\n- Files: {analysis.get('statistics', {}).get('total_files', 0)}\\\\\\\\n- Languages: {', '.join(analysis.get('statistics', {}).get('languages', {}).keys())}\\\\\\\\n- Key components: {len(analysis.get('files', []))} files analyzed\\\\\\\\n\\\\\\\\nSuggest specific improvements while preserving the existing structure and content.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n            try:\\\\\\\\n                suggestions = self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\n                updates['README_suggestions.md'] = suggestions\\\\\\\\n            except Exception as e:\\\\\\\\n                updates['README_suggestions.md'] = f\\\\\\\\\\\\\\\"Error generating suggestions: {str(e)}\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        return updates\\\\\\\\n\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n      \\\\\\\"file_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n      \\\\\\\"language\\\\\\\": \\\\\\\"python\\\\\\\",\\\\n      \\\\\\\"imports\\\\\\\": [\\\\n        \\\\\\\"argparse\\\\\\\",\\\\n        \\\\\\\"asyncio\\\\\\\",\\\\n        \\\\\\\"sys\\\\\\\",\\\\n        \\\\\\\"pathlib.Path\\\\\\\",\\\\n        \\\\\\\"typing.Optional\\\\\\\",\\\\n        \\\\\\\"config.settings\\\\\\\",\\\\n        \\\\\\\"repository_analyzer.RepositoryAnalyzer\\\\\\\",\\\\n        \\\\\\\"ollama_client.OllamaClient\\\\\\\",\\\\n        \\\\\\\"vector_store.VectorStore\\\\\\\",\\\\n        \\\\\\\"rag_system.RAGSystem\\\\\\\",\\\\n        \\\\\\\"documentation_generator.DocumentationBuilder\\\\\\\",\\\\n        \\\\\\\"documentation_generator.DocumentationConfig\\\\\\\",\\\\n        \\\\\\\"api.main\\\\\\\"\\\\n      ],\\\\n      \\\\\\\"elements\\\\\\\": [\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"LocalDeepWiki\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 21,\\\\n          \\\\\\\"line_end\\\\\\\": 254,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Main class for Local DeepWiki functionality.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class LocalDeepWiki\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"LocalDeepWiki.__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 24,\\\\n          \\\\\\\"line_end\\\\\\\": 30,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Initialize LocalDeepWiki with all components.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"LocalDeepWiki.check_prerequisites\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 32,\\\\n          \\\\\\\"line_end\\\\\\\": 65,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Check if all prerequisites are met.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def check_prerequisites(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"LocalDeepWiki.analyze_repository\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 67,\\\\n          \\\\\\\"line_end\\\\\\\": 104,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Analyze a repository and add it to the vector store.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def analyze_repository(self, repo_path, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"LocalDeepWiki.query_repository\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 106,\\\\n          \\\\\\\"line_end\\\\\\\": 129,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Query a repository using the RAG system.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def query_repository(self, query, repo_name, stream)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"LocalDeepWiki.interactive_chat\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 131,\\\\n          \\\\\\\"line_end\\\\\\\": 164,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Start an interactive chat session.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def interactive_chat(self, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"LocalDeepWiki.generate_documentation\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 166,\\\\n          \\\\\\\"line_end\\\\\\\": 199,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate documentation for a repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_documentation(self, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"LocalDeepWiki.list_repositories\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 201,\\\\n          \\\\\\\"line_end\\\\\\\": 231,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"List all analyzed repositories.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def list_repositories(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"LocalDeepWiki.show_stats\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 233,\\\\n          \\\\\\\"line_end\\\\\\\": 254,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Show system statistics.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def show_stats(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"main\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 256,\\\\n          \\\\\\\"line_end\\\\\\\": 342,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Main CLI interface.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def main()\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 24,\\\\n          \\\\\\\"line_end\\\\\\\": 30,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Initialize LocalDeepWiki with all components.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"check_prerequisites\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 32,\\\\n          \\\\\\\"line_end\\\\\\\": 65,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Check if all prerequisites are met.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def check_prerequisites(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"analyze_repository\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 67,\\\\n          \\\\\\\"line_end\\\\\\\": 104,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Analyze a repository and add it to the vector store.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def analyze_repository(self, repo_path, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"query_repository\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 106,\\\\n          \\\\\\\"line_end\\\\\\\": 129,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Query a repository using the RAG system.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def query_repository(self, query, repo_name, stream)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"interactive_chat\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 131,\\\\n          \\\\\\\"line_end\\\\\\\": 164,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Start an interactive chat session.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def interactive_chat(self, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"generate_documentation\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 166,\\\\n          \\\\\\\"line_end\\\\\\\": 199,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate documentation for a repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_documentation(self, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"list_repositories\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 201,\\\\n          \\\\\\\"line_end\\\\\\\": 231,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"List all analyzed repositories.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def list_repositories(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"show_stats\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\main.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 233,\\\\n          \\\\\\\"line_end\\\\\\\": 254,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Show system statistics.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def show_stats(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        }\\\\n      ],\\\\n      \\\\\\\"summary\\\\\\\": null,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"#!/usr/bin/env python3\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nLocal DeepWiki - Main entry point and CLI interface.\\\\\\\\n\\\\\\\\nA local implementation of DeepWiki using Ollama for LLM inference.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport argparse\\\\\\\\nimport asyncio\\\\\\\\nimport sys\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import Optional\\\\\\\\n\\\\\\\\nfrom config import settings\\\\\\\\nfrom repository_analyzer import RepositoryAnalyzer\\\\\\\\nfrom ollama_client import OllamaClient\\\\\\\\nfrom vector_store import VectorStore\\\\\\\\nfrom rag_system import RAGSystem\\\\\\\\nfrom documentation_generator import DocumentationBuilder, DocumentationConfig\\\\\\\\n\\\\\\\\nclass LocalDeepWiki:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Main class for Local DeepWiki functionality.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def __init__(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Initialize LocalDeepWiki with all components.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.ollama_client = OllamaClient()\\\\\\\\n        self.vector_store = VectorStore()\\\\\\\\n        self.rag_system = RAGSystem(self.vector_store, self.ollama_client)\\\\\\\\n        self.repository_analyzer = RepositoryAnalyzer()\\\\\\\\n        self.documentation_builder = DocumentationBuilder(self.ollama_client)\\\\\\\\n    \\\\\\\\n    def check_prerequisites(self) -> bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if all prerequisites are met.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        print(\\\\\\\\\\\\\\\"Checking prerequisites...\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Check Ollama\\\\\\\\n        if not self.ollama_client.is_available():\\\\\\\\n            print(\\\\\\\\\\\\\\\"X Ollama server is not available at\\\\\\\\\\\\\\\", settings.OLLAMA_BASE_URL)\\\\\\\\n            print(\\\\\\\\\\\\\\\"Please start Ollama first:\\\\\\\\\\\\\\\")\\\\\\\\n            print(\\\\\\\\\\\\\\\"  ollama serve\\\\\\\\\\\\\\\")\\\\\\\\n            return False\\\\\\\\n        \\\\\\\\n        print(\\\\\\\\\\\\\\\"OK Ollama server is available\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Check model\\\\\\\\n        models = self.ollama_client.list_models()\\\\\\\\n        model_names = [model['name'] for model in models]\\\\\\\\n        \\\\\\\\n        if settings.OLLAMA_MODEL not in model_names:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"X Model '{settings.OLLAMA_MODEL}' is not available\\\\\\\\\\\\\\\")\\\\\\\\n            print(\\\\\\\\\\\\\\\"Available models:\\\\\\\\\\\\\\\", model_names)\\\\\\\\n            print(f\\\\\\\\\\\\\\\"To download the model, run:\\\\\\\\\\\\\\\")\\\\\\\\n            print(f\\\\\\\\\\\\\\\"  ollama pull {settings.OLLAMA_MODEL}\\\\\\\\\\\\\\\")\\\\\\\\n            return False\\\\\\\\n        \\\\\\\\n        print(f\\\\\\\\\\\\\\\"OK Model '{settings.OLLAMA_MODEL}' is available\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Check embedding model\\\\\\\\n        if settings.OLLAMA_EMBEDDING_MODEL not in model_names:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"! Embedding model '{settings.OLLAMA_EMBEDDING_MODEL}' not found\\\\\\\\\\\\\\\")\\\\\\\\n            print(\\\\\\\\\\\\\\\"Will use fallback embedding model\\\\\\\\\\\\\\\")\\\\\\\\n        else:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"OK Embedding model '{settings.OLLAMA_EMBEDDING_MODEL}' is available\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        return True\\\\\\\\n    \\\\\\\\n    def analyze_repository(self, repo_path: str, repo_name: Optional[str] = None) -> bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyze a repository and add it to the vector store.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        repo_path = Path(repo_path).resolve()\\\\\\\\n        \\\\\\\\n        if not repo_path.exists():\\\\\\\\n            print(f\\\\\\\\\\\\\\\"X Repository path does not exist: {repo_path}\\\\\\\\\\\\\\\")\\\\\\\\n            return False\\\\\\\\n        \\\\\\\\n        repo_name = repo_name or repo_path.name\\\\\\\\n        print(f\\\\\\\\\\\\\\\"* Analyzing repository: {repo_name}\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"   Path: {repo_path}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        try:\\\\\\\\n            # Analyze repository structure\\\\\\\\n            print(\\\\\\\\\\\\\\\"   Parsing files and extracting structure...\\\\\\\\\\\\\\\")\\\\\\\\n            analysis = self.repository_analyzer.analyze_repository(str(repo_path))\\\\\\\\n            analysis['repo_name'] = repo_name\\\\\\\\n            \\\\\\\\n            # Save analysis\\\\\\\\n            analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\\\\\\\\\"{repo_name}_analysis.json\\\\\\\\\\\\\\\"\\\\\\\\n            self.repository_analyzer.save_analysis(analysis, str(analysis_path))\\\\\\\\n            print(f\\\\\\\\\\\\\\\"   Analysis saved to: {analysis_path}\\\\\\\\\\\\\\\")\\\\\\\\n            \\\\\\\\n            # Add to vector store\\\\\\\\n            print(\\\\\\\\\\\\\\\"   Adding to vector store...\\\\\\\\\\\\\\\")\\\\\\\\n            chunks_added = self.vector_store.add_repository(analysis)\\\\\\\\n            \\\\\\\\n            print(f\\\\\\\\\\\\\\\"OK Repository analysis complete!\\\\\\\\\\\\\\\")\\\\\\\\n            print(f\\\\\\\\\\\\\\\"   Files analyzed: {analysis['statistics']['total_files']}\\\\\\\\\\\\\\\")\\\\\\\\n            print(f\\\\\\\\\\\\\\\"   Code files: {analysis['statistics']['code_files']}\\\\\\\\\\\\\\\")\\\\\\\\n            print(f\\\\\\\\\\\\\\\"   Languages: {', '.join(analysis['statistics']['languages'].keys())}\\\\\\\\\\\\\\\")\\\\\\\\n            print(f\\\\\\\\\\\\\\\"   Chunks added to vector store: {chunks_added}\\\\\\\\\\\\\\\")\\\\\\\\n            \\\\\\\\n            return True\\\\\\\\n            \\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"X Error analyzing repository: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            return False\\\\\\\\n    \\\\\\\\n    def query_repository(self, query: str, repo_name: Optional[str] = None, stream: bool = True):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Query a repository using the RAG system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        print(f\\\\\\\\\\\\\\\"? Query: {query}\\\\\\\\\\\\\\\")\\\\\\\\n        if repo_name:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"   Repository: {repo_name}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        try:\\\\\\\\n            result = self.rag_system.query(query, repo_name=repo_name, stream=False)\\\\\\\\n            \\\\\\\\n            if result['context']:\\\\\\\\n                print(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n> Response:\\\\\\\\\\\\\\\")\\\\\\\\n                print(result['response'])\\\\\\\\n                \\\\\\\\n                if result['sources']:\\\\\\\\n                    print(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n* Sources:\\\\\\\\\\\\\\\")\\\\\\\\n                    for i, source in enumerate(result['sources'], 1):\\\\\\\\n                        print(f\\\\\\\\\\\\\\\"   {i}. {source.get('file_path', 'Unknown')}\\\\\\\\\\\\\\\")\\\\\\\\n                        if source.get('element_name'):\\\\\\\\n                            print(f\\\\\\\\\\\\\\\"      Element: {source['element_name']}\\\\\\\\\\\\\\\")\\\\\\\\n            else:\\\\\\\\n                print(\\\\\\\\\\\\\\\"X No relevant context found for your query.\\\\\\\\\\\\\\\")\\\\\\\\n                \\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"X Error processing query: {e}\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    def interactive_chat(self, repo_name: Optional[str] = None):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Start an interactive chat session.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        print(\\\\\\\\\\\\\\\"* Interactive Chat Mode\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"Type 'quit' or 'exit' to end the session\\\\\\\\\\\\\\\")\\\\\\\\n        if repo_name:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Querying repository: {repo_name}\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"-\\\\\\\\\\\\\\\" * 50)\\\\\\\\n        \\\\\\\\n        messages = []\\\\\\\\n        \\\\\\\\n        while True:\\\\\\\\n            try:\\\\\\\\n                user_input = input(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nYou: \\\\\\\\\\\\\\\").strip()\\\\\\\\n                \\\\\\\\n                if user_input.lower() in ['quit', 'exit', 'q']:\\\\\\\\n                    print(\\\\\\\\\\\\\\\"Goodbye!\\\\\\\\\\\\\\\")\\\\\\\\n                    break\\\\\\\\n                \\\\\\\\n                if not user_input:\\\\\\\\n                    continue\\\\\\\\n                \\\\\\\\n                messages.append({\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": user_input})\\\\\\\\n                \\\\\\\\n                print(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nAssistant: \\\\\\\\\\\\\\\", end=\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\", flush=True)\\\\\\\\n                response = self.rag_system.chat_with_repo(messages, repo_name)\\\\\\\\n                print(response)\\\\\\\\n                \\\\\\\\n                messages.append({\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"assistant\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": response})\\\\\\\\n                \\\\\\\\n            except KeyboardInterrupt:\\\\\\\\n                print(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nGoodbye!\\\\\\\\\\\\\\\")\\\\\\\\n                break\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nX Error: {e}\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    def generate_documentation(self, repo_name: str):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate documentation for a repository.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        print(f\\\\\\\\\\\\\\\"* Generating documentation for: {repo_name}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Load analysis\\\\\\\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\\\\\\\\\"{repo_name}_analysis.json\\\\\\\\\\\\\\\"\\\\\\\\n        if not analysis_path.exists():\\\\\\\\n            print(f\\\\\\\\\\\\\\\"X Repository {repo_name} not found. Please analyze it first.\\\\\\\\\\\\\\\")\\\\\\\\n            return False\\\\\\\\n        \\\\\\\\n        try:\\\\\\\\n            analysis = self.repository_analyzer.load_analysis(str(analysis_path))\\\\\\\\n            \\\\\\\\n            config = DocumentationConfig(\\\\\\\\n                include_overview=True,\\\\\\\\n                include_api_docs=True,\\\\\\\\n                include_examples=True,\\\\\\\\n                include_architecture=True\\\\\\\\n            )\\\\\\\\n            \\\\\\\\n            docs = self.documentation_builder.generate_full_documentation(analysis, config)\\\\\\\\n            \\\\\\\\n            print(f\\\\\\\\\\\\\\\"OK Documentation generated!\\\\\\\\\\\\\\\")\\\\\\\\n            print(f\\\\\\\\\\\\\\\"   Files created: {len(docs)}\\\\\\\\\\\\\\\")\\\\\\\\n            print(f\\\\\\\\\\\\\\\"   Output directory: {Path(settings.DOCS_DIRECTORY) / repo_name}\\\\\\\\\\\\\\\")\\\\\\\\n            \\\\\\\\n            for doc_name in docs.keys():\\\\\\\\n                print(f\\\\\\\\\\\\\\\"   - {doc_name}\\\\\\\\\\\\\\\")\\\\\\\\n            \\\\\\\\n            return True\\\\\\\\n            \\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"X Error generating documentation: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            return False\\\\\\\\n    \\\\\\\\n    def list_repositories(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"List all analyzed repositories.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        repos_dir = Path(settings.REPOS_DIRECTORY)\\\\\\\\n        \\\\\\\\n        if not repos_dir.exists():\\\\\\\\n            print(\\\\\\\\\\\\\\\"No repositories found.\\\\\\\\\\\\\\\")\\\\\\\\n            return\\\\\\\\n        \\\\\\\\n        analysis_files = list(repos_dir.glob(\\\\\\\\\\\\\\\"*_analysis.json\\\\\\\\\\\\\\\"))\\\\\\\\n        \\\\\\\\n        if not analysis_files:\\\\\\\\n            print(\\\\\\\\\\\\\\\"No repositories found.\\\\\\\\\\\\\\\")\\\\\\\\n            return\\\\\\\\n        \\\\\\\\n        print(\\\\\\\\\\\\\\\"* Analyzed Repositories:\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"-\\\\\\\\\\\\\\\" * 50)\\\\\\\\n        \\\\\\\\n        for analysis_file in analysis_files:\\\\\\\\n            try:\\\\\\\\n                analysis = self.repository_analyzer.load_analysis(str(analysis_file))\\\\\\\\n                repo_name = analysis.get('repo_name', analysis_file.stem.replace('_analysis', ''))\\\\\\\\n                stats = analysis.get('statistics', {})\\\\\\\\n                \\\\\\\\n                print(f\\\\\\\\\\\\\\\"+ {repo_name}\\\\\\\\\\\\\\\")\\\\\\\\n                print(f\\\\\\\\\\\\\\\"   Path: {analysis.get('repo_path', 'Unknown')}\\\\\\\\\\\\\\\")\\\\\\\\n                print(f\\\\\\\\\\\\\\\"   Files: {stats.get('total_files', 0)} total, {stats.get('code_files', 0)} code\\\\\\\\\\\\\\\")\\\\\\\\n                print(f\\\\\\\\\\\\\\\"   Languages: {', '.join(stats.get('languages', {}).keys())}\\\\\\\\\\\\\\\")\\\\\\\\n                print()\\\\\\\\n                \\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"X Error loading {analysis_file}: {e}\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    def show_stats(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Show system statistics.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        print(\\\\\\\\\\\\\\\"* System Statistics\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"-\\\\\\\\\\\\\\\" * 30)\\\\\\\\n        \\\\\\\\n        # Vector store stats\\\\\\\\n        vector_stats = self.vector_store.get_collection_stats()\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Documents in vector store: {vector_stats.get('total_documents', 0)}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Repository count\\\\\\\\n        repos_dir = Path(settings.REPOS_DIRECTORY)\\\\\\\\n        repo_count = len(list(repos_dir.glob(\\\\\\\\\\\\\\\"*_analysis.json\\\\\\\\\\\\\\\"))) if repos_dir.exists() else 0\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Analyzed repositories: {repo_count}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Generated docs count\\\\\\\\n        docs_dir = Path(settings.DOCS_DIRECTORY)\\\\\\\\n        doc_count = len(list(docs_dir.rglob(\\\\\\\\\\\\\\\"*.md\\\\\\\\\\\\\\\"))) if docs_dir.exists() else 0\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Generated documentation files: {doc_count}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Ollama status\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Ollama available: {'OK' if self.ollama_client.is_available() else 'X'}\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Current model: {settings.OLLAMA_MODEL}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\ndef main():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Main CLI interface.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    parser = argparse.ArgumentParser(description=\\\\\\\\\\\\\\\"Local DeepWiki - Chat with your code repositories\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    subparsers = parser.add_subparsers(dest='command', help='Available commands')\\\\\\\\n    \\\\\\\\n    # Check command\\\\\\\\n    subparsers.add_parser('check', help='Check system prerequisites')\\\\\\\\n    \\\\\\\\n    # Analyze command\\\\\\\\n    analyze_parser = subparsers.add_parser('analyze', help='Analyze a repository')\\\\\\\\n    analyze_parser.add_argument('repo_path', help='Path to the repository')\\\\\\\\n    analyze_parser.add_argument('--name', help='Custom name for the repository')\\\\\\\\n    \\\\\\\\n    # Query command\\\\\\\\n    query_parser = subparsers.add_parser('query', help='Query a repository')\\\\\\\\n    query_parser.add_argument('query', help='Your question or query')\\\\\\\\n    query_parser.add_argument('--repo', help='Repository name to query')\\\\\\\\n    \\\\\\\\n    # Chat command\\\\\\\\n    chat_parser = subparsers.add_parser('chat', help='Start interactive chat')\\\\\\\\n    chat_parser.add_argument('--repo', help='Repository name to chat with')\\\\\\\\n    \\\\\\\\n    # Docs command\\\\\\\\n    docs_parser = subparsers.add_parser('docs', help='Generate documentation')\\\\\\\\n    docs_parser.add_argument('repo_name', help='Repository name')\\\\\\\\n    \\\\\\\\n    # List command\\\\\\\\n    subparsers.add_parser('list', help='List analyzed repositories')\\\\\\\\n    \\\\\\\\n    # Stats command\\\\\\\\n    subparsers.add_parser('stats', help='Show system statistics')\\\\\\\\n    \\\\\\\\n    # Server command\\\\\\\\n    server_parser = subparsers.add_parser('server', help='Start web server')\\\\\\\\n    server_parser.add_argument('--host', default=settings.API_HOST, help='Host address')\\\\\\\\n    server_parser.add_argument('--port', type=int, default=settings.API_PORT, help='Port number')\\\\\\\\n    \\\\\\\\n    args = parser.parse_args()\\\\\\\\n    \\\\\\\\n    if not args.command:\\\\\\\\n        parser.print_help()\\\\\\\\n        return\\\\\\\\n    \\\\\\\\n    # Initialize LocalDeepWiki\\\\\\\\n    ldw = LocalDeepWiki()\\\\\\\\n    \\\\\\\\n    if args.command == 'check':\\\\\\\\n        if ldw.check_prerequisites():\\\\\\\\n            print(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nOK All prerequisites are met! You're ready to use Local DeepWiki.\\\\\\\\\\\\\\\")\\\\\\\\n        else:\\\\\\\\n            print(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nX Please fix the issues above before using Local DeepWiki.\\\\\\\\\\\\\\\")\\\\\\\\n            sys.exit(1)\\\\\\\\n    \\\\\\\\n    elif args.command == 'analyze':\\\\\\\\n        if not ldw.check_prerequisites():\\\\\\\\n            sys.exit(1)\\\\\\\\n        ldw.analyze_repository(args.repo_path, args.name)\\\\\\\\n    \\\\\\\\n    elif args.command == 'query':\\\\\\\\n        if not ldw.check_prerequisites():\\\\\\\\n            sys.exit(1)\\\\\\\\n        ldw.query_repository(args.query, args.repo)\\\\\\\\n    \\\\\\\\n    elif args.command == 'chat':\\\\\\\\n        if not ldw.check_prerequisites():\\\\\\\\n            sys.exit(1)\\\\\\\\n        ldw.interactive_chat(args.repo)\\\\\\\\n    \\\\\\\\n    elif args.command == 'docs':\\\\\\\\n        if not ldw.check_prerequisites():\\\\\\\\n            sys.exit(1)\\\\\\\\n        ldw.generate_documentation(args.repo_name)\\\\\\\\n    \\\\\\\\n    elif args.command == 'list':\\\\\\\\n        ldw.list_repositories()\\\\\\\\n    \\\\\\\\n    elif args.command == 'stats':\\\\\\\\n        ldw.show_stats()\\\\\\\\n    \\\\\\\\n    elif args.command == 'server':\\\\\\\\n        if not ldw.check_prerequisites():\\\\\\\\n            sys.exit(1)\\\\\\\\n        \\\\\\\\n        # Import and run the API server\\\\\\\\n        from api import main as run_server\\\\\\\\n        run_server()\\\\\\\\n\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n    main()\\\\\\\\n\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n      \\\\\\\"file_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n      \\\\\\\"language\\\\\\\": \\\\\\\"python\\\\\\\",\\\\n      \\\\\\\"imports\\\\\\\": [\\\\n        \\\\\\\"json\\\\\\\",\\\\n        \\\\\\\"requests\\\\\\\",\\\\n        \\\\\\\"asyncio\\\\\\\",\\\\n        \\\\\\\"aiohttp\\\\\\\",\\\\n        \\\\\\\"typing.Dict\\\\\\\",\\\\n        \\\\\\\"typing.List\\\\\\\",\\\\n        \\\\\\\"typing.Any\\\\\\\",\\\\n        \\\\\\\"typing.Optional\\\\\\\",\\\\n        \\\\\\\"typing.AsyncGenerator\\\\\\\",\\\\n        \\\\\\\"config.settings\\\\\\\"\\\\n      ],\\\\n      \\\\\\\"elements\\\\\\\": [\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"OllamaClient\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 10,\\\\n          \\\\\\\"line_end\\\\\\\": 231,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Client for interacting with Ollama local LLM server.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class OllamaClient\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"OllamaClient.__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 13,\\\\n          \\\\\\\"line_end\\\\\\\": 16,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self, base_url, model)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"OllamaClient.is_available\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 18,\\\\n          \\\\\\\"line_end\\\\\\\": 24,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Check if Ollama server is available.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def is_available(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"OllamaClient.list_models\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 26,\\\\n          \\\\\\\"line_end\\\\\\\": 34,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"List available models.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def list_models(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"OllamaClient.pull_model\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 36,\\\\n          \\\\\\\"line_end\\\\\\\": 57,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Pull a model if not already available.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def pull_model(self, model_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"OllamaClient.generate\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 59,\\\\n          \\\\\\\"line_end\\\\\\\": 80,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate text using Ollama.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate(self, prompt, model)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"OllamaClient.get_embeddings\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 141,\\\\n          \\\\\\\"line_end\\\\\\\": 160,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Get embeddings for text.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def get_embeddings(self, text, model)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"OllamaClient.chat\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 185,\\\\n          \\\\\\\"line_end\\\\\\\": 206,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Chat completion using Ollama.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def chat(self, messages, model)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationGenerator\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 233,\\\\n          \\\\\\\"line_end\\\\\\\": 352,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate documentation using Ollama.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class DocumentationGenerator\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationGenerator.__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 236,\\\\n          \\\\\\\"line_end\\\\\\\": 237,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self, ollama_client)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationGenerator.generate_file_documentation\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 239,\\\\n          \\\\\\\"line_end\\\\\\\": 295,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate documentation for a single file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_file_documentation(self, file_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"DocumentationGenerator.generate_repository_overview\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 297,\\\\n          \\\\\\\"line_end\\\\\\\": 352,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate high-level repository documentation.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_repository_overview(self, repo_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 13,\\\\n          \\\\\\\"line_end\\\\\\\": 16,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self, base_url, model)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"is_available\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 18,\\\\n          \\\\\\\"line_end\\\\\\\": 24,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Check if Ollama server is available.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def is_available(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"list_models\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 26,\\\\n          \\\\\\\"line_end\\\\\\\": 34,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"List available models.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def list_models(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"pull_model\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 36,\\\\n          \\\\\\\"line_end\\\\\\\": 57,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Pull a model if not already available.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def pull_model(self, model_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"generate\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 59,\\\\n          \\\\\\\"line_end\\\\\\\": 80,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate text using Ollama.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate(self, prompt, model)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"get_embeddings\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 141,\\\\n          \\\\\\\"line_end\\\\\\\": 160,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Get embeddings for text.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def get_embeddings(self, text, model)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 185,\\\\n          \\\\\\\"line_end\\\\\\\": 206,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Chat completion using Ollama.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def chat(self, messages, model)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 236,\\\\n          \\\\\\\"line_end\\\\\\\": 237,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self, ollama_client)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"generate_file_documentation\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 239,\\\\n          \\\\\\\"line_end\\\\\\\": 295,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate documentation for a single file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_file_documentation(self, file_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"generate_repository_overview\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 297,\\\\n          \\\\\\\"line_end\\\\\\\": 352,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate high-level repository documentation.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_repository_overview(self, repo_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        }\\\\n      ],\\\\n      \\\\\\\"summary\\\\\\\": null,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Ollama client for local LLM inference.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport json\\\\\\\\nimport requests\\\\\\\\nimport asyncio\\\\\\\\nimport aiohttp\\\\\\\\nfrom typing import Dict, List, Any, Optional, AsyncGenerator\\\\\\\\nfrom config import settings\\\\\\\\n\\\\\\\\nclass OllamaClient:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Client for interacting with Ollama local LLM server.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def __init__(self, base_url: str = None, model: str = None):\\\\\\\\n        self.base_url = base_url or settings.OLLAMA_BASE_URL\\\\\\\\n        self.model = model or settings.OLLAMA_MODEL\\\\\\\\n        self.embedding_model = settings.OLLAMA_EMBEDDING_MODEL\\\\\\\\n        \\\\\\\\n    def is_available(self) -> bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if Ollama server is available.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            response = requests.get(f\\\\\\\\\\\\\\\"{self.base_url}/api/tags\\\\\\\\\\\\\\\", timeout=5)\\\\\\\\n            return response.status_code == 200\\\\\\\\n        except:\\\\\\\\n            return False\\\\\\\\n    \\\\\\\\n    def list_models(self) -> List[Dict[str, Any]]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"List available models.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            response = requests.get(f\\\\\\\\\\\\\\\"{self.base_url}/api/tags\\\\\\\\\\\\\\\")\\\\\\\\n            response.raise_for_status()\\\\\\\\n            return response.json().get('models', [])\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error listing models: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            return []\\\\\\\\n    \\\\\\\\n    def pull_model(self, model_name: str) -> bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Pull a model if not already available.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            response = requests.post(\\\\\\\\n                f\\\\\\\\\\\\\\\"{self.base_url}/api/pull\\\\\\\\\\\\\\\",\\\\\\\\n                json={\\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": model_name},\\\\\\\\n                stream=True\\\\\\\\n            )\\\\\\\\n            \\\\\\\\n            for line in response.iter_lines():\\\\\\\\n                if line:\\\\\\\\n                    data = json.loads(line)\\\\\\\\n                    if data.get('status'):\\\\\\\\n                        print(f\\\\\\\\\\\\\\\"Pulling {model_name}: {data['status']}\\\\\\\\\\\\\\\")\\\\\\\\n                    if data.get('error'):\\\\\\\\n                        print(f\\\\\\\\\\\\\\\"Error: {data['error']}\\\\\\\\\\\\\\\")\\\\\\\\n                        return False\\\\\\\\n            \\\\\\\\n            return True\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error pulling model {model_name}: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            return False\\\\\\\\n    \\\\\\\\n    def generate(self, prompt: str, model: str = None, **kwargs) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate text using Ollama.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        model = model or self.model\\\\\\\\n        \\\\\\\\n        payload = {\\\\\\\\n            \\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\": model,\\\\\\\\n            \\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\": prompt,\\\\\\\\n            \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\": False,\\\\\\\\n            **kwargs\\\\\\\\n        }\\\\\\\\n        \\\\\\\\n        try:\\\\\\\\n            response = requests.post(\\\\\\\\n                f\\\\\\\\\\\\\\\"{self.base_url}/api/generate\\\\\\\\\\\\\\\",\\\\\\\\n                json=payload,\\\\\\\\n                timeout=120\\\\\\\\n            )\\\\\\\\n            response.raise_for_status()\\\\\\\\n            return response.json()['response']\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error generating text: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            raise\\\\\\\\n    \\\\\\\\n    async def generate_async(self, prompt: str, model: str = None, **kwargs) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate text asynchronously.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        model = model or self.model\\\\\\\\n        \\\\\\\\n        payload = {\\\\\\\\n            \\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\": model,\\\\\\\\n            \\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\": prompt,\\\\\\\\n            \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\": False,\\\\\\\\n            **kwargs\\\\\\\\n        }\\\\\\\\n        \\\\\\\\n        async with aiohttp.ClientSession() as session:\\\\\\\\n            try:\\\\\\\\n                async with session.post(\\\\\\\\n                    f\\\\\\\\\\\\\\\"{self.base_url}/api/generate\\\\\\\\\\\\\\\",\\\\\\\\n                    json=payload,\\\\\\\\n                    timeout=aiohttp.ClientTimeout(total=120)\\\\\\\\n                ) as response:\\\\\\\\n                    response.raise_for_status()\\\\\\\\n                    result = await response.json()\\\\\\\\n                    return result['response']\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Error generating text: {e}\\\\\\\\\\\\\\\")\\\\\\\\n                raise\\\\\\\\n    \\\\\\\\n    async def generate_stream(self, prompt: str, model: str = None, **kwargs) -> AsyncGenerator[str, None]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate text with streaming response.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        model = model or self.model\\\\\\\\n        \\\\\\\\n        payload = {\\\\\\\\n            \\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\": model,\\\\\\\\n            \\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\": prompt,\\\\\\\\n            \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\": True,\\\\\\\\n            **kwargs\\\\\\\\n        }\\\\\\\\n        \\\\\\\\n        async with aiohttp.ClientSession() as session:\\\\\\\\n            try:\\\\\\\\n                async with session.post(\\\\\\\\n                    f\\\\\\\\\\\\\\\"{self.base_url}/api/generate\\\\\\\\\\\\\\\",\\\\\\\\n                    json=payload,\\\\\\\\n                    timeout=aiohttp.ClientTimeout(total=None)\\\\\\\\n                ) as response:\\\\\\\\n                    response.raise_for_status()\\\\\\\\n                    \\\\\\\\n                    async for line in response.content:\\\\\\\\n                        if line:\\\\\\\\n                            try:\\\\\\\\n                                data = json.loads(line)\\\\\\\\n                                if 'response' in data:\\\\\\\\n                                    yield data['response']\\\\\\\\n                                if data.get('done', False):\\\\\\\\n                                    break\\\\\\\\n                            except json.JSONDecodeError:\\\\\\\\n                                continue\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Error in streaming generation: {e}\\\\\\\\\\\\\\\")\\\\\\\\n                raise\\\\\\\\n    \\\\\\\\n    def get_embeddings(self, text: str, model: str = None) -> List[float]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get embeddings for text.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        model = model or self.embedding_model\\\\\\\\n        \\\\\\\\n        payload = {\\\\\\\\n            \\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\": model,\\\\\\\\n            \\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\": text\\\\\\\\n        }\\\\\\\\n        \\\\\\\\n        try:\\\\\\\\n            response = requests.post(\\\\\\\\n                f\\\\\\\\\\\\\\\"{self.base_url}/api/embeddings\\\\\\\\\\\\\\\",\\\\\\\\n                json=payload,\\\\\\\\n                timeout=60\\\\\\\\n            )\\\\\\\\n            response.raise_for_status()\\\\\\\\n            return response.json()['embedding']\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error getting embeddings: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            raise\\\\\\\\n    \\\\\\\\n    async def get_embeddings_async(self, text: str, model: str = None) -> List[float]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get embeddings asynchronously.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        model = model or self.embedding_model\\\\\\\\n        \\\\\\\\n        payload = {\\\\\\\\n            \\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\": model,\\\\\\\\n            \\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\": text\\\\\\\\n        }\\\\\\\\n        \\\\\\\\n        async with aiohttp.ClientSession() as session:\\\\\\\\n            try:\\\\\\\\n                async with session.post(\\\\\\\\n                    f\\\\\\\\\\\\\\\"{self.base_url}/api/embeddings\\\\\\\\\\\\\\\",\\\\\\\\n                    json=payload,\\\\\\\\n                    timeout=aiohttp.ClientTimeout(total=60)\\\\\\\\n                ) as response:\\\\\\\\n                    response.raise_for_status()\\\\\\\\n                    result = await response.json()\\\\\\\\n                    return result['embedding']\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Error getting embeddings: {e}\\\\\\\\\\\\\\\")\\\\\\\\n                raise\\\\\\\\n    \\\\\\\\n    def chat(self, messages: List[Dict[str, str]], model: str = None, **kwargs) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Chat completion using Ollama.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        model = model or self.model\\\\\\\\n        \\\\\\\\n        payload = {\\\\\\\\n            \\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\": model,\\\\\\\\n            \\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\": messages,\\\\\\\\n            \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\": False,\\\\\\\\n            **kwargs\\\\\\\\n        }\\\\\\\\n        \\\\\\\\n        try:\\\\\\\\n            response = requests.post(\\\\\\\\n                f\\\\\\\\\\\\\\\"{self.base_url}/api/chat\\\\\\\\\\\\\\\",\\\\\\\\n                json=payload,\\\\\\\\n                timeout=120\\\\\\\\n            )\\\\\\\\n            response.raise_for_status()\\\\\\\\n            return response.json()['message']['content']\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error in chat completion: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            raise\\\\\\\\n    \\\\\\\\n    async def chat_async(self, messages: List[Dict[str, str]], model: str = None, **kwargs) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Chat completion asynchronously.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        model = model or self.model\\\\\\\\n        \\\\\\\\n        payload = {\\\\\\\\n            \\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\": model,\\\\\\\\n            \\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\": messages,\\\\\\\\n            \\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\": False,\\\\\\\\n            **kwargs\\\\\\\\n        }\\\\\\\\n        \\\\\\\\n        async with aiohttp.ClientSession() as session:\\\\\\\\n            try:\\\\\\\\n                async with session.post(\\\\\\\\n                    f\\\\\\\\\\\\\\\"{self.base_url}/api/chat\\\\\\\\\\\\\\\",\\\\\\\\n                    json=payload,\\\\\\\\n                    timeout=aiohttp.ClientTimeout(total=120)\\\\\\\\n                ) as response:\\\\\\\\n                    response.raise_for_status()\\\\\\\\n                    result = await response.json()\\\\\\\\n                    return result['message']['content']\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Error in chat completion: {e}\\\\\\\\\\\\\\\")\\\\\\\\n                raise\\\\\\\\n\\\\\\\\nclass DocumentationGenerator:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate documentation using Ollama.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def __init__(self, ollama_client: OllamaClient):\\\\\\\\n        self.client = ollama_client\\\\\\\\n    \\\\\\\\n    def generate_file_documentation(self, file_analysis: Dict[str, Any]) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate documentation for a single file.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        # Build context from file analysis\\\\\\\\n        context = []\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"File: {file_analysis['file_path']}\\\\\\\\\\\\\\\")\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Language: {file_analysis.get('language', 'Unknown')}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        if file_analysis.get('imports'):\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\"Imports: {', '.join(file_analysis['imports'][:10])}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Add code elements\\\\\\\\n        elements_summary = []\\\\\\\\n        for element in file_analysis.get('elements', []):\\\\\\\\n            elem_type = element['type']\\\\\\\\n            name = element['name']\\\\\\\\n            signature = element.get('signature', '')\\\\\\\\n            docstring = element.get('docstring', '')\\\\\\\\n            \\\\\\\\n            elem_desc = f\\\\\\\\\\\\\\\"{elem_type}: {name}\\\\\\\\\\\\\\\"\\\\\\\\n            if signature:\\\\\\\\n                elem_desc += f\\\\\\\\\\\\\\\" - {signature}\\\\\\\\\\\\\\\"\\\\\\\\n            if docstring:\\\\\\\\n                elem_desc += f\\\\\\\\\\\\\\\" - {docstring[:100]}...\\\\\\\\\\\\\\\"\\\\\\\\n            \\\\\\\\n            elements_summary.append(elem_desc)\\\\\\\\n        \\\\\\\\n        if elements_summary:\\\\\\\\n            context.append(\\\\\\\\\\\\\\\"Code Elements:\\\\\\\\\\\\\\\")\\\\\\\\n            context.extend(elements_summary[:15])  # Limit to prevent prompt overflow\\\\\\\\n        \\\\\\\\n        # Add file content preview\\\\\\\\n        content = file_analysis.get('content', '')\\\\\\\\n        if content:\\\\\\\\n            content_preview = content[:2000] + \\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\" if len(content) > 2000 else content\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\"Content Preview:\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n{content_preview}\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        context_str = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\".join(context)\\\\\\\\n        \\\\\\\\n        prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyze the following code file and generate comprehensive documentation in Markdown format.\\\\\\\\n\\\\\\\\n{context_str}\\\\\\\\n\\\\\\\\nPlease provide:\\\\\\\\n1. A brief overview of what this file does\\\\\\\\n2. Main components and their purposes\\\\\\\\n3. Key functions/classes with descriptions\\\\\\\\n4. Usage examples if applicable\\\\\\\\n5. Dependencies and relationships\\\\\\\\n\\\\\\\\nFormat the output as clean Markdown with appropriate headers and code blocks.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            return self.client.generate(prompt, temperature=0.3, max_tokens=2000)\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error generating documentation for {file_analysis['file_path']}: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            return f\\\\\\\\\\\\\\\"# {file_analysis['file_path']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nError generating documentation: {str(e)}\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def generate_repository_overview(self, repo_analysis: Dict[str, Any]) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate high-level repository documentation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        stats = repo_analysis.get('statistics', {})\\\\\\\\n        structure = repo_analysis.get('structure', {})\\\\\\\\n        \\\\\\\\n        context = []\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Repository: {repo_analysis.get('repo_name', 'Unknown')}\\\\\\\\\\\\\\\")\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Total Files: {stats.get('total_files', 0)}\\\\\\\\\\\\\\\")\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Code Files: {stats.get('code_files', 0)}\\\\\\\\\\\\\\\")\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Documentation Files: {stats.get('doc_files', 0)}\\\\\\\\\\\\\\\")\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\"Total Lines: {stats.get('total_lines', 0)}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        if stats.get('languages'):\\\\\\\\n            langs = list(stats['languages'].keys())\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\"Languages: {', '.join(langs)}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Add git info if available\\\\\\\\n        git_info = repo_analysis.get('git_info')\\\\\\\\n        if git_info:\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\"Current Branch: {git_info.get('current_branch', 'Unknown')}\\\\\\\\\\\\\\\")\\\\\\\\n            if git_info.get('last_commit'):\\\\\\\\n                commit = git_info['last_commit']\\\\\\\\n                context.append(f\\\\\\\\\\\\\\\"Last Commit: {commit.get('message', '')[:100]}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Add main files/directories\\\\\\\\n        main_files = []\\\\\\\\n        for file_data in repo_analysis.get('files', [])[:10]:\\\\\\\\n            if file_data.get('file_type') == 'documentation':\\\\\\\\n                main_files.append(file_data['file_path'])\\\\\\\\n        \\\\\\\\n        if main_files:\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\"Key Documentation: {', '.join(main_files)}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        context_str = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\".join(context)\\\\\\\\n        \\\\\\\\n        prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyze this code repository and generate a comprehensive overview documentation in Markdown format.\\\\\\\\n\\\\\\\\nRepository Information:\\\\\\\\n{context_str}\\\\\\\\n\\\\\\\\nPlease provide:\\\\\\\\n1. Project overview and purpose\\\\\\\\n2. Architecture and structure\\\\\\\\n3. Key components and modules\\\\\\\\n4. Getting started guide\\\\\\\\n5. Development setup instructions\\\\\\\\n6. Main features and capabilities\\\\\\\\n\\\\\\\\nFormat as professional README-style documentation with proper Markdown structure.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            return self.client.generate(prompt, temperature=0.3, max_tokens=3000)\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error generating repository overview: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            return f\\\\\\\\\\\\\\\"# Repository Overview\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nError generating overview: {str(e)}\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n      \\\\\\\"file_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n      \\\\\\\"language\\\\\\\": \\\\\\\"python\\\\\\\",\\\\n      \\\\\\\"imports\\\\\\\": [\\\\n        \\\\\\\"json\\\\\\\",\\\\n        \\\\\\\"typing.List\\\\\\\",\\\\n        \\\\\\\"typing.Dict\\\\\\\",\\\\n        \\\\\\\"typing.Any\\\\\\\",\\\\n        \\\\\\\"typing.Optional\\\\\\\",\\\\n        \\\\\\\"typing.Tuple\\\\\\\",\\\\n        \\\\\\\"dataclasses.dataclass\\\\\\\",\\\\n        \\\\\\\"ollama_client.OllamaClient\\\\\\\",\\\\n        \\\\\\\"vector_store.VectorStore\\\\\\\"\\\\n      ],\\\\n      \\\\\\\"elements\\\\\\\": [\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGContext\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 10,\\\\n          \\\\\\\"line_end\\\\\\\": 15,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Context information for RAG system.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class RAGContext\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 17,\\\\n          \\\\\\\"line_end\\\\\\\": 329,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Retrieval-Augmented Generation system.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class RAGSystem\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem.__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 20,\\\\n          \\\\\\\"line_end\\\\\\\": 62,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self, vector_store, ollama_client)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem.determine_query_type\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 64,\\\\n          \\\\\\\"line_end\\\\\\\": 75,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Determine the type of query to select appropriate prompt.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def determine_query_type(self, query)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem.retrieve_context\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 77,\\\\n          \\\\\\\"line_end\\\\\\\": 79,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Retrieve relevant context for the query.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def retrieve_context(self, query, n_results, filter_metadata)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem.build_context_text\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 81,\\\\n          \\\\\\\"line_end\\\\\\\": 110,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Build context text from retrieved chunks.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def build_context_text(self, retrieved_chunks, max_context_length)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem.generate_response\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 112,\\\\n          \\\\\\\"line_end\\\\\\\": 133,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate response using RAG context.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_response(self, query, context, stream)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem.query\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 135,\\\\n          \\\\\\\"line_end\\\\\\\": 191,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Main query interface for RAG system.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def query(self, query, repo_name, file_path, n_results, stream)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem.explain_code\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 193,\\\\n          \\\\\\\"line_end\\\\\\\": 214,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Explain a specific code snippet.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def explain_code(self, code, language, context)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem.suggest_improvements\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 216,\\\\n          \\\\\\\"line_end\\\\\\\": 237,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Suggest improvements for code.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def suggest_improvements(self, code, language)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem.search_similar_code\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 239,\\\\n          \\\\\\\"line_end\\\\\\\": 248,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Find similar code in the repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def search_similar_code(self, code_snippet, language, n_results)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem.get_file_summary\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 250,\\\\n          \\\\\\\"line_end\\\\\\\": 282,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Get a summary of a specific file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def get_file_summary(self, file_path, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem.get_repository_overview\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 284,\\\\n          \\\\\\\"line_end\\\\\\\": 295,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Get an overview of the repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def get_repository_overview(self, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RAGSystem.chat_with_repo\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 297,\\\\n          \\\\\\\"line_end\\\\\\\": 329,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Chat interface for conversational interaction with repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def chat_with_repo(self, messages, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 20,\\\\n          \\\\\\\"line_end\\\\\\\": 62,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self, vector_store, ollama_client)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"determine_query_type\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 64,\\\\n          \\\\\\\"line_end\\\\\\\": 75,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Determine the type of query to select appropriate prompt.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def determine_query_type(self, query)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"retrieve_context\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 77,\\\\n          \\\\\\\"line_end\\\\\\\": 79,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Retrieve relevant context for the query.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def retrieve_context(self, query, n_results, filter_metadata)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"build_context_text\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 81,\\\\n          \\\\\\\"line_end\\\\\\\": 110,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Build context text from retrieved chunks.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def build_context_text(self, retrieved_chunks, max_context_length)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"generate_response\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 112,\\\\n          \\\\\\\"line_end\\\\\\\": 133,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Generate response using RAG context.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def generate_response(self, query, context, stream)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"query\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 135,\\\\n          \\\\\\\"line_end\\\\\\\": 191,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Main query interface for RAG system.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def query(self, query, repo_name, file_path, n_results, stream)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"explain_code\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 193,\\\\n          \\\\\\\"line_end\\\\\\\": 214,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Explain a specific code snippet.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def explain_code(self, code, language, context)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"suggest_improvements\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 216,\\\\n          \\\\\\\"line_end\\\\\\\": 237,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Suggest improvements for code.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def suggest_improvements(self, code, language)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"search_similar_code\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 239,\\\\n          \\\\\\\"line_end\\\\\\\": 248,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Find similar code in the repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def search_similar_code(self, code_snippet, language, n_results)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"get_file_summary\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 250,\\\\n          \\\\\\\"line_end\\\\\\\": 282,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Get a summary of a specific file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def get_file_summary(self, file_path, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"get_repository_overview\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 284,\\\\n          \\\\\\\"line_end\\\\\\\": 295,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Get an overview of the repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def get_repository_overview(self, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"chat_with_repo\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\rag_system.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 297,\\\\n          \\\\\\\"line_end\\\\\\\": 329,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Chat interface for conversational interaction with repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def chat_with_repo(self, messages, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        }\\\\n      ],\\\\n      \\\\\\\"summary\\\\\\\": null,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"RAG (Retrieval-Augmented Generation) system for context-aware responses.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport json\\\\\\\\nfrom typing import List, Dict, Any, Optional, Tuple\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\nfrom ollama_client import OllamaClient\\\\\\\\nfrom vector_store import VectorStore\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass RAGContext:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Context information for RAG system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    query: str\\\\\\\\n    retrieved_chunks: List[Dict[str, Any]]\\\\\\\\n    context_text: str\\\\\\\\n    metadata: Dict[str, Any]\\\\\\\\n\\\\\\\\nclass RAGSystem:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Retrieval-Augmented Generation system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def __init__(self, vector_store: VectorStore, ollama_client: OllamaClient):\\\\\\\\n        self.vector_store = vector_store\\\\\\\\n        self.ollama_client = ollama_client\\\\\\\\n        \\\\\\\\n        # System prompts for different types of queries\\\\\\\\n        self.system_prompts = {\\\\\\\\n            'code_explanation': \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"You are an expert code analyst. Your task is to explain code clearly and concisely based on the provided context. \\\\\\\\n\\\\\\\\nFocus on:\\\\\\\\n- What the code does\\\\\\\\n- How it works\\\\\\\\n- Key components and their relationships\\\\\\\\n- Usage examples when relevant\\\\\\\\n- Best practices and potential improvements\\\\\\\\n\\\\\\\\nBe accurate and reference the specific code provided in the context.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\",\\\\\\\\n\\\\\\\\n            'general_question': \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"You are a helpful assistant that answers questions about codebases and documentation. \\\\\\\\n\\\\\\\\nUse the provided context to give accurate, helpful answers. If the context doesn't contain enough information to answer fully, say so and provide what information you can from the context.\\\\\\\\n\\\\\\\\nBe concise but thorough, and always ground your answers in the provided context.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\",\\\\\\\\n\\\\\\\\n            'documentation': \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"You are a technical documentation expert. Generate clear, well-structured documentation based on the provided code and context.\\\\\\\\n\\\\\\\\nFocus on:\\\\\\\\n- Clear explanations of functionality\\\\\\\\n- Proper formatting with headers and code blocks\\\\\\\\n- Usage examples and best practices\\\\\\\\n- Integration with other parts of the system\\\\\\\\n\\\\\\\\nUse proper Markdown formatting.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\",\\\\\\\\n\\\\\\\\n            'troubleshooting': \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"You are a debugging expert. Help identify issues, suggest solutions, and provide troubleshooting guidance based on the code context.\\\\\\\\n\\\\\\\\nFocus on:\\\\\\\\n- Identifying potential problems\\\\\\\\n- Suggesting specific solutions\\\\\\\\n- Explaining the reasoning behind recommendations\\\\\\\\n- Providing preventive measures\\\\\\\\n\\\\\\\\nBe practical and actionable in your suggestions.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        }\\\\\\\\n    \\\\\\\\n    def determine_query_type(self, query: str) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Determine the type of query to select appropriate prompt.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        query_lower = query.lower()\\\\\\\\n        \\\\\\\\n        if any(word in query_lower for word in ['how does', 'what does', 'explain', 'how to']):\\\\\\\\n            return 'code_explanation'\\\\\\\\n        elif any(word in query_lower for word in ['document', 'generate docs', 'create documentation']):\\\\\\\\n            return 'documentation'\\\\\\\\n        elif any(word in query_lower for word in ['error', 'bug', 'fix', 'problem', 'issue', 'debug']):\\\\\\\\n            return 'troubleshooting'\\\\\\\\n        else:\\\\\\\\n            return 'general_question'\\\\\\\\n    \\\\\\\\n    def retrieve_context(self, query: str, n_results: int = 5, filter_metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Retrieve relevant context for the query.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return self.vector_store.search(query, n_results, filter_metadata)\\\\\\\\n    \\\\\\\\n    def build_context_text(self, retrieved_chunks: List[Dict[str, Any]], max_context_length: int = 4000) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Build context text from retrieved chunks.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        context_parts = []\\\\\\\\n        current_length = 0\\\\\\\\n        \\\\\\\\n        for chunk in retrieved_chunks:\\\\\\\\n            text = chunk['text']\\\\\\\\n            metadata = chunk.get('metadata', {})\\\\\\\\n            \\\\\\\\n            # Add metadata header for context\\\\\\\\n            header = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n            if metadata.get('file_path'):\\\\\\\\n                header += f\\\\\\\\\\\\\\\"File: {metadata['file_path']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            if metadata.get('element_name'):\\\\\\\\n                header += f\\\\\\\\\\\\\\\"Element: {metadata['element_name']} ({metadata.get('element_type', 'unknown')})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            if metadata.get('type'):\\\\\\\\n                header += f\\\\\\\\\\\\\\\"Type: {metadata['type']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            \\\\\\\\n            chunk_text = header + \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\" + text + \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\" + \\\\\\\\\\\\\\\"=\\\\\\\\\\\\\\\"*50 + \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            \\\\\\\\n            # Check if adding this chunk would exceed max length\\\\\\\\n            if current_length + len(chunk_text) > max_context_length:\\\\\\\\n                if not context_parts:  # If first chunk is too long, truncate it\\\\\\\\n                    context_parts.append(chunk_text[:max_context_length])\\\\\\\\n                break\\\\\\\\n            \\\\\\\\n            context_parts.append(chunk_text)\\\\\\\\n            current_length += len(chunk_text)\\\\\\\\n        \\\\\\\\n        return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\".join(context_parts)\\\\\\\\n    \\\\\\\\n    def generate_response(self, query: str, context: RAGContext, stream: bool = False) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate response using RAG context.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        query_type = self.determine_query_type(query)\\\\\\\\n        system_prompt = self.system_prompts.get(query_type, self.system_prompts['general_question'])\\\\\\\\n        \\\\\\\\n        # Build the full prompt\\\\\\\\n        full_prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"{system_prompt}\\\\\\\\n\\\\\\\\nCONTEXT:\\\\\\\\n{context.context_text}\\\\\\\\n\\\\\\\\nUSER QUERY: {query}\\\\\\\\n\\\\\\\\nPlease provide a helpful response based on the context above. If the context doesn't contain sufficient information, clearly state what information is missing.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            if stream:\\\\\\\\n                return self.ollama_client.generate_stream(full_prompt, temperature=0.3)\\\\\\\\n            else:\\\\\\\\n                return self.ollama_client.generate(full_prompt, temperature=0.3)\\\\\\\\n        except Exception as e:\\\\\\\\n            return f\\\\\\\\\\\\\\\"Error generating response: {str(e)}\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def query(self, \\\\\\\\n              query: str, \\\\\\\\n              repo_name: str = None, \\\\\\\\n              file_path: str = None,\\\\\\\\n              n_results: int = 5,\\\\\\\\n              stream: bool = False) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Main query interface for RAG system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        # Build filter for specific repository or file\\\\\\\\n        filter_metadata = {}\\\\\\\\n        if repo_name:\\\\\\\\n            filter_metadata['repo_name'] = repo_name\\\\\\\\n        if file_path:\\\\\\\\n            filter_metadata['file_path'] = file_path\\\\\\\\n        \\\\\\\\n        # Retrieve relevant context\\\\\\\\n        retrieved_chunks = self.retrieve_context(query, n_results, filter_metadata or None)\\\\\\\\n        \\\\\\\\n        if not retrieved_chunks:\\\\\\\\n            return {\\\\\\\\n                'response': f\\\\\\\\\\\\\\\"No relevant context found for query: {query}\\\\\\\\\\\\\\\",\\\\\\\\n                'context': None,\\\\\\\\n                'sources': []\\\\\\\\n            }\\\\\\\\n        \\\\\\\\n        # Build context\\\\\\\\n        context_text = self.build_context_text(retrieved_chunks)\\\\\\\\n        context = RAGContext(\\\\\\\\n            query=query,\\\\\\\\n            retrieved_chunks=retrieved_chunks,\\\\\\\\n            context_text=context_text,\\\\\\\\n            metadata={'repo_name': repo_name, 'file_path': file_path}\\\\\\\\n        )\\\\\\\\n        \\\\\\\\n        # Generate response\\\\\\\\n        response = self.generate_response(query, context, stream)\\\\\\\\n        \\\\\\\\n        # Extract sources\\\\\\\\n        sources = []\\\\\\\\n        for chunk in retrieved_chunks:\\\\\\\\n            metadata = chunk.get('metadata', {})\\\\\\\\n            source = {\\\\\\\\n                'file_path': metadata.get('file_path'),\\\\\\\\n                'element_name': metadata.get('element_name'),\\\\\\\\n                'type': metadata.get('type'),\\\\\\\\n                'distance': chunk.get('distance', 0)\\\\\\\\n            }\\\\\\\\n            # Remove None values\\\\\\\\n            source = {k: v for k, v in source.items() if v is not None}\\\\\\\\n            if source and source not in sources:\\\\\\\\n                sources.append(source)\\\\\\\\n        \\\\\\\\n        return {\\\\\\\\n            'response': response,\\\\\\\\n            'context': context,\\\\\\\\n            'sources': sources[:5]  # Limit to top 5 sources\\\\\\\\n        }\\\\\\\\n    \\\\\\\\n    def explain_code(self, code: str, language: str = None, context: str = None) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Explain a specific code snippet.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Explain the following code clearly and concisely:\\\\\\\\n\\\\\\\\nLanguage: {language or 'Unknown'}\\\\\\\\n{f'Context: {context}' if context else ''}\\\\\\\\n\\\\\\\\nCode:\\\\\\\\n```{language or ''}\\\\\\\\n{code}\\\\\\\\n```\\\\\\\\n\\\\\\\\nPlease explain:\\\\\\\\n1. What this code does\\\\\\\\n2. How it works\\\\\\\\n3. Key components and their purpose\\\\\\\\n4. Any notable patterns or techniques used\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\n        except Exception as e:\\\\\\\\n            return f\\\\\\\\\\\\\\\"Error explaining code: {str(e)}\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def suggest_improvements(self, code: str, language: str = None) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Suggest improvements for code.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyze the following code and suggest improvements:\\\\\\\\n\\\\\\\\nLanguage: {language or 'Unknown'}\\\\\\\\n\\\\\\\\nCode:\\\\\\\\n```{language or ''}\\\\\\\\n{code}\\\\\\\\n```\\\\\\\\n\\\\\\\\nPlease provide:\\\\\\\\n1. Code quality assessment\\\\\\\\n2. Potential improvements\\\\\\\\n3. Best practices recommendations\\\\\\\\n4. Performance optimizations if applicable\\\\\\\\n5. Security considerations if relevant\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\n        except Exception as e:\\\\\\\\n            return f\\\\\\\\\\\\\\\"Error suggesting improvements: {str(e)}\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def search_similar_code(self, code_snippet: str, language: str = None, n_results: int = 3) -> List[Dict[str, Any]]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Find similar code in the repository.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Create a search query from the code\\\\\\\\n        query = f\\\\\\\\\\\\\\\"code similar to: {code_snippet[:200]}...\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        filter_metadata = {}\\\\\\\\n        if language:\\\\\\\\n            filter_metadata['language'] = language\\\\\\\\n        \\\\\\\\n        return self.retrieve_context(query, n_results, filter_metadata or None)\\\\\\\\n    \\\\\\\\n    def get_file_summary(self, file_path: str, repo_name: str = None) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get a summary of a specific file.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        filter_metadata = {'file_path': file_path}\\\\\\\\n        if repo_name:\\\\\\\\n            filter_metadata['repo_name'] = repo_name\\\\\\\\n        \\\\\\\\n        # Get file overview chunk\\\\\\\\n        chunks = self.vector_store.search(\\\\\\\\n            f\\\\\\\\\\\\\\\"file overview {file_path}\\\\\\\\\\\\\\\", \\\\\\\\n            n_results=1, \\\\\\\\n            filter_metadata=filter_metadata\\\\\\\\n        )\\\\\\\\n        \\\\\\\\n        if not chunks:\\\\\\\\n            return f\\\\\\\\\\\\\\\"No information found for file: {file_path}\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        chunk = chunks[0]\\\\\\\\n        context_text = chunk['text']\\\\\\\\n        \\\\\\\\n        prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Provide a concise summary of this file:\\\\\\\\n\\\\\\\\n{context_text}\\\\\\\\n\\\\\\\\nSummary should include:\\\\\\\\n- Purpose of the file\\\\\\\\n- Main components\\\\\\\\n- Key functionality\\\\\\\\n- Dependencies\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\n        except Exception as e:\\\\\\\\n            return f\\\\\\\\\\\\\\\"Error generating file summary: {str(e)}\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def get_repository_overview(self, repo_name: str) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get an overview of the repository.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        chunks = self.vector_store.search(\\\\\\\\n            f\\\\\\\\\\\\\\\"repository overview {repo_name}\\\\\\\\\\\\\\\",\\\\\\\\n            n_results=1,\\\\\\\\n            filter_metadata={'repo_name': repo_name, 'type': 'repository_overview'}\\\\\\\\n        )\\\\\\\\n        \\\\\\\\n        if not chunks:\\\\\\\\n            return f\\\\\\\\\\\\\\\"No overview found for repository: {repo_name}\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        return chunks[0]['text']\\\\\\\\n    \\\\\\\\n    def chat_with_repo(self, messages: List[Dict[str, str]], repo_name: str = None) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Chat interface for conversational interaction with repository.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not messages:\\\\\\\\n            return \\\\\\\\\\\\\\\"No messages provided\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        # Get the latest user message\\\\\\\\n        latest_message = messages[-1]['content']\\\\\\\\n        \\\\\\\\n        # Get context for the latest query\\\\\\\\n        result = self.query(latest_message, repo_name=repo_name, stream=False)\\\\\\\\n        \\\\\\\\n        # Build conversation context\\\\\\\\n        conversation_context = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\".join([\\\\\\\\n            f\\\\\\\\\\\\\\\"{msg['role']}: {msg['content']}\\\\\\\\\\\\\\\" \\\\\\\\n            for msg in messages[:-1]  # Exclude the latest message\\\\\\\\n        ])\\\\\\\\n        \\\\\\\\n        # Enhanced prompt with conversation history\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"You are having a conversation about a codebase. Here's the conversation history:\\\\\\\\n\\\\\\\\n{conversation_context}\\\\\\\\n\\\\\\\\nCurrent context from the codebase:\\\\\\\\n{result['context'].context_text if result['context'] else 'No relevant context found'}\\\\\\\\n\\\\\\\\nCurrent question: {latest_message}\\\\\\\\n\\\\\\\\nPlease provide a helpful response that considers both the conversation history and the current context.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.4)\\\\\\\\n        except Exception as e:\\\\\\\\n            return f\\\\\\\\\\\\\\\"Error in chat response: {str(e)}\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\README.md\\\\\\\",\\\\n      \\\\\\\"file_type\\\\\\\": \\\\\\\"documentation\\\\\\\",\\\\n      \\\\\\\"language\\\\\\\": null,\\\\n      \\\\\\\"imports\\\\\\\": [],\\\\n      \\\\\\\"elements\\\\\\\": [],\\\\n      \\\\\\\"summary\\\\\\\": null,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"# Local DeepWiki\\\\\\\\n\\\\\\\\nA local implementation of DeepWiki that allows you to chat with your code repositories using Ollama and local LLMs. This system provides repository analysis, documentation generation, and conversational AI capabilities - all running locally on your machine.\\\\\\\\n\\\\\\\\n## Features\\\\\\\\n\\\\\\\\n- ðŸ” **Repository Analysis**: Automatically parse and understand code structure\\\\\\\\n- ðŸ¤– **Local LLM Integration**: Uses Ollama for privacy-focused AI inference\\\\\\\\n- ðŸ“š **Documentation Generation**: Create comprehensive docs from your codebase\\\\\\\\n- ðŸ’¬ **Interactive Chat**: Ask questions about your code in natural language\\\\\\\\n- ðŸ”Ž **Semantic Search**: Find relevant code and documentation quickly\\\\\\\\n- ðŸŒ **Web Interface**: Clean, modern UI for easy interaction\\\\\\\\n- ðŸ“– **RAG System**: Context-aware responses grounded in your actual code\\\\\\\\n\\\\\\\\n## Prerequisites\\\\\\\\n\\\\\\\\n1. **Python 3.8+**\\\\\\\\n2. **Ollama** - Download from [ollama.ai](https://ollama.ai)\\\\\\\\n3. **Git** (optional, for repository information)\\\\\\\\n\\\\\\\\n## Installation\\\\\\\\n\\\\\\\\n1. **Clone this repository:**\\\\\\\\n```bash\\\\\\\\ngit clone <repository-url>\\\\\\\\ncd local_deepwiki\\\\\\\\n```\\\\\\\\n\\\\\\\\n2. **Install Python dependencies:**\\\\\\\\n```bash\\\\\\\\npip install -r requirements.txt\\\\\\\\n```\\\\\\\\n\\\\\\\\n3. **Install and start Ollama:**\\\\\\\\n```bash\\\\\\\\n# Install Ollama (see https://ollama.ai for platform-specific instructions)\\\\\\\\n\\\\\\\\n# Start Ollama server\\\\\\\\nollama serve\\\\\\\\n\\\\\\\\n# Pull required models (in another terminal)\\\\\\\\nollama pull llama2          # Main language model\\\\\\\\nollama pull nomic-embed-text  # Embedding model (optional)\\\\\\\\n```\\\\\\\\n\\\\\\\\n4. **Check prerequisites:**\\\\\\\\n```bash\\\\\\\\npython main.py check\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Quick Start\\\\\\\\n\\\\\\\\n### 1. Analyze a Repository\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Analyze your current directory\\\\\\\\npython main.py analyze .\\\\\\\\n\\\\\\\\n# Analyze a specific repository\\\\\\\\npython main.py analyze /path/to/your/repo --name my-project\\\\\\\\n\\\\\\\\n# Analyze with custom name\\\\\\\\npython main.py analyze ~/projects/my-app --name my-awesome-app\\\\\\\\n```\\\\\\\\n\\\\\\\\n### 2. Chat with Your Code\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Start interactive chat\\\\\\\\npython main.py chat\\\\\\\\n\\\\\\\\n# Chat with specific repository\\\\\\\\npython main.py chat --repo my-project\\\\\\\\n```\\\\\\\\n\\\\\\\\n### 3. Query Your Repository\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Ask a specific question\\\\\\\\npython main.py query \\\\\\\\\\\\\\\"How does user authentication work?\\\\\\\\\\\\\\\" --repo my-project\\\\\\\\n\\\\\\\\n# Query without specifying repository (searches all)\\\\\\\\npython main.py query \\\\\\\\\\\\\\\"Show me the main entry point\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\n### 4. Generate Documentation\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Generate comprehensive documentation\\\\\\\\npython main.py docs my-project\\\\\\\\n```\\\\\\\\n\\\\\\\\n### 5. Web Interface\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Start the web server\\\\\\\\npython main.py server\\\\\\\\n\\\\\\\\n# Or with custom host/port\\\\\\\\npython main.py server --host 127.0.0.1 --port 8080\\\\\\\\n```\\\\\\\\n\\\\\\\\nThen open http://localhost:8000 in your browser.\\\\\\\\n\\\\\\\\n## Configuration\\\\\\\\n\\\\\\\\nCreate a `.env` file to customize settings:\\\\\\\\n\\\\\\\\n```env\\\\\\\\n# Ollama Configuration\\\\\\\\nOLLAMA_BASE_URL=http://localhost:11434\\\\\\\\nOLLAMA_MODEL=llama2\\\\\\\\nOLLAMA_EMBEDDING_MODEL=nomic-embed-text\\\\\\\\n\\\\\\\\n# API Configuration\\\\\\\\nAPI_HOST=0.0.0.0\\\\\\\\nAPI_PORT=8000\\\\\\\\n\\\\\\\\n# Storage Configuration\\\\\\\\nCHROMA_PERSIST_DIRECTORY=./data/chroma_db\\\\\\\\nREPOS_DIRECTORY=./data/repos\\\\\\\\nDOCS_DIRECTORY=./data/generated_docs\\\\\\\\n\\\\\\\\n# Processing Configuration\\\\\\\\nMAX_CHUNK_SIZE=2000\\\\\\\\nCHUNK_OVERLAP=200\\\\\\\\nMAX_CONTEXT_LENGTH=4000\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Supported Languages\\\\\\\\n\\\\\\\\nThe system can analyze and understand code in:\\\\\\\\n\\\\\\\\n- Python (.py)\\\\\\\\n- JavaScript/TypeScript (.js, .ts, .jsx, .tsx)\\\\\\\\n- Java (.java)\\\\\\\\n- C/C++ (.c, .cpp, .h)\\\\\\\\n- C# (.cs)\\\\\\\\n- PHP (.php)\\\\\\\\n- Ruby (.rb)\\\\\\\\n- Go (.go)\\\\\\\\n- Rust (.rs)\\\\\\\\n- Swift (.swift)\\\\\\\\n- Kotlin (.kt)\\\\\\\\n- Scala (.scala)\\\\\\\\n- And more...\\\\\\\\n\\\\\\\\nPlus documentation files:\\\\\\\\n- Markdown (.md)\\\\\\\\n- reStructuredText (.rst)\\\\\\\\n- Plain text (.txt)\\\\\\\\n\\\\\\\\n## CLI Commands\\\\\\\\n\\\\\\\\n### Repository Management\\\\\\\\n```bash\\\\\\\\n# List analyzed repositories\\\\\\\\npython main.py list\\\\\\\\n\\\\\\\\n# Show system statistics\\\\\\\\npython main.py stats\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Analysis and Documentation\\\\\\\\n```bash\\\\\\\\n# Analyze repository\\\\\\\\npython main.py analyze <path> [--name <name>]\\\\\\\\n\\\\\\\\n# Generate documentation\\\\\\\\npython main.py docs <repo-name>\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Querying\\\\\\\\n```bash\\\\\\\\n# One-time query\\\\\\\\npython main.py query \\\\\\\\\\\\\\\"<question>\\\\\\\\\\\\\\\" [--repo <name>]\\\\\\\\n\\\\\\\\n# Interactive chat\\\\\\\\npython main.py chat [--repo <name>]\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Web Server\\\\\\\\n```bash\\\\\\\\n# Start web interface\\\\\\\\npython main.py server [--host <host>] [--port <port>]\\\\\\\\n```\\\\\\\\n\\\\\\\\n## API Endpoints\\\\\\\\n\\\\\\\\nWhen running the web server, these endpoints are available:\\\\\\\\n\\\\\\\\n### Health & System\\\\\\\\n- `GET /health` - System health check\\\\\\\\n- `GET /stats` - System statistics\\\\\\\\n- `GET /models` - List available Ollama models\\\\\\\\n\\\\\\\\n### Repository Management\\\\\\\\n- `POST /repositories/analyze` - Analyze repository\\\\\\\\n- `GET /repositories` - List repositories\\\\\\\\n- `DELETE /repositories/{name}` - Delete repository\\\\\\\\n\\\\\\\\n### Querying\\\\\\\\n- `POST /query` - Query with RAG system\\\\\\\\n- `POST /chat` - Chat interface\\\\\\\\n- `POST /explain` - Explain code snippet\\\\\\\\n- `POST /improve` - Suggest code improvements\\\\\\\\n\\\\\\\\n### Documentation\\\\\\\\n- `POST /repositories/{name}/generate-docs` - Generate docs\\\\\\\\n- `GET /repositories/{name}/docs` - List generated docs\\\\\\\\n- `GET /repositories/{name}/docs/{path}` - Get specific doc\\\\\\\\n\\\\\\\\n### Search\\\\\\\\n- `GET /search` - Search all repositories\\\\\\\\n- `GET /repositories/{name}/search` - Search specific repository\\\\\\\\n\\\\\\\\n## How It Works\\\\\\\\n\\\\\\\\n1. **Repository Analysis**: The system parses your codebase, extracting:\\\\\\\\n   - File structure and organization\\\\\\\\n   - Functions, classes, and their relationships\\\\\\\\n   - Import dependencies\\\\\\\\n   - Documentation and comments\\\\\\\\n   - Git information (if available)\\\\\\\\n\\\\\\\\n2. **Vector Embeddings**: Code and documentation are chunked and converted to embeddings using:\\\\\\\\n   - Ollama embedding models (preferred)\\\\\\\\n   - Sentence Transformers (fallback)\\\\\\\\n   - ChromaDB for efficient storage and retrieval\\\\\\\\n\\\\\\\\n3. **RAG System**: When you ask questions:\\\\\\\\n   - Your query is embedded and matched against the codebase\\\\\\\\n   - Relevant code snippets and documentation are retrieved\\\\\\\\n   - Context is provided to the LLM for accurate, grounded responses\\\\\\\\n\\\\\\\\n4. **Documentation Generation**: Using the analyzed structure:\\\\\\\\n   - README files with project overviews\\\\\\\\n   - API documentation for each file\\\\\\\\n   - Architecture documentation\\\\\\\\n   - Usage examples and tutorials\\\\\\\\n\\\\\\\\n## Example Queries\\\\\\\\n\\\\\\\\nHere are some example questions you can ask:\\\\\\\\n\\\\\\\\n### Code Understanding\\\\\\\\n- \\\\\\\\\\\\\\\"How does user authentication work in this project?\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"What is the main entry point of the application?\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"Show me all the API endpoints\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"How is data validation handled?\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n### Architecture Questions\\\\\\\\n- \\\\\\\\\\\\\\\"What's the overall architecture of this system?\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"How do the different modules interact?\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"What design patterns are used?\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"What are the main dependencies?\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n### Implementation Details\\\\\\\\n- \\\\\\\\\\\\\\\"How is error handling implemented?\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"Where is the database connection configured?\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"How are user permissions checked?\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"What testing framework is used?\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n### Documentation\\\\\\\\n- \\\\\\\\\\\\\\\"Generate API documentation for the user service\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"Create a getting started guide\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"Explain the deployment process\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n## Troubleshooting\\\\\\\\n\\\\\\\\n### Ollama Issues\\\\\\\\n```bash\\\\\\\\n# Check if Ollama is running\\\\\\\\ncurl http://localhost:11434/api/tags\\\\\\\\n\\\\\\\\n# Pull required models\\\\\\\\nollama pull llama2\\\\\\\\nollama pull nomic-embed-text\\\\\\\\n\\\\\\\\n# Check model availability\\\\\\\\nollama list\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Common Problems\\\\\\\\n\\\\\\\\n1. **\\\\\\\\\\\\\\\"Ollama server not available\\\\\\\\\\\\\\\"**\\\\\\\\n   - Make sure Ollama is installed and running (`ollama serve`)\\\\\\\\n   - Check the OLLAMA_BASE_URL in your configuration\\\\\\\\n\\\\\\\\n2. **\\\\\\\\\\\\\\\"Model not found\\\\\\\\\\\\\\\"**\\\\\\\\n   - Pull the required model: `ollama pull llama2`\\\\\\\\n   - Update OLLAMA_MODEL in configuration if using a different model\\\\\\\\n\\\\\\\\n3. **\\\\\\\\\\\\\\\"No relevant context found\\\\\\\\\\\\\\\"**\\\\\\\\n   - Make sure the repository has been analyzed\\\\\\\\n   - Try rephrasing your question\\\\\\\\n   - Check that the repository contains relevant code\\\\\\\\n\\\\\\\\n4. **Slow responses**\\\\\\\\n   - Consider using a smaller, faster model (e.g., `llama2:7b`)\\\\\\\\n   - Reduce MAX_CONTEXT_LENGTH in configuration\\\\\\\\n   - Use more specific queries\\\\\\\\n\\\\\\\\n### Performance Tips\\\\\\\\n\\\\\\\\n1. **Model Selection**: \\\\\\\\n   - Use `codellama` for better code understanding\\\\\\\\n   - Use `llama2:7b` for faster responses\\\\\\\\n   - Use `mistral` for a good balance\\\\\\\\n\\\\\\\\n2. **Configuration Tuning**:\\\\\\\\n   - Adjust MAX_CHUNK_SIZE for your hardware\\\\\\\\n   - Reduce MAX_CONTEXT_LENGTH for faster responses\\\\\\\\n   - Increase CHUNK_OVERLAP for better context\\\\\\\\n\\\\\\\\n3. **Repository Size**:\\\\\\\\n   - Large repositories may take time to analyze\\\\\\\\n   - Consider analyzing specific directories for faster results\\\\\\\\n   - Use .gitignore patterns to exclude unnecessary files\\\\\\\\n\\\\\\\\n## Contributing\\\\\\\\n\\\\\\\\n1. Fork the repository\\\\\\\\n2. Create a feature branch\\\\\\\\n3. Make your changes\\\\\\\\n4. Add tests if applicable\\\\\\\\n5. Submit a pull request\\\\\\\\n\\\\\\\\n## License\\\\\\\\n\\\\\\\\nThis project is licensed under the MIT License - see the LICENSE file for details.\\\\\\\\n\\\\\\\\n## Acknowledgments\\\\\\\\n\\\\\\\\n- [Ollama](https://ollama.ai) for local LLM inference\\\\\\\\n- [ChromaDB](https://www.trychroma.com/) for vector storage\\\\\\\\n- [LangChain](https://langchain.com/) for RAG implementation\\\\\\\\n- [FastAPI](https://fastapi.tiangolo.com/) for the web API\\\\\\\\n- [Vue.js](https://vuejs.org/) for the web interface\\\\\\\\n\\\\\\\\n## Roadmap\\\\\\\\n\\\\\\\\n- [ ] Support for more programming languages\\\\\\\\n- [ ] Advanced code analysis (call graphs, dependency analysis)\\\\\\\\n- [ ] Integration with popular IDEs\\\\\\\\n- [ ] Multi-repository projects support\\\\\\\\n- [ ] Custom model fine-tuning\\\\\\\\n- [ ] Collaborative features\\\\\\\\n- [ ] Plugin system for extensibility\\\\\\\\n\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n      \\\\\\\"file_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n      \\\\\\\"language\\\\\\\": \\\\\\\"python\\\\\\\",\\\\n      \\\\\\\"imports\\\\\\\": [\\\\n        \\\\\\\"os\\\\\\\",\\\\n        \\\\\\\"ast\\\\\\\",\\\\n        \\\\\\\"re\\\\\\\",\\\\n        \\\\\\\"json\\\\\\\",\\\\n        \\\\\\\"pathlib.Path\\\\\\\",\\\\n        \\\\\\\"typing.Dict\\\\\\\",\\\\n        \\\\\\\"typing.List\\\\\\\",\\\\n        \\\\\\\"typing.Any\\\\\\\",\\\\n        \\\\\\\"typing.Optional\\\\\\\",\\\\n        \\\\\\\"typing.Tuple\\\\\\\",\\\\n        \\\\\\\"dataclasses.dataclass\\\\\\\",\\\\n        \\\\\\\"dataclasses.asdict\\\\\\\",\\\\n        \\\\\\\"git\\\\\\\",\\\\n        \\\\\\\"config.settings\\\\\\\"\\\\n      ],\\\\n      \\\\\\\"elements\\\\\\\": [\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"CodeElement\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 14,\\\\n          \\\\\\\"line_end\\\\\\\": 28,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Represents a code element (function, class, etc.).\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class CodeElement\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"CodeElement.__post_init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 26,\\\\n          \\\\\\\"line_end\\\\\\\": 28,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __post_init__(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"FileAnalysis\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 31,\\\\n          \\\\\\\"line_end\\\\\\\": 45,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Analysis results for a single file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class FileAnalysis\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"FileAnalysis.__post_init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 41,\\\\n          \\\\\\\"line_end\\\\\\\": 45,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __post_init__(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 47,\\\\n          \\\\\\\"line_end\\\\\\\": 348,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Analyzes code repositories to extract structure and content.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class RepositoryAnalyzer\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer.__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 50,\\\\n          \\\\\\\"line_end\\\\\\\": 69,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer.analyze_repository\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 71,\\\\n          \\\\\\\"line_end\\\\\\\": 132,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Analyze an entire repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def analyze_repository(self, repo_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer.analyze_file\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 134,\\\\n          \\\\\\\"line_end\\\\\\\": 170,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Analyze a single file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def analyze_file(self, file_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer._analyze_python_file\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 172,\\\\n          \\\\\\\"line_end\\\\\\\": 230,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Analyze Python file for structure.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _analyze_python_file(self, analysis, content)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer._analyze_js_ts_file\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 232,\\\\n          \\\\\\\"line_end\\\\\\\": 285,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Analyze JavaScript/TypeScript file for structure.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _analyze_js_ts_file(self, analysis, content)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer._get_function_args\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 287,\\\\n          \\\\\\\"line_end\\\\\\\": 292,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Extract function arguments as string.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _get_function_args(self, node)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer._get_files_to_analyze\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 294,\\\\n          \\\\\\\"line_end\\\\\\\": 307,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Get list of files to analyze, respecting ignore patterns.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _get_files_to_analyze(self, repo_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer._should_ignore_dir\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 309,\\\\n          \\\\\\\"line_end\\\\\\\": 311,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Check if directory should be ignored.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _should_ignore_dir(self, dirname)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer._should_analyze_file\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 313,\\\\n          \\\\\\\"line_end\\\\\\\": 316,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Check if file should be analyzed.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _should_analyze_file(self, file_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer._build_directory_structure\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 318,\\\\n          \\\\\\\"line_end\\\\\\\": 338,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Build a tree representation of the directory structure.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _build_directory_structure(self, repo_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer.save_analysis\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 340,\\\\n          \\\\\\\"line_end\\\\\\\": 343,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Save analysis results to JSON file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def save_analysis(self, analysis, output_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"RepositoryAnalyzer.load_analysis\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 345,\\\\n          \\\\\\\"line_end\\\\\\\": 348,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Load analysis results from JSON file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def load_analysis(self, input_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"__post_init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 26,\\\\n          \\\\\\\"line_end\\\\\\\": 28,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __post_init__(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"__post_init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 41,\\\\n          \\\\\\\"line_end\\\\\\\": 45,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __post_init__(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 50,\\\\n          \\\\\\\"line_end\\\\\\\": 69,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"analyze_repository\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 71,\\\\n          \\\\\\\"line_end\\\\\\\": 132,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Analyze an entire repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def analyze_repository(self, repo_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"analyze_file\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 134,\\\\n          \\\\\\\"line_end\\\\\\\": 170,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Analyze a single file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def analyze_file(self, file_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"_analyze_python_file\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 172,\\\\n          \\\\\\\"line_end\\\\\\\": 230,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Analyze Python file for structure.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _analyze_python_file(self, analysis, content)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"_analyze_js_ts_file\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 232,\\\\n          \\\\\\\"line_end\\\\\\\": 285,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Analyze JavaScript/TypeScript file for structure.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _analyze_js_ts_file(self, analysis, content)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"_get_function_args\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 287,\\\\n          \\\\\\\"line_end\\\\\\\": 292,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Extract function arguments as string.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _get_function_args(self, node)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"_get_files_to_analyze\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 294,\\\\n          \\\\\\\"line_end\\\\\\\": 307,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Get list of files to analyze, respecting ignore patterns.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _get_files_to_analyze(self, repo_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"_should_ignore_dir\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 309,\\\\n          \\\\\\\"line_end\\\\\\\": 311,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Check if directory should be ignored.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _should_ignore_dir(self, dirname)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"_should_analyze_file\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 313,\\\\n          \\\\\\\"line_end\\\\\\\": 316,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Check if file should be analyzed.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _should_analyze_file(self, file_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"_build_directory_structure\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 318,\\\\n          \\\\\\\"line_end\\\\\\\": 338,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Build a tree representation of the directory structure.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def _build_directory_structure(self, repo_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"save_analysis\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 340,\\\\n          \\\\\\\"line_end\\\\\\\": 343,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Save analysis results to JSON file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def save_analysis(self, analysis, output_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"load_analysis\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 345,\\\\n          \\\\\\\"line_end\\\\\\\": 348,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Load analysis results from JSON file.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def load_analysis(self, input_path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"build_tree\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 320,\\\\n          \\\\\\\"line_end\\\\\\\": 336,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def build_tree(path)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        }\\\\n      ],\\\\n      \\\\\\\"summary\\\\\\\": null,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Repository analysis module for extracting code structure and content.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport os\\\\\\\\nimport ast\\\\\\\\nimport re\\\\\\\\nimport json\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import Dict, List, Any, Optional, Tuple\\\\\\\\nfrom dataclasses import dataclass, asdict\\\\\\\\nimport git\\\\\\\\nfrom config import settings\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass CodeElement:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Represents a code element (function, class, etc.).\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    name: str\\\\\\\\n    type: str  # 'function', 'class', 'method', 'variable'\\\\\\\\n    file_path: str\\\\\\\\n    line_start: int\\\\\\\\n    line_end: int\\\\\\\\n    docstring: Optional[str] = None\\\\\\\\n    signature: Optional[str] = None\\\\\\\\n    content: Optional[str] = None\\\\\\\\n    dependencies: List[str] = None\\\\\\\\n    \\\\\\\\n    def __post_init__(self):\\\\\\\\n        if self.dependencies is None:\\\\\\\\n            self.dependencies = []\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass FileAnalysis:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analysis results for a single file.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    file_path: str\\\\\\\\n    file_type: str  # 'code', 'documentation', 'config'\\\\\\\\n    language: Optional[str] = None\\\\\\\\n    imports: List[str] = None\\\\\\\\n    elements: List[CodeElement] = None\\\\\\\\n    summary: Optional[str] = None\\\\\\\\n    content: Optional[str] = None\\\\\\\\n    \\\\\\\\n    def __post_init__(self):\\\\\\\\n        if self.imports is None:\\\\\\\\n            self.imports = []\\\\\\\\n        if self.elements is None:\\\\\\\\n            self.elements = []\\\\\\\\n\\\\\\\\nclass RepositoryAnalyzer:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyzes code repositories to extract structure and content.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def __init__(self):\\\\\\\\n        self.supported_languages = {\\\\\\\\n            '.py': 'python',\\\\\\\\n            '.js': 'javascript', \\\\\\\\n            '.ts': 'typescript',\\\\\\\\n            '.jsx': 'javascript',\\\\\\\\n            '.tsx': 'typescript',\\\\\\\\n            '.java': 'java',\\\\\\\\n            '.cpp': 'cpp',\\\\\\\\n            '.c': 'c',\\\\\\\\n            '.h': 'c',\\\\\\\\n            '.cs': 'csharp',\\\\\\\\n            '.php': 'php',\\\\\\\\n            '.rb': 'ruby',\\\\\\\\n            '.go': 'go',\\\\\\\\n            '.rs': 'rust',\\\\\\\\n            '.swift': 'swift',\\\\\\\\n            '.kt': 'kotlin',\\\\\\\\n            '.scala': 'scala'\\\\\\\\n        }\\\\\\\\n    \\\\\\\\n    def analyze_repository(self, repo_path: str) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyze an entire repository.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        repo_path = Path(repo_path)\\\\\\\\n        \\\\\\\\n        if not repo_path.exists():\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\"Repository path does not exist: {repo_path}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        analysis = {\\\\\\\\n            'repo_path': str(repo_path),\\\\\\\\n            'repo_name': repo_path.name,\\\\\\\\n            'files': [],\\\\\\\\n            'structure': {},\\\\\\\\n            'statistics': {\\\\\\\\n                'total_files': 0,\\\\\\\\n                'code_files': 0,\\\\\\\\n                'doc_files': 0,\\\\\\\\n                'languages': {},\\\\\\\\n                'total_lines': 0\\\\\\\\n            }\\\\\\\\n        }\\\\\\\\n        \\\\\\\\n        # Get git info if available\\\\\\\\n        try:\\\\\\\\n            repo = git.Repo(repo_path)\\\\\\\\n            analysis['git_info'] = {\\\\\\\\n                'remote_url': repo.remotes.origin.url if repo.remotes else None,\\\\\\\\n                'current_branch': repo.active_branch.name,\\\\\\\\n                'last_commit': {\\\\\\\\n                    'hash': repo.head.commit.hexsha[:8],\\\\\\\\n                    'message': repo.head.commit.message.strip(),\\\\\\\\n                    'author': str(repo.head.commit.author),\\\\\\\\n                    'date': repo.head.commit.committed_datetime.isoformat()\\\\\\\\n                }\\\\\\\\n            }\\\\\\\\n        except:\\\\\\\\n            analysis['git_info'] = None\\\\\\\\n        \\\\\\\\n        # Analyze files\\\\\\\\n        for file_path in self._get_files_to_analyze(repo_path):\\\\\\\\n            file_analysis = self.analyze_file(file_path)\\\\\\\\n            if file_analysis:\\\\\\\\n                analysis['files'].append(asdict(file_analysis))\\\\\\\\n                \\\\\\\\n                # Update statistics\\\\\\\\n                analysis['statistics']['total_files'] += 1\\\\\\\\n                if file_analysis.file_type == 'code':\\\\\\\\n                    analysis['statistics']['code_files'] += 1\\\\\\\\n                    if file_analysis.language:\\\\\\\\n                        lang = file_analysis.language\\\\\\\\n                        analysis['statistics']['languages'][lang] = \\\\\\\\\\\\\\\\\\\\\\\\n                            analysis['statistics']['languages'].get(lang, 0) + 1\\\\\\\\n                elif file_analysis.file_type == 'documentation':\\\\\\\\n                    analysis['statistics']['doc_files'] += 1\\\\\\\\n                \\\\\\\\n                # Count lines\\\\\\\\n                if file_analysis.content:\\\\\\\\n                    analysis['statistics']['total_lines'] += len(file_analysis.content.split('\\\\\\\\\\\\\\\\n'))\\\\\\\\n        \\\\\\\\n        # Build directory structure\\\\\\\\n        analysis['structure'] = self._build_directory_structure(repo_path)\\\\\\\\n        \\\\\\\\n        return analysis\\\\\\\\n    \\\\\\\\n    def analyze_file(self, file_path: Path) -> Optional[FileAnalysis]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyze a single file.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\\\\\\\\n                content = f.read()\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error reading file {file_path}: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            return None\\\\\\\\n        \\\\\\\\n        file_ext = file_path.suffix.lower()\\\\\\\\n        relative_path = str(file_path)\\\\\\\\n        \\\\\\\\n        # Determine file type and language\\\\\\\\n        if file_ext in settings.CODE_EXTENSIONS:\\\\\\\\n            file_type = 'code'\\\\\\\\n            language = self.supported_languages.get(file_ext)\\\\\\\\n        elif file_ext in settings.DOC_EXTENSIONS:\\\\\\\\n            file_type = 'documentation'\\\\\\\\n            language = None\\\\\\\\n        else:\\\\\\\\n            file_type = 'config'\\\\\\\\n            language = None\\\\\\\\n        \\\\\\\\n        analysis = FileAnalysis(\\\\\\\\n            file_path=relative_path,\\\\\\\\n            file_type=file_type,\\\\\\\\n            language=language,\\\\\\\\n            content=content\\\\\\\\n        )\\\\\\\\n        \\\\\\\\n        # Language-specific analysis\\\\\\\\n        if language == 'python':\\\\\\\\n            self._analyze_python_file(analysis, content)\\\\\\\\n        elif language in ['javascript', 'typescript']:\\\\\\\\n            self._analyze_js_ts_file(analysis, content)\\\\\\\\n        \\\\\\\\n        return analysis\\\\\\\\n    \\\\\\\\n    def _analyze_python_file(self, analysis: FileAnalysis, content: str):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyze Python file for structure.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            tree = ast.parse(content)\\\\\\\\n            \\\\\\\\n            # Extract imports\\\\\\\\n            for node in ast.walk(tree):\\\\\\\\n                if isinstance(node, ast.Import):\\\\\\\\n                    for alias in node.names:\\\\\\\\n                        analysis.imports.append(alias.name)\\\\\\\\n                elif isinstance(node, ast.ImportFrom):\\\\\\\\n                    module = node.module or ''\\\\\\\\n                    for alias in node.names:\\\\\\\\n                        analysis.imports.append(f\\\\\\\\\\\\\\\"{module}.{alias.name}\\\\\\\\\\\\\\\")\\\\\\\\n            \\\\\\\\n            # Extract classes and functions\\\\\\\\n            for node in ast.walk(tree):\\\\\\\\n                if isinstance(node, ast.ClassDef):\\\\\\\\n                    element = CodeElement(\\\\\\\\n                        name=node.name,\\\\\\\\n                        type='class',\\\\\\\\n                        file_path=analysis.file_path,\\\\\\\\n                        line_start=node.lineno,\\\\\\\\n                        line_end=getattr(node, 'end_lineno', node.lineno),\\\\\\\\n                        docstring=ast.get_docstring(node),\\\\\\\\n                        signature=f\\\\\\\\\\\\\\\"class {node.name}\\\\\\\\\\\\\\\"\\\\\\\\n                    )\\\\\\\\n                    analysis.elements.append(element)\\\\\\\\n                    \\\\\\\\n                    # Extract methods\\\\\\\\n                    for item in node.body:\\\\\\\\n                        if isinstance(item, ast.FunctionDef):\\\\\\\\n                            method = CodeElement(\\\\\\\\n                                name=f\\\\\\\\\\\\\\\"{node.name}.{item.name}\\\\\\\\\\\\\\\",\\\\\\\\n                                type='method',\\\\\\\\n                                file_path=analysis.file_path,\\\\\\\\n                                line_start=item.lineno,\\\\\\\\n                                line_end=getattr(item, 'end_lineno', item.lineno),\\\\\\\\n                                docstring=ast.get_docstring(item),\\\\\\\\n                                signature=f\\\\\\\\\\\\\\\"def {item.name}({self._get_function_args(item)})\\\\\\\\\\\\\\\"\\\\\\\\n                            )\\\\\\\\n                            analysis.elements.append(method)\\\\\\\\n                \\\\\\\\n                elif isinstance(node, ast.FunctionDef):\\\\\\\\n                    # Only top-level functions (not methods)\\\\\\\\n                    if isinstance(getattr(node, 'parent', None), ast.Module) or not hasattr(node, 'parent'):\\\\\\\\n                        element = CodeElement(\\\\\\\\n                            name=node.name,\\\\\\\\n                            type='function',\\\\\\\\n                            file_path=analysis.file_path,\\\\\\\\n                            line_start=node.lineno,\\\\\\\\n                            line_end=getattr(node, 'end_lineno', node.lineno),\\\\\\\\n                            docstring=ast.get_docstring(node),\\\\\\\\n                            signature=f\\\\\\\\\\\\\\\"def {node.name}({self._get_function_args(node)})\\\\\\\\\\\\\\\"\\\\\\\\n                        )\\\\\\\\n                        analysis.elements.append(element)\\\\\\\\n                        \\\\\\\\n        except SyntaxError as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Syntax error in {analysis.file_path}: {e}\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    def _analyze_js_ts_file(self, analysis: FileAnalysis, content: str):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyze JavaScript/TypeScript file for structure.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        lines = content.split('\\\\\\\\\\\\\\\\n')\\\\\\\\n        \\\\\\\\n        # Extract imports (simple regex-based approach)\\\\\\\\n        import_patterns = [\\\\\\\\n            r'import\\\\\\\\\\\\\\\\s+.*?\\\\\\\\\\\\\\\\s+from\\\\\\\\\\\\\\\\s+[\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"]([^\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"]+)[\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"]',\\\\\\\\n            r'const\\\\\\\\\\\\\\\\s+.*?\\\\\\\\\\\\\\\\s*=\\\\\\\\\\\\\\\\s*require\\\\\\\\\\\\\\\\([\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"]([^\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"]+)[\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\)',\\\\\\\\n            r'import\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\(\\\\\\\\\\\\\\\\s*[\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"]([^\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"]+)[\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\)'\\\\\\\\n        ]\\\\\\\\n        \\\\\\\\n        for line in lines:\\\\\\\\n            for pattern in import_patterns:\\\\\\\\n                matches = re.findall(pattern, line)\\\\\\\\n                analysis.imports.extend(matches)\\\\\\\\n        \\\\\\\\n        # Extract functions and classes (basic regex patterns)\\\\\\\\n        function_patterns = [\\\\\\\\n            r'function\\\\\\\\\\\\\\\\s+(\\\\\\\\\\\\\\\\w+)\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\(',\\\\\\\\n            r'const\\\\\\\\\\\\\\\\s+(\\\\\\\\\\\\\\\\w+)\\\\\\\\\\\\\\\\s*=\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\(',\\\\\\\\n            r'(\\\\\\\\\\\\\\\\w+)\\\\\\\\\\\\\\\\s*:\\\\\\\\\\\\\\\\s*function\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\(',\\\\\\\\n            r'(\\\\\\\\\\\\\\\\w+)\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\([^)]*\\\\\\\\\\\\\\\\)\\\\\\\\\\\\\\\\s*=>',\\\\\\\\n            r'async\\\\\\\\\\\\\\\\s+function\\\\\\\\\\\\\\\\s+(\\\\\\\\\\\\\\\\w+)\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\('\\\\\\\\n        ]\\\\\\\\n        \\\\\\\\n        class_pattern = r'class\\\\\\\\\\\\\\\\s+(\\\\\\\\\\\\\\\\w+)'\\\\\\\\n        \\\\\\\\n        for i, line in enumerate(lines, 1):\\\\\\\\n            # Find classes\\\\\\\\n            class_match = re.search(class_pattern, line)\\\\\\\\n            if class_match:\\\\\\\\n                element = CodeElement(\\\\\\\\n                    name=class_match.group(1),\\\\\\\\n                    type='class',\\\\\\\\n                    file_path=analysis.file_path,\\\\\\\\n                    line_start=i,\\\\\\\\n                    line_end=i,  # We'd need more sophisticated parsing to find end\\\\\\\\n                    signature=line.strip()\\\\\\\\n                )\\\\\\\\n                analysis.elements.append(element)\\\\\\\\n            \\\\\\\\n            # Find functions\\\\\\\\n            for pattern in function_patterns:\\\\\\\\n                func_match = re.search(pattern, line)\\\\\\\\n                if func_match:\\\\\\\\n                    element = CodeElement(\\\\\\\\n                        name=func_match.group(1),\\\\\\\\n                        type='function',\\\\\\\\n                        file_path=analysis.file_path,\\\\\\\\n                        line_start=i,\\\\\\\\n                        line_end=i,\\\\\\\\n                        signature=line.strip()\\\\\\\\n                    )\\\\\\\\n                    analysis.elements.append(element)\\\\\\\\n    \\\\\\\\n    def _get_function_args(self, node: ast.FunctionDef) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Extract function arguments as string.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        args = []\\\\\\\\n        for arg in node.args.args:\\\\\\\\n            args.append(arg.arg)\\\\\\\\n        return ', '.join(args)\\\\\\\\n    \\\\\\\\n    def _get_files_to_analyze(self, repo_path: Path) -> List[Path]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get list of files to analyze, respecting ignore patterns.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        files = []\\\\\\\\n        \\\\\\\\n        for root, dirs, filenames in os.walk(repo_path):\\\\\\\\n            # Remove ignored directories\\\\\\\\n            dirs[:] = [d for d in dirs if not self._should_ignore_dir(d)]\\\\\\\\n            \\\\\\\\n            for filename in filenames:\\\\\\\\n                file_path = Path(root) / filename\\\\\\\\n                if self._should_analyze_file(file_path):\\\\\\\\n                    files.append(file_path)\\\\\\\\n        \\\\\\\\n        return files\\\\\\\\n    \\\\\\\\n    def _should_ignore_dir(self, dirname: str) -> bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if directory should be ignored.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return dirname in settings.IGNORED_DIRS or dirname.startswith('.')\\\\\\\\n    \\\\\\\\n    def _should_analyze_file(self, file_path: Path) -> bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if file should be analyzed.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        ext = file_path.suffix.lower()\\\\\\\\n        return ext in settings.CODE_EXTENSIONS or ext in settings.DOC_EXTENSIONS\\\\\\\\n    \\\\\\\\n    def _build_directory_structure(self, repo_path: Path) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Build a tree representation of the directory structure.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        def build_tree(path: Path) -> Dict[str, Any]:\\\\\\\\n            tree = {'name': path.name, 'type': 'directory', 'children': []}\\\\\\\\n            \\\\\\\\n            try:\\\\\\\\n                for item in sorted(path.iterdir()):\\\\\\\\n                    if item.is_dir() and not self._should_ignore_dir(item.name):\\\\\\\\n                        tree['children'].append(build_tree(item))\\\\\\\\n                    elif item.is_file() and self._should_analyze_file(item):\\\\\\\\n                        tree['children'].append({\\\\\\\\n                            'name': item.name,\\\\\\\\n                            'type': 'file',\\\\\\\\n                            'path': str(item.relative_to(repo_path))\\\\\\\\n                        })\\\\\\\\n            except PermissionError:\\\\\\\\n                pass\\\\\\\\n            \\\\\\\\n            return tree\\\\\\\\n        \\\\\\\\n        return build_tree(repo_path)\\\\\\\\n\\\\\\\\n    def save_analysis(self, analysis: Dict[str, Any], output_path: str):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Save analysis results to JSON file.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        with open(output_path, 'w', encoding='utf-8') as f:\\\\\\\\n            json.dump(analysis, f, indent=2, ensure_ascii=False)\\\\\\\\n    \\\\\\\\n    def load_analysis(self, input_path: str) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Load analysis results from JSON file.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        with open(input_path, 'r', encoding='utf-8') as f:\\\\\\\\n            return json.load(f)\\\\\\\\n\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\requirements.txt\\\\\\\",\\\\n      \\\\\\\"file_type\\\\\\\": \\\\\\\"documentation\\\\\\\",\\\\n      \\\\\\\"language\\\\\\\": null,\\\\n      \\\\\\\"imports\\\\\\\": [],\\\\n      \\\\\\\"elements\\\\\\\": [],\\\\n      \\\\\\\"summary\\\\\\\": null,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"ollama>=0.2.0\\\\\\\\nlangchain>=0.1.0\\\\\\\\nlangchain-community>=0.0.20\\\\\\\\nchromadb>=0.4.0\\\\\\\\nsentence-transformers>=2.2.2\\\\\\\\nfastapi>=0.104.0\\\\\\\\nuvicorn>=0.24.0\\\\\\\\npydantic>=2.5.0\\\\\\\\npython-multipart>=0.0.6\\\\\\\\ngitpython>=3.1.40\\\\\\\\npathspec>=0.12.0\\\\\\\\ntiktoken>=0.5.0\\\\\\\\njinja2>=3.1.0\\\\\\\\nmarkdown>=3.5.0\\\\\\\\nbeautifulsoup4>=4.12.0\\\\\\\\ntree-sitter>=0.20.0\\\\\\\\ntree-sitter-python>=0.20.0\\\\\\\\ntree-sitter-javascript>=0.20.0\\\\\\\\ntree-sitter-typescript>=0.20.0\\\\\\\\naiofiles>=23.2.0\\\\\\\\nwatchdog>=3.0.0\\\\\\\\n\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n      \\\\\\\"file_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n      \\\\\\\"language\\\\\\\": \\\\\\\"python\\\\\\\",\\\\n      \\\\\\\"imports\\\\\\\": [\\\\n        \\\\\\\"os\\\\\\\",\\\\n        \\\\\\\"hashlib\\\\\\\",\\\\n        \\\\\\\"json\\\\\\\",\\\\n        \\\\\\\"pathlib.Path\\\\\\\",\\\\n        \\\\\\\"typing.List\\\\\\\",\\\\n        \\\\\\\"typing.Dict\\\\\\\",\\\\n        \\\\\\\"typing.Any\\\\\\\",\\\\n        \\\\\\\"typing.Optional\\\\\\\",\\\\n        \\\\\\\"typing.Tuple\\\\\\\",\\\\n        \\\\\\\"chromadb\\\\\\\",\\\\n        \\\\\\\"chromadb.config.Settings\\\\\\\",\\\\n        \\\\\\\"sentence_transformers.SentenceTransformer\\\\\\\",\\\\n        \\\\\\\"tiktoken\\\\\\\",\\\\n        \\\\\\\"config.settings\\\\\\\",\\\\n        \\\\\\\"ollama_client.OllamaClient\\\\\\\"\\\\n      ],\\\\n      \\\\\\\"elements\\\\\\\": [\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"TextChunker\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 15,\\\\n          \\\\\\\"line_end\\\\\\\": 188,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Utility class for chunking text into manageable pieces.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class TextChunker\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"TextChunker.__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 18,\\\\n          \\\\\\\"line_end\\\\\\\": 26,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self, max_chunk_size, overlap)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"TextChunker.count_tokens\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 28,\\\\n          \\\\\\\"line_end\\\\\\\": 34,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Count tokens in text.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def count_tokens(self, text)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"TextChunker.chunk_text\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 36,\\\\n          \\\\\\\"line_end\\\\\\\": 113,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Split text into chunks with metadata.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def chunk_text(self, text, metadata)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"TextChunker.chunk_code_file\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 115,\\\\n          \\\\\\\"line_end\\\\\\\": 188,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Chunk code file based on structure.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def chunk_code_file(self, content, file_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"VectorStore\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"class\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 190,\\\\n          \\\\\\\"line_end\\\\\\\": 411,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Vector store for embeddings using ChromaDB and local embeddings.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"class VectorStore\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"VectorStore.__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 193,\\\\n          \\\\\\\"line_end\\\\\\\": 219,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self, persist_directory, collection_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"VectorStore.get_embedding\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 221,\\\\n          \\\\\\\"line_end\\\\\\\": 238,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Get embedding for text using available models.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def get_embedding(self, text)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"VectorStore.add_repository\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 240,\\\\n          \\\\\\\"line_end\\\\\\\": 270,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Add entire repository to vector store.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def add_repository(self, repo_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"VectorStore.add_file_analysis\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 272,\\\\n          \\\\\\\"line_end\\\\\\\": 295,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Add file analysis to vector store.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def add_file_analysis(self, file_analysis, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"VectorStore.add_document\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 297,\\\\n          \\\\\\\"line_end\\\\\\\": 300,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Add a single document to vector store.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def add_document(self, text, metadata)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"VectorStore.add_chunks\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 302,\\\\n          \\\\\\\"line_end\\\\\\\": 348,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Add multiple chunks to vector store.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def add_chunks(self, chunks)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"VectorStore.search\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 350,\\\\n          \\\\\\\"line_end\\\\\\\": 379,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Search vector store for relevant documents.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def search(self, query, n_results, filter_metadata)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"VectorStore.get_collection_stats\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 381,\\\\n          \\\\\\\"line_end\\\\\\\": 391,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Get statistics about the collection.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def get_collection_stats(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"VectorStore.clear_collection\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 393,\\\\n          \\\\\\\"line_end\\\\\\\": 400,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Clear all documents from collection.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def clear_collection(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"VectorStore.delete_repository\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"method\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 402,\\\\n          \\\\\\\"line_end\\\\\\\": 411,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Delete all documents from a specific repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def delete_repository(self, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 18,\\\\n          \\\\\\\"line_end\\\\\\\": 26,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self, max_chunk_size, overlap)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"count_tokens\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 28,\\\\n          \\\\\\\"line_end\\\\\\\": 34,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Count tokens in text.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def count_tokens(self, text)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"chunk_text\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 36,\\\\n          \\\\\\\"line_end\\\\\\\": 113,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Split text into chunks with metadata.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def chunk_text(self, text, metadata)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"chunk_code_file\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 115,\\\\n          \\\\\\\"line_end\\\\\\\": 188,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Chunk code file based on structure.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def chunk_code_file(self, content, file_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"__init__\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 193,\\\\n          \\\\\\\"line_end\\\\\\\": 219,\\\\n          \\\\\\\"docstring\\\\\\\": null,\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def __init__(self, persist_directory, collection_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"get_embedding\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 221,\\\\n          \\\\\\\"line_end\\\\\\\": 238,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Get embedding for text using available models.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def get_embedding(self, text)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"add_repository\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 240,\\\\n          \\\\\\\"line_end\\\\\\\": 270,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Add entire repository to vector store.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def add_repository(self, repo_analysis)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"add_file_analysis\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 272,\\\\n          \\\\\\\"line_end\\\\\\\": 295,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Add file analysis to vector store.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def add_file_analysis(self, file_analysis, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"add_document\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 297,\\\\n          \\\\\\\"line_end\\\\\\\": 300,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Add a single document to vector store.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def add_document(self, text, metadata)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"add_chunks\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 302,\\\\n          \\\\\\\"line_end\\\\\\\": 348,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Add multiple chunks to vector store.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def add_chunks(self, chunks)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"search\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 350,\\\\n          \\\\\\\"line_end\\\\\\\": 379,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Search vector store for relevant documents.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def search(self, query, n_results, filter_metadata)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"get_collection_stats\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 381,\\\\n          \\\\\\\"line_end\\\\\\\": 391,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Get statistics about the collection.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def get_collection_stats(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"clear_collection\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 393,\\\\n          \\\\\\\"line_end\\\\\\\": 400,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Clear all documents from collection.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def clear_collection(self)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        },\\\\n        {\\\\n          \\\\\\\"name\\\\\\\": \\\\\\\"delete_repository\\\\\\\",\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"function\\\\\\\",\\\\n          \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\vector_store.py\\\\\\\",\\\\n          \\\\\\\"line_start\\\\\\\": 402,\\\\n          \\\\\\\"line_end\\\\\\\": 411,\\\\n          \\\\\\\"docstring\\\\\\\": \\\\\\\"Delete all documents from a specific repository.\\\\\\\",\\\\n          \\\\\\\"signature\\\\\\\": \\\\\\\"def delete_repository(self, repo_name)\\\\\\\",\\\\n          \\\\\\\"content\\\\\\\": null,\\\\n          \\\\\\\"dependencies\\\\\\\": []\\\\n        }\\\\n      ],\\\\n      \\\\\\\"summary\\\\\\\": null,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Vector embedding and storage system using ChromaDB.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport os\\\\\\\\nimport hashlib\\\\\\\\nimport json\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import List, Dict, Any, Optional, Tuple\\\\\\\\nimport chromadb\\\\\\\\nfrom chromadb.config import Settings\\\\\\\\nfrom sentence_transformers import SentenceTransformer\\\\\\\\nimport tiktoken\\\\\\\\nfrom config import settings\\\\\\\\nfrom ollama_client import OllamaClient\\\\\\\\n\\\\\\\\nclass TextChunker:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Utility class for chunking text into manageable pieces.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def __init__(self, max_chunk_size: int = None, overlap: int = None):\\\\\\\\n        self.max_chunk_size = max_chunk_size or settings.MAX_CHUNK_SIZE\\\\\\\\n        self.overlap = overlap or settings.CHUNK_OVERLAP\\\\\\\\n        \\\\\\\\n        # Initialize tokenizer for accurate token counting\\\\\\\\n        try:\\\\\\\\n            self.tokenizer = tiktoken.get_encoding(\\\\\\\\\\\\\\\"cl100k_base\\\\\\\\\\\\\\\")\\\\\\\\n        except:\\\\\\\\n            self.tokenizer = None\\\\\\\\n    \\\\\\\\n    def count_tokens(self, text: str) -> int:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Count tokens in text.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if self.tokenizer:\\\\\\\\n            return len(self.tokenizer.encode(text))\\\\\\\\n        else:\\\\\\\\n            # Rough approximation: 1 token â‰ˆ 4 characters\\\\\\\\n            return len(text) // 4\\\\\\\\n    \\\\\\\\n    def chunk_text(self, text: str, metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Split text into chunks with metadata.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if metadata is None:\\\\\\\\n            metadata = {}\\\\\\\\n        \\\\\\\\n        chunks = []\\\\\\\\n        \\\\\\\\n        # Split by paragraphs first\\\\\\\\n        paragraphs = text.split('\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n')\\\\\\\\n        current_chunk = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        current_tokens = 0\\\\\\\\n        \\\\\\\\n        for para in paragraphs:\\\\\\\\n            para_tokens = self.count_tokens(para)\\\\\\\\n            \\\\\\\\n            # If single paragraph exceeds max size, split it further\\\\\\\\n            if para_tokens > self.max_chunk_size:\\\\\\\\n                # Save current chunk if not empty\\\\\\\\n                if current_chunk.strip():\\\\\\\\n                    chunks.append({\\\\\\\\n                        'text': current_chunk.strip(),\\\\\\\\n                        'tokens': current_tokens,\\\\\\\\n                        **metadata\\\\\\\\n                    })\\\\\\\\n                    current_chunk = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n                    current_tokens = 0\\\\\\\\n                \\\\\\\\n                # Split large paragraph by sentences\\\\\\\\n                sentences = para.split('. ')\\\\\\\\n                for sentence in sentences:\\\\\\\\n                    sentence_tokens = self.count_tokens(sentence)\\\\\\\\n                    \\\\\\\\n                    if current_tokens + sentence_tokens > self.max_chunk_size:\\\\\\\\n                        if current_chunk.strip():\\\\\\\\n                            chunks.append({\\\\\\\\n                                'text': current_chunk.strip(),\\\\\\\\n                                'tokens': current_tokens,\\\\\\\\n                                **metadata\\\\\\\\n                            })\\\\\\\\n                        current_chunk = sentence\\\\\\\\n                        current_tokens = sentence_tokens\\\\\\\\n                    else:\\\\\\\\n                        current_chunk += (\\\\\\\\\\\\\\\". \\\\\\\\\\\\\\\" if current_chunk else \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\") + sentence\\\\\\\\n                        current_tokens += sentence_tokens\\\\\\\\n            \\\\\\\\n            # Normal paragraph processing\\\\\\\\n            elif current_tokens + para_tokens > self.max_chunk_size:\\\\\\\\n                # Save current chunk\\\\\\\\n                if current_chunk.strip():\\\\\\\\n                    chunks.append({\\\\\\\\n                        'text': current_chunk.strip(),\\\\\\\\n                        'tokens': current_tokens,\\\\\\\\n                        **metadata\\\\\\\\n                    })\\\\\\\\n                \\\\\\\\n                # Start new chunk with overlap\\\\\\\\n                if self.overlap > 0 and chunks:\\\\\\\\n                    # Get last few words for overlap\\\\\\\\n                    last_chunk_words = current_chunk.split()\\\\\\\\n                    overlap_words = last_chunk_words[-self.overlap:] if len(last_chunk_words) > self.overlap else last_chunk_words\\\\\\\\n                    current_chunk = \\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\".join(overlap_words) + \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\" + para\\\\\\\\n                else:\\\\\\\\n                    current_chunk = para\\\\\\\\n                \\\\\\\\n                current_tokens = self.count_tokens(current_chunk)\\\\\\\\n            else:\\\\\\\\n                current_chunk += (\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\" if current_chunk else \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\") + para\\\\\\\\n                current_tokens += para_tokens\\\\\\\\n        \\\\\\\\n        # Add final chunk\\\\\\\\n        if current_chunk.strip():\\\\\\\\n            chunks.append({\\\\\\\\n                'text': current_chunk.strip(),\\\\\\\\n                'tokens': current_tokens,\\\\\\\\n                **metadata\\\\\\\\n            })\\\\\\\\n        \\\\\\\\n        return chunks\\\\\\\\n    \\\\\\\\n    def chunk_code_file(self, content: str, file_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Chunk code file based on structure.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        chunks = []\\\\\\\\n        \\\\\\\\n        # Create chunk for file overview\\\\\\\\n        overview_text = f\\\\\\\\\\\\\\\"File: {file_analysis['file_path']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        overview_text += f\\\\\\\\\\\\\\\"Language: {file_analysis.get('language', 'Unknown')}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        if file_analysis.get('imports'):\\\\\\\\n            overview_text += f\\\\\\\\\\\\\\\"Imports: {', '.join(file_analysis['imports'])}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        # Add summary of elements\\\\\\\\n        elements = file_analysis.get('elements', [])\\\\\\\\n        if elements:\\\\\\\\n            overview_text += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nCode Elements:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            for element in elements:\\\\\\\\n                overview_text += f\\\\\\\\\\\\\\\"- {element['type']}: {element['name']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n                if element.get('docstring'):\\\\\\\\n                    overview_text += f\\\\\\\\\\\\\\\"  {element['docstring'][:100]}...\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\\n        chunks.append({\\\\\\\\n            'text': overview_text,\\\\\\\\n            'type': 'file_overview',\\\\\\\\n            'file_path': file_analysis['file_path'],\\\\\\\\n            'language': file_analysis.get('language'),\\\\\\\\n            'source': 'code_analysis'\\\\\\\\n        })\\\\\\\\n        \\\\\\\\n        # Create chunks for individual code elements\\\\\\\\n        lines = content.split('\\\\\\\\\\\\\\\\n')\\\\\\\\n        for element in elements:\\\\\\\\n            start_line = element.get('line_start', 1) - 1  # Convert to 0-based\\\\\\\\n            end_line = element.get('line_end', len(lines))\\\\\\\\n            \\\\\\\\n            if start_line < len(lines):\\\\\\\\n                element_content = '\\\\\\\\\\\\\\\\n'.join(lines[start_line:min(end_line, len(lines))])\\\\\\\\n                \\\\\\\\n                element_text = f\\\\\\\\\\\\\\\"Element: {element['name']} ({element['type']})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n                element_text += f\\\\\\\\\\\\\\\"File: {file_analysis['file_path']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n                \\\\\\\\n                if element.get('signature'):\\\\\\\\n                    element_text += f\\\\\\\\\\\\\\\"Signature: {element['signature']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n                \\\\\\\\n                if element.get('docstring'):\\\\\\\\n                    element_text += f\\\\\\\\\\\\\\\"Documentation: {element['docstring']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n                \\\\\\\\n                element_text += f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nCode:\\\\\\\\\\\\\\\\n```{file_analysis.get('language', '')}\\\\\\\\\\\\\\\\n{element_content}\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\"\\\\\\\\n                \\\\\\\\n                chunks.append({\\\\\\\\n                    'text': element_text,\\\\\\\\n                    'type': 'code_element',\\\\\\\\n                    'element_type': element['type'],\\\\\\\\n                    'element_name': element['name'],\\\\\\\\n                    'file_path': file_analysis['file_path'],\\\\\\\\n                    'language': file_analysis.get('language'),\\\\\\\\n                    'line_start': element.get('line_start'),\\\\\\\\n                    'line_end': element.get('line_end'),\\\\\\\\n                    'source': 'code_analysis'\\\\\\\\n                })\\\\\\\\n        \\\\\\\\n        # If no elements found, chunk the entire file content\\\\\\\\n        if not elements and content.strip():\\\\\\\\n            file_chunks = self.chunk_text(\\\\\\\\n                content, \\\\\\\\n                {\\\\\\\\n                    'type': 'file_content',\\\\\\\\n                    'file_path': file_analysis['file_path'],\\\\\\\\n                    'language': file_analysis.get('language'),\\\\\\\\n                    'source': 'file_content'\\\\\\\\n                }\\\\\\\\n            )\\\\\\\\n            chunks.extend(file_chunks)\\\\\\\\n        \\\\\\\\n        return chunks\\\\\\\\n\\\\\\\\nclass VectorStore:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Vector store for embeddings using ChromaDB and local embeddings.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n    def __init__(self, persist_directory: str = None, collection_name: str = None):\\\\\\\\n        self.persist_directory = persist_directory or settings.CHROMA_PERSIST_DIRECTORY\\\\\\\\n        self.collection_name = collection_name or settings.COLLECTION_NAME\\\\\\\\n        \\\\\\\\n        # Initialize ChromaDB\\\\\\\\n        self.client = chromadb.PersistentClient(\\\\\\\\n            path=self.persist_directory,\\\\\\\\n            settings=Settings(anonymized_telemetry=False)\\\\\\\\n        )\\\\\\\\n        \\\\\\\\n        # Get or create collection\\\\\\\\n        try:\\\\\\\\n            self.collection = self.client.get_collection(name=self.collection_name)\\\\\\\\n        except:\\\\\\\\n            self.collection = self.client.create_collection(name=self.collection_name)\\\\\\\\n        \\\\\\\\n        # Initialize embedding models\\\\\\\\n        self.ollama_client = OllamaClient()\\\\\\\\n        \\\\\\\\n        # Fallback to sentence transformers if Ollama embeddings fail\\\\\\\\n        try:\\\\\\\\n            self.sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')\\\\\\\\n        except:\\\\\\\\n            print(\\\\\\\\\\\\\\\"Warning: Could not load sentence transformer model\\\\\\\\\\\\\\\")\\\\\\\\n            self.sentence_transformer = None\\\\\\\\n        \\\\\\\\n        self.chunker = TextChunker()\\\\\\\\n    \\\\\\\\n    def get_embedding(self, text: str) -> List[float]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get embedding for text using available models.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Try Ollama first\\\\\\\\n        if self.ollama_client.is_available():\\\\\\\\n            try:\\\\\\\\n                return self.ollama_client.get_embeddings(text)\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Ollama embedding failed: {e}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        # Fallback to sentence transformer\\\\\\\\n        if self.sentence_transformer:\\\\\\\\n            try:\\\\\\\\n                embedding = self.sentence_transformer.encode(text)\\\\\\\\n                return embedding.tolist()\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Sentence transformer embedding failed: {e}\\\\\\\\\\\\\\\")\\\\\\\\n        \\\\\\\\n        raise Exception(\\\\\\\\\\\\\\\"No embedding model available\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    def add_repository(self, repo_analysis: Dict[str, Any]) -> int:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Add entire repository to vector store.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        repo_name = repo_analysis.get('repo_name', 'unknown')\\\\\\\\n        total_chunks = 0\\\\\\\\n        \\\\\\\\n        # Add repository overview\\\\\\\\n        if repo_analysis.get('files'):\\\\\\\\n            overview_text = f\\\\\\\\\\\\\\\"Repository: {repo_name}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            overview_text += f\\\\\\\\\\\\\\\"Total files: {repo_analysis['statistics']['total_files']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            overview_text += f\\\\\\\\\\\\\\\"Languages: {', '.join(repo_analysis['statistics']['languages'].keys())}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            \\\\\\\\n            # Add file list\\\\\\\\n            overview_text += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nFiles:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            for file_data in repo_analysis['files'][:20]:  # Limit to first 20 files\\\\\\\\n                overview_text += f\\\\\\\\\\\\\\\"- {file_data['file_path']}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            \\\\\\\\n            total_chunks += self.add_document(\\\\\\\\n                overview_text,\\\\\\\\n                {\\\\\\\\n                    'type': 'repository_overview',\\\\\\\\n                    'repo_name': repo_name,\\\\\\\\n                    'source': 'repository_analysis'\\\\\\\\n                }\\\\\\\\n            )\\\\\\\\n        \\\\\\\\n        # Add individual files\\\\\\\\n        for file_data in repo_analysis.get('files', []):\\\\\\\\n            file_chunks = self.add_file_analysis(file_data, repo_name)\\\\\\\\n            total_chunks += file_chunks\\\\\\\\n        \\\\\\\\n        return total_chunks\\\\\\\\n    \\\\\\\\n    def add_file_analysis(self, file_analysis: Dict[str, Any], repo_name: str = None) -> int:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Add file analysis to vector store.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if file_analysis.get('file_type') == 'code':\\\\\\\\n            chunks = self.chunker.chunk_code_file(\\\\\\\\n                file_analysis.get('content', ''), \\\\\\\\n                file_analysis\\\\\\\\n            )\\\\\\\\n        else:\\\\\\\\n            # Regular text chunking for documentation files\\\\\\\\n            chunks = self.chunker.chunk_text(\\\\\\\\n                file_analysis.get('content', ''),\\\\\\\\n                {\\\\\\\\n                    'type': 'documentation',\\\\\\\\n                    'file_path': file_analysis['file_path'],\\\\\\\\n                    'source': 'file_content'\\\\\\\\n                }\\\\\\\\n            )\\\\\\\\n        \\\\\\\\n        # Add repository name to all chunks\\\\\\\\n        for chunk in chunks:\\\\\\\\n            if repo_name:\\\\\\\\n                chunk['repo_name'] = repo_name\\\\\\\\n        \\\\\\\\n        return self.add_chunks(chunks)\\\\\\\\n    \\\\\\\\n    def add_document(self, text: str, metadata: Dict[str, Any]) -> int:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Add a single document to vector store.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        chunks = self.chunker.chunk_text(text, metadata)\\\\\\\\n        return self.add_chunks(chunks)\\\\\\\\n    \\\\\\\\n    def add_chunks(self, chunks: List[Dict[str, Any]]) -> int:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Add multiple chunks to vector store.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not chunks:\\\\\\\\n            return 0\\\\\\\\n        \\\\\\\\n        documents = []\\\\\\\\n        metadatas = []\\\\\\\\n        ids = []\\\\\\\\n        embeddings = []\\\\\\\\n        \\\\\\\\n        for i, chunk in enumerate(chunks):\\\\\\\\n            text = chunk['text']\\\\\\\\n            \\\\\\\\n            # Create unique ID\\\\\\\\n            chunk_id = hashlib.md5(text.encode()).hexdigest()\\\\\\\\n            \\\\\\\\n            # Prepare metadata (remove 'text' key)\\\\\\\\n            metadata = {k: v for k, v in chunk.items() if k != 'text'}\\\\\\\\n            \\\\\\\\n            try:\\\\\\\\n                # Get embedding\\\\\\\\n                embedding = self.get_embedding(text)\\\\\\\\n                \\\\\\\\n                documents.append(text)\\\\\\\\n                metadatas.append(metadata)\\\\\\\\n                ids.append(chunk_id)\\\\\\\\n                embeddings.append(embedding)\\\\\\\\n                \\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Error processing chunk {i}: {e}\\\\\\\\\\\\\\\")\\\\\\\\n                continue\\\\\\\\n        \\\\\\\\n        if documents:\\\\\\\\n            try:\\\\\\\\n                self.collection.add(\\\\\\\\n                    documents=documents,\\\\\\\\n                    metadatas=metadatas,\\\\\\\\n                    ids=ids,\\\\\\\\n                    embeddings=embeddings\\\\\\\\n                )\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Added {len(documents)} chunks to vector store\\\\\\\\\\\\\\\")\\\\\\\\n                return len(documents)\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Error adding to vector store: {e}\\\\\\\\\\\\\\\")\\\\\\\\n                return 0\\\\\\\\n        \\\\\\\\n        return 0\\\\\\\\n    \\\\\\\\n    def search(self, query: str, n_results: int = 5, filter_metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Search vector store for relevant documents.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            query_embedding = self.get_embedding(query)\\\\\\\\n            \\\\\\\\n            search_kwargs = {\\\\\\\\n                'query_embeddings': [query_embedding],\\\\\\\\n                'n_results': n_results\\\\\\\\n            }\\\\\\\\n            \\\\\\\\n            if filter_metadata:\\\\\\\\n                search_kwargs['where'] = filter_metadata\\\\\\\\n            \\\\\\\\n            results = self.collection.query(**search_kwargs)\\\\\\\\n            \\\\\\\\n            # Format results\\\\\\\\n            formatted_results = []\\\\\\\\n            for i in range(len(results['documents'][0])):\\\\\\\\n                formatted_results.append({\\\\\\\\n                    'text': results['documents'][0][i],\\\\\\\\n                    'metadata': results['metadatas'][0][i],\\\\\\\\n                    'distance': results['distances'][0][i],\\\\\\\\n                    'id': results['ids'][0][i]\\\\\\\\n                })\\\\\\\\n            \\\\\\\\n            return formatted_results\\\\\\\\n            \\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error searching vector store: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            return []\\\\\\\\n    \\\\\\\\n    def get_collection_stats(self) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get statistics about the collection.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            count = self.collection.count()\\\\\\\\n            return {\\\\\\\\n                'total_documents': count,\\\\\\\\n                'collection_name': self.collection_name\\\\\\\\n            }\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error getting collection stats: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            return {'total_documents': 0, 'collection_name': self.collection_name}\\\\\\\\n    \\\\\\\\n    def clear_collection(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Clear all documents from collection.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            self.client.delete_collection(name=self.collection_name)\\\\\\\\n            self.collection = self.client.create_collection(name=self.collection_name)\\\\\\\\n            print(\\\\\\\\\\\\\\\"Collection cleared successfully\\\\\\\\\\\\\\\")\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error clearing collection: {e}\\\\\\\\\\\\\\\")\\\\\\\\n    \\\\\\\\n    def delete_repository(self, repo_name: str):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Delete all documents from a specific repository.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            # Get all documents with repo_name\\\\\\\\n            results = self.collection.get(where={\\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\": repo_name})\\\\\\\\n            if results['ids']:\\\\\\\\n                self.collection.delete(ids=results['ids'])\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Deleted {len(results['ids'])} documents for repository {repo_name}\\\\\\\\\\\\\\\")\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error deleting repository {repo_name}: {e}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\data\\\\\\\\\\\\\\\\repos\\\\\\\\\\\\\\\\wikillm_analysis.json\\\\\\\",\\\\n      \\\\\\\"file_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n      \\\\\\\"language\\\\\\\": null,\\\\n      \\\\\\\"imports\\\\\\\": [],\\\\n      \\\\\\\"elements\\\\\\\": [],\\\\n      \\\\\\\"summary\\\\\\\": null,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"{\\\\\\\\n  \\\\\\\\\\\\\\\"repo_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\",\\\\\\\\n  \\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"wikillm\\\\\\\\\\\\\\\",\\\\\\\\n  \\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\": [\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\api.py\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"file_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"imports\\\\\\\\\\\\\\\": [\\\\\\\\n        \\\\\\\\\\\\\\\"asyncio\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"traceback\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"pathlib.Path\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Dict\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.List\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Any\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Optional\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"fastapi.FastAPI\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"fastapi.HTTPException\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"fastapi.BackgroundTasks\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"fastapi.UploadFile\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"fastapi.File\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"fastapi.middleware.cors.CORSMiddleware\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"fastapi.responses.StreamingResponse\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"fastapi.responses.JSONResponse\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"fastapi.staticfiles.StaticFiles\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"pydantic.BaseModel\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"uvicorn\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"config.settings\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"repository_analyzer.RepositoryAnalyzer\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"ollama_client.OllamaClient\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"vector_store.VectorStore\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"rag_system.RAGSystem\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"documentation_generator.DocumentationBuilder\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"documentation_generator.DocumentationConfig\\\\\\\\\\\\\\\"\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"elements\\\\\\\\\\\\\\\": [\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"QueryRequest\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\api.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 23,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 27,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class QueryRequest\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ChatMessage\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\api.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 29,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 31,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class ChatMessage\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ChatRequest\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\api.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 33,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 35,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class ChatRequest\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryRequest\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\api.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 37,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 39,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class RepositoryRequest\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ExplainCodeRequest\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\api.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 41,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 44,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class ExplainCodeRequest\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationRequest\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\api.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 46,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 51,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class DocumentationRequest\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"main\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\api.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 422,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 438,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Main function to run the API server.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def main()\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        }\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"FastAPI server for Local DeepWiki.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\nimport traceback\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom typing import Dict, List, Any, Optional\\\\\\\\\\\\\\\\nfrom fastapi import FastAPI, HTTPException, BackgroundTasks, UploadFile, File\\\\\\\\\\\\\\\\nfrom fastapi.middleware.cors import CORSMiddleware\\\\\\\\\\\\\\\\nfrom fastapi.responses import StreamingResponse, JSONResponse\\\\\\\\\\\\\\\\nfrom fastapi.staticfiles import StaticFiles\\\\\\\\\\\\\\\\nfrom pydantic import BaseModel\\\\\\\\\\\\\\\\nimport uvicorn\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom config import settings\\\\\\\\\\\\\\\\nfrom repository_analyzer import RepositoryAnalyzer\\\\\\\\\\\\\\\\nfrom ollama_client import OllamaClient\\\\\\\\\\\\\\\\nfrom vector_store import VectorStore\\\\\\\\\\\\\\\\nfrom rag_system import RAGSystem\\\\\\\\\\\\\\\\nfrom documentation_generator import DocumentationBuilder, DocumentationConfig\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Pydantic models for API\\\\\\\\\\\\\\\\nclass QueryRequest(BaseModel):\\\\\\\\\\\\\\\\n    query: str\\\\\\\\\\\\\\\\n    repo_name: Optional[str] = None\\\\\\\\\\\\\\\\n    file_path: Optional[str] = None\\\\\\\\\\\\\\\\n    stream: Optional[bool] = False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass ChatMessage(BaseModel):\\\\\\\\\\\\\\\\n    role: str  # 'user' or 'assistant'\\\\\\\\\\\\\\\\n    content: str\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass ChatRequest(BaseModel):\\\\\\\\\\\\\\\\n    messages: List[ChatMessage]\\\\\\\\\\\\\\\\n    repo_name: Optional[str] = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass RepositoryRequest(BaseModel):\\\\\\\\\\\\\\\\n    repo_path: str\\\\\\\\\\\\\\\\n    repo_name: Optional[str] = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass ExplainCodeRequest(BaseModel):\\\\\\\\\\\\\\\\n    code: str\\\\\\\\\\\\\\\\n    language: Optional[str] = None\\\\\\\\\\\\\\\\n    context: Optional[str] = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass DocumentationRequest(BaseModel):\\\\\\\\\\\\\\\\n    repo_name: str\\\\\\\\\\\\\\\\n    include_overview: bool = True\\\\\\\\\\\\\\\\n    include_api_docs: bool = True\\\\\\\\\\\\\\\\n    include_examples: bool = True\\\\\\\\\\\\\\\\n    include_architecture: bool = True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Global instances\\\\\\\\\\\\\\\\napp = FastAPI(title=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Local DeepWiki\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", version=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nollama_client = OllamaClient()\\\\\\\\\\\\\\\\nvector_store = VectorStore()\\\\\\\\\\\\\\\\nrag_system = RAGSystem(vector_store, ollama_client)\\\\\\\\\\\\\\\\nrepository_analyzer = RepositoryAnalyzer()\\\\\\\\\\\\\\\\ndocumentation_builder = DocumentationBuilder(ollama_client)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Add CORS middleware\\\\\\\\\\\\\\\\napp.add_middleware(\\\\\\\\\\\\\\\\n    CORSMiddleware,\\\\\\\\\\\\\\\\n    allow_origins=[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n    allow_credentials=True,\\\\\\\\\\\\\\\\n    allow_methods=[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n    allow_headers=[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Health check endpoints\\\\\\\\\\\\\\\\n@app.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/health\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def health_check():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Health check endpoint.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    ollama_available = ollama_client.is_available()\\\\\\\\\\\\\\\\n    vector_stats = vector_store.get_collection_stats()\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    return {\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"healthy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ollama_available\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": ollama_available,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ollama_url\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": settings.OLLAMA_BASE_URL,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ollama_model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": settings.OLLAMA_MODEL,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"vector_store\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": vector_stats\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@app.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/models\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def list_models():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"List available Ollama models.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        models = ollama_client.list_models()\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"models\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": models}\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error listing models: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Repository management endpoints\\\\\\\\\\\\\\\\n@app.post(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/repositories/analyze\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def analyze_repository(request: RepositoryRequest, background_tasks: BackgroundTasks):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyze a repository and add it to the vector store.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    repo_path = Path(request.repo_path)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    if not repo_path.exists():\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=404, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository path not found: {repo_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    repo_name = request.repo_name or repo_path.name\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        # Start analysis in background\\\\\\\\\\\\\\\\n        background_tasks.add_task(analyze_repository_task, str(repo_path), repo_name)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository analysis started for {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": repo_name,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo_path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": str(repo_path)\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error starting analysis: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nasync def analyze_repository_task(repo_path: str, repo_name: str):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Background task to analyze repository.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Starting analysis of {repo_name} at {repo_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Analyze repository\\\\\\\\\\\\\\\\n        analysis = repository_analyzer.analyze_repository(repo_path)\\\\\\\\\\\\\\\\n        analysis['repo_name'] = repo_name\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Save analysis\\\\\\\\\\\\\\\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{repo_name}_analysis.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        repository_analyzer.save_analysis(analysis, str(analysis_path))\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add to vector store\\\\\\\\\\\\\\\\n        chunks_added = vector_store.add_repository(analysis)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analysis complete for {repo_name}: {chunks_added} chunks added to vector store\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error in repository analysis task: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        traceback.print_exc()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@app.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/repositories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def list_repositories():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"List analyzed repositories.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    repos = []\\\\\\\\\\\\\\\\n    repos_dir = Path(settings.REPOS_DIRECTORY)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    if repos_dir.exists():\\\\\\\\\\\\\\\\n        for analysis_file in repos_dir.glob(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"*_analysis.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                analysis = repository_analyzer.load_analysis(str(analysis_file))\\\\\\\\\\\\\\\\n                repos.append({\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": analysis.get('repo_name', analysis_file.stem.replace('_analysis', '')),\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": analysis.get('repo_path', ''),\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": analysis.get('statistics', {}).get('total_files', 0),\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"languages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": list(analysis.get('statistics', {}).get('languages', {}).keys())\\\\\\\\\\\\\\\\n                })\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error loading analysis from {analysis_file}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repositories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": repos}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@app.delete(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/repositories/{repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def delete_repository(repo_name: str):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Delete repository from vector store.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        vector_store.delete_repository(repo_name)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Also delete analysis file\\\\\\\\\\\\\\\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{repo_name}_analysis.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if analysis_path.exists():\\\\\\\\\\\\\\\\n            analysis_path.unlink()\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository {repo_name} deleted successfully\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error deleting repository: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Query endpoints\\\\\\\\\\\\\\\\n@app.post(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/query\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def query_repository(request: QueryRequest):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Query repository using RAG system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        if request.stream:\\\\\\\\\\\\\\\\n            # Return streaming response\\\\\\\\\\\\\\\\n            return StreamingResponse(\\\\\\\\\\\\\\\\n                stream_query_response(request),\\\\\\\\\\\\\\\\n                media_type=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text/plain\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            # Return complete response\\\\\\\\\\\\\\\\n            result = rag_system.query(\\\\\\\\\\\\\\\\n                request.query,\\\\\\\\\\\\\\\\n                repo_name=request.repo_name,\\\\\\\\\\\\\\\\n                file_path=request.file_path,\\\\\\\\\\\\\\\\n                stream=False\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n            return result\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error processing query: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nasync def stream_query_response(request: QueryRequest):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Stream query response for real-time updates.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        # Get context first\\\\\\\\\\\\\\\\n        filter_metadata = {}\\\\\\\\\\\\\\\\n        if request.repo_name:\\\\\\\\\\\\\\\\n            filter_metadata['repo_name'] = request.repo_name\\\\\\\\\\\\\\\\n        if request.file_path:\\\\\\\\\\\\\\\\n            filter_metadata['file_path'] = request.file_path\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        retrieved_chunks = rag_system.retrieve_context(\\\\\\\\\\\\\\\\n            request.query, \\\\\\\\\\\\\\\\n            n_results=5, \\\\\\\\\\\\\\\\n            filter_metadata=filter_metadata or None\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if not retrieved_chunks:\\\\\\\\\\\\\\\\n            yield \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No relevant context found for query.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        context_text = rag_system.build_context_text(retrieved_chunks)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Build prompt\\\\\\\\\\\\\\\\n        system_prompt = rag_system.system_prompts['general_question']\\\\\\\\\\\\\\\\n        full_prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{system_prompt}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCONTEXT:\\\\\\\\\\\\\\\\n{context_text}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nUSER QUERY: {request.query}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nPlease provide a helpful response based on the context above.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Stream response\\\\\\\\\\\\\\\\n        async for chunk in ollama_client.generate_stream(full_prompt, temperature=0.3):\\\\\\\\\\\\\\\\n            yield chunk\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        yield f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@app.post(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def chat_with_repository(request: ChatRequest):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Chat interface for conversational interaction.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        messages = [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": msg.role, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": msg.content} for msg in request.messages]\\\\\\\\\\\\\\\\n        response = rag_system.chat_with_repo(messages, request.repo_name)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": response,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": request.repo_name\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error in chat: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@app.post(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/explain\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def explain_code(request: ExplainCodeRequest):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Explain code snippet.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        explanation = rag_system.explain_code(\\\\\\\\\\\\\\\\n            request.code,\\\\\\\\\\\\\\\\n            request.language,\\\\\\\\\\\\\\\\n            request.context\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"explanation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": explanation}\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error explaining code: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@app.post(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/improve\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def suggest_improvements(request: ExplainCodeRequest):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Suggest code improvements.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        suggestions = rag_system.suggest_improvements(\\\\\\\\\\\\\\\\n            request.code,\\\\\\\\\\\\\\\\n            request.language\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"suggestions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": suggestions}\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error suggesting improvements: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@app.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/repositories/{repo_name}/overview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def get_repository_overview(repo_name: str):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get repository overview.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        overview = rag_system.get_repository_overview(repo_name)\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"overview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": overview, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": repo_name}\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error getting overview: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@app.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/repositories/{repo_name}/files/{file_path:path}/summary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def get_file_summary(repo_name: str, file_path: str):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get file summary.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        summary = rag_system.get_file_summary(file_path, repo_name)\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": summary, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": file_path, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": repo_name}\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error getting file summary: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Documentation endpoints\\\\\\\\\\\\\\\\n@app.post(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/repositories/{repo_name}/generate-docs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def generate_documentation(repo_name: str, request: DocumentationRequest, background_tasks: BackgroundTasks):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate comprehensive documentation for repository.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        # Load repository analysis\\\\\\\\\\\\\\\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{repo_name}_analysis.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not analysis_path.exists():\\\\\\\\\\\\\\\\n            raise HTTPException(status_code=404, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository {repo_name} not found. Please analyze it first.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        analysis = repository_analyzer.load_analysis(str(analysis_path))\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        config = DocumentationConfig(\\\\\\\\\\\\\\\\n            include_overview=request.include_overview,\\\\\\\\\\\\\\\\n            include_api_docs=request.include_api_docs,\\\\\\\\\\\\\\\\n            include_examples=request.include_examples,\\\\\\\\\\\\\\\\n            include_architecture=request.include_architecture\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Start documentation generation in background\\\\\\\\\\\\\\\\n        background_tasks.add_task(generate_docs_task, analysis, config, repo_name)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Documentation generation started for {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": repo_name\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error starting documentation generation: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nasync def generate_docs_task(analysis: Dict[str, Any], config: DocumentationConfig, repo_name: str):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Background task to generate documentation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Starting documentation generation for {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        docs = documentation_builder.generate_full_documentation(analysis, config)\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Documentation generation complete for {repo_name}: {len(docs)} files generated\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error in documentation generation task: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        traceback.print_exc()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@app.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/repositories/{repo_name}/docs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def list_generated_docs(repo_name: str):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"List generated documentation files.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    docs_dir = Path(settings.DOCS_DIRECTORY) / repo_name\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    if not docs_dir.exists():\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"documents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": []}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    docs = []\\\\\\\\\\\\\\\\n    for doc_file in docs_dir.rglob(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"*.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n        relative_path = doc_file.relative_to(docs_dir)\\\\\\\\\\\\\\\\n        docs.append({\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": doc_file.name,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": str(relative_path),\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": doc_file.stat().st_size\\\\\\\\\\\\\\\\n        })\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"documents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": docs}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@app.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/repositories/{repo_name}/docs/{doc_path:path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def get_documentation(repo_name: str, doc_path: str):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get specific documentation file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    doc_file = Path(settings.DOCS_DIRECTORY) / repo_name / doc_path\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    if not doc_file.exists():\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=404, detail=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Documentation file not found\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        with open(doc_file, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n            content = f.read()\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": content,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": doc_path,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": repo_name\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error reading documentation: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Search endpoints\\\\\\\\\\\\\\\\n@app.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/search\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def search_all_repositories(q: str, limit: int = 10):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Search across all repositories.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        results = vector_store.search(q, n_results=limit)\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": results, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"query\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": q}\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error searching: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@app.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/repositories/{repo_name}/search\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def search_repository(repo_name: str, q: str, limit: int = 10):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Search within specific repository.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        results = vector_store.search(\\\\\\\\\\\\\\\\n            q, \\\\\\\\\\\\\\\\n            n_results=limit, \\\\\\\\\\\\\\\\n            filter_metadata={\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": repo_name}\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": results, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"query\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": q, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": repo_name}\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error searching repository: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Statistics endpoint\\\\\\\\\\\\\\\\n@app.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/stats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nasync def get_system_stats():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get system statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        vector_stats = vector_store.get_collection_stats()\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Count repositories\\\\\\\\\\\\\\\\n        repos_dir = Path(settings.REPOS_DIRECTORY)\\\\\\\\\\\\\\\\n        repo_count = len(list(repos_dir.glob(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"*_analysis.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))) if repos_dir.exists() else 0\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Count generated docs\\\\\\\\\\\\\\\\n        docs_dir = Path(settings.DOCS_DIRECTORY)\\\\\\\\\\\\\\\\n        doc_count = len(list(docs_dir.rglob(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"*.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))) if docs_dir.exists() else 0\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repositories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": repo_count,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"documents_in_vector_store\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": vector_stats.get('total_documents', 0),\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"generated_docs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": doc_count,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ollama_available\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": ollama_client.is_available(),\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ollama_model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": settings.OLLAMA_MODEL\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        raise HTTPException(status_code=500, detail=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error getting stats: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Main function to run the server\\\\\\\\\\\\\\\\ndef main():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main function to run the API server.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Starting Local DeepWiki server on {settings.API_HOST}:{settings.API_PORT}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Ollama URL: {settings.OLLAMA_BASE_URL}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Model: {settings.OLLAMA_MODEL}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Check Ollama availability\\\\\\\\\\\\\\\\n    if not ollama_client.is_available():\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"WARNING: Ollama server not available. Please start Ollama first.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Run: ollama serve\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    uvicorn.run(\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"api:app\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        host=settings.API_HOST,\\\\\\\\\\\\\\\\n        port=settings.API_PORT,\\\\\\\\\\\\\\\\n        reload=True\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n    main()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\config.py\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"file_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"imports\\\\\\\\\\\\\\\": [\\\\\\\\n        \\\\\\\\\\\\\\\"os\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"pathlib.Path\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.List\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Dict\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Any\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"pydantic_settings.BaseSettings\\\\\\\\\\\\\\\"\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"elements\\\\\\\\\\\\\\\": [\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Settings\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\config.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 8,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 53,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Application settings.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class Settings\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Config\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\config.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 52,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 53,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class Config\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        }\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Configuration settings for Local DeepWiki.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom typing import List, Dict, Any\\\\\\\\\\\\\\\\nfrom pydantic_settings import BaseSettings\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass Settings(BaseSettings):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Application settings.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Ollama settings\\\\\\\\\\\\\\\\n    OLLAMA_BASE_URL: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"http://localhost:11434\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    OLLAMA_MODEL: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"deepseek-coder:6.7b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Using available code-focused model\\\\\\\\\\\\\\\\n    OLLAMA_EMBEDDING_MODEL: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"nomic-embed-text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Vector database settings\\\\\\\\\\\\\\\\n    CHROMA_PERSIST_DIRECTORY: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"./data/chroma_db\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    COLLECTION_NAME: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"codebase_docs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Repository settings\\\\\\\\\\\\\\\\n    REPOS_DIRECTORY: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"./data/repos\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    DOCS_DIRECTORY: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"./data/generated_docs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Generation settings\\\\\\\\\\\\\\\\n    MAX_CHUNK_SIZE: int = 2000\\\\\\\\\\\\\\\\n    CHUNK_OVERLAP: int = 200\\\\\\\\\\\\\\\\n    MAX_CONTEXT_LENGTH: int = 4000\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # API settings\\\\\\\\\\\\\\\\n    API_HOST: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"0.0.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    API_PORT: int = 8000\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Supported file extensions\\\\\\\\\\\\\\\\n    CODE_EXTENSIONS: List[str] = [\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".js\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".ts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".jsx\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".tsx\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".java\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".cpp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".c\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".h\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".cs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".php\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".rb\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".go\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".rs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".swift\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".kt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".scala\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".r\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".sql\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".sh\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".yml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".xml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".css\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".scss\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".less\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".vue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".svelte\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    ]\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    DOC_EXTENSIONS: List[str] = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".rst\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".adoc\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Ignored directories\\\\\\\\\\\\\\\\n    IGNORED_DIRS: List[str] = [\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".git\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".svn\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".hg\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__pycache__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".pytest_cache\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"node_modules\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".npm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".yarn\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bower_components\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".venv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"venv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"env\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".env\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"virtualenv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dist\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"build\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"target\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bin\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"obj\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".idea\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".vscode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".vs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"*.egg-info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    ]\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    class Config:\\\\\\\\\\\\\\\\n        env_file = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".env\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Global settings instance\\\\\\\\\\\\\\\\nsettings = Settings()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Ensure data directories exist\\\\\\\\\\\\\\\\nPath(settings.CHROMA_PERSIST_DIRECTORY).mkdir(parents=True, exist_ok=True)\\\\\\\\\\\\\\\\nPath(settings.REPOS_DIRECTORY).mkdir(parents=True, exist_ok=True)\\\\\\\\\\\\\\\\nPath(settings.DOCS_DIRECTORY).mkdir(parents=True, exist_ok=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"file_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"imports\\\\\\\\\\\\\\\": [\\\\\\\\n        \\\\\\\\\\\\\\\"os\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"pathlib.Path\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Dict\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.List\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Any\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Optional\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"dataclasses.dataclass\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"markdown\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"jinja2.Template\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"ollama_client.OllamaClient\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"ollama_client.DocumentationGenerator\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"repository_analyzer.RepositoryAnalyzer\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"config.settings\\\\\\\\\\\\\\\"\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"elements\\\\\\\\\\\\\\\": [\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationConfig\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 15,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 22,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Configuration for documentation generation.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class DocumentationConfig\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationBuilder\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 24,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 502,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Build comprehensive documentation from repository analysis.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class DocumentationBuilder\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationBuilder.__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 27,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 94,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self, ollama_client)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationBuilder.generate_full_documentation\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 96,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 161,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate complete documentation for a repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_full_documentation(self, repo_analysis, config, output_dir)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationBuilder.generate_repository_readme\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 163,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 224,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate main repository README.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_repository_readme(self, repo_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationBuilder.generate_file_api_docs\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 226,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 303,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate API documentation for a single file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_file_api_docs(self, file_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationBuilder.generate_architecture_docs\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 305,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 366,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate architecture documentation.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_architecture_docs(self, repo_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationBuilder.generate_examples_docs\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 368,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 447,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate usage examples documentation.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_examples_docs(self, repo_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationBuilder.generate_table_of_contents\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 449,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 470,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate table of contents for all documentation.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_table_of_contents(self, documentation)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationBuilder.update_existing_docs\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 472,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 502,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Update existing documentation files with new analysis.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def update_existing_docs(self, repo_path, analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 27,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 94,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self, ollama_client)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"generate_full_documentation\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 96,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 161,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate complete documentation for a repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_full_documentation(self, repo_analysis, config, output_dir)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"generate_repository_readme\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 163,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 224,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate main repository README.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_repository_readme(self, repo_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"generate_file_api_docs\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 226,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 303,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate API documentation for a single file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_file_api_docs(self, file_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"generate_architecture_docs\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 305,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 366,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate architecture documentation.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_architecture_docs(self, repo_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"generate_examples_docs\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 368,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 447,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate usage examples documentation.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_examples_docs(self, repo_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"generate_table_of_contents\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 449,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 470,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate table of contents for all documentation.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_table_of_contents(self, documentation)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"update_existing_docs\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 472,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 502,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Update existing documentation files with new analysis.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def update_existing_docs(self, repo_path, analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        }\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Documentation generation system using local LLMs.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom typing import Dict, List, Any, Optional\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\\\\\\\\\nimport markdown\\\\\\\\\\\\\\\\nfrom jinja2 import Template\\\\\\\\\\\\\\\\nfrom ollama_client import OllamaClient, DocumentationGenerator\\\\\\\\\\\\\\\\nfrom repository_analyzer import RepositoryAnalyzer\\\\\\\\\\\\\\\\nfrom config import settings\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass DocumentationConfig:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Configuration for documentation generation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    include_overview: bool = True\\\\\\\\\\\\\\\\n    include_api_docs: bool = True\\\\\\\\\\\\\\\\n    include_examples: bool = True\\\\\\\\\\\\\\\\n    include_architecture: bool = True\\\\\\\\\\\\\\\\n    output_format: str = 'markdown'  # 'markdown', 'html'\\\\\\\\\\\\\\\\n    template_style: str = 'default'  # 'default', 'minimal', 'detailed'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass DocumentationBuilder:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Build comprehensive documentation from repository analysis.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def __init__(self, ollama_client: OllamaClient):\\\\\\\\\\\\\\\\n        self.ollama_client = ollama_client\\\\\\\\\\\\\\\\n        self.doc_generator = DocumentationGenerator(ollama_client)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Documentation templates\\\\\\\\\\\\\\\\n        self.templates = {\\\\\\\\\\\\\\\\n            'repository_readme': \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# {{ repo_name }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ overview }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Architecture\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ architecture }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Getting Started\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ getting_started }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## API Documentation\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ api_docs }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Examples\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ examples }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Contributing\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ contributing }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            'api_reference': \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# API Reference - {{ file_name }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ file_overview }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Classes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ classes }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Functions\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ functions }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Constants\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ constants }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            'module_docs': \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# {{ module_name }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ description }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Usage\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ usage }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Implementation Details\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ implementation }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Dependencies\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{{ dependencies }}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def generate_full_documentation(self, \\\\\\\\\\\\\\\\n                                  repo_analysis: Dict[str, Any], \\\\\\\\\\\\\\\\n                                  config: DocumentationConfig = None,\\\\\\\\\\\\\\\\n                                  output_dir: str = None) -> Dict[str, str]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate complete documentation for a repository.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if config is None:\\\\\\\\\\\\\\\\n            config = DocumentationConfig()\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if output_dir is None:\\\\\\\\\\\\\\\\n            output_dir = settings.DOCS_DIRECTORY\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        output_dir = Path(output_dir)\\\\\\\\\\\\\\\\n        repo_name = repo_analysis.get('repo_name', 'unknown')\\\\\\\\\\\\\\\\n        repo_output_dir = output_dir / repo_name\\\\\\\\\\\\\\\\n        repo_output_dir.mkdir(parents=True, exist_ok=True)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        documentation = {}\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Generate main README\\\\\\\\\\\\\\\\n        if config.include_overview:\\\\\\\\\\\\\\\\n            readme_content = self.generate_repository_readme(repo_analysis)\\\\\\\\\\\\\\\\n            readme_path = repo_output_dir / 'README.md'\\\\\\\\\\\\\\\\n            with open(readme_path, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n                f.write(readme_content)\\\\\\\\\\\\\\\\n            documentation['README.md'] = readme_content\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Generate API documentation for each file\\\\\\\\\\\\\\\\n        if config.include_api_docs:\\\\\\\\\\\\\\\\n            api_dir = repo_output_dir / 'api'\\\\\\\\\\\\\\\\n            api_dir.mkdir(exist_ok=True)\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            for file_data in repo_analysis.get('files', []):\\\\\\\\\\\\\\\\n                if file_data.get('file_type') == 'code':\\\\\\\\\\\\\\\\n                    api_doc = self.generate_file_api_docs(file_data)\\\\\\\\\\\\\\\\n                    file_name = Path(file_data['file_path']).stem\\\\\\\\\\\\\\\\n                    api_file_path = api_dir / f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{file_name}.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    with open(api_file_path, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n                        f.write(api_doc)\\\\\\\\\\\\\\\\n                    documentation[f'api/{file_name}.md'] = api_doc\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Generate architecture documentation\\\\\\\\\\\\\\\\n        if config.include_architecture:\\\\\\\\\\\\\\\\n            arch_doc = self.generate_architecture_docs(repo_analysis)\\\\\\\\\\\\\\\\n            arch_path = repo_output_dir / 'ARCHITECTURE.md'\\\\\\\\\\\\\\\\n            with open(arch_path, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n                f.write(arch_doc)\\\\\\\\\\\\\\\\n            documentation['ARCHITECTURE.md'] = arch_doc\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Generate examples\\\\\\\\\\\\\\\\n        if config.include_examples:\\\\\\\\\\\\\\\\n            examples_doc = self.generate_examples_docs(repo_analysis)\\\\\\\\\\\\\\\\n            examples_path = repo_output_dir / 'EXAMPLES.md'\\\\\\\\\\\\\\\\n            with open(examples_path, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n                f.write(examples_doc)\\\\\\\\\\\\\\\\n            documentation['EXAMPLES.md'] = examples_doc\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Generate table of contents\\\\\\\\\\\\\\\\n        toc = self.generate_table_of_contents(documentation)\\\\\\\\\\\\\\\\n        toc_path = repo_output_dir / 'TABLE_OF_CONTENTS.md'\\\\\\\\\\\\\\\\n        with open(toc_path, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n            f.write(toc)\\\\\\\\\\\\\\\\n        documentation['TABLE_OF_CONTENTS.md'] = toc\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return documentation\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def generate_repository_readme(self, repo_analysis: Dict[str, Any]) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate main repository README.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        repo_name = repo_analysis.get('repo_name', 'Repository')\\\\\\\\\\\\\\\\n        stats = repo_analysis.get('statistics', {})\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Build context for LLM\\\\\\\\\\\\\\\\n        context = []\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository: {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Total files: {stats.get('total_files', 0)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Code files: {stats.get('code_files', 0)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Languages: {', '.join(stats.get('languages', {}).keys())}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add git information\\\\\\\\\\\\\\\\n        git_info = repo_analysis.get('git_info')\\\\\\\\\\\\\\\\n        if git_info:\\\\\\\\\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Current branch: {git_info.get('current_branch', 'main')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            if git_info.get('last_commit'):\\\\\\\\\\\\\\\\n                commit = git_info['last_commit']\\\\\\\\\\\\\\\\n                context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Last commit: {commit.get('message', '')[:100]}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add file structure overview\\\\\\\\\\\\\\\\n        main_files = []\\\\\\\\\\\\\\\\n        config_files = []\\\\\\\\\\\\\\\\n        doc_files = []\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        for file_data in repo_analysis.get('files', []):\\\\\\\\\\\\\\\\n            file_path = file_data['file_path']\\\\\\\\\\\\\\\\n            if any(name in file_path.lower() for name in ['readme', 'license', 'changelog']):\\\\\\\\\\\\\\\\n                doc_files.append(file_path)\\\\\\\\\\\\\\\\n            elif any(ext in file_path.lower() for ext in ['.json', '.yaml', '.yml', '.toml', '.ini']):\\\\\\\\\\\\\\\\n                config_files.append(file_path)\\\\\\\\\\\\\\\\n            elif file_data.get('file_type') == 'code':\\\\\\\\\\\\\\\\n                main_files.append(file_path)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main code files: {', '.join(main_files[:10])}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        if config_files:\\\\\\\\\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Configuration files: {', '.join(config_files[:5])}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        if doc_files:\\\\\\\\\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Documentation files: {', '.join(doc_files)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        context_str = '\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n'.join(context)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate a comprehensive README.md for this repository based on the following information:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{context_str}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nPlease include:\\\\\\\\\\\\\\\\n1. Project title and brief description\\\\\\\\\\\\\\\\n2. Features and capabilities\\\\\\\\\\\\\\\\n3. Installation instructions\\\\\\\\\\\\\\\\n4. Quick start guide\\\\\\\\\\\\\\\\n5. Usage examples\\\\\\\\\\\\\\\\n6. Project structure overview\\\\\\\\\\\\\\\\n7. Contributing guidelines\\\\\\\\\\\\\\\\n8. License information\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nMake it professional and well-formatted with proper Markdown syntax.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nError generating README: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def generate_file_api_docs(self, file_analysis: Dict[str, Any]) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate API documentation for a single file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        file_path = file_analysis['file_path']\\\\\\\\\\\\\\\\n        language = file_analysis.get('language', 'Unknown')\\\\\\\\\\\\\\\\n        elements = file_analysis.get('elements', [])\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Group elements by type\\\\\\\\\\\\\\\\n        classes = [e for e in elements if e['type'] == 'class']\\\\\\\\\\\\\\\\n        functions = [e for e in elements if e['type'] in ['function', 'method']]\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        doc_content = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# API Reference - {Path(file_path).name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"**File**: `{file_path}`  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"**Language**: {language}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # File overview\\\\\\\\\\\\\\\\n        overview_prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Provide a brief overview of this {language} file:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nFile: {file_path}\\\\\\\\\\\\\\\\nElements: {len(elements)} total ({len(classes)} classes, {len(functions)} functions)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nContent preview:\\\\\\\\\\\\\\\\n{file_analysis.get('content', '')[:1000]}...\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWrite a 2-3 sentence overview of what this file does.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            overview = self.ollama_client.generate(overview_prompt, temperature=0.3)\\\\\\\\\\\\\\\\n            doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"## Overview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n{overview}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        except:\\\\\\\\\\\\\\\\n            doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"## Overview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis file contains {len(elements)} code elements.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Document classes\\\\\\\\\\\\\\\\n        if classes:\\\\\\\\\\\\\\\\n            doc_content += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"## Classes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            for cls in classes:\\\\\\\\\\\\\\\\n                doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"### {cls['name']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                if cls.get('docstring'):\\\\\\\\\\\\\\\\n                    doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{cls['docstring']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                # Get methods for this class\\\\\\\\\\\\\\\\n                class_methods = [e for e in elements if e['type'] == 'method' and e['name'].startswith(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{cls['name']}.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")]\\\\\\\\\\\\\\\\n                if class_methods:\\\\\\\\\\\\\\\\n                    doc_content += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"#### Methods\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    for method in class_methods:\\\\\\\\\\\\\\\\n                        method_name = method['name'].split('.')[-1]\\\\\\\\\\\\\\\\n                        doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- **{method_name}**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                        if method.get('signature'):\\\\\\\\\\\\\\\\n                            doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": `{method['signature']}`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                        if method.get('docstring'):\\\\\\\\\\\\\\\\n                            doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" - {method['docstring'][:100]}...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                        doc_content += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    doc_content += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Document functions\\\\\\\\\\\\\\\\n        if functions:\\\\\\\\\\\\\\\\n            doc_content += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"## Functions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            for func in functions:\\\\\\\\\\\\\\\\n                if func['type'] == 'method':\\\\\\\\\\\\\\\\n                    continue  # Skip methods (already documented with classes)\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"### {func['name']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                if func.get('signature'):\\\\\\\\\\\\\\\\n                    doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"```{language}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n{func['signature']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                if func.get('docstring'):\\\\\\\\\\\\\\\\n                    doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{func['docstring']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add imports if available\\\\\\\\\\\\\\\\n        imports = file_analysis.get('imports', [])\\\\\\\\\\\\\\\\n        if imports:\\\\\\\\\\\\\\\\n            doc_content += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"## Dependencies\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            doc_content += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"This file imports:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            for imp in imports[:10]:  # Limit to first 10 imports\\\\\\\\\\\\\\\\n                doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- `{imp}`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            if len(imports) > 10:\\\\\\\\\\\\\\\\n                doc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- ... and {len(imports) - 10} more\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            doc_content += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return doc_content\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def generate_architecture_docs(self, repo_analysis: Dict[str, Any]) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate architecture documentation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        repo_name = repo_analysis.get('repo_name', 'Repository')\\\\\\\\\\\\\\\\n        stats = repo_analysis.get('statistics', {})\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Analyze project structure\\\\\\\\\\\\\\\\n        languages = stats.get('languages', {})\\\\\\\\\\\\\\\\n        files = repo_analysis.get('files', [])\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Group files by directory\\\\\\\\\\\\\\\\n        directories = {}\\\\\\\\\\\\\\\\n        for file_data in files:\\\\\\\\\\\\\\\\n            dir_path = str(Path(file_data['file_path']).parent)\\\\\\\\\\\\\\\\n            if dir_path not in directories:\\\\\\\\\\\\\\\\n                directories[dir_path] = []\\\\\\\\\\\\\\\\n            directories[dir_path].append(file_data)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Build context for architecture analysis\\\\\\\\\\\\\\\\n        context = []\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository: {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Languages: {', '.join(languages.keys())}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Total files: {stats.get('total_files', 0)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        context.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nDirectory structure:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        for dir_path, dir_files in sorted(directories.items())[:15]:  # Limit directories\\\\\\\\\\\\\\\\n            file_count = len(dir_files)\\\\\\\\\\\\\\\\n            main_types = set()\\\\\\\\\\\\\\\\n            for f in dir_files:\\\\\\\\\\\\\\\\n                if f.get('language'):\\\\\\\\\\\\\\\\n                    main_types.add(f['language'])\\\\\\\\\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- {dir_path}: {file_count} files ({', '.join(main_types)})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add key files analysis\\\\\\\\\\\\\\\\n        key_files = []\\\\\\\\\\\\\\\\n        for file_data in files:\\\\\\\\\\\\\\\\n            if any(keyword in file_data['file_path'].lower() for keyword in ['main', 'app', 'index', '__init__', 'server', 'client']):\\\\\\\\\\\\\\\\n                key_files.append(file_data['file_path'])\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if key_files:\\\\\\\\\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nKey files: {', '.join(key_files[:10])}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        context_str = '\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n'.join(context)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyze the architecture of this project and generate comprehensive architecture documentation:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{context_str}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nPlease provide:\\\\\\\\\\\\\\\\n1. High-level architecture overview\\\\\\\\\\\\\\\\n2. Component breakdown and relationships\\\\\\\\\\\\\\\\n3. Data flow and system interactions\\\\\\\\\\\\\\\\n4. Design patterns used\\\\\\\\\\\\\\\\n5. Technology stack analysis\\\\\\\\\\\\\\\\n6. Scalability considerations\\\\\\\\\\\\\\\\n7. Deployment architecture\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nFormat as professional technical documentation with proper Markdown structure.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# Architecture Documentation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nError generating architecture docs: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def generate_examples_docs(self, repo_analysis: Dict[str, Any]) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate usage examples documentation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        repo_name = repo_analysis.get('repo_name', 'Repository')\\\\\\\\\\\\\\\\n        languages = repo_analysis.get('statistics', {}).get('languages', {})\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Find main entry points\\\\\\\\\\\\\\\\n        entry_points = []\\\\\\\\\\\\\\\\n        main_classes = []\\\\\\\\\\\\\\\\n        main_functions = []\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        for file_data in repo_analysis.get('files', []):\\\\\\\\\\\\\\\\n            if file_data.get('file_type') == 'code':\\\\\\\\\\\\\\\\n                elements = file_data.get('elements', [])\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                # Look for main functions or entry points\\\\\\\\\\\\\\\\n                for element in elements:\\\\\\\\\\\\\\\\n                    if element['name'].lower() in ['main', 'run', 'start', 'init']:\\\\\\\\\\\\\\\\n                        entry_points.append({\\\\\\\\\\\\\\\\n                            'name': element['name'],\\\\\\\\\\\\\\\\n                            'file': file_data['file_path'],\\\\\\\\\\\\\\\\n                            'signature': element.get('signature', ''),\\\\\\\\\\\\\\\\n                            'type': element['type']\\\\\\\\\\\\\\\\n                        })\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    if element['type'] == 'class' and len(element.get('name', '')) > 3:\\\\\\\\\\\\\\\\n                        main_classes.append({\\\\\\\\\\\\\\\\n                            'name': element['name'],\\\\\\\\\\\\\\\\n                            'file': file_data['file_path'],\\\\\\\\\\\\\\\\n                            'signature': element.get('signature', ''),\\\\\\\\\\\\\\\\n                            'docstring': element.get('docstring', '')\\\\\\\\\\\\\\\\n                        })\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    if element['type'] == 'function' and element.get('docstring'):\\\\\\\\\\\\\\\\n                        main_functions.append({\\\\\\\\\\\\\\\\n                            'name': element['name'],\\\\\\\\\\\\\\\\n                            'file': file_data['file_path'],\\\\\\\\\\\\\\\\n                            'signature': element.get('signature', ''),\\\\\\\\\\\\\\\\n                            'docstring': element.get('docstring', '')\\\\\\\\\\\\\\\\n                        })\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Build context\\\\\\\\\\\\\\\\n        context = []\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository: {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Languages: {', '.join(languages.keys())}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if entry_points:\\\\\\\\\\\\\\\\n            context.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nEntry points:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            for ep in entry_points[:5]:\\\\\\\\\\\\\\\\n                context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- {ep['name']} in {ep['file']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if main_classes:\\\\\\\\\\\\\\\\n            context.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nMain classes:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            for cls in main_classes[:5]:\\\\\\\\\\\\\\\\n                context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- {cls['name']} in {cls['file']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if main_functions:\\\\\\\\\\\\\\\\n            context.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nKey functions:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            for func in main_functions[:5]:\\\\\\\\\\\\\\\\n                context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- {func['name']} in {func['file']}: {func['docstring'][:50]}...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        context_str = '\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n'.join(context)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate practical usage examples and tutorials for this project:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{context_str}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nPlease provide:\\\\\\\\\\\\\\\\n1. Quick start example\\\\\\\\\\\\\\\\n2. Basic usage patterns\\\\\\\\\\\\\\\\n3. Common use cases with code examples\\\\\\\\\\\\\\\\n4. Integration examples\\\\\\\\\\\\\\\\n5. Configuration examples\\\\\\\\\\\\\\\\n6. Troubleshooting common issues\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nInclude actual code snippets with explanations. Format with proper Markdown and code blocks.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# Usage Examples\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nError generating examples: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def generate_table_of_contents(self, documentation: Dict[str, str]) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate table of contents for all documentation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        toc_content = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# Table of Contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        toc_content += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"This repository contains the following documentation:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Main documentation\\\\\\\\\\\\\\\\n        main_docs = ['README.md', 'ARCHITECTURE.md', 'EXAMPLES.md']\\\\\\\\\\\\\\\\n        for doc in main_docs:\\\\\\\\\\\\\\\\n            if doc in documentation:\\\\\\\\\\\\\\\\n                toc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- [{doc}](./{doc})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # API documentation\\\\\\\\\\\\\\\\n        api_docs = [k for k in documentation.keys() if k.startswith('api/')]\\\\\\\\\\\\\\\\n        if api_docs:\\\\\\\\\\\\\\\\n            toc_content += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## API Documentation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            for doc in sorted(api_docs):\\\\\\\\\\\\\\\\n                file_name = Path(doc).stem\\\\\\\\\\\\\\\\n                toc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- [{file_name}](./{doc})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        toc_content += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n*Documentation generated automatically from codebase analysis.*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return toc_content\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def update_existing_docs(self, repo_path: str, analysis: Dict[str, Any]) -> Dict[str, str]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Update existing documentation files with new analysis.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        repo_path = Path(repo_path)\\\\\\\\\\\\\\\\n        updates = {}\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Check for existing README\\\\\\\\\\\\\\\\n        readme_path = repo_path / 'README.md'\\\\\\\\\\\\\\\\n        if readme_path.exists():\\\\\\\\\\\\\\\\n            with open(readme_path, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n                existing_readme = f.read()\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Generate enhancement suggestions\\\\\\\\\\\\\\\\n            prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyze this existing README and suggest improvements based on the codebase analysis:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCurrent README:\\\\\\\\\\\\\\\\n{existing_readme[:2000]}...\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCodebase info:\\\\\\\\\\\\\\\\n- Files: {analysis.get('statistics', {}).get('total_files', 0)}\\\\\\\\\\\\\\\\n- Languages: {', '.join(analysis.get('statistics', {}).get('languages', {}).keys())}\\\\\\\\\\\\\\\\n- Key components: {len(analysis.get('files', []))} files analyzed\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nSuggest specific improvements while preserving the existing structure and content.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                suggestions = self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\\\\\\\\\n                updates['README_suggestions.md'] = suggestions\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                updates['README_suggestions.md'] = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error generating suggestions: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return updates\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"file_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"imports\\\\\\\\\\\\\\\": [\\\\\\\\n        \\\\\\\\\\\\\\\"argparse\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"asyncio\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"sys\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"pathlib.Path\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Optional\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"config.settings\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"repository_analyzer.RepositoryAnalyzer\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"ollama_client.OllamaClient\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"vector_store.VectorStore\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"rag_system.RAGSystem\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"documentation_generator.DocumentationBuilder\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"documentation_generator.DocumentationConfig\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"api.main\\\\\\\\\\\\\\\"\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"elements\\\\\\\\\\\\\\\": [\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"LocalDeepWiki\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 21,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 254,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Main class for Local DeepWiki functionality.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class LocalDeepWiki\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"LocalDeepWiki.__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 24,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 30,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Initialize LocalDeepWiki with all components.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"LocalDeepWiki.check_prerequisites\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 32,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 65,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Check if all prerequisites are met.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def check_prerequisites(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"LocalDeepWiki.analyze_repository\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 67,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 104,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Analyze a repository and add it to the vector store.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def analyze_repository(self, repo_path, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"LocalDeepWiki.query_repository\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 106,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 129,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Query a repository using the RAG system.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def query_repository(self, query, repo_name, stream)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"LocalDeepWiki.interactive_chat\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 131,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 164,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Start an interactive chat session.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def interactive_chat(self, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"LocalDeepWiki.generate_documentation\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 166,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 199,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate documentation for a repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_documentation(self, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"LocalDeepWiki.list_repositories\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 201,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 231,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"List all analyzed repositories.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def list_repositories(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"LocalDeepWiki.show_stats\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 233,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 254,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Show system statistics.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def show_stats(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"main\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 256,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 342,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Main CLI interface.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def main()\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 24,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 30,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Initialize LocalDeepWiki with all components.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"check_prerequisites\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 32,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 65,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Check if all prerequisites are met.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def check_prerequisites(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"analyze_repository\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 67,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 104,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Analyze a repository and add it to the vector store.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def analyze_repository(self, repo_path, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"query_repository\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 106,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 129,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Query a repository using the RAG system.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def query_repository(self, query, repo_name, stream)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"interactive_chat\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 131,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 164,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Start an interactive chat session.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def interactive_chat(self, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"generate_documentation\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 166,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 199,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate documentation for a repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_documentation(self, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"list_repositories\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 201,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 231,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"List all analyzed repositories.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def list_repositories(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"show_stats\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 233,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 254,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Show system statistics.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def show_stats(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        }\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#!/usr/bin/env python3\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nLocal DeepWiki - Main entry point and CLI interface.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nA local implementation of DeepWiki using Ollama for LLM inference.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport argparse\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport sys\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom typing import Optional\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom config import settings\\\\\\\\\\\\\\\\nfrom repository_analyzer import RepositoryAnalyzer\\\\\\\\\\\\\\\\nfrom ollama_client import OllamaClient\\\\\\\\\\\\\\\\nfrom vector_store import VectorStore\\\\\\\\\\\\\\\\nfrom rag_system import RAGSystem\\\\\\\\\\\\\\\\nfrom documentation_generator import DocumentationBuilder, DocumentationConfig\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass LocalDeepWiki:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main class for Local DeepWiki functionality.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def __init__(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Initialize LocalDeepWiki with all components.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.ollama_client = OllamaClient()\\\\\\\\\\\\\\\\n        self.vector_store = VectorStore()\\\\\\\\\\\\\\\\n        self.rag_system = RAGSystem(self.vector_store, self.ollama_client)\\\\\\\\\\\\\\\\n        self.repository_analyzer = RepositoryAnalyzer()\\\\\\\\\\\\\\\\n        self.documentation_builder = DocumentationBuilder(self.ollama_client)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def check_prerequisites(self) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if all prerequisites are met.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Checking prerequisites...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Check Ollama\\\\\\\\\\\\\\\\n        if not self.ollama_client.is_available():\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"X Ollama server is not available at\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", settings.OLLAMA_BASE_URL)\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Please start Ollama first:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  ollama serve\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"OK Ollama server is available\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Check model\\\\\\\\\\\\\\\\n        models = self.ollama_client.list_models()\\\\\\\\\\\\\\\\n        model_names = [model['name'] for model in models]\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if settings.OLLAMA_MODEL not in model_names:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"X Model '{settings.OLLAMA_MODEL}' is not available\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Available models:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", model_names)\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"To download the model, run:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  ollama pull {settings.OLLAMA_MODEL}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"OK Model '{settings.OLLAMA_MODEL}' is available\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Check embedding model\\\\\\\\\\\\\\\\n        if settings.OLLAMA_EMBEDDING_MODEL not in model_names:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"! Embedding model '{settings.OLLAMA_EMBEDDING_MODEL}' not found\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Will use fallback embedding model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"OK Embedding model '{settings.OLLAMA_EMBEDDING_MODEL}' is available\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return True\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def analyze_repository(self, repo_path: str, repo_name: Optional[str] = None) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyze a repository and add it to the vector store.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        repo_path = Path(repo_path).resolve()\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if not repo_path.exists():\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"X Repository path does not exist: {repo_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        repo_name = repo_name or repo_path.name\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"* Analyzing repository: {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Path: {repo_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            # Analyze repository structure\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Parsing files and extracting structure...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            analysis = self.repository_analyzer.analyze_repository(str(repo_path))\\\\\\\\\\\\\\\\n            analysis['repo_name'] = repo_name\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Save analysis\\\\\\\\\\\\\\\\n            analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{repo_name}_analysis.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            self.repository_analyzer.save_analysis(analysis, str(analysis_path))\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Analysis saved to: {analysis_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Add to vector store\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Adding to vector store...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            chunks_added = self.vector_store.add_repository(analysis)\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"OK Repository analysis complete!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Files analyzed: {analysis['statistics']['total_files']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Code files: {analysis['statistics']['code_files']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Languages: {', '.join(analysis['statistics']['languages'].keys())}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Chunks added to vector store: {chunks_added}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            return True\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"X Error analyzing repository: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def query_repository(self, query: str, repo_name: Optional[str] = None, stream: bool = True):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Query a repository using the RAG system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"? Query: {query}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        if repo_name:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Repository: {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            result = self.rag_system.query(query, repo_name=repo_name, stream=False)\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            if result['context']:\\\\\\\\\\\\\\\\n                print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n> Response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                print(result['response'])\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                if result['sources']:\\\\\\\\\\\\\\\\n                    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n* Sources:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                    for i, source in enumerate(result['sources'], 1):\\\\\\\\\\\\\\\\n                        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   {i}. {source.get('file_path', 'Unknown')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                        if source.get('element_name'):\\\\\\\\\\\\\\\\n                            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"      Element: {source['element_name']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\n                print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"X No relevant context found for your query.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"X Error processing query: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def interactive_chat(self, repo_name: Optional[str] = None):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Start an interactive chat session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"* Interactive Chat Mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Type 'quit' or 'exit' to end the session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        if repo_name:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Querying repository: {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 50)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        messages = []\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        while True:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                user_input = input(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\").strip()\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                if user_input.lower() in ['quit', 'exit', 'q']:\\\\\\\\\\\\\\\\n                    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Goodbye!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                    break\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                if not user_input:\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                messages.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": user_input})\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAssistant: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", end=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", flush=True)\\\\\\\\\\\\\\\\n                response = self.rag_system.chat_with_repo(messages, repo_name)\\\\\\\\\\\\\\\\n                print(response)\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                messages.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"assistant\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": response})\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n            except KeyboardInterrupt:\\\\\\\\\\\\\\\\n                print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nGoodbye!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                break\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nX Error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def generate_documentation(self, repo_name: str):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate documentation for a repository.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"* Generating documentation for: {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Load analysis\\\\\\\\\\\\\\\\n        analysis_path = Path(settings.REPOS_DIRECTORY) / f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{repo_name}_analysis.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not analysis_path.exists():\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"X Repository {repo_name} not found. Please analyze it first.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            analysis = self.repository_analyzer.load_analysis(str(analysis_path))\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            config = DocumentationConfig(\\\\\\\\\\\\\\\\n                include_overview=True,\\\\\\\\\\\\\\\\n                include_api_docs=True,\\\\\\\\\\\\\\\\n                include_examples=True,\\\\\\\\\\\\\\\\n                include_architecture=True\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            docs = self.documentation_builder.generate_full_documentation(analysis, config)\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"OK Documentation generated!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Files created: {len(docs)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Output directory: {Path(settings.DOCS_DIRECTORY) / repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            for doc_name in docs.keys():\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   - {doc_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            return True\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"X Error generating documentation: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def list_repositories(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"List all analyzed repositories.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        repos_dir = Path(settings.REPOS_DIRECTORY)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if not repos_dir.exists():\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No repositories found.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        analysis_files = list(repos_dir.glob(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"*_analysis.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if not analysis_files:\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No repositories found.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"* Analyzed Repositories:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 50)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        for analysis_file in analysis_files:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                analysis = self.repository_analyzer.load_analysis(str(analysis_file))\\\\\\\\\\\\\\\\n                repo_name = analysis.get('repo_name', analysis_file.stem.replace('_analysis', ''))\\\\\\\\\\\\\\\\n                stats = analysis.get('statistics', {})\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"+ {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Path: {analysis.get('repo_path', 'Unknown')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Files: {stats.get('total_files', 0)} total, {stats.get('code_files', 0)} code\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Languages: {', '.join(stats.get('languages', {}).keys())}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                print()\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"X Error loading {analysis_file}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def show_stats(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Show system statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"* System Statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 30)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Vector store stats\\\\\\\\\\\\\\\\n        vector_stats = self.vector_store.get_collection_stats()\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Documents in vector store: {vector_stats.get('total_documents', 0)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Repository count\\\\\\\\\\\\\\\\n        repos_dir = Path(settings.REPOS_DIRECTORY)\\\\\\\\\\\\\\\\n        repo_count = len(list(repos_dir.glob(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"*_analysis.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))) if repos_dir.exists() else 0\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyzed repositories: {repo_count}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Generated docs count\\\\\\\\\\\\\\\\n        docs_dir = Path(settings.DOCS_DIRECTORY)\\\\\\\\\\\\\\\\n        doc_count = len(list(docs_dir.rglob(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"*.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))) if docs_dir.exists() else 0\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generated documentation files: {doc_count}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Ollama status\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Ollama available: {'OK' if self.ollama_client.is_available() else 'X'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Current model: {settings.OLLAMA_MODEL}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef main():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main CLI interface.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    parser = argparse.ArgumentParser(description=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Local DeepWiki - Chat with your code repositories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    subparsers = parser.add_subparsers(dest='command', help='Available commands')\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Check command\\\\\\\\\\\\\\\\n    subparsers.add_parser('check', help='Check system prerequisites')\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Analyze command\\\\\\\\\\\\\\\\n    analyze_parser = subparsers.add_parser('analyze', help='Analyze a repository')\\\\\\\\\\\\\\\\n    analyze_parser.add_argument('repo_path', help='Path to the repository')\\\\\\\\\\\\\\\\n    analyze_parser.add_argument('--name', help='Custom name for the repository')\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Query command\\\\\\\\\\\\\\\\n    query_parser = subparsers.add_parser('query', help='Query a repository')\\\\\\\\\\\\\\\\n    query_parser.add_argument('query', help='Your question or query')\\\\\\\\\\\\\\\\n    query_parser.add_argument('--repo', help='Repository name to query')\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Chat command\\\\\\\\\\\\\\\\n    chat_parser = subparsers.add_parser('chat', help='Start interactive chat')\\\\\\\\\\\\\\\\n    chat_parser.add_argument('--repo', help='Repository name to chat with')\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Docs command\\\\\\\\\\\\\\\\n    docs_parser = subparsers.add_parser('docs', help='Generate documentation')\\\\\\\\\\\\\\\\n    docs_parser.add_argument('repo_name', help='Repository name')\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # List command\\\\\\\\\\\\\\\\n    subparsers.add_parser('list', help='List analyzed repositories')\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Stats command\\\\\\\\\\\\\\\\n    subparsers.add_parser('stats', help='Show system statistics')\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Server command\\\\\\\\\\\\\\\\n    server_parser = subparsers.add_parser('server', help='Start web server')\\\\\\\\\\\\\\\\n    server_parser.add_argument('--host', default=settings.API_HOST, help='Host address')\\\\\\\\\\\\\\\\n    server_parser.add_argument('--port', type=int, default=settings.API_PORT, help='Port number')\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    args = parser.parse_args()\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    if not args.command:\\\\\\\\\\\\\\\\n        parser.print_help()\\\\\\\\\\\\\\\\n        return\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Initialize LocalDeepWiki\\\\\\\\\\\\\\\\n    ldw = LocalDeepWiki()\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    if args.command == 'check':\\\\\\\\\\\\\\\\n        if ldw.check_prerequisites():\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nOK All prerequisites are met! You're ready to use Local DeepWiki.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nX Please fix the issues above before using Local DeepWiki.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            sys.exit(1)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    elif args.command == 'analyze':\\\\\\\\\\\\\\\\n        if not ldw.check_prerequisites():\\\\\\\\\\\\\\\\n            sys.exit(1)\\\\\\\\\\\\\\\\n        ldw.analyze_repository(args.repo_path, args.name)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    elif args.command == 'query':\\\\\\\\\\\\\\\\n        if not ldw.check_prerequisites():\\\\\\\\\\\\\\\\n            sys.exit(1)\\\\\\\\\\\\\\\\n        ldw.query_repository(args.query, args.repo)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    elif args.command == 'chat':\\\\\\\\\\\\\\\\n        if not ldw.check_prerequisites():\\\\\\\\\\\\\\\\n            sys.exit(1)\\\\\\\\\\\\\\\\n        ldw.interactive_chat(args.repo)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    elif args.command == 'docs':\\\\\\\\\\\\\\\\n        if not ldw.check_prerequisites():\\\\\\\\\\\\\\\\n            sys.exit(1)\\\\\\\\\\\\\\\\n        ldw.generate_documentation(args.repo_name)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    elif args.command == 'list':\\\\\\\\\\\\\\\\n        ldw.list_repositories()\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    elif args.command == 'stats':\\\\\\\\\\\\\\\\n        ldw.show_stats()\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    elif args.command == 'server':\\\\\\\\\\\\\\\\n        if not ldw.check_prerequisites():\\\\\\\\\\\\\\\\n            sys.exit(1)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Import and run the API server\\\\\\\\\\\\\\\\n        from api import main as run_server\\\\\\\\\\\\\\\\n        run_server()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n    main()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"file_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"imports\\\\\\\\\\\\\\\": [\\\\\\\\n        \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"requests\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"asyncio\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"aiohttp\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Dict\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.List\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Any\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Optional\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.AsyncGenerator\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"config.settings\\\\\\\\\\\\\\\"\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"elements\\\\\\\\\\\\\\\": [\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"OllamaClient\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 10,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 231,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Client for interacting with Ollama local LLM server.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class OllamaClient\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"OllamaClient.__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 13,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 16,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self, base_url, model)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"OllamaClient.is_available\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 18,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 24,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Check if Ollama server is available.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def is_available(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"OllamaClient.list_models\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 26,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 34,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"List available models.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def list_models(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"OllamaClient.pull_model\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 36,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 57,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Pull a model if not already available.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def pull_model(self, model_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"OllamaClient.generate\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 59,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 80,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate text using Ollama.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate(self, prompt, model)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"OllamaClient.get_embeddings\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 141,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 160,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Get embeddings for text.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def get_embeddings(self, text, model)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"OllamaClient.chat\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 185,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 206,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Chat completion using Ollama.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def chat(self, messages, model)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationGenerator\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 233,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 352,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate documentation using Ollama.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class DocumentationGenerator\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationGenerator.__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 236,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 237,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self, ollama_client)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationGenerator.generate_file_documentation\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 239,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 295,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate documentation for a single file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_file_documentation(self, file_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"DocumentationGenerator.generate_repository_overview\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 297,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 352,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate high-level repository documentation.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_repository_overview(self, repo_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 13,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 16,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self, base_url, model)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"is_available\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 18,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 24,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Check if Ollama server is available.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def is_available(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"list_models\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 26,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 34,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"List available models.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def list_models(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"pull_model\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 36,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 57,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Pull a model if not already available.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def pull_model(self, model_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"generate\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 59,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 80,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate text using Ollama.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate(self, prompt, model)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"get_embeddings\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 141,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 160,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Get embeddings for text.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def get_embeddings(self, text, model)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 185,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 206,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Chat completion using Ollama.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def chat(self, messages, model)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 236,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 237,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self, ollama_client)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"generate_file_documentation\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 239,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 295,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate documentation for a single file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_file_documentation(self, file_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"generate_repository_overview\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 297,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 352,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate high-level repository documentation.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_repository_overview(self, repo_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        }\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Ollama client for local LLM inference.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\nimport requests\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport aiohttp\\\\\\\\\\\\\\\\nfrom typing import Dict, List, Any, Optional, AsyncGenerator\\\\\\\\\\\\\\\\nfrom config import settings\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass OllamaClient:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Client for interacting with Ollama local LLM server.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def __init__(self, base_url: str = None, model: str = None):\\\\\\\\\\\\\\\\n        self.base_url = base_url or settings.OLLAMA_BASE_URL\\\\\\\\\\\\\\\\n        self.model = model or settings.OLLAMA_MODEL\\\\\\\\\\\\\\\\n        self.embedding_model = settings.OLLAMA_EMBEDDING_MODEL\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n    def is_available(self) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if Ollama server is available.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            response = requests.get(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{self.base_url}/api/tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", timeout=5)\\\\\\\\\\\\\\\\n            return response.status_code == 200\\\\\\\\\\\\\\\\n        except:\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def list_models(self) -> List[Dict[str, Any]]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"List available models.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            response = requests.get(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{self.base_url}/api/tags\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            response.raise_for_status()\\\\\\\\\\\\\\\\n            return response.json().get('models', [])\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error listing models: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return []\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def pull_model(self, model_name: str) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Pull a model if not already available.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            response = requests.post(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{self.base_url}/api/pull\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                json={\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model_name},\\\\\\\\\\\\\\\\n                stream=True\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            for line in response.iter_lines():\\\\\\\\\\\\\\\\n                if line:\\\\\\\\\\\\\\\\n                    data = json.loads(line)\\\\\\\\\\\\\\\\n                    if data.get('status'):\\\\\\\\\\\\\\\\n                        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Pulling {model_name}: {data['status']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                    if data.get('error'):\\\\\\\\\\\\\\\\n                        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error: {data['error']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                        return False\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            return True\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error pulling model {model_name}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def generate(self, prompt: str, model: str = None, **kwargs) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate text using Ollama.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        model = model or self.model\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        payload = {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": prompt,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": False,\\\\\\\\\\\\\\\\n            **kwargs\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            response = requests.post(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{self.base_url}/api/generate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                json=payload,\\\\\\\\\\\\\\\\n                timeout=120\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n            response.raise_for_status()\\\\\\\\\\\\\\\\n            return response.json()['response']\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error generating text: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            raise\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    async def generate_async(self, prompt: str, model: str = None, **kwargs) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate text asynchronously.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        model = model or self.model\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        payload = {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": prompt,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": False,\\\\\\\\\\\\\\\\n            **kwargs\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        async with aiohttp.ClientSession() as session:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                async with session.post(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{self.base_url}/api/generate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    json=payload,\\\\\\\\\\\\\\\\n                    timeout=aiohttp.ClientTimeout(total=120)\\\\\\\\\\\\\\\\n                ) as response:\\\\\\\\\\\\\\\\n                    response.raise_for_status()\\\\\\\\\\\\\\\\n                    result = await response.json()\\\\\\\\\\\\\\\\n                    return result['response']\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error generating text: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                raise\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    async def generate_stream(self, prompt: str, model: str = None, **kwargs) -> AsyncGenerator[str, None]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate text with streaming response.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        model = model or self.model\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        payload = {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": prompt,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": True,\\\\\\\\\\\\\\\\n            **kwargs\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        async with aiohttp.ClientSession() as session:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                async with session.post(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{self.base_url}/api/generate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    json=payload,\\\\\\\\\\\\\\\\n                    timeout=aiohttp.ClientTimeout(total=None)\\\\\\\\\\\\\\\\n                ) as response:\\\\\\\\\\\\\\\\n                    response.raise_for_status()\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    async for line in response.content:\\\\\\\\\\\\\\\\n                        if line:\\\\\\\\\\\\\\\\n                            try:\\\\\\\\\\\\\\\\n                                data = json.loads(line)\\\\\\\\\\\\\\\\n                                if 'response' in data:\\\\\\\\\\\\\\\\n                                    yield data['response']\\\\\\\\\\\\\\\\n                                if data.get('done', False):\\\\\\\\\\\\\\\\n                                    break\\\\\\\\\\\\\\\\n                            except json.JSONDecodeError:\\\\\\\\\\\\\\\\n                                continue\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error in streaming generation: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                raise\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def get_embeddings(self, text: str, model: str = None) -> List[float]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get embeddings for text.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        model = model or self.embedding_model\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        payload = {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": text\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            response = requests.post(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{self.base_url}/api/embeddings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                json=payload,\\\\\\\\\\\\\\\\n                timeout=60\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n            response.raise_for_status()\\\\\\\\\\\\\\\\n            return response.json()['embedding']\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error getting embeddings: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            raise\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    async def get_embeddings_async(self, text: str, model: str = None) -> List[float]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get embeddings asynchronously.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        model = model or self.embedding_model\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        payload = {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": text\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        async with aiohttp.ClientSession() as session:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                async with session.post(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{self.base_url}/api/embeddings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    json=payload,\\\\\\\\\\\\\\\\n                    timeout=aiohttp.ClientTimeout(total=60)\\\\\\\\\\\\\\\\n                ) as response:\\\\\\\\\\\\\\\\n                    response.raise_for_status()\\\\\\\\\\\\\\\\n                    result = await response.json()\\\\\\\\\\\\\\\\n                    return result['embedding']\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error getting embeddings: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                raise\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def chat(self, messages: List[Dict[str, str]], model: str = None, **kwargs) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Chat completion using Ollama.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        model = model or self.model\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        payload = {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": messages,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": False,\\\\\\\\\\\\\\\\n            **kwargs\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            response = requests.post(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{self.base_url}/api/chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                json=payload,\\\\\\\\\\\\\\\\n                timeout=120\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n            response.raise_for_status()\\\\\\\\\\\\\\\\n            return response.json()['message']['content']\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error in chat completion: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            raise\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    async def chat_async(self, messages: List[Dict[str, str]], model: str = None, **kwargs) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Chat completion asynchronously.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        model = model or self.model\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        payload = {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": model,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": messages,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": False,\\\\\\\\\\\\\\\\n            **kwargs\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        async with aiohttp.ClientSession() as session:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                async with session.post(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{self.base_url}/api/chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    json=payload,\\\\\\\\\\\\\\\\n                    timeout=aiohttp.ClientTimeout(total=120)\\\\\\\\\\\\\\\\n                ) as response:\\\\\\\\\\\\\\\\n                    response.raise_for_status()\\\\\\\\\\\\\\\\n                    result = await response.json()\\\\\\\\\\\\\\\\n                    return result['message']['content']\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error in chat completion: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                raise\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass DocumentationGenerator:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate documentation using Ollama.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def __init__(self, ollama_client: OllamaClient):\\\\\\\\\\\\\\\\n        self.client = ollama_client\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def generate_file_documentation(self, file_analysis: Dict[str, Any]) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate documentation for a single file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Build context from file analysis\\\\\\\\\\\\\\\\n        context = []\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"File: {file_analysis['file_path']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Language: {file_analysis.get('language', 'Unknown')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if file_analysis.get('imports'):\\\\\\\\\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Imports: {', '.join(file_analysis['imports'][:10])}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add code elements\\\\\\\\\\\\\\\\n        elements_summary = []\\\\\\\\\\\\\\\\n        for element in file_analysis.get('elements', []):\\\\\\\\\\\\\\\\n            elem_type = element['type']\\\\\\\\\\\\\\\\n            name = element['name']\\\\\\\\\\\\\\\\n            signature = element.get('signature', '')\\\\\\\\\\\\\\\\n            docstring = element.get('docstring', '')\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            elem_desc = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{elem_type}: {name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            if signature:\\\\\\\\\\\\\\\\n                elem_desc += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" - {signature}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            if docstring:\\\\\\\\\\\\\\\\n                elem_desc += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" - {docstring[:100]}...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            elements_summary.append(elem_desc)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if elements_summary:\\\\\\\\\\\\\\\\n            context.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Code Elements:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            context.extend(elements_summary[:15])  # Limit to prevent prompt overflow\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add file content preview\\\\\\\\\\\\\\\\n        content = file_analysis.get('content', '')\\\\\\\\\\\\\\\\n        if content:\\\\\\\\\\\\\\\\n            content_preview = content[:2000] + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" if len(content) > 2000 else content\\\\\\\\\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Content Preview:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n{content_preview}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        context_str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join(context)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyze the following code file and generate comprehensive documentation in Markdown format.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{context_str}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nPlease provide:\\\\\\\\\\\\\\\\n1. A brief overview of what this file does\\\\\\\\\\\\\\\\n2. Main components and their purposes\\\\\\\\\\\\\\\\n3. Key functions/classes with descriptions\\\\\\\\\\\\\\\\n4. Usage examples if applicable\\\\\\\\\\\\\\\\n5. Dependencies and relationships\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nFormat the output as clean Markdown with appropriate headers and code blocks.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            return self.client.generate(prompt, temperature=0.3, max_tokens=2000)\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error generating documentation for {file_analysis['file_path']}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# {file_analysis['file_path']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nError generating documentation: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def generate_repository_overview(self, repo_analysis: Dict[str, Any]) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate high-level repository documentation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        stats = repo_analysis.get('statistics', {})\\\\\\\\\\\\\\\\n        structure = repo_analysis.get('structure', {})\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        context = []\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository: {repo_analysis.get('repo_name', 'Unknown')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Total Files: {stats.get('total_files', 0)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Code Files: {stats.get('code_files', 0)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Documentation Files: {stats.get('doc_files', 0)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Total Lines: {stats.get('total_lines', 0)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if stats.get('languages'):\\\\\\\\\\\\\\\\n            langs = list(stats['languages'].keys())\\\\\\\\\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Languages: {', '.join(langs)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add git info if available\\\\\\\\\\\\\\\\n        git_info = repo_analysis.get('git_info')\\\\\\\\\\\\\\\\n        if git_info:\\\\\\\\\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Current Branch: {git_info.get('current_branch', 'Unknown')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            if git_info.get('last_commit'):\\\\\\\\\\\\\\\\n                commit = git_info['last_commit']\\\\\\\\\\\\\\\\n                context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Last Commit: {commit.get('message', '')[:100]}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add main files/directories\\\\\\\\\\\\\\\\n        main_files = []\\\\\\\\\\\\\\\\n        for file_data in repo_analysis.get('files', [])[:10]:\\\\\\\\\\\\\\\\n            if file_data.get('file_type') == 'documentation':\\\\\\\\\\\\\\\\n                main_files.append(file_data['file_path'])\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if main_files:\\\\\\\\\\\\\\\\n            context.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Key Documentation: {', '.join(main_files)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        context_str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join(context)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyze this code repository and generate a comprehensive overview documentation in Markdown format.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nRepository Information:\\\\\\\\\\\\\\\\n{context_str}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nPlease provide:\\\\\\\\\\\\\\\\n1. Project overview and purpose\\\\\\\\\\\\\\\\n2. Architecture and structure\\\\\\\\\\\\\\\\n3. Key components and modules\\\\\\\\\\\\\\\\n4. Getting started guide\\\\\\\\\\\\\\\\n5. Development setup instructions\\\\\\\\\\\\\\\\n6. Main features and capabilities\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nFormat as professional README-style documentation with proper Markdown structure.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            return self.client.generate(prompt, temperature=0.3, max_tokens=3000)\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error generating repository overview: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# Repository Overview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nError generating overview: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"file_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"imports\\\\\\\\\\\\\\\": [\\\\\\\\n        \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.List\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Dict\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Any\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Optional\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Tuple\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"dataclasses.dataclass\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"ollama_client.OllamaClient\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"vector_store.VectorStore\\\\\\\\\\\\\\\"\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"elements\\\\\\\\\\\\\\\": [\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGContext\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 10,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 15,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Context information for RAG system.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class RAGContext\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 17,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 329,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Retrieval-Augmented Generation system.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class RAGSystem\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem.__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 20,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 62,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self, vector_store, ollama_client)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem.determine_query_type\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 64,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 75,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Determine the type of query to select appropriate prompt.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def determine_query_type(self, query)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem.retrieve_context\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 77,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 79,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Retrieve relevant context for the query.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def retrieve_context(self, query, n_results, filter_metadata)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem.build_context_text\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 81,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 110,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Build context text from retrieved chunks.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def build_context_text(self, retrieved_chunks, max_context_length)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem.generate_response\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 112,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 133,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate response using RAG context.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_response(self, query, context, stream)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem.query\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 135,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 191,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Main query interface for RAG system.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def query(self, query, repo_name, file_path, n_results, stream)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem.explain_code\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 193,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 214,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Explain a specific code snippet.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def explain_code(self, code, language, context)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem.suggest_improvements\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 216,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 237,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Suggest improvements for code.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def suggest_improvements(self, code, language)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem.search_similar_code\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 239,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 248,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Find similar code in the repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def search_similar_code(self, code_snippet, language, n_results)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem.get_file_summary\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 250,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 282,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Get a summary of a specific file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def get_file_summary(self, file_path, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem.get_repository_overview\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 284,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 295,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Get an overview of the repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def get_repository_overview(self, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RAGSystem.chat_with_repo\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 297,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 329,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Chat interface for conversational interaction with repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def chat_with_repo(self, messages, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 20,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 62,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self, vector_store, ollama_client)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"determine_query_type\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 64,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 75,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Determine the type of query to select appropriate prompt.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def determine_query_type(self, query)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"retrieve_context\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 77,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 79,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Retrieve relevant context for the query.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def retrieve_context(self, query, n_results, filter_metadata)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"build_context_text\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 81,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 110,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Build context text from retrieved chunks.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def build_context_text(self, retrieved_chunks, max_context_length)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"generate_response\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 112,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 133,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Generate response using RAG context.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def generate_response(self, query, context, stream)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"query\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 135,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 191,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Main query interface for RAG system.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def query(self, query, repo_name, file_path, n_results, stream)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"explain_code\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 193,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 214,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Explain a specific code snippet.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def explain_code(self, code, language, context)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"suggest_improvements\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 216,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 237,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Suggest improvements for code.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def suggest_improvements(self, code, language)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"search_similar_code\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 239,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 248,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Find similar code in the repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def search_similar_code(self, code_snippet, language, n_results)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"get_file_summary\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 250,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 282,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Get a summary of a specific file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def get_file_summary(self, file_path, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"get_repository_overview\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 284,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 295,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Get an overview of the repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def get_repository_overview(self, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat_with_repo\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 297,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 329,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Chat interface for conversational interaction with repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def chat_with_repo(self, messages, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        }\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"RAG (Retrieval-Augmented Generation) system for context-aware responses.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\nfrom typing import List, Dict, Any, Optional, Tuple\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\\\\\\\\\nfrom ollama_client import OllamaClient\\\\\\\\\\\\\\\\nfrom vector_store import VectorStore\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass RAGContext:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Context information for RAG system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    query: str\\\\\\\\\\\\\\\\n    retrieved_chunks: List[Dict[str, Any]]\\\\\\\\\\\\\\\\n    context_text: str\\\\\\\\\\\\\\\\n    metadata: Dict[str, Any]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass RAGSystem:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Retrieval-Augmented Generation system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def __init__(self, vector_store: VectorStore, ollama_client: OllamaClient):\\\\\\\\\\\\\\\\n        self.vector_store = vector_store\\\\\\\\\\\\\\\\n        self.ollama_client = ollama_client\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # System prompts for different types of queries\\\\\\\\\\\\\\\\n        self.system_prompts = {\\\\\\\\\\\\\\\\n            'code_explanation': \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"You are an expert code analyst. Your task is to explain code clearly and concisely based on the provided context. \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nFocus on:\\\\\\\\\\\\\\\\n- What the code does\\\\\\\\\\\\\\\\n- How it works\\\\\\\\\\\\\\\\n- Key components and their relationships\\\\\\\\\\\\\\\\n- Usage examples when relevant\\\\\\\\\\\\\\\\n- Best practices and potential improvements\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nBe accurate and reference the specific code provided in the context.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            'general_question': \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"You are a helpful assistant that answers questions about codebases and documentation. \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nUse the provided context to give accurate, helpful answers. If the context doesn't contain enough information to answer fully, say so and provide what information you can from the context.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nBe concise but thorough, and always ground your answers in the provided context.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            'documentation': \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"You are a technical documentation expert. Generate clear, well-structured documentation based on the provided code and context.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nFocus on:\\\\\\\\\\\\\\\\n- Clear explanations of functionality\\\\\\\\\\\\\\\\n- Proper formatting with headers and code blocks\\\\\\\\\\\\\\\\n- Usage examples and best practices\\\\\\\\\\\\\\\\n- Integration with other parts of the system\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nUse proper Markdown formatting.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            'troubleshooting': \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"You are a debugging expert. Help identify issues, suggest solutions, and provide troubleshooting guidance based on the code context.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nFocus on:\\\\\\\\\\\\\\\\n- Identifying potential problems\\\\\\\\\\\\\\\\n- Suggesting specific solutions\\\\\\\\\\\\\\\\n- Explaining the reasoning behind recommendations\\\\\\\\\\\\\\\\n- Providing preventive measures\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nBe practical and actionable in your suggestions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def determine_query_type(self, query: str) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Determine the type of query to select appropriate prompt.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        query_lower = query.lower()\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if any(word in query_lower for word in ['how does', 'what does', 'explain', 'how to']):\\\\\\\\\\\\\\\\n            return 'code_explanation'\\\\\\\\\\\\\\\\n        elif any(word in query_lower for word in ['document', 'generate docs', 'create documentation']):\\\\\\\\\\\\\\\\n            return 'documentation'\\\\\\\\\\\\\\\\n        elif any(word in query_lower for word in ['error', 'bug', 'fix', 'problem', 'issue', 'debug']):\\\\\\\\\\\\\\\\n            return 'troubleshooting'\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            return 'general_question'\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def retrieve_context(self, query: str, n_results: int = 5, filter_metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Retrieve relevant context for the query.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return self.vector_store.search(query, n_results, filter_metadata)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def build_context_text(self, retrieved_chunks: List[Dict[str, Any]], max_context_length: int = 4000) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Build context text from retrieved chunks.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        context_parts = []\\\\\\\\\\\\\\\\n        current_length = 0\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        for chunk in retrieved_chunks:\\\\\\\\\\\\\\\\n            text = chunk['text']\\\\\\\\\\\\\\\\n            metadata = chunk.get('metadata', {})\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Add metadata header for context\\\\\\\\\\\\\\\\n            header = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            if metadata.get('file_path'):\\\\\\\\\\\\\\\\n                header += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"File: {metadata['file_path']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            if metadata.get('element_name'):\\\\\\\\\\\\\\\\n                header += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Element: {metadata['element_name']} ({metadata.get('element_type', 'unknown')})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            if metadata.get('type'):\\\\\\\\\\\\\\\\n                header += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Type: {metadata['type']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            chunk_text = header + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" + text + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"*50 + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Check if adding this chunk would exceed max length\\\\\\\\\\\\\\\\n            if current_length + len(chunk_text) > max_context_length:\\\\\\\\\\\\\\\\n                if not context_parts:  # If first chunk is too long, truncate it\\\\\\\\\\\\\\\\n                    context_parts.append(chunk_text[:max_context_length])\\\\\\\\\\\\\\\\n                break\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            context_parts.append(chunk_text)\\\\\\\\\\\\\\\\n            current_length += len(chunk_text)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join(context_parts)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def generate_response(self, query: str, context: RAGContext, stream: bool = False) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate response using RAG context.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        query_type = self.determine_query_type(query)\\\\\\\\\\\\\\\\n        system_prompt = self.system_prompts.get(query_type, self.system_prompts['general_question'])\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Build the full prompt\\\\\\\\\\\\\\\\n        full_prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{system_prompt}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCONTEXT:\\\\\\\\\\\\\\\\n{context.context_text}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nUSER QUERY: {query}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nPlease provide a helpful response based on the context above. If the context doesn't contain sufficient information, clearly state what information is missing.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            if stream:\\\\\\\\\\\\\\\\n                return self.ollama_client.generate_stream(full_prompt, temperature=0.3)\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\n                return self.ollama_client.generate(full_prompt, temperature=0.3)\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error generating response: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def query(self, \\\\\\\\\\\\\\\\n              query: str, \\\\\\\\\\\\\\\\n              repo_name: str = None, \\\\\\\\\\\\\\\\n              file_path: str = None,\\\\\\\\\\\\\\\\n              n_results: int = 5,\\\\\\\\\\\\\\\\n              stream: bool = False) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main query interface for RAG system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Build filter for specific repository or file\\\\\\\\\\\\\\\\n        filter_metadata = {}\\\\\\\\\\\\\\\\n        if repo_name:\\\\\\\\\\\\\\\\n            filter_metadata['repo_name'] = repo_name\\\\\\\\\\\\\\\\n        if file_path:\\\\\\\\\\\\\\\\n            filter_metadata['file_path'] = file_path\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Retrieve relevant context\\\\\\\\\\\\\\\\n        retrieved_chunks = self.retrieve_context(query, n_results, filter_metadata or None)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if not retrieved_chunks:\\\\\\\\\\\\\\\\n            return {\\\\\\\\\\\\\\\\n                'response': f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No relevant context found for query: {query}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                'context': None,\\\\\\\\\\\\\\\\n                'sources': []\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Build context\\\\\\\\\\\\\\\\n        context_text = self.build_context_text(retrieved_chunks)\\\\\\\\\\\\\\\\n        context = RAGContext(\\\\\\\\\\\\\\\\n            query=query,\\\\\\\\\\\\\\\\n            retrieved_chunks=retrieved_chunks,\\\\\\\\\\\\\\\\n            context_text=context_text,\\\\\\\\\\\\\\\\n            metadata={'repo_name': repo_name, 'file_path': file_path}\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Generate response\\\\\\\\\\\\\\\\n        response = self.generate_response(query, context, stream)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Extract sources\\\\\\\\\\\\\\\\n        sources = []\\\\\\\\\\\\\\\\n        for chunk in retrieved_chunks:\\\\\\\\\\\\\\\\n            metadata = chunk.get('metadata', {})\\\\\\\\\\\\\\\\n            source = {\\\\\\\\\\\\\\\\n                'file_path': metadata.get('file_path'),\\\\\\\\\\\\\\\\n                'element_name': metadata.get('element_name'),\\\\\\\\\\\\\\\\n                'type': metadata.get('type'),\\\\\\\\\\\\\\\\n                'distance': chunk.get('distance', 0)\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\n            # Remove None values\\\\\\\\\\\\\\\\n            source = {k: v for k, v in source.items() if v is not None}\\\\\\\\\\\\\\\\n            if source and source not in sources:\\\\\\\\\\\\\\\\n                sources.append(source)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            'response': response,\\\\\\\\\\\\\\\\n            'context': context,\\\\\\\\\\\\\\\\n            'sources': sources[:5]  # Limit to top 5 sources\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def explain_code(self, code: str, language: str = None, context: str = None) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Explain a specific code snippet.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Explain the following code clearly and concisely:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nLanguage: {language or 'Unknown'}\\\\\\\\\\\\\\\\n{f'Context: {context}' if context else ''}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCode:\\\\\\\\\\\\\\\\n```{language or ''}\\\\\\\\\\\\\\\\n{code}\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nPlease explain:\\\\\\\\\\\\\\\\n1. What this code does\\\\\\\\\\\\\\\\n2. How it works\\\\\\\\\\\\\\\\n3. Key components and their purpose\\\\\\\\\\\\\\\\n4. Any notable patterns or techniques used\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error explaining code: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def suggest_improvements(self, code: str, language: str = None) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Suggest improvements for code.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyze the following code and suggest improvements:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nLanguage: {language or 'Unknown'}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCode:\\\\\\\\\\\\\\\\n```{language or ''}\\\\\\\\\\\\\\\\n{code}\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nPlease provide:\\\\\\\\\\\\\\\\n1. Code quality assessment\\\\\\\\\\\\\\\\n2. Potential improvements\\\\\\\\\\\\\\\\n3. Best practices recommendations\\\\\\\\\\\\\\\\n4. Performance optimizations if applicable\\\\\\\\\\\\\\\\n5. Security considerations if relevant\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error suggesting improvements: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def search_similar_code(self, code_snippet: str, language: str = None, n_results: int = 3) -> List[Dict[str, Any]]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Find similar code in the repository.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Create a search query from the code\\\\\\\\\\\\\\\\n        query = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"code similar to: {code_snippet[:200]}...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        filter_metadata = {}\\\\\\\\\\\\\\\\n        if language:\\\\\\\\\\\\\\\\n            filter_metadata['language'] = language\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return self.retrieve_context(query, n_results, filter_metadata or None)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def get_file_summary(self, file_path: str, repo_name: str = None) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get a summary of a specific file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        filter_metadata = {'file_path': file_path}\\\\\\\\\\\\\\\\n        if repo_name:\\\\\\\\\\\\\\\\n            filter_metadata['repo_name'] = repo_name\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Get file overview chunk\\\\\\\\\\\\\\\\n        chunks = self.vector_store.search(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file overview {file_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\n            n_results=1, \\\\\\\\\\\\\\\\n            filter_metadata=filter_metadata\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if not chunks:\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No information found for file: {file_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        chunk = chunks[0]\\\\\\\\\\\\\\\\n        context_text = chunk['text']\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Provide a concise summary of this file:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{context_text}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nSummary should include:\\\\\\\\\\\\\\\\n- Purpose of the file\\\\\\\\\\\\\\\\n- Main components\\\\\\\\\\\\\\\\n- Key functionality\\\\\\\\\\\\\\\\n- Dependencies\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.3)\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error generating file summary: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def get_repository_overview(self, repo_name: str) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get an overview of the repository.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        chunks = self.vector_store.search(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repository overview {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            n_results=1,\\\\\\\\\\\\\\\\n            filter_metadata={'repo_name': repo_name, 'type': 'repository_overview'}\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if not chunks:\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No overview found for repository: {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return chunks[0]['text']\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def chat_with_repo(self, messages: List[Dict[str, str]], repo_name: str = None) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Chat interface for conversational interaction with repository.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not messages:\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No messages provided\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Get the latest user message\\\\\\\\\\\\\\\\n        latest_message = messages[-1]['content']\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Get context for the latest query\\\\\\\\\\\\\\\\n        result = self.query(latest_message, repo_name=repo_name, stream=False)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Build conversation context\\\\\\\\\\\\\\\\n        conversation_context = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join([\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{msg['role']}: {msg['content']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n            for msg in messages[:-1]  # Exclude the latest message\\\\\\\\\\\\\\\\n        ])\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Enhanced prompt with conversation history\\\\\\\\\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"You are having a conversation about a codebase. Here's the conversation history:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n{conversation_context}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCurrent context from the codebase:\\\\\\\\\\\\\\\\n{result['context'].context_text if result['context'] else 'No relevant context found'}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCurrent question: {latest_message}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nPlease provide a helpful response that considers both the conversation history and the current context.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            return self.ollama_client.generate(prompt, temperature=0.4)\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error in chat response: {str(e)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\README.md\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"file_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"documentation\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"imports\\\\\\\\\\\\\\\": [],\\\\\\\\n      \\\\\\\\\\\\\\\"elements\\\\\\\\\\\\\\\": [],\\\\\\\\n      \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# Local DeepWiki\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nA local implementation of DeepWiki that allows you to chat with your code repositories using Ollama and local LLMs. This system provides repository analysis, documentation generation, and conversational AI capabilities - all running locally on your machine.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Features\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- ðŸ” **Repository Analysis**: Automatically parse and understand code structure\\\\\\\\\\\\\\\\n- ðŸ¤– **Local LLM Integration**: Uses Ollama for privacy-focused AI inference\\\\\\\\\\\\\\\\n- ðŸ“š **Documentation Generation**: Create comprehensive docs from your codebase\\\\\\\\\\\\\\\\n- ðŸ’¬ **Interactive Chat**: Ask questions about your code in natural language\\\\\\\\\\\\\\\\n- ðŸ”Ž **Semantic Search**: Find relevant code and documentation quickly\\\\\\\\\\\\\\\\n- ðŸŒ **Web Interface**: Clean, modern UI for easy interaction\\\\\\\\\\\\\\\\n- ðŸ“– **RAG System**: Context-aware responses grounded in your actual code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Prerequisites\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **Python 3.8+**\\\\\\\\\\\\\\\\n2. **Ollama** - Download from [ollama.ai](https://ollama.ai)\\\\\\\\\\\\\\\\n3. **Git** (optional, for repository information)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Installation\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **Clone this repository:**\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\ngit clone <repository-url>\\\\\\\\\\\\\\\\ncd local_deepwiki\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n2. **Install Python dependencies:**\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\npip install -r requirements.txt\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n3. **Install and start Ollama:**\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Install Ollama (see https://ollama.ai for platform-specific instructions)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Start Ollama server\\\\\\\\\\\\\\\\nollama serve\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Pull required models (in another terminal)\\\\\\\\\\\\\\\\nollama pull llama2          # Main language model\\\\\\\\\\\\\\\\nollama pull nomic-embed-text  # Embedding model (optional)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n4. **Check prerequisites:**\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\npython main.py check\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Quick Start\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 1. Analyze a Repository\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Analyze your current directory\\\\\\\\\\\\\\\\npython main.py analyze .\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Analyze a specific repository\\\\\\\\\\\\\\\\npython main.py analyze /path/to/your/repo --name my-project\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Analyze with custom name\\\\\\\\\\\\\\\\npython main.py analyze ~/projects/my-app --name my-awesome-app\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 2. Chat with Your Code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Start interactive chat\\\\\\\\\\\\\\\\npython main.py chat\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Chat with specific repository\\\\\\\\\\\\\\\\npython main.py chat --repo my-project\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 3. Query Your Repository\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Ask a specific question\\\\\\\\\\\\\\\\npython main.py query \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"How does user authentication work?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" --repo my-project\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Query without specifying repository (searches all)\\\\\\\\\\\\\\\\npython main.py query \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Show me the main entry point\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 4. Generate Documentation\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Generate comprehensive documentation\\\\\\\\\\\\\\\\npython main.py docs my-project\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 5. Web Interface\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Start the web server\\\\\\\\\\\\\\\\npython main.py server\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Or with custom host/port\\\\\\\\\\\\\\\\npython main.py server --host 127.0.0.1 --port 8080\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThen open http://localhost:8000 in your browser.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Configuration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCreate a `.env` file to customize settings:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```env\\\\\\\\\\\\\\\\n# Ollama Configuration\\\\\\\\\\\\\\\\nOLLAMA_BASE_URL=http://localhost:11434\\\\\\\\\\\\\\\\nOLLAMA_MODEL=llama2\\\\\\\\\\\\\\\\nOLLAMA_EMBEDDING_MODEL=nomic-embed-text\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# API Configuration\\\\\\\\\\\\\\\\nAPI_HOST=0.0.0.0\\\\\\\\\\\\\\\\nAPI_PORT=8000\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Storage Configuration\\\\\\\\\\\\\\\\nCHROMA_PERSIST_DIRECTORY=./data/chroma_db\\\\\\\\\\\\\\\\nREPOS_DIRECTORY=./data/repos\\\\\\\\\\\\\\\\nDOCS_DIRECTORY=./data/generated_docs\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Processing Configuration\\\\\\\\\\\\\\\\nMAX_CHUNK_SIZE=2000\\\\\\\\\\\\\\\\nCHUNK_OVERLAP=200\\\\\\\\\\\\\\\\nMAX_CONTEXT_LENGTH=4000\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Supported Languages\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe system can analyze and understand code in:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- Python (.py)\\\\\\\\\\\\\\\\n- JavaScript/TypeScript (.js, .ts, .jsx, .tsx)\\\\\\\\\\\\\\\\n- Java (.java)\\\\\\\\\\\\\\\\n- C/C++ (.c, .cpp, .h)\\\\\\\\\\\\\\\\n- C# (.cs)\\\\\\\\\\\\\\\\n- PHP (.php)\\\\\\\\\\\\\\\\n- Ruby (.rb)\\\\\\\\\\\\\\\\n- Go (.go)\\\\\\\\\\\\\\\\n- Rust (.rs)\\\\\\\\\\\\\\\\n- Swift (.swift)\\\\\\\\\\\\\\\\n- Kotlin (.kt)\\\\\\\\\\\\\\\\n- Scala (.scala)\\\\\\\\\\\\\\\\n- And more...\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nPlus documentation files:\\\\\\\\\\\\\\\\n- Markdown (.md)\\\\\\\\\\\\\\\\n- reStructuredText (.rst)\\\\\\\\\\\\\\\\n- Plain text (.txt)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## CLI Commands\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Repository Management\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# List analyzed repositories\\\\\\\\\\\\\\\\npython main.py list\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Show system statistics\\\\\\\\\\\\\\\\npython main.py stats\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Analysis and Documentation\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Analyze repository\\\\\\\\\\\\\\\\npython main.py analyze <path> [--name <name>]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Generate documentation\\\\\\\\\\\\\\\\npython main.py docs <repo-name>\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Querying\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# One-time query\\\\\\\\\\\\\\\\npython main.py query \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"<question>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" [--repo <name>]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Interactive chat\\\\\\\\\\\\\\\\npython main.py chat [--repo <name>]\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Web Server\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Start web interface\\\\\\\\\\\\\\\\npython main.py server [--host <host>] [--port <port>]\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## API Endpoints\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWhen running the web server, these endpoints are available:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Health & System\\\\\\\\\\\\\\\\n- `GET /health` - System health check\\\\\\\\\\\\\\\\n- `GET /stats` - System statistics\\\\\\\\\\\\\\\\n- `GET /models` - List available Ollama models\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Repository Management\\\\\\\\\\\\\\\\n- `POST /repositories/analyze` - Analyze repository\\\\\\\\\\\\\\\\n- `GET /repositories` - List repositories\\\\\\\\\\\\\\\\n- `DELETE /repositories/{name}` - Delete repository\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Querying\\\\\\\\\\\\\\\\n- `POST /query` - Query with RAG system\\\\\\\\\\\\\\\\n- `POST /chat` - Chat interface\\\\\\\\\\\\\\\\n- `POST /explain` - Explain code snippet\\\\\\\\\\\\\\\\n- `POST /improve` - Suggest code improvements\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Documentation\\\\\\\\\\\\\\\\n- `POST /repositories/{name}/generate-docs` - Generate docs\\\\\\\\\\\\\\\\n- `GET /repositories/{name}/docs` - List generated docs\\\\\\\\\\\\\\\\n- `GET /repositories/{name}/docs/{path}` - Get specific doc\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Search\\\\\\\\\\\\\\\\n- `GET /search` - Search all repositories\\\\\\\\\\\\\\\\n- `GET /repositories/{name}/search` - Search specific repository\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## How It Works\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **Repository Analysis**: The system parses your codebase, extracting:\\\\\\\\\\\\\\\\n   - File structure and organization\\\\\\\\\\\\\\\\n   - Functions, classes, and their relationships\\\\\\\\\\\\\\\\n   - Import dependencies\\\\\\\\\\\\\\\\n   - Documentation and comments\\\\\\\\\\\\\\\\n   - Git information (if available)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n2. **Vector Embeddings**: Code and documentation are chunked and converted to embeddings using:\\\\\\\\\\\\\\\\n   - Ollama embedding models (preferred)\\\\\\\\\\\\\\\\n   - Sentence Transformers (fallback)\\\\\\\\\\\\\\\\n   - ChromaDB for efficient storage and retrieval\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n3. **RAG System**: When you ask questions:\\\\\\\\\\\\\\\\n   - Your query is embedded and matched against the codebase\\\\\\\\\\\\\\\\n   - Relevant code snippets and documentation are retrieved\\\\\\\\\\\\\\\\n   - Context is provided to the LLM for accurate, grounded responses\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n4. **Documentation Generation**: Using the analyzed structure:\\\\\\\\\\\\\\\\n   - README files with project overviews\\\\\\\\\\\\\\\\n   - API documentation for each file\\\\\\\\\\\\\\\\n   - Architecture documentation\\\\\\\\\\\\\\\\n   - Usage examples and tutorials\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Example Queries\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nHere are some example questions you can ask:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Code Understanding\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"How does user authentication work in this project?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What is the main entry point of the application?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Show me all the API endpoints\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"How is data validation handled?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Architecture Questions\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What's the overall architecture of this system?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"How do the different modules interact?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What design patterns are used?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What are the main dependencies?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Implementation Details\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"How is error handling implemented?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Where is the database connection configured?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"How are user permissions checked?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What testing framework is used?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Documentation\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate API documentation for the user service\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create a getting started guide\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Explain the deployment process\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Troubleshooting\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Ollama Issues\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Check if Ollama is running\\\\\\\\\\\\\\\\ncurl http://localhost:11434/api/tags\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Pull required models\\\\\\\\\\\\\\\\nollama pull llama2\\\\\\\\\\\\\\\\nollama pull nomic-embed-text\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Check model availability\\\\\\\\\\\\\\\\nollama list\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Common Problems\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Ollama server not available\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"**\\\\\\\\\\\\\\\\n   - Make sure Ollama is installed and running (`ollama serve`)\\\\\\\\\\\\\\\\n   - Check the OLLAMA_BASE_URL in your configuration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n2. **\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Model not found\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"**\\\\\\\\\\\\\\\\n   - Pull the required model: `ollama pull llama2`\\\\\\\\\\\\\\\\n   - Update OLLAMA_MODEL in configuration if using a different model\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n3. **\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No relevant context found\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"**\\\\\\\\\\\\\\\\n   - Make sure the repository has been analyzed\\\\\\\\\\\\\\\\n   - Try rephrasing your question\\\\\\\\\\\\\\\\n   - Check that the repository contains relevant code\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n4. **Slow responses**\\\\\\\\\\\\\\\\n   - Consider using a smaller, faster model (e.g., `llama2:7b`)\\\\\\\\\\\\\\\\n   - Reduce MAX_CONTEXT_LENGTH in configuration\\\\\\\\\\\\\\\\n   - Use more specific queries\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Performance Tips\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **Model Selection**: \\\\\\\\\\\\\\\\n   - Use `codellama` for better code understanding\\\\\\\\\\\\\\\\n   - Use `llama2:7b` for faster responses\\\\\\\\\\\\\\\\n   - Use `mistral` for a good balance\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n2. **Configuration Tuning**:\\\\\\\\\\\\\\\\n   - Adjust MAX_CHUNK_SIZE for your hardware\\\\\\\\\\\\\\\\n   - Reduce MAX_CONTEXT_LENGTH for faster responses\\\\\\\\\\\\\\\\n   - Increase CHUNK_OVERLAP for better context\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n3. **Repository Size**:\\\\\\\\\\\\\\\\n   - Large repositories may take time to analyze\\\\\\\\\\\\\\\\n   - Consider analyzing specific directories for faster results\\\\\\\\\\\\\\\\n   - Use .gitignore patterns to exclude unnecessary files\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Contributing\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. Fork the repository\\\\\\\\\\\\\\\\n2. Create a feature branch\\\\\\\\\\\\\\\\n3. Make your changes\\\\\\\\\\\\\\\\n4. Add tests if applicable\\\\\\\\\\\\\\\\n5. Submit a pull request\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## License\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis project is licensed under the MIT License - see the LICENSE file for details.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Acknowledgments\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- [Ollama](https://ollama.ai) for local LLM inference\\\\\\\\\\\\\\\\n- [ChromaDB](https://www.trychroma.com/) for vector storage\\\\\\\\\\\\\\\\n- [LangChain](https://langchain.com/) for RAG implementation\\\\\\\\\\\\\\\\n- [FastAPI](https://fastapi.tiangolo.com/) for the web API\\\\\\\\\\\\\\\\n- [Vue.js](https://vuejs.org/) for the web interface\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Roadmap\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- [ ] Support for more programming languages\\\\\\\\\\\\\\\\n- [ ] Advanced code analysis (call graphs, dependency analysis)\\\\\\\\\\\\\\\\n- [ ] Integration with popular IDEs\\\\\\\\\\\\\\\\n- [ ] Multi-repository projects support\\\\\\\\\\\\\\\\n- [ ] Custom model fine-tuning\\\\\\\\\\\\\\\\n- [ ] Collaborative features\\\\\\\\\\\\\\\\n- [ ] Plugin system for extensibility\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"file_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"imports\\\\\\\\\\\\\\\": [\\\\\\\\n        \\\\\\\\\\\\\\\"os\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"ast\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"re\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"pathlib.Path\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Dict\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.List\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Any\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Optional\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Tuple\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"dataclasses.dataclass\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"dataclasses.asdict\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"git\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"config.settings\\\\\\\\\\\\\\\"\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"elements\\\\\\\\\\\\\\\": [\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"CodeElement\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 14,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 28,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Represents a code element (function, class, etc.).\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class CodeElement\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"CodeElement.__post_init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 26,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 28,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __post_init__(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"FileAnalysis\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 31,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 45,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Analysis results for a single file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class FileAnalysis\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"FileAnalysis.__post_init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 41,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 45,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __post_init__(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 47,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 348,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Analyzes code repositories to extract structure and content.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class RepositoryAnalyzer\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer.__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 50,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 69,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer.analyze_repository\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 71,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 132,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Analyze an entire repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def analyze_repository(self, repo_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer.analyze_file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 134,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 170,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Analyze a single file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def analyze_file(self, file_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer._analyze_python_file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 172,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 230,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Analyze Python file for structure.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _analyze_python_file(self, analysis, content)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer._analyze_js_ts_file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 232,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 285,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Analyze JavaScript/TypeScript file for structure.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _analyze_js_ts_file(self, analysis, content)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer._get_function_args\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 287,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 292,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Extract function arguments as string.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _get_function_args(self, node)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer._get_files_to_analyze\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 294,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 307,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Get list of files to analyze, respecting ignore patterns.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _get_files_to_analyze(self, repo_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer._should_ignore_dir\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 309,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 311,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Check if directory should be ignored.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _should_ignore_dir(self, dirname)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer._should_analyze_file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 313,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 316,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Check if file should be analyzed.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _should_analyze_file(self, file_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer._build_directory_structure\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 318,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 338,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Build a tree representation of the directory structure.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _build_directory_structure(self, repo_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer.save_analysis\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 340,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 343,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Save analysis results to JSON file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def save_analysis(self, analysis, output_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"RepositoryAnalyzer.load_analysis\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 345,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 348,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Load analysis results from JSON file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def load_analysis(self, input_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"__post_init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 26,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 28,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __post_init__(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"__post_init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 41,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 45,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __post_init__(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 50,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 69,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"analyze_repository\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 71,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 132,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Analyze an entire repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def analyze_repository(self, repo_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"analyze_file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 134,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 170,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Analyze a single file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def analyze_file(self, file_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"_analyze_python_file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 172,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 230,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Analyze Python file for structure.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _analyze_python_file(self, analysis, content)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"_analyze_js_ts_file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 232,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 285,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Analyze JavaScript/TypeScript file for structure.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _analyze_js_ts_file(self, analysis, content)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"_get_function_args\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 287,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 292,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Extract function arguments as string.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _get_function_args(self, node)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"_get_files_to_analyze\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 294,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 307,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Get list of files to analyze, respecting ignore patterns.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _get_files_to_analyze(self, repo_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"_should_ignore_dir\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 309,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 311,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Check if directory should be ignored.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _should_ignore_dir(self, dirname)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"_should_analyze_file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 313,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 316,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Check if file should be analyzed.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _should_analyze_file(self, file_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"_build_directory_structure\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 318,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 338,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Build a tree representation of the directory structure.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def _build_directory_structure(self, repo_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"save_analysis\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 340,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 343,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Save analysis results to JSON file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def save_analysis(self, analysis, output_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"load_analysis\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 345,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 348,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Load analysis results from JSON file.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def load_analysis(self, input_path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"build_tree\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 320,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 336,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def build_tree(path)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        }\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository analysis module for extracting code structure and content.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport ast\\\\\\\\\\\\\\\\nimport re\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom typing import Dict, List, Any, Optional, Tuple\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass, asdict\\\\\\\\\\\\\\\\nimport git\\\\\\\\\\\\\\\\nfrom config import settings\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass CodeElement:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Represents a code element (function, class, etc.).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    name: str\\\\\\\\\\\\\\\\n    type: str  # 'function', 'class', 'method', 'variable'\\\\\\\\\\\\\\\\n    file_path: str\\\\\\\\\\\\\\\\n    line_start: int\\\\\\\\\\\\\\\\n    line_end: int\\\\\\\\\\\\\\\\n    docstring: Optional[str] = None\\\\\\\\\\\\\\\\n    signature: Optional[str] = None\\\\\\\\\\\\\\\\n    content: Optional[str] = None\\\\\\\\\\\\\\\\n    dependencies: List[str] = None\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def __post_init__(self):\\\\\\\\\\\\\\\\n        if self.dependencies is None:\\\\\\\\\\\\\\\\n            self.dependencies = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass FileAnalysis:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analysis results for a single file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    file_path: str\\\\\\\\\\\\\\\\n    file_type: str  # 'code', 'documentation', 'config'\\\\\\\\\\\\\\\\n    language: Optional[str] = None\\\\\\\\\\\\\\\\n    imports: List[str] = None\\\\\\\\\\\\\\\\n    elements: List[CodeElement] = None\\\\\\\\\\\\\\\\n    summary: Optional[str] = None\\\\\\\\\\\\\\\\n    content: Optional[str] = None\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def __post_init__(self):\\\\\\\\\\\\\\\\n        if self.imports is None:\\\\\\\\\\\\\\\\n            self.imports = []\\\\\\\\\\\\\\\\n        if self.elements is None:\\\\\\\\\\\\\\\\n            self.elements = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass RepositoryAnalyzer:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyzes code repositories to extract structure and content.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def __init__(self):\\\\\\\\\\\\\\\\n        self.supported_languages = {\\\\\\\\\\\\\\\\n            '.py': 'python',\\\\\\\\\\\\\\\\n            '.js': 'javascript', \\\\\\\\\\\\\\\\n            '.ts': 'typescript',\\\\\\\\\\\\\\\\n            '.jsx': 'javascript',\\\\\\\\\\\\\\\\n            '.tsx': 'typescript',\\\\\\\\\\\\\\\\n            '.java': 'java',\\\\\\\\\\\\\\\\n            '.cpp': 'cpp',\\\\\\\\\\\\\\\\n            '.c': 'c',\\\\\\\\\\\\\\\\n            '.h': 'c',\\\\\\\\\\\\\\\\n            '.cs': 'csharp',\\\\\\\\\\\\\\\\n            '.php': 'php',\\\\\\\\\\\\\\\\n            '.rb': 'ruby',\\\\\\\\\\\\\\\\n            '.go': 'go',\\\\\\\\\\\\\\\\n            '.rs': 'rust',\\\\\\\\\\\\\\\\n            '.swift': 'swift',\\\\\\\\\\\\\\\\n            '.kt': 'kotlin',\\\\\\\\\\\\\\\\n            '.scala': 'scala'\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def analyze_repository(self, repo_path: str) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyze an entire repository.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        repo_path = Path(repo_path)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if not repo_path.exists():\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository path does not exist: {repo_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        analysis = {\\\\\\\\\\\\\\\\n            'repo_path': str(repo_path),\\\\\\\\\\\\\\\\n            'repo_name': repo_path.name,\\\\\\\\\\\\\\\\n            'files': [],\\\\\\\\\\\\\\\\n            'structure': {},\\\\\\\\\\\\\\\\n            'statistics': {\\\\\\\\\\\\\\\\n                'total_files': 0,\\\\\\\\\\\\\\\\n                'code_files': 0,\\\\\\\\\\\\\\\\n                'doc_files': 0,\\\\\\\\\\\\\\\\n                'languages': {},\\\\\\\\\\\\\\\\n                'total_lines': 0\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Get git info if available\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            repo = git.Repo(repo_path)\\\\\\\\\\\\\\\\n            analysis['git_info'] = {\\\\\\\\\\\\\\\\n                'remote_url': repo.remotes.origin.url if repo.remotes else None,\\\\\\\\\\\\\\\\n                'current_branch': repo.active_branch.name,\\\\\\\\\\\\\\\\n                'last_commit': {\\\\\\\\\\\\\\\\n                    'hash': repo.head.commit.hexsha[:8],\\\\\\\\\\\\\\\\n                    'message': repo.head.commit.message.strip(),\\\\\\\\\\\\\\\\n                    'author': str(repo.head.commit.author),\\\\\\\\\\\\\\\\n                    'date': repo.head.commit.committed_datetime.isoformat()\\\\\\\\\\\\\\\\n                }\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\n        except:\\\\\\\\\\\\\\\\n            analysis['git_info'] = None\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Analyze files\\\\\\\\\\\\\\\\n        for file_path in self._get_files_to_analyze(repo_path):\\\\\\\\\\\\\\\\n            file_analysis = self.analyze_file(file_path)\\\\\\\\\\\\\\\\n            if file_analysis:\\\\\\\\\\\\\\\\n                analysis['files'].append(asdict(file_analysis))\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                # Update statistics\\\\\\\\\\\\\\\\n                analysis['statistics']['total_files'] += 1\\\\\\\\\\\\\\\\n                if file_analysis.file_type == 'code':\\\\\\\\\\\\\\\\n                    analysis['statistics']['code_files'] += 1\\\\\\\\\\\\\\\\n                    if file_analysis.language:\\\\\\\\\\\\\\\\n                        lang = file_analysis.language\\\\\\\\\\\\\\\\n                        analysis['statistics']['languages'][lang] = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            analysis['statistics']['languages'].get(lang, 0) + 1\\\\\\\\\\\\\\\\n                elif file_analysis.file_type == 'documentation':\\\\\\\\\\\\\\\\n                    analysis['statistics']['doc_files'] += 1\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                # Count lines\\\\\\\\\\\\\\\\n                if file_analysis.content:\\\\\\\\\\\\\\\\n                    analysis['statistics']['total_lines'] += len(file_analysis.content.split('\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n'))\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Build directory structure\\\\\\\\\\\\\\\\n        analysis['structure'] = self._build_directory_structure(repo_path)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return analysis\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def analyze_file(self, file_path: Path) -> Optional[FileAnalysis]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyze a single file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\\\\\\\\\\\\\\\\n                content = f.read()\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error reading file {file_path}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return None\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        file_ext = file_path.suffix.lower()\\\\\\\\\\\\\\\\n        relative_path = str(file_path)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Determine file type and language\\\\\\\\\\\\\\\\n        if file_ext in settings.CODE_EXTENSIONS:\\\\\\\\\\\\\\\\n            file_type = 'code'\\\\\\\\\\\\\\\\n            language = self.supported_languages.get(file_ext)\\\\\\\\\\\\\\\\n        elif file_ext in settings.DOC_EXTENSIONS:\\\\\\\\\\\\\\\\n            file_type = 'documentation'\\\\\\\\\\\\\\\\n            language = None\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            file_type = 'config'\\\\\\\\\\\\\\\\n            language = None\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        analysis = FileAnalysis(\\\\\\\\\\\\\\\\n            file_path=relative_path,\\\\\\\\\\\\\\\\n            file_type=file_type,\\\\\\\\\\\\\\\\n            language=language,\\\\\\\\\\\\\\\\n            content=content\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Language-specific analysis\\\\\\\\\\\\\\\\n        if language == 'python':\\\\\\\\\\\\\\\\n            self._analyze_python_file(analysis, content)\\\\\\\\\\\\\\\\n        elif language in ['javascript', 'typescript']:\\\\\\\\\\\\\\\\n            self._analyze_js_ts_file(analysis, content)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return analysis\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def _analyze_python_file(self, analysis: FileAnalysis, content: str):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyze Python file for structure.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            tree = ast.parse(content)\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Extract imports\\\\\\\\\\\\\\\\n            for node in ast.walk(tree):\\\\\\\\\\\\\\\\n                if isinstance(node, ast.Import):\\\\\\\\\\\\\\\\n                    for alias in node.names:\\\\\\\\\\\\\\\\n                        analysis.imports.append(alias.name)\\\\\\\\\\\\\\\\n                elif isinstance(node, ast.ImportFrom):\\\\\\\\\\\\\\\\n                    module = node.module or ''\\\\\\\\\\\\\\\\n                    for alias in node.names:\\\\\\\\\\\\\\\\n                        analysis.imports.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{module}.{alias.name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Extract classes and functions\\\\\\\\\\\\\\\\n            for node in ast.walk(tree):\\\\\\\\\\\\\\\\n                if isinstance(node, ast.ClassDef):\\\\\\\\\\\\\\\\n                    element = CodeElement(\\\\\\\\\\\\\\\\n                        name=node.name,\\\\\\\\\\\\\\\\n                        type='class',\\\\\\\\\\\\\\\\n                        file_path=analysis.file_path,\\\\\\\\\\\\\\\\n                        line_start=node.lineno,\\\\\\\\\\\\\\\\n                        line_end=getattr(node, 'end_lineno', node.lineno),\\\\\\\\\\\\\\\\n                        docstring=ast.get_docstring(node),\\\\\\\\\\\\\\\\n                        signature=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"class {node.name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\n                    analysis.elements.append(element)\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    # Extract methods\\\\\\\\\\\\\\\\n                    for item in node.body:\\\\\\\\\\\\\\\\n                        if isinstance(item, ast.FunctionDef):\\\\\\\\\\\\\\\\n                            method = CodeElement(\\\\\\\\\\\\\\\\n                                name=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{node.name}.{item.name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                                type='method',\\\\\\\\\\\\\\\\n                                file_path=analysis.file_path,\\\\\\\\\\\\\\\\n                                line_start=item.lineno,\\\\\\\\\\\\\\\\n                                line_end=getattr(item, 'end_lineno', item.lineno),\\\\\\\\\\\\\\\\n                                docstring=ast.get_docstring(item),\\\\\\\\\\\\\\\\n                                signature=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"def {item.name}({self._get_function_args(item)})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                            )\\\\\\\\\\\\\\\\n                            analysis.elements.append(method)\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                elif isinstance(node, ast.FunctionDef):\\\\\\\\\\\\\\\\n                    # Only top-level functions (not methods)\\\\\\\\\\\\\\\\n                    if isinstance(getattr(node, 'parent', None), ast.Module) or not hasattr(node, 'parent'):\\\\\\\\\\\\\\\\n                        element = CodeElement(\\\\\\\\\\\\\\\\n                            name=node.name,\\\\\\\\\\\\\\\\n                            type='function',\\\\\\\\\\\\\\\\n                            file_path=analysis.file_path,\\\\\\\\\\\\\\\\n                            line_start=node.lineno,\\\\\\\\\\\\\\\\n                            line_end=getattr(node, 'end_lineno', node.lineno),\\\\\\\\\\\\\\\\n                            docstring=ast.get_docstring(node),\\\\\\\\\\\\\\\\n                            signature=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"def {node.name}({self._get_function_args(node)})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                        )\\\\\\\\\\\\\\\\n                        analysis.elements.append(element)\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\n        except SyntaxError as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Syntax error in {analysis.file_path}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def _analyze_js_ts_file(self, analysis: FileAnalysis, content: str):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyze JavaScript/TypeScript file for structure.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        lines = content.split('\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n')\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Extract imports (simple regex-based approach)\\\\\\\\\\\\\\\\n        import_patterns = [\\\\\\\\\\\\\\\\n            r'import\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s+.*?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s+from\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s+[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]([^\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]+)[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]',\\\\\\\\\\\\\\\\n            r'const\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s+.*?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*require\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\([\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]([^\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]+)[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\)',\\\\\\\\\\\\\\\\n            r'import\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]([^\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]+)[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\)'\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        for line in lines:\\\\\\\\\\\\\\\\n            for pattern in import_patterns:\\\\\\\\\\\\\\\\n                matches = re.findall(pattern, line)\\\\\\\\\\\\\\\\n                analysis.imports.extend(matches)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Extract functions and classes (basic regex patterns)\\\\\\\\\\\\\\\\n        function_patterns = [\\\\\\\\\\\\\\\\n            r'function\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s+(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\w+)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\(',\\\\\\\\\\\\\\\\n            r'const\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s+(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\w+)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\(',\\\\\\\\\\\\\\\\n            r'(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\w+)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*function\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\(',\\\\\\\\\\\\\\\\n            r'(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\w+)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\([^)]*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*=>',\\\\\\\\\\\\\\\\n            r'async\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s+function\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s+(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\w+)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\('\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        class_pattern = r'class\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s+(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\w+)'\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        for i, line in enumerate(lines, 1):\\\\\\\\\\\\\\\\n            # Find classes\\\\\\\\\\\\\\\\n            class_match = re.search(class_pattern, line)\\\\\\\\\\\\\\\\n            if class_match:\\\\\\\\\\\\\\\\n                element = CodeElement(\\\\\\\\\\\\\\\\n                    name=class_match.group(1),\\\\\\\\\\\\\\\\n                    type='class',\\\\\\\\\\\\\\\\n                    file_path=analysis.file_path,\\\\\\\\\\\\\\\\n                    line_start=i,\\\\\\\\\\\\\\\\n                    line_end=i,  # We'd need more sophisticated parsing to find end\\\\\\\\\\\\\\\\n                    signature=line.strip()\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n                analysis.elements.append(element)\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Find functions\\\\\\\\\\\\\\\\n            for pattern in function_patterns:\\\\\\\\\\\\\\\\n                func_match = re.search(pattern, line)\\\\\\\\\\\\\\\\n                if func_match:\\\\\\\\\\\\\\\\n                    element = CodeElement(\\\\\\\\\\\\\\\\n                        name=func_match.group(1),\\\\\\\\\\\\\\\\n                        type='function',\\\\\\\\\\\\\\\\n                        file_path=analysis.file_path,\\\\\\\\\\\\\\\\n                        line_start=i,\\\\\\\\\\\\\\\\n                        line_end=i,\\\\\\\\\\\\\\\\n                        signature=line.strip()\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\n                    analysis.elements.append(element)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def _get_function_args(self, node: ast.FunctionDef) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Extract function arguments as string.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        args = []\\\\\\\\\\\\\\\\n        for arg in node.args.args:\\\\\\\\\\\\\\\\n            args.append(arg.arg)\\\\\\\\\\\\\\\\n        return ', '.join(args)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def _get_files_to_analyze(self, repo_path: Path) -> List[Path]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get list of files to analyze, respecting ignore patterns.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        files = []\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        for root, dirs, filenames in os.walk(repo_path):\\\\\\\\\\\\\\\\n            # Remove ignored directories\\\\\\\\\\\\\\\\n            dirs[:] = [d for d in dirs if not self._should_ignore_dir(d)]\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            for filename in filenames:\\\\\\\\\\\\\\\\n                file_path = Path(root) / filename\\\\\\\\\\\\\\\\n                if self._should_analyze_file(file_path):\\\\\\\\\\\\\\\\n                    files.append(file_path)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return files\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def _should_ignore_dir(self, dirname: str) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if directory should be ignored.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return dirname in settings.IGNORED_DIRS or dirname.startswith('.')\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def _should_analyze_file(self, file_path: Path) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if file should be analyzed.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        ext = file_path.suffix.lower()\\\\\\\\\\\\\\\\n        return ext in settings.CODE_EXTENSIONS or ext in settings.DOC_EXTENSIONS\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def _build_directory_structure(self, repo_path: Path) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Build a tree representation of the directory structure.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        def build_tree(path: Path) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n            tree = {'name': path.name, 'type': 'directory', 'children': []}\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                for item in sorted(path.iterdir()):\\\\\\\\\\\\\\\\n                    if item.is_dir() and not self._should_ignore_dir(item.name):\\\\\\\\\\\\\\\\n                        tree['children'].append(build_tree(item))\\\\\\\\\\\\\\\\n                    elif item.is_file() and self._should_analyze_file(item):\\\\\\\\\\\\\\\\n                        tree['children'].append({\\\\\\\\\\\\\\\\n                            'name': item.name,\\\\\\\\\\\\\\\\n                            'type': 'file',\\\\\\\\\\\\\\\\n                            'path': str(item.relative_to(repo_path))\\\\\\\\\\\\\\\\n                        })\\\\\\\\\\\\\\\\n            except PermissionError:\\\\\\\\\\\\\\\\n                pass\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            return tree\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return build_tree(repo_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def save_analysis(self, analysis: Dict[str, Any], output_path: str):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Save analysis results to JSON file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        with open(output_path, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n            json.dump(analysis, f, indent=2, ensure_ascii=False)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def load_analysis(self, input_path: str) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Load analysis results from JSON file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        with open(input_path, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n            return json.load(f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\requirements.txt\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"file_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"documentation\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"imports\\\\\\\\\\\\\\\": [],\\\\\\\\n      \\\\\\\\\\\\\\\"elements\\\\\\\\\\\\\\\": [],\\\\\\\\n      \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ollama>=0.2.0\\\\\\\\\\\\\\\\nlangchain>=0.1.0\\\\\\\\\\\\\\\\nlangchain-community>=0.0.20\\\\\\\\\\\\\\\\nchromadb>=0.4.0\\\\\\\\\\\\\\\\nsentence-transformers>=2.2.2\\\\\\\\\\\\\\\\nfastapi>=0.104.0\\\\\\\\\\\\\\\\nuvicorn>=0.24.0\\\\\\\\\\\\\\\\npydantic>=2.5.0\\\\\\\\\\\\\\\\npython-multipart>=0.0.6\\\\\\\\\\\\\\\\ngitpython>=3.1.40\\\\\\\\\\\\\\\\npathspec>=0.12.0\\\\\\\\\\\\\\\\ntiktoken>=0.5.0\\\\\\\\\\\\\\\\njinja2>=3.1.0\\\\\\\\\\\\\\\\nmarkdown>=3.5.0\\\\\\\\\\\\\\\\nbeautifulsoup4>=4.12.0\\\\\\\\\\\\\\\\ntree-sitter>=0.20.0\\\\\\\\\\\\\\\\ntree-sitter-python>=0.20.0\\\\\\\\\\\\\\\\ntree-sitter-javascript>=0.20.0\\\\\\\\\\\\\\\\ntree-sitter-typescript>=0.20.0\\\\\\\\\\\\\\\\naiofiles>=23.2.0\\\\\\\\\\\\\\\\nwatchdog>=3.0.0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"file_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"imports\\\\\\\\\\\\\\\": [\\\\\\\\n        \\\\\\\\\\\\\\\"os\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"hashlib\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"pathlib.Path\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.List\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Dict\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Any\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Optional\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"typing.Tuple\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"chromadb\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"chromadb.config.Settings\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"sentence_transformers.SentenceTransformer\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"tiktoken\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"config.settings\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"ollama_client.OllamaClient\\\\\\\\\\\\\\\"\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"elements\\\\\\\\\\\\\\\": [\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"TextChunker\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 15,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 188,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Utility class for chunking text into manageable pieces.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class TextChunker\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"TextChunker.__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 18,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 26,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self, max_chunk_size, overlap)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"TextChunker.count_tokens\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 28,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 34,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Count tokens in text.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def count_tokens(self, text)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"TextChunker.chunk_text\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 36,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 113,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Split text into chunks with metadata.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def chunk_text(self, text, metadata)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"TextChunker.chunk_code_file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 115,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 188,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Chunk code file based on structure.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def chunk_code_file(self, content, file_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"VectorStore\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 190,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 411,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Vector store for embeddings using ChromaDB and local embeddings.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"class VectorStore\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"VectorStore.__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 193,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 219,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self, persist_directory, collection_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"VectorStore.get_embedding\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 221,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 238,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Get embedding for text using available models.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def get_embedding(self, text)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"VectorStore.add_repository\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 240,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 270,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Add entire repository to vector store.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def add_repository(self, repo_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"VectorStore.add_file_analysis\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 272,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 295,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Add file analysis to vector store.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def add_file_analysis(self, file_analysis, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"VectorStore.add_document\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 297,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 300,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Add a single document to vector store.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def add_document(self, text, metadata)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"VectorStore.add_chunks\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 302,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 348,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Add multiple chunks to vector store.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def add_chunks(self, chunks)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"VectorStore.search\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 350,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 379,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Search vector store for relevant documents.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def search(self, query, n_results, filter_metadata)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"VectorStore.get_collection_stats\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 381,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 391,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Get statistics about the collection.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def get_collection_stats(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"VectorStore.clear_collection\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 393,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 400,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Clear all documents from collection.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def clear_collection(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"VectorStore.delete_repository\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"method\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 402,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 411,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Delete all documents from a specific repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def delete_repository(self, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 18,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 26,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self, max_chunk_size, overlap)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"count_tokens\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 28,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 34,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Count tokens in text.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def count_tokens(self, text)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chunk_text\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 36,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 113,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Split text into chunks with metadata.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def chunk_text(self, text, metadata)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chunk_code_file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 115,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 188,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Chunk code file based on structure.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def chunk_code_file(self, content, file_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"__init__\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 193,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 219,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def __init__(self, persist_directory, collection_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"get_embedding\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 221,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 238,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Get embedding for text using available models.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def get_embedding(self, text)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"add_repository\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 240,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 270,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Add entire repository to vector store.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def add_repository(self, repo_analysis)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"add_file_analysis\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 272,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 295,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Add file analysis to vector store.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def add_file_analysis(self, file_analysis, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"add_document\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 297,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 300,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Add a single document to vector store.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def add_document(self, text, metadata)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"add_chunks\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 302,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 348,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Add multiple chunks to vector store.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def add_chunks(self, chunks)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"search\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 350,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 379,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Search vector store for relevant documents.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def search(self, query, n_results, filter_metadata)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"get_collection_stats\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 381,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 391,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Get statistics about the collection.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def get_collection_stats(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"clear_collection\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 393,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 400,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Clear all documents from collection.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def clear_collection(self)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        },\\\\\\\\n        {\\\\\\\\n          \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"delete_repository\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"function\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"line_start\\\\\\\\\\\\\\\": 402,\\\\\\\\n          \\\\\\\\\\\\\\\"line_end\\\\\\\\\\\\\\\": 411,\\\\\\\\n          \\\\\\\\\\\\\\\"docstring\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Delete all documents from a specific repository.\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"signature\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"def delete_repository(self, repo_name)\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": null,\\\\\\\\n          \\\\\\\\\\\\\\\"dependencies\\\\\\\\\\\\\\\": []\\\\\\\\n        }\\\\\\\\n      ],\\\\\\\\n      \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vector embedding and storage system using ChromaDB.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport hashlib\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom typing import List, Dict, Any, Optional, Tuple\\\\\\\\\\\\\\\\nimport chromadb\\\\\\\\\\\\\\\\nfrom chromadb.config import Settings\\\\\\\\\\\\\\\\nfrom sentence_transformers import SentenceTransformer\\\\\\\\\\\\\\\\nimport tiktoken\\\\\\\\\\\\\\\\nfrom config import settings\\\\\\\\\\\\\\\\nfrom ollama_client import OllamaClient\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TextChunker:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Utility class for chunking text into manageable pieces.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def __init__(self, max_chunk_size: int = None, overlap: int = None):\\\\\\\\\\\\\\\\n        self.max_chunk_size = max_chunk_size or settings.MAX_CHUNK_SIZE\\\\\\\\\\\\\\\\n        self.overlap = overlap or settings.CHUNK_OVERLAP\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Initialize tokenizer for accurate token counting\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            self.tokenizer = tiktoken.get_encoding(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cl100k_base\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        except:\\\\\\\\\\\\\\\\n            self.tokenizer = None\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def count_tokens(self, text: str) -> int:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Count tokens in text.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if self.tokenizer:\\\\\\\\\\\\\\\\n            return len(self.tokenizer.encode(text))\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            # Rough approximation: 1 token â‰ˆ 4 characters\\\\\\\\\\\\\\\\n            return len(text) // 4\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def chunk_text(self, text: str, metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Split text into chunks with metadata.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if metadata is None:\\\\\\\\\\\\\\\\n            metadata = {}\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        chunks = []\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Split by paragraphs first\\\\\\\\\\\\\\\\n        paragraphs = text.split('\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n')\\\\\\\\\\\\\\\\n        current_chunk = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        current_tokens = 0\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        for para in paragraphs:\\\\\\\\\\\\\\\\n            para_tokens = self.count_tokens(para)\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # If single paragraph exceeds max size, split it further\\\\\\\\\\\\\\\\n            if para_tokens > self.max_chunk_size:\\\\\\\\\\\\\\\\n                # Save current chunk if not empty\\\\\\\\\\\\\\\\n                if current_chunk.strip():\\\\\\\\\\\\\\\\n                    chunks.append({\\\\\\\\\\\\\\\\n                        'text': current_chunk.strip(),\\\\\\\\\\\\\\\\n                        'tokens': current_tokens,\\\\\\\\\\\\\\\\n                        **metadata\\\\\\\\\\\\\\\\n                    })\\\\\\\\\\\\\\\\n                    current_chunk = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    current_tokens = 0\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                # Split large paragraph by sentences\\\\\\\\\\\\\\\\n                sentences = para.split('. ')\\\\\\\\\\\\\\\\n                for sentence in sentences:\\\\\\\\\\\\\\\\n                    sentence_tokens = self.count_tokens(sentence)\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    if current_tokens + sentence_tokens > self.max_chunk_size:\\\\\\\\\\\\\\\\n                        if current_chunk.strip():\\\\\\\\\\\\\\\\n                            chunks.append({\\\\\\\\\\\\\\\\n                                'text': current_chunk.strip(),\\\\\\\\\\\\\\\\n                                'tokens': current_tokens,\\\\\\\\\\\\\\\\n                                **metadata\\\\\\\\\\\\\\\\n                            })\\\\\\\\\\\\\\\\n                        current_chunk = sentence\\\\\\\\\\\\\\\\n                        current_tokens = sentence_tokens\\\\\\\\\\\\\\\\n                    else:\\\\\\\\\\\\\\\\n                        current_chunk += (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\". \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" if current_chunk else \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") + sentence\\\\\\\\\\\\\\\\n                        current_tokens += sentence_tokens\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Normal paragraph processing\\\\\\\\\\\\\\\\n            elif current_tokens + para_tokens > self.max_chunk_size:\\\\\\\\\\\\\\\\n                # Save current chunk\\\\\\\\\\\\\\\\n                if current_chunk.strip():\\\\\\\\\\\\\\\\n                    chunks.append({\\\\\\\\\\\\\\\\n                        'text': current_chunk.strip(),\\\\\\\\\\\\\\\\n                        'tokens': current_tokens,\\\\\\\\\\\\\\\\n                        **metadata\\\\\\\\\\\\\\\\n                    })\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                # Start new chunk with overlap\\\\\\\\\\\\\\\\n                if self.overlap > 0 and chunks:\\\\\\\\\\\\\\\\n                    # Get last few words for overlap\\\\\\\\\\\\\\\\n                    last_chunk_words = current_chunk.split()\\\\\\\\\\\\\\\\n                    overlap_words = last_chunk_words[-self.overlap:] if len(last_chunk_words) > self.overlap else last_chunk_words\\\\\\\\\\\\\\\\n                    current_chunk = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join(overlap_words) + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" + para\\\\\\\\\\\\\\\\n                else:\\\\\\\\\\\\\\\\n                    current_chunk = para\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                current_tokens = self.count_tokens(current_chunk)\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\n                current_chunk += (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" if current_chunk else \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") + para\\\\\\\\\\\\\\\\n                current_tokens += para_tokens\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add final chunk\\\\\\\\\\\\\\\\n        if current_chunk.strip():\\\\\\\\\\\\\\\\n            chunks.append({\\\\\\\\\\\\\\\\n                'text': current_chunk.strip(),\\\\\\\\\\\\\\\\n                'tokens': current_tokens,\\\\\\\\\\\\\\\\n                **metadata\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return chunks\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def chunk_code_file(self, content: str, file_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Chunk code file based on structure.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        chunks = []\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Create chunk for file overview\\\\\\\\\\\\\\\\n        overview_text = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"File: {file_analysis['file_path']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        overview_text += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Language: {file_analysis.get('language', 'Unknown')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if file_analysis.get('imports'):\\\\\\\\\\\\\\\\n            overview_text += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Imports: {', '.join(file_analysis['imports'])}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add summary of elements\\\\\\\\\\\\\\\\n        elements = file_analysis.get('elements', [])\\\\\\\\\\\\\\\\n        if elements:\\\\\\\\\\\\\\\\n            overview_text += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nCode Elements:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            for element in elements:\\\\\\\\\\\\\\\\n                overview_text += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- {element['type']}: {element['name']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                if element.get('docstring'):\\\\\\\\\\\\\\\\n                    overview_text += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  {element['docstring'][:100]}...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        chunks.append({\\\\\\\\\\\\\\\\n            'text': overview_text,\\\\\\\\\\\\\\\\n            'type': 'file_overview',\\\\\\\\\\\\\\\\n            'file_path': file_analysis['file_path'],\\\\\\\\\\\\\\\\n            'language': file_analysis.get('language'),\\\\\\\\\\\\\\\\n            'source': 'code_analysis'\\\\\\\\\\\\\\\\n        })\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Create chunks for individual code elements\\\\\\\\\\\\\\\\n        lines = content.split('\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n')\\\\\\\\\\\\\\\\n        for element in elements:\\\\\\\\\\\\\\\\n            start_line = element.get('line_start', 1) - 1  # Convert to 0-based\\\\\\\\\\\\\\\\n            end_line = element.get('line_end', len(lines))\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            if start_line < len(lines):\\\\\\\\\\\\\\\\n                element_content = '\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n'.join(lines[start_line:min(end_line, len(lines))])\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                element_text = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Element: {element['name']} ({element['type']})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                element_text += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"File: {file_analysis['file_path']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                if element.get('signature'):\\\\\\\\\\\\\\\\n                    element_text += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Signature: {element['signature']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                if element.get('docstring'):\\\\\\\\\\\\\\\\n                    element_text += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Documentation: {element['docstring']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                element_text += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nCode:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```{file_analysis.get('language', '')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n{element_content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                chunks.append({\\\\\\\\\\\\\\\\n                    'text': element_text,\\\\\\\\\\\\\\\\n                    'type': 'code_element',\\\\\\\\\\\\\\\\n                    'element_type': element['type'],\\\\\\\\\\\\\\\\n                    'element_name': element['name'],\\\\\\\\\\\\\\\\n                    'file_path': file_analysis['file_path'],\\\\\\\\\\\\\\\\n                    'language': file_analysis.get('language'),\\\\\\\\\\\\\\\\n                    'line_start': element.get('line_start'),\\\\\\\\\\\\\\\\n                    'line_end': element.get('line_end'),\\\\\\\\\\\\\\\\n                    'source': 'code_analysis'\\\\\\\\\\\\\\\\n                })\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # If no elements found, chunk the entire file content\\\\\\\\\\\\\\\\n        if not elements and content.strip():\\\\\\\\\\\\\\\\n            file_chunks = self.chunk_text(\\\\\\\\\\\\\\\\n                content, \\\\\\\\\\\\\\\\n                {\\\\\\\\\\\\\\\\n                    'type': 'file_content',\\\\\\\\\\\\\\\\n                    'file_path': file_analysis['file_path'],\\\\\\\\\\\\\\\\n                    'language': file_analysis.get('language'),\\\\\\\\\\\\\\\\n                    'source': 'file_content'\\\\\\\\\\\\\\\\n                }\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n            chunks.extend(file_chunks)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return chunks\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass VectorStore:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vector store for embeddings using ChromaDB and local embeddings.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def __init__(self, persist_directory: str = None, collection_name: str = None):\\\\\\\\\\\\\\\\n        self.persist_directory = persist_directory or settings.CHROMA_PERSIST_DIRECTORY\\\\\\\\\\\\\\\\n        self.collection_name = collection_name or settings.COLLECTION_NAME\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Initialize ChromaDB\\\\\\\\\\\\\\\\n        self.client = chromadb.PersistentClient(\\\\\\\\\\\\\\\\n            path=self.persist_directory,\\\\\\\\\\\\\\\\n            settings=Settings(anonymized_telemetry=False)\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Get or create collection\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            self.collection = self.client.get_collection(name=self.collection_name)\\\\\\\\\\\\\\\\n        except:\\\\\\\\\\\\\\\\n            self.collection = self.client.create_collection(name=self.collection_name)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Initialize embedding models\\\\\\\\\\\\\\\\n        self.ollama_client = OllamaClient()\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Fallback to sentence transformers if Ollama embeddings fail\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            self.sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')\\\\\\\\\\\\\\\\n        except:\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Warning: Could not load sentence transformer model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            self.sentence_transformer = None\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        self.chunker = TextChunker()\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def get_embedding(self, text: str) -> List[float]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get embedding for text using available models.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Try Ollama first\\\\\\\\\\\\\\\\n        if self.ollama_client.is_available():\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                return self.ollama_client.get_embeddings(text)\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Ollama embedding failed: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Fallback to sentence transformer\\\\\\\\\\\\\\\\n        if self.sentence_transformer:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                embedding = self.sentence_transformer.encode(text)\\\\\\\\\\\\\\\\n                return embedding.tolist()\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Sentence transformer embedding failed: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        raise Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No embedding model available\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def add_repository(self, repo_analysis: Dict[str, Any]) -> int:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Add entire repository to vector store.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        repo_name = repo_analysis.get('repo_name', 'unknown')\\\\\\\\\\\\\\\\n        total_chunks = 0\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add repository overview\\\\\\\\\\\\\\\\n        if repo_analysis.get('files'):\\\\\\\\\\\\\\\\n            overview_text = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Repository: {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            overview_text += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Total files: {repo_analysis['statistics']['total_files']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            overview_text += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Languages: {', '.join(repo_analysis['statistics']['languages'].keys())}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Add file list\\\\\\\\\\\\\\\\n            overview_text += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nFiles:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            for file_data in repo_analysis['files'][:20]:  # Limit to first 20 files\\\\\\\\\\\\\\\\n                overview_text += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"- {file_data['file_path']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            total_chunks += self.add_document(\\\\\\\\\\\\\\\\n                overview_text,\\\\\\\\\\\\\\\\n                {\\\\\\\\\\\\\\\\n                    'type': 'repository_overview',\\\\\\\\\\\\\\\\n                    'repo_name': repo_name,\\\\\\\\\\\\\\\\n                    'source': 'repository_analysis'\\\\\\\\\\\\\\\\n                }\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add individual files\\\\\\\\\\\\\\\\n        for file_data in repo_analysis.get('files', []):\\\\\\\\\\\\\\\\n            file_chunks = self.add_file_analysis(file_data, repo_name)\\\\\\\\\\\\\\\\n            total_chunks += file_chunks\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return total_chunks\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def add_file_analysis(self, file_analysis: Dict[str, Any], repo_name: str = None) -> int:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Add file analysis to vector store.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if file_analysis.get('file_type') == 'code':\\\\\\\\\\\\\\\\n            chunks = self.chunker.chunk_code_file(\\\\\\\\\\\\\\\\n                file_analysis.get('content', ''), \\\\\\\\\\\\\\\\n                file_analysis\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            # Regular text chunking for documentation files\\\\\\\\\\\\\\\\n            chunks = self.chunker.chunk_text(\\\\\\\\\\\\\\\\n                file_analysis.get('content', ''),\\\\\\\\\\\\\\\\n                {\\\\\\\\\\\\\\\\n                    'type': 'documentation',\\\\\\\\\\\\\\\\n                    'file_path': file_analysis['file_path'],\\\\\\\\\\\\\\\\n                    'source': 'file_content'\\\\\\\\\\\\\\\\n                }\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        # Add repository name to all chunks\\\\\\\\\\\\\\\\n        for chunk in chunks:\\\\\\\\\\\\\\\\n            if repo_name:\\\\\\\\\\\\\\\\n                chunk['repo_name'] = repo_name\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return self.add_chunks(chunks)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def add_document(self, text: str, metadata: Dict[str, Any]) -> int:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Add a single document to vector store.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        chunks = self.chunker.chunk_text(text, metadata)\\\\\\\\\\\\\\\\n        return self.add_chunks(chunks)\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def add_chunks(self, chunks: List[Dict[str, Any]]) -> int:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Add multiple chunks to vector store.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not chunks:\\\\\\\\\\\\\\\\n            return 0\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        documents = []\\\\\\\\\\\\\\\\n        metadatas = []\\\\\\\\\\\\\\\\n        ids = []\\\\\\\\\\\\\\\\n        embeddings = []\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        for i, chunk in enumerate(chunks):\\\\\\\\\\\\\\\\n            text = chunk['text']\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Create unique ID\\\\\\\\\\\\\\\\n            chunk_id = hashlib.md5(text.encode()).hexdigest()\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Prepare metadata (remove 'text' key)\\\\\\\\\\\\\\\\n            metadata = {k: v for k, v in chunk.items() if k != 'text'}\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                # Get embedding\\\\\\\\\\\\\\\\n                embedding = self.get_embedding(text)\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n                documents.append(text)\\\\\\\\\\\\\\\\n                metadatas.append(metadata)\\\\\\\\\\\\\\\\n                ids.append(chunk_id)\\\\\\\\\\\\\\\\n                embeddings.append(embedding)\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error processing chunk {i}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                continue\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        if documents:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                self.collection.add(\\\\\\\\\\\\\\\\n                    documents=documents,\\\\\\\\\\\\\\\\n                    metadatas=metadatas,\\\\\\\\\\\\\\\\n                    ids=ids,\\\\\\\\\\\\\\\\n                    embeddings=embeddings\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Added {len(documents)} chunks to vector store\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                return len(documents)\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error adding to vector store: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                return 0\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\n        return 0\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def search(self, query: str, n_results: int = 5, filter_metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Search vector store for relevant documents.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            query_embedding = self.get_embedding(query)\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            search_kwargs = {\\\\\\\\\\\\\\\\n                'query_embeddings': [query_embedding],\\\\\\\\\\\\\\\\n                'n_results': n_results\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            if filter_metadata:\\\\\\\\\\\\\\\\n                search_kwargs['where'] = filter_metadata\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            results = self.collection.query(**search_kwargs)\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            # Format results\\\\\\\\\\\\\\\\n            formatted_results = []\\\\\\\\\\\\\\\\n            for i in range(len(results['documents'][0])):\\\\\\\\\\\\\\\\n                formatted_results.append({\\\\\\\\\\\\\\\\n                    'text': results['documents'][0][i],\\\\\\\\\\\\\\\\n                    'metadata': results['metadatas'][0][i],\\\\\\\\\\\\\\\\n                    'distance': results['distances'][0][i],\\\\\\\\\\\\\\\\n                    'id': results['ids'][0][i]\\\\\\\\\\\\\\\\n                })\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n            return formatted_results\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error searching vector store: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return []\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def get_collection_stats(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get statistics about the collection.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            count = self.collection.count()\\\\\\\\\\\\\\\\n            return {\\\\\\\\\\\\\\\\n                'total_documents': count,\\\\\\\\\\\\\\\\n                'collection_name': self.collection_name\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error getting collection stats: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return {'total_documents': 0, 'collection_name': self.collection_name}\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def clear_collection(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Clear all documents from collection.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            self.client.delete_collection(name=self.collection_name)\\\\\\\\\\\\\\\\n            self.collection = self.client.create_collection(name=self.collection_name)\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Collection cleared successfully\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error clearing collection: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    def delete_repository(self, repo_name: str):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Delete all documents from a specific repository.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            # Get all documents with repo_name\\\\\\\\\\\\\\\\n            results = self.collection.get(where={\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": repo_name})\\\\\\\\\\\\\\\\n            if results['ids']:\\\\\\\\\\\\\\\\n                self.collection.delete(ids=results['ids'])\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Deleted {len(results['ids'])} documents for repository {repo_name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error deleting repository {repo_name}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"file_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"C:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\index.html\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"file_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"code\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"language\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"imports\\\\\\\\\\\\\\\": [],\\\\\\\\n      \\\\\\\\\\\\\\\"elements\\\\\\\\\\\\\\\": [],\\\\\\\\n      \\\\\\\\\\\\\\\"summary\\\\\\\\\\\\\\\": null,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"<!DOCTYPE html>\\\\\\\\\\\\\\\\n<html lang=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"en\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n<head>\\\\\\\\\\\\\\\\n    <meta charset=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"UTF-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n    <meta name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"viewport\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" content=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"width=device-width, initial-scale=1.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n    <title>Local DeepWiki</title>\\\\\\\\\\\\\\\\n    <script src=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://unpkg.com/vue@3/dist/vue.global.js\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></script>\\\\\\\\\\\\\\\\n    <script src=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://unpkg.com/axios/dist/axios.min.js\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></script>\\\\\\\\\\\\\\\\n    <link href=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" rel=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"stylesheet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n    <link href=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" rel=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"stylesheet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n    <style>\\\\\\\\\\\\\\\\n        .chat-message {\\\\\\\\\\\\\\\\n            max-width: 80%;\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        .user-message {\\\\\\\\\\\\\\\\n            margin-left: auto;\\\\\\\\\\\\\\\\n            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        .assistant-message {\\\\\\\\\\\\\\\\n            margin-right: auto;\\\\\\\\\\\\\\\\n            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        .code-block {\\\\\\\\\\\\\\\\n            background-color: #1e1e1e;\\\\\\\\\\\\\\\\n            border-radius: 8px;\\\\\\\\\\\\\\\\n            padding: 1rem;\\\\\\\\\\\\\\\\n            overflow-x: auto;\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        .sidebar {\\\\\\\\\\\\\\\\n            transition: transform 0.3s ease-in-out;\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        .sidebar-closed {\\\\\\\\\\\\\\\\n            transform: translateX(-100%);\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        .loading-dots {\\\\\\\\\\\\\\\\n            display: inline-block;\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        .loading-dots:after {\\\\\\\\\\\\\\\\n            content: '';\\\\\\\\\\\\\\\\n            animation: dots 1.5s infinite;\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        @keyframes dots {\\\\\\\\\\\\\\\\n            0%, 20% { content: '.'; }\\\\\\\\\\\\\\\\n            40% { content: '..'; }\\\\\\\\\\\\\\\\n            60%, 100% { content: '...'; }\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n    </style>\\\\\\\\\\\\\\\\n</head>\\\\\\\\\\\\\\\\n<body class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bg-gray-100 font-sans\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n    <div id=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n        <!-- Header -->\\\\\\\\\\\\\\\\n        <header class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bg-white shadow-lg\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n            <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex justify-between items-center py-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex items-center\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                        <button @click=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"toggleSidebar\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mr-4 text-gray-600 hover:text-gray-900\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-bars text-xl\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                        </button>\\\\\\\\\\\\\\\\n                        <h1 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-2xl font-bold text-gray-900\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-book text-blue-600 mr-2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                            Local DeepWiki\\\\\\\\\\\\\\\\n                        </h1>\\\\\\\\\\\\\\\\n                    </div>\\\\\\\\\\\\\\\\n                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex items-center space-x-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex items-center space-x-2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <div :class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{'bg-green-500': systemStatus.ollama_available, 'bg-red-500': !systemStatus.ollama_available}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                                 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w-3 h-3 rounded-full\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></div>\\\\\\\\\\\\\\\\n                            <span class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-sm text-gray-600\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                {{ systemStatus.ollama_available ? 'Ollama Connected' : 'Ollama Disconnected' }}\\\\\\\\\\\\\\\\n                            </span>\\\\\\\\\\\\\\\\n                        </div>\\\\\\\\\\\\\\\\n                        <button @click=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"checkHealth\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-blue-600 hover:text-blue-800\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-sync-alt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                        </button>\\\\\\\\\\\\\\\\n                    </div>\\\\\\\\\\\\\\\\n                </div>\\\\\\\\\\\\\\\\n            </div>\\\\\\\\\\\\\\\\n        </header>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex h-screen\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n            <!-- Sidebar -->\\\\\\\\\\\\\\\\n            <div :class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{'sidebar-closed': !sidebarOpen}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sidebar fixed inset-y-0 left-0 z-50 w-64 bg-white shadow-lg transform lg:translate-x-0 lg:static lg:inset-0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex flex-col h-full\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                    <!-- Sidebar Header -->\\\\\\\\\\\\\\\\n                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex items-center justify-between p-4 border-b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                        <h2 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-lg font-semibold text-gray-900\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">Repositories</h2>\\\\\\\\\\\\\\\\n                        <button @click=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"showAddRepoModal = true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-blue-600 hover:text-blue-800\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-plus\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                        </button>\\\\\\\\\\\\\\\\n                    </div>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    <!-- Repository List -->\\\\\\\\\\\\\\\\n                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex-1 overflow-y-auto p-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                        <div v-if=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repositories.length === 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-gray-500 text-center py-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-folder-open text-4xl mb-2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                            <p>No repositories added yet</p>\\\\\\\\\\\\\\\\n                        </div>\\\\\\\\\\\\\\\\n                        <div v-for=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo in repositories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" :key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"repo.name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                             @click=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"selectRepository(repo)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                             :class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{'bg-blue-50 border-blue-200': selectedRepo?.name === repo.name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                             class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"p-3 mb-2 border rounded-lg cursor-pointer hover:bg-gray-50 transition-colors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex items-center justify-between\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                <div>\\\\\\\\\\\\\\\\n                                    <h3 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"font-medium text-gray-900\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">{{ repo.name }}</h3>\\\\\\\\\\\\\\\\n                                    <p class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-sm text-gray-600\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">{{ repo.files }} files</p>\\\\\\\\\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex flex-wrap gap-1 mt-1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                        <span v-for=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"lang in repo.languages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" :key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"lang\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                                              class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"px-2 py-1 bg-gray-200 text-gray-700 text-xs rounded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                            {{ lang }}\\\\\\\\\\\\\\\\n                                        </span>\\\\\\\\\\\\\\\\n                                    </div>\\\\\\\\\\\\\\\\n                                </div>\\\\\\\\\\\\\\\\n                                <button @click.stop=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"deleteRepo(repo.name)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                                        class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-red-500 hover:text-red-700 text-sm\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                    <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-trash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                                </button>\\\\\\\\\\\\\\\\n                            </div>\\\\\\\\\\\\\\\\n                        </div>\\\\\\\\\\\\\\\\n                    </div>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    <!-- System Stats -->\\\\\\\\\\\\\\\\n                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"p-4 border-t bg-gray-50\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-sm text-gray-600\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <div>Repos: {{ stats.repositories || 0 }}</div>\\\\\\\\\\\\\\\\n                            <div>Documents: {{ stats.documents_in_vector_store || 0 }}</div>\\\\\\\\\\\\\\\\n                            <div>Model: {{ systemStatus.ollama_model || 'Unknown' }}</div>\\\\\\\\\\\\\\\\n                        </div>\\\\\\\\\\\\\\\\n                    </div>\\\\\\\\\\\\\\\\n                </div>\\\\\\\\\\\\\\\\n            </div>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            <!-- Main Content -->\\\\\\\\\\\\\\\\n            <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex-1 flex flex-col lg:ml-0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" :class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{'ml-0': !sidebarOpen, 'ml-64': sidebarOpen}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                <!-- Tab Navigation -->\\\\\\\\\\\\\\\\n                <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bg-white border-b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                    <nav class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex space-x-8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <button v-for=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tab in tabs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" :key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tab.id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                    @click=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"activeTab = tab.id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                    :class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{'border-blue-500 text-blue-600': activeTab === tab.id, 'border-transparent text-gray-500': activeTab !== tab.id}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                    class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"py-4 px-1 border-b-2 font-medium text-sm hover:text-gray-700\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                <i :class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tab.icon\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mr-2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                                {{ tab.name }}\\\\\\\\\\\\\\\\n                            </button>\\\\\\\\\\\\\\\\n                        </div>\\\\\\\\\\\\\\\\n                    </nav>\\\\\\\\\\\\\\\\n                </div>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                <!-- Tab Content -->\\\\\\\\\\\\\\\\n                <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex-1 overflow-hidden\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                    <!-- Chat Tab -->\\\\\\\\\\\\\\\\n                    <div v-show=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"activeTab === 'chat'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"h-full flex flex-col\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex-1 overflow-y-auto p-6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <div v-if=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chatMessages.length === 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-center py-12\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-comments text-6xl text-gray-300 mb-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                                <h3 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-xl font-medium text-gray-900 mb-2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">Start a conversation</h3>\\\\\\\\\\\\\\\\n                                <p class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-gray-600\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">Ask questions about your code repositories</p>\\\\\\\\\\\\\\\\n                            </div>\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\n                            <div v-for=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"(message, index) in chatMessages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" :key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"index\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mb-6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                <div :class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{'user-message': message.role === 'user', 'assistant-message': message.role === 'assistant'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                     class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat-message p-4 rounded-lg text-white\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex items-start space-x-3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex-shrink-0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                            <i :class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message.role === 'user' ? 'fas fa-user' : 'fas fa-robot'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                                               class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-lg\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                                        </div>\\\\\\\\\\\\\\\\n                                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex-1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                            <div v-html=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"formatMessage(message.content)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></div>\\\\\\\\\\\\\\\\n                                        </div>\\\\\\\\\\\\\\\\n                                    </div>\\\\\\\\\\\\\\\\n                                </div>\\\\\\\\\\\\\\\\n                            </div>\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\n                            <div v-if=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"isLoading\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mb-6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"assistant-message chat-message p-4 rounded-lg text-white\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex items-start space-x-3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex-shrink-0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                            <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-robot text-lg\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                                        </div>\\\\\\\\\\\\\\\\n                                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex-1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                            <span class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"loading-dots\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">Thinking</span>\\\\\\\\\\\\\\\\n                                        </div>\\\\\\\\\\\\\\\\n                                    </div>\\\\\\\\\\\\\\\\n                                </div>\\\\\\\\\\\\\\\\n                            </div>\\\\\\\\\\\\\\\\n                        </div>\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\n                        <!-- Chat Input -->\\\\\\\\\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"border-t bg-white p-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"max-w-4xl mx-auto\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex items-end space-x-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex-1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                        <textarea v-model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chatInput\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                                                @keydown.enter.prevent=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sendChatMessage\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                                :disabled=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"isLoading\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                                placeholder=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Ask a question about your code...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                                class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w-full px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-transparent resize-none\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                                rows=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></textarea>\\\\\\\\\\\\\\\\n                                    </div>\\\\\\\\\\\\\\\\n                                    <button @click=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sendChatMessage\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                                            :disabled=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"isLoading || !chatInput.trim()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                            class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50 disabled:cursor-not-allowed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                        <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-paper-plane\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                                    </button>\\\\\\\\\\\\\\\\n                                </div>\\\\\\\\\\\\\\\\n                                <div v-if=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"selectedRepo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mt-2 text-sm text-gray-600\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                    Querying: {{ selectedRepo.name }}\\\\\\\\\\\\\\\\n                                </div>\\\\\\\\\\\\\\\\n                            </div>\\\\\\\\\\\\\\\\n                        </div>\\\\\\\\\\\\\\\\n                    </div>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    <!-- Search Tab -->\\\\\\\\\\\\\\\\n                    <div v-show=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"activeTab === 'search'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"h-full p-6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"max-w-4xl mx-auto\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mb-6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex space-x-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                    <input v-model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"searchQuery\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                                           @keydown.enter=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"search\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                           type=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                                           placeholder=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Search across all repositories...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                           class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                    <button @click=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"search\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                                            :disabled=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"!searchQuery.trim()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                            class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                        <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-search\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                                    </button>\\\\\\\\\\\\\\\\n                                </div>\\\\\\\\\\\\\\\\n                            </div>\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\n                            <div v-if=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"searchResults.length > 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                <h3 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-lg font-medium mb-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">Search Results</h3>\\\\\\\\\\\\\\\\n                                <div v-for=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"result in searchResults\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" :key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"result.id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                                     class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mb-4 p-4 bg-white rounded-lg shadow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex justify-between items-start mb-2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-sm text-gray-600\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                            {{ result.metadata.file_path || 'Unknown file' }}\\\\\\\\\\\\\\\\n                                        </div>\\\\\\\\\\\\\\\\n                                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-sm text-gray-500\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                            Score: {{ (1 - result.distance).toFixed(3) }}\\\\\\\\\\\\\\\\n                                        </div>\\\\\\\\\\\\\\\\n                                    </div>\\\\\\\\\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-gray-900\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                        {{ result.text.substring(0, 300) }}...\\\\\\\\\\\\\\\\n                                    </div>\\\\\\\\\\\\\\\\n                                </div>\\\\\\\\\\\\\\\\n                            </div>\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\n                            <div v-else-if=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"searchQuery && !isSearching\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-center py-12\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-search text-6xl text-gray-300 mb-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                                <p class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-gray-600\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">No results found</p>\\\\\\\\\\\\\\\\n                            </div>\\\\\\\\\\\\\\\\n                        </div>\\\\\\\\\\\\\\\\n                    </div>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    <!-- Documentation Tab -->\\\\\\\\\\\\\\\\n                    <div v-show=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"activeTab === 'docs'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"h-full p-6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"max-w-4xl mx-auto\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                            <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mb-6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                <h2 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-2xl font-bold mb-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">Documentation</h2>\\\\\\\\\\\\\\\\n                                \\\\\\\\\\\\\\\\n                                <div v-if=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"selectedRepo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mb-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                    <button @click=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"generateDocs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                                            :disabled=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"isGeneratingDocs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                            class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"px-4 py-2 bg-green-600 text-white rounded-lg hover:bg-green-700 disabled:opacity-50\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                        <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-file-alt mr-2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                                        Generate Documentation\\\\\\\\\\\\\\\\n                                    </button>\\\\\\\\\\\\\\\\n                                </div>\\\\\\\\\\\\\\\\n                                \\\\\\\\\\\\\\\\n                                <div v-if=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"generatedDocs.length > 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                    <h3 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-lg font-medium mb-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">Generated Documents</h3>\\\\\\\\\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"grid gap-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                        <div v-for=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"doc in generatedDocs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" :key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"doc.path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                             @click=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"viewDocument(doc)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                                             class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"p-4 bg-white rounded-lg shadow cursor-pointer hover:shadow-md transition-shadow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                            <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex items-center space-x-3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                                                <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-file-markdown text-blue-600\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                                                <div>\\\\\\\\\\\\\\\\n                                                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"font-medium\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">{{ doc.name }}</div>\\\\\\\\\\\\\\\\n                                                    <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-sm text-gray-600\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">{{ doc.path }}</div>\\\\\\\\\\\\\\\\n                                                </div>\\\\\\\\\\\\\\\\n                                            </div>\\\\\\\\\\\\\\\\n                                        </div>\\\\\\\\\\\\\\\\n                                    </div>\\\\\\\\\\\\\\\\n                                </div>\\\\\\\\\\\\\\\\n                            </div>\\\\\\\\\\\\\\\\n                        </div>\\\\\\\\\\\\\\\\n                    </div>\\\\\\\\\\\\\\\\n                </div>\\\\\\\\\\\\\\\\n            </div>\\\\\\\\\\\\\\\\n        </div>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        <!-- Add Repository Modal -->\\\\\\\\\\\\\\\\n        <div v-if=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"showAddRepoModal\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n            <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bg-white rounded-lg p-6 w-full max-w-md mx-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                <h3 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-lg font-medium mb-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">Add Repository</h3>\\\\\\\\\\\\\\\\n                <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mb-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                    <label class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"block text-sm font-medium text-gray-700 mb-2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">Repository Path</label>\\\\\\\\\\\\\\\\n                    <input v-model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"newRepoPath\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                           type=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                           placeholder=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/path/to/your/repository\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                           class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                </div>\\\\\\\\\\\\\\\\n                <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mb-6\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                    <label class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"block text-sm font-medium text-gray-700 mb-2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">Repository Name (optional)</label>\\\\\\\\\\\\\\\\n                    <input v-model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"newRepoName\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                           type=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                           placeholder=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"my-project\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                           class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                </div>\\\\\\\\\\\\\\\\n                <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex justify-end space-x-3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                    <button @click=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"showAddRepoModal = false\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                            class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"px-4 py-2 text-gray-700 border border-gray-300 rounded-md hover:bg-gray-50\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                        Cancel\\\\\\\\\\\\\\\\n                    </button>\\\\\\\\\\\\\\\\n                    <button @click=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"addRepository\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n                            :disabled=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"!newRepoPath.trim()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                            class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"px-4 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700 disabled:opacity-50\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                        Add Repository\\\\\\\\\\\\\\\\n                    </button>\\\\\\\\\\\\\\\\n                </div>\\\\\\\\\\\\\\\\n            </div>\\\\\\\\\\\\\\\\n        </div>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        <!-- Document Viewer Modal -->\\\\\\\\\\\\\\\\n        <div v-if=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"showDocModal\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n            <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bg-white rounded-lg w-full max-w-4xl mx-4 h-5/6 flex flex-col\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex items-center justify-between p-4 border-b\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                    <h3 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-lg font-medium\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">{{ currentDoc?.name }}</h3>\\\\\\\\\\\\\\\\n                    <button @click=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"showDocModal = false\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-gray-500 hover:text-gray-700\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                        <i class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"fas fa-times\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></i>\\\\\\\\\\\\\\\\n                    </button>\\\\\\\\\\\\\\\\n                </div>\\\\\\\\\\\\\\\\n                <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"flex-1 overflow-auto p-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                    <div v-html=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"formatMarkdown(currentDocContent)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prose max-w-none\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"></div>\\\\\\\\\\\\\\\\n                </div>\\\\\\\\\\\\\\\\n            </div>\\\\\\\\\\\\\\\\n        </div>\\\\\\\\\\\\\\\\n    </div>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    <script>\\\\\\\\\\\\\\\\n        const { createApp } = Vue;\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        createApp({\\\\\\\\\\\\\\\\n            data() {\\\\\\\\\\\\\\\\n                return {\\\\\\\\\\\\\\\\n                    sidebarOpen: true,\\\\\\\\\\\\\\\\n                    activeTab: 'chat',\\\\\\\\\\\\\\\\n                    systemStatus: {\\\\\\\\\\\\\\\\n                        ollama_available: false,\\\\\\\\\\\\\\\\n                        ollama_model: ''\\\\\\\\\\\\\\\\n                    },\\\\\\\\\\\\\\\\n                    stats: {},\\\\\\\\\\\\\\\\n                    repositories: [],\\\\\\\\\\\\\\\\n                    selectedRepo: null,\\\\\\\\\\\\\\\\n                    chatMessages: [],\\\\\\\\\\\\\\\\n                    chatInput: '',\\\\\\\\\\\\\\\\n                    isLoading: false,\\\\\\\\\\\\\\\\n                    searchQuery: '',\\\\\\\\\\\\\\\\n                    searchResults: [],\\\\\\\\\\\\\\\\n                    isSearching: false,\\\\\\\\\\\\\\\\n                    generatedDocs: [],\\\\\\\\\\\\\\\\n                    isGeneratingDocs: false,\\\\\\\\\\\\\\\\n                    showAddRepoModal: false,\\\\\\\\\\\\\\\\n                    newRepoPath: '',\\\\\\\\\\\\\\\\n                    newRepoName: '',\\\\\\\\\\\\\\\\n                    showDocModal: false,\\\\\\\\\\\\\\\\n                    currentDoc: null,\\\\\\\\\\\\\\\\n                    currentDocContent: '',\\\\\\\\\\\\\\\\n                    tabs: [\\\\\\\\\\\\\\\\n                        { id: 'chat', name: 'Chat', icon: 'fas fa-comments' },\\\\\\\\\\\\\\\\n                        { id: 'search', name: 'Search', icon: 'fas fa-search' },\\\\\\\\\\\\\\\\n                        { id: 'docs', name: 'Documentation', icon: 'fas fa-file-alt' }\\\\\\\\\\\\\\\\n                    ]\\\\\\\\\\\\\\\\n                };\\\\\\\\\\\\\\\\n            },\\\\\\\\\\\\\\\\n            async mounted() {\\\\\\\\\\\\\\\\n                await this.checkHealth();\\\\\\\\\\\\\\\\n                await this.loadRepositories();\\\\\\\\\\\\\\\\n                await this.loadStats();\\\\\\\\\\\\\\\\n            },\\\\\\\\\\\\\\\\n            methods: {\\\\\\\\\\\\\\\\n                toggleSidebar() {\\\\\\\\\\\\\\\\n                    this.sidebarOpen = !this.sidebarOpen;\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                async checkHealth() {\\\\\\\\\\\\\\\\n                    try {\\\\\\\\\\\\\\\\n                        const response = await axios.get('/health');\\\\\\\\\\\\\\\\n                        this.systemStatus = response.data;\\\\\\\\\\\\\\\\n                    } catch (error) {\\\\\\\\\\\\\\\\n                        console.error('Health check failed:', error);\\\\\\\\\\\\\\\\n                        this.systemStatus.ollama_available = false;\\\\\\\\\\\\\\\\n                    }\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                async loadRepositories() {\\\\\\\\\\\\\\\\n                    try {\\\\\\\\\\\\\\\\n                        const response = await axios.get('/repositories');\\\\\\\\\\\\\\\\n                        this.repositories = response.data.repositories;\\\\\\\\\\\\\\\\n                    } catch (error) {\\\\\\\\\\\\\\\\n                        console.error('Failed to load repositories:', error);\\\\\\\\\\\\\\\\n                    }\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                async loadStats() {\\\\\\\\\\\\\\\\n                    try {\\\\\\\\\\\\\\\\n                        const response = await axios.get('/stats');\\\\\\\\\\\\\\\\n                        this.stats = response.data;\\\\\\\\\\\\\\\\n                    } catch (error) {\\\\\\\\\\\\\\\\n                        console.error('Failed to load stats:', error);\\\\\\\\\\\\\\\\n                    }\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                selectRepository(repo) {\\\\\\\\\\\\\\\\n                    this.selectedRepo = repo;\\\\\\\\\\\\\\\\n                    this.loadGeneratedDocs();\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                async addRepository() {\\\\\\\\\\\\\\\\n                    if (!this.newRepoPath.trim()) return;\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    try {\\\\\\\\\\\\\\\\n                        await axios.post('/repositories/analyze', {\\\\\\\\\\\\\\\\n                            repo_path: this.newRepoPath,\\\\\\\\\\\\\\\\n                            repo_name: this.newRepoName || undefined\\\\\\\\\\\\\\\\n                        });\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\n                        this.showAddRepoModal = false;\\\\\\\\\\\\\\\\n                        this.newRepoPath = '';\\\\\\\\\\\\\\\\n                        this.newRepoName = '';\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\n                        // Reload repositories after a short delay\\\\\\\\\\\\\\\\n                        setTimeout(() => {\\\\\\\\\\\\\\\\n                            this.loadRepositories();\\\\\\\\\\\\\\\\n                            this.loadStats();\\\\\\\\\\\\\\\\n                        }, 2000);\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\n                        alert('Repository analysis started. It may take a few moments to complete.');\\\\\\\\\\\\\\\\n                    } catch (error) {\\\\\\\\\\\\\\\\n                        console.error('Failed to add repository:', error);\\\\\\\\\\\\\\\\n                        alert('Failed to add repository: ' + (error.response?.data?.detail || error.message));\\\\\\\\\\\\\\\\n                    }\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                async deleteRepo(repoName) {\\\\\\\\\\\\\\\\n                    if (!confirm(`Are you sure you want to delete ${repoName}?`)) return;\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    try {\\\\\\\\\\\\\\\\n                        await axios.delete(`/repositories/${repoName}`);\\\\\\\\\\\\\\\\n                        await this.loadRepositories();\\\\\\\\\\\\\\\\n                        await this.loadStats();\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\n                        if (this.selectedRepo?.name === repoName) {\\\\\\\\\\\\\\\\n                            this.selectedRepo = null;\\\\\\\\\\\\\\\\n                        }\\\\\\\\\\\\\\\\n                    } catch (error) {\\\\\\\\\\\\\\\\n                        console.error('Failed to delete repository:', error);\\\\\\\\\\\\\\\\n                        alert('Failed to delete repository');\\\\\\\\\\\\\\\\n                    }\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                async sendChatMessage() {\\\\\\\\\\\\\\\\n                    if (!this.chatInput.trim() || this.isLoading) return;\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    const userMessage = {\\\\\\\\\\\\\\\\n                        role: 'user',\\\\\\\\\\\\\\\\n                        content: this.chatInput.trim()\\\\\\\\\\\\\\\\n                    };\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    this.chatMessages.push(userMessage);\\\\\\\\\\\\\\\\n                    this.chatInput = '';\\\\\\\\\\\\\\\\n                    this.isLoading = true;\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    try {\\\\\\\\\\\\\\\\n                        const response = await axios.post('/chat', {\\\\\\\\\\\\\\\\n                            messages: this.chatMessages,\\\\\\\\\\\\\\\\n                            repo_name: this.selectedRepo?.name\\\\\\\\\\\\\\\\n                        });\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\n                        this.chatMessages.push({\\\\\\\\\\\\\\\\n                            role: 'assistant',\\\\\\\\\\\\\\\\n                            content: response.data.response\\\\\\\\\\\\\\\\n                        });\\\\\\\\\\\\\\\\n                    } catch (error) {\\\\\\\\\\\\\\\\n                        console.error('Chat failed:', error);\\\\\\\\\\\\\\\\n                        this.chatMessages.push({\\\\\\\\\\\\\\\\n                            role: 'assistant',\\\\\\\\\\\\\\\\n                            content: 'Sorry, I encountered an error processing your request.'\\\\\\\\\\\\\\\\n                        });\\\\\\\\\\\\\\\\n                    } finally {\\\\\\\\\\\\\\\\n                        this.isLoading = false;\\\\\\\\\\\\\\\\n                        this.$nextTick(() => {\\\\\\\\\\\\\\\\n                            // Scroll to bottom\\\\\\\\\\\\\\\\n                            const chatContainer = document.querySelector('.overflow-y-auto');\\\\\\\\\\\\\\\\n                            if (chatContainer) {\\\\\\\\\\\\\\\\n                                chatContainer.scrollTop = chatContainer.scrollHeight;\\\\\\\\\\\\\\\\n                            }\\\\\\\\\\\\\\\\n                        });\\\\\\\\\\\\\\\\n                    }\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                async search() {\\\\\\\\\\\\\\\\n                    if (!this.searchQuery.trim()) return;\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    this.isSearching = true;\\\\\\\\\\\\\\\\n                    this.searchResults = [];\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    try {\\\\\\\\\\\\\\\\n                        const endpoint = this.selectedRepo \\\\\\\\\\\\\\\\n                            ? `/repositories/${this.selectedRepo.name}/search`\\\\\\\\\\\\\\\\n                            : '/search';\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\n                        const response = await axios.get(endpoint, {\\\\\\\\\\\\\\\\n                            params: { q: this.searchQuery, limit: 10 }\\\\\\\\\\\\\\\\n                        });\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\n                        this.searchResults = response.data.results;\\\\\\\\\\\\\\\\n                    } catch (error) {\\\\\\\\\\\\\\\\n                        console.error('Search failed:', error);\\\\\\\\\\\\\\\\n                    } finally {\\\\\\\\\\\\\\\\n                        this.isSearching = false;\\\\\\\\\\\\\\\\n                    }\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                async generateDocs() {\\\\\\\\\\\\\\\\n                    if (!this.selectedRepo) return;\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    this.isGeneratingDocs = true;\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    try {\\\\\\\\\\\\\\\\n                        await axios.post(`/repositories/${this.selectedRepo.name}/generate-docs`, {\\\\\\\\\\\\\\\\n                            repo_name: this.selectedRepo.name,\\\\\\\\\\\\\\\\n                            include_overview: true,\\\\\\\\\\\\\\\\n                            include_api_docs: true,\\\\\\\\\\\\\\\\n                            include_examples: true,\\\\\\\\\\\\\\\\n                            include_architecture: true\\\\\\\\\\\\\\\\n                        });\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\n                        alert('Documentation generation started. It may take a few moments to complete.');\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\n                        // Reload docs after a delay\\\\\\\\\\\\\\\\n                        setTimeout(() => {\\\\\\\\\\\\\\\\n                            this.loadGeneratedDocs();\\\\\\\\\\\\\\\\n                        }, 5000);\\\\\\\\\\\\\\\\n                    } catch (error) {\\\\\\\\\\\\\\\\n                        console.error('Failed to generate docs:', error);\\\\\\\\\\\\\\\\n                        alert('Failed to generate documentation');\\\\\\\\\\\\\\\\n                    } finally {\\\\\\\\\\\\\\\\n                        this.isGeneratingDocs = false;\\\\\\\\\\\\\\\\n                    }\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                async loadGeneratedDocs() {\\\\\\\\\\\\\\\\n                    if (!this.selectedRepo) return;\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    try {\\\\\\\\\\\\\\\\n                        const response = await axios.get(`/repositories/${this.selectedRepo.name}/docs`);\\\\\\\\\\\\\\\\n                        this.generatedDocs = response.data.documents;\\\\\\\\\\\\\\\\n                    } catch (error) {\\\\\\\\\\\\\\\\n                        console.error('Failed to load generated docs:', error);\\\\\\\\\\\\\\\\n                        this.generatedDocs = [];\\\\\\\\\\\\\\\\n                    }\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                async viewDocument(doc) {\\\\\\\\\\\\\\\\n                    if (!this.selectedRepo) return;\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\n                    try {\\\\\\\\\\\\\\\\n                        const response = await axios.get(`/repositories/${this.selectedRepo.name}/docs/${doc.path}`);\\\\\\\\\\\\\\\\n                        this.currentDoc = doc;\\\\\\\\\\\\\\\\n                        this.currentDocContent = response.data.content;\\\\\\\\\\\\\\\\n                        this.showDocModal = true;\\\\\\\\\\\\\\\\n                    } catch (error) {\\\\\\\\\\\\\\\\n                        console.error('Failed to load document:', error);\\\\\\\\\\\\\\\\n                        alert('Failed to load document');\\\\\\\\\\\\\\\\n                    }\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                formatMessage(content) {\\\\\\\\\\\\\\\\n                    // Simple markdown-like formatting\\\\\\\\\\\\\\\\n                    return content\\\\\\\\\\\\\\\\n                        .replace(/```(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\w+)?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n([\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\S]*?)```/g, '<pre class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"code-block\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"><code>$2</code></pre>')\\\\\\\\\\\\\\\\n                        .replace(/`([^`]+)`/g, '<code class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bg-gray-200 px-1 rounded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">$1</code>')\\\\\\\\\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\*(.*?)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\*/g, '<strong>$1</strong>')\\\\\\\\\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\*(.*?)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\*/g, '<em>$1</em>')\\\\\\\\\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n/g, '<br>');\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                formatMarkdown(content) {\\\\\\\\\\\\\\\\n                    // Basic markdown formatting for document viewer\\\\\\\\\\\\\\\\n                    return content\\\\\\\\\\\\\\\\n                        .replace(/# (.*)/g, '<h1 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-3xl font-bold mb-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">$1</h1>')\\\\\\\\\\\\\\\\n                        .replace(/## (.*)/g, '<h2 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-2xl font-semibold mb-3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">$1</h2>')\\\\\\\\\\\\\\\\n                        .replace(/### (.*)/g, '<h3 class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"text-xl font-medium mb-2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">$1</h3>')\\\\\\\\\\\\\\\\n                        .replace(/```(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\w+)?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n([\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\S]*?)```/g, '<pre class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bg-gray-900 text-white p-4 rounded-lg overflow-x-auto mb-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"><code>$2</code></pre>')\\\\\\\\\\\\\\\\n                        .replace(/`([^`]+)`/g, '<code class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bg-gray-200 px-1 rounded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">$1</code>')\\\\\\\\\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\*(.*?)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\*\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\*/g, '<strong>$1</strong>')\\\\\\\\\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\*(.*?)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\*/g, '<em>$1</em>')\\\\\\\\\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n/g, '</p><p class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mb-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">')\\\\\\\\\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n/g, '<br>')\\\\\\\\\\\\\\\\n                        .replace(/^/, '<p class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mb-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">') + '</p>';\\\\\\\\\\\\\\\\n                }\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\n        }).mount('#app');\\\\\\\\\\\\\\\\n    </script>\\\\\\\\\\\\\\\\n</body>\\\\\\\\\\\\\\\\n</html>\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n    }\\\\\\\\n  ],\\\\\\\\n  \\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"wikillm\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"children\\\\\\\\\\\\\\\": [\\\\\\\\n      {\\\\\\\\n        \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"api.py\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"api.py\\\\\\\\\\\\\\\"\\\\\\\\n      },\\\\\\\\n      {\\\\\\\\n        \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"config.py\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"config.py\\\\\\\\\\\\\\\"\\\\\\\\n      },\\\\\\\\n      {\\\\\\\\n        \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"children\\\\\\\\\\\\\\\": [\\\\\\\\n          {\\\\\\\\n            \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chroma_db\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"children\\\\\\\\\\\\\\\": []\\\\\\\\n          },\\\\\\\\n          {\\\\\\\\n            \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"generated_docs\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"children\\\\\\\\\\\\\\\": []\\\\\\\\n          },\\\\\\\\n          {\\\\\\\\n            \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"repos\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"children\\\\\\\\\\\\\\\": []\\\\\\\\n          }\\\\\\\\n        ]\\\\\\\\n      },\\\\\\\\n      {\\\\\\\\n        \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"documentation_generator.py\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"documentation_generator.py\\\\\\\\\\\\\\\"\\\\\\\\n      },\\\\\\\\n      {\\\\\\\\n        \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"main.py\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"main.py\\\\\\\\\\\\\\\"\\\\\\\\n      },\\\\\\\\n      {\\\\\\\\n        \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ollama_client.py\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ollama_client.py\\\\\\\\\\\\\\\"\\\\\\\\n      },\\\\\\\\n      {\\\\\\\\n        \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"rag_system.py\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"rag_system.py\\\\\\\\\\\\\\\"\\\\\\\\n      },\\\\\\\\n      {\\\\\\\\n        \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"README.md\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"README.md\\\\\\\\\\\\\\\"\\\\\\\\n      },\\\\\\\\n      {\\\\\\\\n        \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"repository_analyzer.py\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"repository_analyzer.py\\\\\\\\\\\\\\\"\\\\\\\\n      },\\\\\\\\n      {\\\\\\\\n        \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"requirements.txt\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"requirements.txt\\\\\\\\\\\\\\\"\\\\\\\\n      },\\\\\\\\n      {\\\\\\\\n        \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"vector_store.py\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"vector_store.py\\\\\\\\\\\\\\\"\\\\\\\\n      },\\\\\\\\n      {\\\\\\\\n        \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\",\\\\\\\\n        \\\\\\\\\\\\\\\"children\\\\\\\\\\\\\\\": [\\\\\\\\n          {\\\\\\\\n            \\\\\\\\\\\\\\\"name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"index.html\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\index.html\\\\\\\\\\\\\\\"\\\\\\\\n          }\\\\\\\\n        ]\\\\\\\\n      }\\\\\\\\n    ]\\\\\\\\n  },\\\\\\\\n  \\\\\\\\\\\\\\\"statistics\\\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\": 11,\\\\\\\\n    \\\\\\\\\\\\\\\"code_files\\\\\\\\\\\\\\\": 9,\\\\\\\\n    \\\\\\\\\\\\\\\"doc_files\\\\\\\\\\\\\\\": 2,\\\\\\\\n    \\\\\\\\\\\\\\\"languages\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\": 8\\\\\\\\n    },\\\\\\\\n    \\\\\\\\\\\\\\\"total_lines\\\\\\\\\\\\\\\": 3767\\\\\\\\n  },\\\\\\\\n  \\\\\\\\\\\\\\\"git_info\\\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\\\"remote_url\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"https://github.com/sharmaharsh/wikillm.git\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"current_branch\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"main\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"last_commit\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"hash\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"f0138481\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"init\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"author\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"sharmaharsh\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"date\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"2025-08-08T21:50:42-05:00\\\\\\\\\\\\\\\"\\\\\\\\n    }\\\\\\\\n  }\\\\\\\\n}\\\\\\\"\\\\n    },\\\\n    {\\\\n      \\\\\\\"file_path\\\\\\\": \\\\\\\"C:\\\\\\\\\\\\\\\\Users\\\\\\\\\\\\\\\\chuba\\\\\\\\\\\\\\\\wikillm\\\\\\\\\\\\\\\\web\\\\\\\\\\\\\\\\index.html\\\\\\\",\\\\n      \\\\\\\"file_type\\\\\\\": \\\\\\\"code\\\\\\\",\\\\n      \\\\\\\"language\\\\\\\": null,\\\\n      \\\\\\\"imports\\\\\\\": [],\\\\n      \\\\\\\"elements\\\\\\\": [],\\\\n      \\\\\\\"summary\\\\\\\": null,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"<!DOCTYPE html>\\\\\\\\n<html lang=\\\\\\\\\\\\\\\"en\\\\\\\\\\\\\\\">\\\\\\\\n<head>\\\\\\\\n    <meta charset=\\\\\\\\\\\\\\\"UTF-8\\\\\\\\\\\\\\\">\\\\\\\\n    <meta name=\\\\\\\\\\\\\\\"viewport\\\\\\\\\\\\\\\" content=\\\\\\\\\\\\\\\"width=device-width, initial-scale=1.0\\\\\\\\\\\\\\\">\\\\\\\\n    <title>Local DeepWiki</title>\\\\\\\\n    <script src=\\\\\\\\\\\\\\\"https://unpkg.com/vue@3/dist/vue.global.js\\\\\\\\\\\\\\\"></script>\\\\\\\\n    <script src=\\\\\\\\\\\\\\\"https://unpkg.com/axios/dist/axios.min.js\\\\\\\\\\\\\\\"></script>\\\\\\\\n    <link href=\\\\\\\\\\\\\\\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\\\\\\\\\\\\\\\" rel=\\\\\\\\\\\\\\\"stylesheet\\\\\\\\\\\\\\\">\\\\\\\\n    <link href=\\\\\\\\\\\\\\\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css\\\\\\\\\\\\\\\" rel=\\\\\\\\\\\\\\\"stylesheet\\\\\\\\\\\\\\\">\\\\\\\\n    <style>\\\\\\\\n        .chat-message {\\\\\\\\n            max-width: 80%;\\\\\\\\n        }\\\\\\\\n        .user-message {\\\\\\\\n            margin-left: auto;\\\\\\\\n            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\\\\\\\\n        }\\\\\\\\n        .assistant-message {\\\\\\\\n            margin-right: auto;\\\\\\\\n            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\\\\\\\\n        }\\\\\\\\n        .code-block {\\\\\\\\n            background-color: #1e1e1e;\\\\\\\\n            border-radius: 8px;\\\\\\\\n            padding: 1rem;\\\\\\\\n            overflow-x: auto;\\\\\\\\n        }\\\\\\\\n        .sidebar {\\\\\\\\n            transition: transform 0.3s ease-in-out;\\\\\\\\n        }\\\\\\\\n        .sidebar-closed {\\\\\\\\n            transform: translateX(-100%);\\\\\\\\n        }\\\\\\\\n        .loading-dots {\\\\\\\\n            display: inline-block;\\\\\\\\n        }\\\\\\\\n        .loading-dots:after {\\\\\\\\n            content: '';\\\\\\\\n            animation: dots 1.5s infinite;\\\\\\\\n        }\\\\\\\\n        @keyframes dots {\\\\\\\\n            0%, 20% { content: '.'; }\\\\\\\\n            40% { content: '..'; }\\\\\\\\n            60%, 100% { content: '...'; }\\\\\\\\n        }\\\\\\\\n    </style>\\\\\\\\n</head>\\\\\\\\n<body class=\\\\\\\\\\\\\\\"bg-gray-100 font-sans\\\\\\\\\\\\\\\">\\\\\\\\n    <div id=\\\\\\\\\\\\\\\"app\\\\\\\\\\\\\\\">\\\\\\\\n        <!-- Header -->\\\\\\\\n        <header class=\\\\\\\\\\\\\\\"bg-white shadow-lg\\\\\\\\\\\\\\\">\\\\\\\\n            <div class=\\\\\\\\\\\\\\\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\\\\\\\\\\\\\\\">\\\\\\\\n                <div class=\\\\\\\\\\\\\\\"flex justify-between items-center py-4\\\\\\\\\\\\\\\">\\\\\\\\n                    <div class=\\\\\\\\\\\\\\\"flex items-center\\\\\\\\\\\\\\\">\\\\\\\\n                        <button @click=\\\\\\\\\\\\\\\"toggleSidebar\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"mr-4 text-gray-600 hover:text-gray-900\\\\\\\\\\\\\\\">\\\\\\\\n                            <i class=\\\\\\\\\\\\\\\"fas fa-bars text-xl\\\\\\\\\\\\\\\"></i>\\\\\\\\n                        </button>\\\\\\\\n                        <h1 class=\\\\\\\\\\\\\\\"text-2xl font-bold text-gray-900\\\\\\\\\\\\\\\">\\\\\\\\n                            <i class=\\\\\\\\\\\\\\\"fas fa-book text-blue-600 mr-2\\\\\\\\\\\\\\\"></i>\\\\\\\\n                            Local DeepWiki\\\\\\\\n                        </h1>\\\\\\\\n                    </div>\\\\\\\\n                    <div class=\\\\\\\\\\\\\\\"flex items-center space-x-4\\\\\\\\\\\\\\\">\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\"flex items-center space-x-2\\\\\\\\\\\\\\\">\\\\\\\\n                            <div :class=\\\\\\\\\\\\\\\"{'bg-green-500': systemStatus.ollama_available, 'bg-red-500': !systemStatus.ollama_available}\\\\\\\\\\\\\\\" \\\\\\\\n                                 class=\\\\\\\\\\\\\\\"w-3 h-3 rounded-full\\\\\\\\\\\\\\\"></div>\\\\\\\\n                            <span class=\\\\\\\\\\\\\\\"text-sm text-gray-600\\\\\\\\\\\\\\\">\\\\\\\\n                                {{ systemStatus.ollama_available ? 'Ollama Connected' : 'Ollama Disconnected' }}\\\\\\\\n                            </span>\\\\\\\\n                        </div>\\\\\\\\n                        <button @click=\\\\\\\\\\\\\\\"checkHealth\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"text-blue-600 hover:text-blue-800\\\\\\\\\\\\\\\">\\\\\\\\n                            <i class=\\\\\\\\\\\\\\\"fas fa-sync-alt\\\\\\\\\\\\\\\"></i>\\\\\\\\n                        </button>\\\\\\\\n                    </div>\\\\\\\\n                </div>\\\\\\\\n            </div>\\\\\\\\n        </header>\\\\\\\\n\\\\\\\\n        <div class=\\\\\\\\\\\\\\\"flex h-screen\\\\\\\\\\\\\\\">\\\\\\\\n            <!-- Sidebar -->\\\\\\\\n            <div :class=\\\\\\\\\\\\\\\"{'sidebar-closed': !sidebarOpen}\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"sidebar fixed inset-y-0 left-0 z-50 w-64 bg-white shadow-lg transform lg:translate-x-0 lg:static lg:inset-0\\\\\\\\\\\\\\\">\\\\\\\\n                <div class=\\\\\\\\\\\\\\\"flex flex-col h-full\\\\\\\\\\\\\\\">\\\\\\\\n                    <!-- Sidebar Header -->\\\\\\\\n                    <div class=\\\\\\\\\\\\\\\"flex items-center justify-between p-4 border-b\\\\\\\\\\\\\\\">\\\\\\\\n                        <h2 class=\\\\\\\\\\\\\\\"text-lg font-semibold text-gray-900\\\\\\\\\\\\\\\">Repositories</h2>\\\\\\\\n                        <button @click=\\\\\\\\\\\\\\\"showAddRepoModal = true\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"text-blue-600 hover:text-blue-800\\\\\\\\\\\\\\\">\\\\\\\\n                            <i class=\\\\\\\\\\\\\\\"fas fa-plus\\\\\\\\\\\\\\\"></i>\\\\\\\\n                        </button>\\\\\\\\n                    </div>\\\\\\\\n\\\\\\\\n                    <!-- Repository List -->\\\\\\\\n                    <div class=\\\\\\\\\\\\\\\"flex-1 overflow-y-auto p-4\\\\\\\\\\\\\\\">\\\\\\\\n                        <div v-if=\\\\\\\\\\\\\\\"repositories.length === 0\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"text-gray-500 text-center py-8\\\\\\\\\\\\\\\">\\\\\\\\n                            <i class=\\\\\\\\\\\\\\\"fas fa-folder-open text-4xl mb-2\\\\\\\\\\\\\\\"></i>\\\\\\\\n                            <p>No repositories added yet</p>\\\\\\\\n                        </div>\\\\\\\\n                        <div v-for=\\\\\\\\\\\\\\\"repo in repositories\\\\\\\\\\\\\\\" :key=\\\\\\\\\\\\\\\"repo.name\\\\\\\\\\\\\\\" \\\\\\\\n                             @click=\\\\\\\\\\\\\\\"selectRepository(repo)\\\\\\\\\\\\\\\"\\\\\\\\n                             :class=\\\\\\\\\\\\\\\"{'bg-blue-50 border-blue-200': selectedRepo?.name === repo.name}\\\\\\\\\\\\\\\"\\\\\\\\n                             class=\\\\\\\\\\\\\\\"p-3 mb-2 border rounded-lg cursor-pointer hover:bg-gray-50 transition-colors\\\\\\\\\\\\\\\">\\\\\\\\n                            <div class=\\\\\\\\\\\\\\\"flex items-center justify-between\\\\\\\\\\\\\\\">\\\\\\\\n                                <div>\\\\\\\\n                                    <h3 class=\\\\\\\\\\\\\\\"font-medium text-gray-900\\\\\\\\\\\\\\\">{{ repo.name }}</h3>\\\\\\\\n                                    <p class=\\\\\\\\\\\\\\\"text-sm text-gray-600\\\\\\\\\\\\\\\">{{ repo.files }} files</p>\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\"flex flex-wrap gap-1 mt-1\\\\\\\\\\\\\\\">\\\\\\\\n                                        <span v-for=\\\\\\\\\\\\\\\"lang in repo.languages\\\\\\\\\\\\\\\" :key=\\\\\\\\\\\\\\\"lang\\\\\\\\\\\\\\\" \\\\\\\\n                                              class=\\\\\\\\\\\\\\\"px-2 py-1 bg-gray-200 text-gray-700 text-xs rounded\\\\\\\\\\\\\\\">\\\\\\\\n                                            {{ lang }}\\\\\\\\n                                        </span>\\\\\\\\n                                    </div>\\\\\\\\n                                </div>\\\\\\\\n                                <button @click.stop=\\\\\\\\\\\\\\\"deleteRepo(repo.name)\\\\\\\\\\\\\\\" \\\\\\\\n                                        class=\\\\\\\\\\\\\\\"text-red-500 hover:text-red-700 text-sm\\\\\\\\\\\\\\\">\\\\\\\\n                                    <i class=\\\\\\\\\\\\\\\"fas fa-trash\\\\\\\\\\\\\\\"></i>\\\\\\\\n                                </button>\\\\\\\\n                            </div>\\\\\\\\n                        </div>\\\\\\\\n                    </div>\\\\\\\\n\\\\\\\\n                    <!-- System Stats -->\\\\\\\\n                    <div class=\\\\\\\\\\\\\\\"p-4 border-t bg-gray-50\\\\\\\\\\\\\\\">\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\"text-sm text-gray-600\\\\\\\\\\\\\\\">\\\\\\\\n                            <div>Repos: {{ stats.repositories || 0 }}</div>\\\\\\\\n                            <div>Documents: {{ stats.documents_in_vector_store || 0 }}</div>\\\\\\\\n                            <div>Model: {{ systemStatus.ollama_model || 'Unknown' }}</div>\\\\\\\\n                        </div>\\\\\\\\n                    </div>\\\\\\\\n                </div>\\\\\\\\n            </div>\\\\\\\\n\\\\\\\\n            <!-- Main Content -->\\\\\\\\n            <div class=\\\\\\\\\\\\\\\"flex-1 flex flex-col lg:ml-0\\\\\\\\\\\\\\\" :class=\\\\\\\\\\\\\\\"{'ml-0': !sidebarOpen, 'ml-64': sidebarOpen}\\\\\\\\\\\\\\\">\\\\\\\\n                <!-- Tab Navigation -->\\\\\\\\n                <div class=\\\\\\\\\\\\\\\"bg-white border-b\\\\\\\\\\\\\\\">\\\\\\\\n                    <nav class=\\\\\\\\\\\\\\\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\\\\\\\\\\\\\\\">\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\"flex space-x-8\\\\\\\\\\\\\\\">\\\\\\\\n                            <button v-for=\\\\\\\\\\\\\\\"tab in tabs\\\\\\\\\\\\\\\" :key=\\\\\\\\\\\\\\\"tab.id\\\\\\\\\\\\\\\"\\\\\\\\n                                    @click=\\\\\\\\\\\\\\\"activeTab = tab.id\\\\\\\\\\\\\\\"\\\\\\\\n                                    :class=\\\\\\\\\\\\\\\"{'border-blue-500 text-blue-600': activeTab === tab.id, 'border-transparent text-gray-500': activeTab !== tab.id}\\\\\\\\\\\\\\\"\\\\\\\\n                                    class=\\\\\\\\\\\\\\\"py-4 px-1 border-b-2 font-medium text-sm hover:text-gray-700\\\\\\\\\\\\\\\">\\\\\\\\n                                <i :class=\\\\\\\\\\\\\\\"tab.icon\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"mr-2\\\\\\\\\\\\\\\"></i>\\\\\\\\n                                {{ tab.name }}\\\\\\\\n                            </button>\\\\\\\\n                        </div>\\\\\\\\n                    </nav>\\\\\\\\n                </div>\\\\\\\\n\\\\\\\\n                <!-- Tab Content -->\\\\\\\\n                <div class=\\\\\\\\\\\\\\\"flex-1 overflow-hidden\\\\\\\\\\\\\\\">\\\\\\\\n                    <!-- Chat Tab -->\\\\\\\\n                    <div v-show=\\\\\\\\\\\\\\\"activeTab === 'chat'\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"h-full flex flex-col\\\\\\\\\\\\\\\">\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\"flex-1 overflow-y-auto p-6\\\\\\\\\\\\\\\">\\\\\\\\n                            <div v-if=\\\\\\\\\\\\\\\"chatMessages.length === 0\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"text-center py-12\\\\\\\\\\\\\\\">\\\\\\\\n                                <i class=\\\\\\\\\\\\\\\"fas fa-comments text-6xl text-gray-300 mb-4\\\\\\\\\\\\\\\"></i>\\\\\\\\n                                <h3 class=\\\\\\\\\\\\\\\"text-xl font-medium text-gray-900 mb-2\\\\\\\\\\\\\\\">Start a conversation</h3>\\\\\\\\n                                <p class=\\\\\\\\\\\\\\\"text-gray-600\\\\\\\\\\\\\\\">Ask questions about your code repositories</p>\\\\\\\\n                            </div>\\\\\\\\n                            \\\\\\\\n                            <div v-for=\\\\\\\\\\\\\\\"(message, index) in chatMessages\\\\\\\\\\\\\\\" :key=\\\\\\\\\\\\\\\"index\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"mb-6\\\\\\\\\\\\\\\">\\\\\\\\n                                <div :class=\\\\\\\\\\\\\\\"{'user-message': message.role === 'user', 'assistant-message': message.role === 'assistant'}\\\\\\\\\\\\\\\"\\\\\\\\n                                     class=\\\\\\\\\\\\\\\"chat-message p-4 rounded-lg text-white\\\\\\\\\\\\\\\">\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\"flex items-start space-x-3\\\\\\\\\\\\\\\">\\\\\\\\n                                        <div class=\\\\\\\\\\\\\\\"flex-shrink-0\\\\\\\\\\\\\\\">\\\\\\\\n                                            <i :class=\\\\\\\\\\\\\\\"message.role === 'user' ? 'fas fa-user' : 'fas fa-robot'\\\\\\\\\\\\\\\" \\\\\\\\n                                               class=\\\\\\\\\\\\\\\"text-lg\\\\\\\\\\\\\\\"></i>\\\\\\\\n                                        </div>\\\\\\\\n                                        <div class=\\\\\\\\\\\\\\\"flex-1\\\\\\\\\\\\\\\">\\\\\\\\n                                            <div v-html=\\\\\\\\\\\\\\\"formatMessage(message.content)\\\\\\\\\\\\\\\"></div>\\\\\\\\n                                        </div>\\\\\\\\n                                    </div>\\\\\\\\n                                </div>\\\\\\\\n                            </div>\\\\\\\\n                            \\\\\\\\n                            <div v-if=\\\\\\\\\\\\\\\"isLoading\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"mb-6\\\\\\\\\\\\\\\">\\\\\\\\n                                <div class=\\\\\\\\\\\\\\\"assistant-message chat-message p-4 rounded-lg text-white\\\\\\\\\\\\\\\">\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\"flex items-start space-x-3\\\\\\\\\\\\\\\">\\\\\\\\n                                        <div class=\\\\\\\\\\\\\\\"flex-shrink-0\\\\\\\\\\\\\\\">\\\\\\\\n                                            <i class=\\\\\\\\\\\\\\\"fas fa-robot text-lg\\\\\\\\\\\\\\\"></i>\\\\\\\\n                                        </div>\\\\\\\\n                                        <div class=\\\\\\\\\\\\\\\"flex-1\\\\\\\\\\\\\\\">\\\\\\\\n                                            <span class=\\\\\\\\\\\\\\\"loading-dots\\\\\\\\\\\\\\\">Thinking</span>\\\\\\\\n                                        </div>\\\\\\\\n                                    </div>\\\\\\\\n                                </div>\\\\\\\\n                            </div>\\\\\\\\n                        </div>\\\\\\\\n                        \\\\\\\\n                        <!-- Chat Input -->\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\"border-t bg-white p-4\\\\\\\\\\\\\\\">\\\\\\\\n                            <div class=\\\\\\\\\\\\\\\"max-w-4xl mx-auto\\\\\\\\\\\\\\\">\\\\\\\\n                                <div class=\\\\\\\\\\\\\\\"flex items-end space-x-4\\\\\\\\\\\\\\\">\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\"flex-1\\\\\\\\\\\\\\\">\\\\\\\\n                                        <textarea v-model=\\\\\\\\\\\\\\\"chatInput\\\\\\\\\\\\\\\" \\\\\\\\n                                                @keydown.enter.prevent=\\\\\\\\\\\\\\\"sendChatMessage\\\\\\\\\\\\\\\"\\\\\\\\n                                                :disabled=\\\\\\\\\\\\\\\"isLoading\\\\\\\\\\\\\\\"\\\\\\\\n                                                placeholder=\\\\\\\\\\\\\\\"Ask a question about your code...\\\\\\\\\\\\\\\"\\\\\\\\n                                                class=\\\\\\\\\\\\\\\"w-full px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-transparent resize-none\\\\\\\\\\\\\\\"\\\\\\\\n                                                rows=\\\\\\\\\\\\\\\"2\\\\\\\\\\\\\\\"></textarea>\\\\\\\\n                                    </div>\\\\\\\\n                                    <button @click=\\\\\\\\\\\\\\\"sendChatMessage\\\\\\\\\\\\\\\" \\\\\\\\n                                            :disabled=\\\\\\\\\\\\\\\"isLoading || !chatInput.trim()\\\\\\\\\\\\\\\"\\\\\\\\n                                            class=\\\\\\\\\\\\\\\"px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50 disabled:cursor-not-allowed\\\\\\\\\\\\\\\">\\\\\\\\n                                        <i class=\\\\\\\\\\\\\\\"fas fa-paper-plane\\\\\\\\\\\\\\\"></i>\\\\\\\\n                                    </button>\\\\\\\\n                                </div>\\\\\\\\n                                <div v-if=\\\\\\\\\\\\\\\"selectedRepo\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"mt-2 text-sm text-gray-600\\\\\\\\\\\\\\\">\\\\\\\\n                                    Querying: {{ selectedRepo.name }}\\\\\\\\n                                </div>\\\\\\\\n                            </div>\\\\\\\\n                        </div>\\\\\\\\n                    </div>\\\\\\\\n\\\\\\\\n                    <!-- Search Tab -->\\\\\\\\n                    <div v-show=\\\\\\\\\\\\\\\"activeTab === 'search'\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"h-full p-6\\\\\\\\\\\\\\\">\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\"max-w-4xl mx-auto\\\\\\\\\\\\\\\">\\\\\\\\n                            <div class=\\\\\\\\\\\\\\\"mb-6\\\\\\\\\\\\\\\">\\\\\\\\n                                <div class=\\\\\\\\\\\\\\\"flex space-x-4\\\\\\\\\\\\\\\">\\\\\\\\n                                    <input v-model=\\\\\\\\\\\\\\\"searchQuery\\\\\\\\\\\\\\\" \\\\\\\\n                                           @keydown.enter=\\\\\\\\\\\\\\\"search\\\\\\\\\\\\\\\"\\\\\\\\n                                           type=\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\" \\\\\\\\n                                           placeholder=\\\\\\\\\\\\\\\"Search across all repositories...\\\\\\\\\\\\\\\"\\\\\\\\n                                           class=\\\\\\\\\\\\\\\"flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500\\\\\\\\\\\\\\\">\\\\\\\\n                                    <button @click=\\\\\\\\\\\\\\\"search\\\\\\\\\\\\\\\" \\\\\\\\n                                            :disabled=\\\\\\\\\\\\\\\"!searchQuery.trim()\\\\\\\\\\\\\\\"\\\\\\\\n                                            class=\\\\\\\\\\\\\\\"px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50\\\\\\\\\\\\\\\">\\\\\\\\n                                        <i class=\\\\\\\\\\\\\\\"fas fa-search\\\\\\\\\\\\\\\"></i>\\\\\\\\n                                    </button>\\\\\\\\n                                </div>\\\\\\\\n                            </div>\\\\\\\\n                            \\\\\\\\n                            <div v-if=\\\\\\\\\\\\\\\"searchResults.length > 0\\\\\\\\\\\\\\\">\\\\\\\\n                                <h3 class=\\\\\\\\\\\\\\\"text-lg font-medium mb-4\\\\\\\\\\\\\\\">Search Results</h3>\\\\\\\\n                                <div v-for=\\\\\\\\\\\\\\\"result in searchResults\\\\\\\\\\\\\\\" :key=\\\\\\\\\\\\\\\"result.id\\\\\\\\\\\\\\\" \\\\\\\\n                                     class=\\\\\\\\\\\\\\\"mb-4 p-4 bg-white rounded-lg shadow\\\\\\\\\\\\\\\">\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\"flex justify-between items-start mb-2\\\\\\\\\\\\\\\">\\\\\\\\n                                        <div class=\\\\\\\\\\\\\\\"text-sm text-gray-600\\\\\\\\\\\\\\\">\\\\\\\\n                                            {{ result.metadata.file_path || 'Unknown file' }}\\\\\\\\n                                        </div>\\\\\\\\n                                        <div class=\\\\\\\\\\\\\\\"text-sm text-gray-500\\\\\\\\\\\\\\\">\\\\\\\\n                                            Score: {{ (1 - result.distance).toFixed(3) }}\\\\\\\\n                                        </div>\\\\\\\\n                                    </div>\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\"text-gray-900\\\\\\\\\\\\\\\">\\\\\\\\n                                        {{ result.text.substring(0, 300) }}...\\\\\\\\n                                    </div>\\\\\\\\n                                </div>\\\\\\\\n                            </div>\\\\\\\\n                            \\\\\\\\n                            <div v-else-if=\\\\\\\\\\\\\\\"searchQuery && !isSearching\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"text-center py-12\\\\\\\\\\\\\\\">\\\\\\\\n                                <i class=\\\\\\\\\\\\\\\"fas fa-search text-6xl text-gray-300 mb-4\\\\\\\\\\\\\\\"></i>\\\\\\\\n                                <p class=\\\\\\\\\\\\\\\"text-gray-600\\\\\\\\\\\\\\\">No results found</p>\\\\\\\\n                            </div>\\\\\\\\n                        </div>\\\\\\\\n                    </div>\\\\\\\\n\\\\\\\\n                    <!-- Documentation Tab -->\\\\\\\\n                    <div v-show=\\\\\\\\\\\\\\\"activeTab === 'docs'\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"h-full p-6\\\\\\\\\\\\\\\">\\\\\\\\n                        <div class=\\\\\\\\\\\\\\\"max-w-4xl mx-auto\\\\\\\\\\\\\\\">\\\\\\\\n                            <div class=\\\\\\\\\\\\\\\"mb-6\\\\\\\\\\\\\\\">\\\\\\\\n                                <h2 class=\\\\\\\\\\\\\\\"text-2xl font-bold mb-4\\\\\\\\\\\\\\\">Documentation</h2>\\\\\\\\n                                \\\\\\\\n                                <div v-if=\\\\\\\\\\\\\\\"selectedRepo\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"mb-4\\\\\\\\\\\\\\\">\\\\\\\\n                                    <button @click=\\\\\\\\\\\\\\\"generateDocs\\\\\\\\\\\\\\\" \\\\\\\\n                                            :disabled=\\\\\\\\\\\\\\\"isGeneratingDocs\\\\\\\\\\\\\\\"\\\\\\\\n                                            class=\\\\\\\\\\\\\\\"px-4 py-2 bg-green-600 text-white rounded-lg hover:bg-green-700 disabled:opacity-50\\\\\\\\\\\\\\\">\\\\\\\\n                                        <i class=\\\\\\\\\\\\\\\"fas fa-file-alt mr-2\\\\\\\\\\\\\\\"></i>\\\\\\\\n                                        Generate Documentation\\\\\\\\n                                    </button>\\\\\\\\n                                </div>\\\\\\\\n                                \\\\\\\\n                                <div v-if=\\\\\\\\\\\\\\\"generatedDocs.length > 0\\\\\\\\\\\\\\\">\\\\\\\\n                                    <h3 class=\\\\\\\\\\\\\\\"text-lg font-medium mb-4\\\\\\\\\\\\\\\">Generated Documents</h3>\\\\\\\\n                                    <div class=\\\\\\\\\\\\\\\"grid gap-4\\\\\\\\\\\\\\\">\\\\\\\\n                                        <div v-for=\\\\\\\\\\\\\\\"doc in generatedDocs\\\\\\\\\\\\\\\" :key=\\\\\\\\\\\\\\\"doc.path\\\\\\\\\\\\\\\"\\\\\\\\n                                             @click=\\\\\\\\\\\\\\\"viewDocument(doc)\\\\\\\\\\\\\\\"\\\\\\\\n                                             class=\\\\\\\\\\\\\\\"p-4 bg-white rounded-lg shadow cursor-pointer hover:shadow-md transition-shadow\\\\\\\\\\\\\\\">\\\\\\\\n                                            <div class=\\\\\\\\\\\\\\\"flex items-center space-x-3\\\\\\\\\\\\\\\">\\\\\\\\n                                                <i class=\\\\\\\\\\\\\\\"fas fa-file-markdown text-blue-600\\\\\\\\\\\\\\\"></i>\\\\\\\\n                                                <div>\\\\\\\\n                                                    <div class=\\\\\\\\\\\\\\\"font-medium\\\\\\\\\\\\\\\">{{ doc.name }}</div>\\\\\\\\n                                                    <div class=\\\\\\\\\\\\\\\"text-sm text-gray-600\\\\\\\\\\\\\\\">{{ doc.path }}</div>\\\\\\\\n                                                </div>\\\\\\\\n                                            </div>\\\\\\\\n                                        </div>\\\\\\\\n                                    </div>\\\\\\\\n                                </div>\\\\\\\\n                            </div>\\\\\\\\n                        </div>\\\\\\\\n                    </div>\\\\\\\\n                </div>\\\\\\\\n            </div>\\\\\\\\n        </div>\\\\\\\\n\\\\\\\\n        <!-- Add Repository Modal -->\\\\\\\\n        <div v-if=\\\\\\\\\\\\\\\"showAddRepoModal\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50\\\\\\\\\\\\\\\">\\\\\\\\n            <div class=\\\\\\\\\\\\\\\"bg-white rounded-lg p-6 w-full max-w-md mx-4\\\\\\\\\\\\\\\">\\\\\\\\n                <h3 class=\\\\\\\\\\\\\\\"text-lg font-medium mb-4\\\\\\\\\\\\\\\">Add Repository</h3>\\\\\\\\n                <div class=\\\\\\\\\\\\\\\"mb-4\\\\\\\\\\\\\\\">\\\\\\\\n                    <label class=\\\\\\\\\\\\\\\"block text-sm font-medium text-gray-700 mb-2\\\\\\\\\\\\\\\">Repository Path</label>\\\\\\\\n                    <input v-model=\\\\\\\\\\\\\\\"newRepoPath\\\\\\\\\\\\\\\" \\\\\\\\n                           type=\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\" \\\\\\\\n                           placeholder=\\\\\\\\\\\\\\\"/path/to/your/repository\\\\\\\\\\\\\\\"\\\\\\\\n                           class=\\\\\\\\\\\\\\\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500\\\\\\\\\\\\\\\">\\\\\\\\n                </div>\\\\\\\\n                <div class=\\\\\\\\\\\\\\\"mb-6\\\\\\\\\\\\\\\">\\\\\\\\n                    <label class=\\\\\\\\\\\\\\\"block text-sm font-medium text-gray-700 mb-2\\\\\\\\\\\\\\\">Repository Name (optional)</label>\\\\\\\\n                    <input v-model=\\\\\\\\\\\\\\\"newRepoName\\\\\\\\\\\\\\\" \\\\\\\\n                           type=\\\\\\\\\\\\\\\"text\\\\\\\\\\\\\\\" \\\\\\\\n                           placeholder=\\\\\\\\\\\\\\\"my-project\\\\\\\\\\\\\\\"\\\\\\\\n                           class=\\\\\\\\\\\\\\\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500\\\\\\\\\\\\\\\">\\\\\\\\n                </div>\\\\\\\\n                <div class=\\\\\\\\\\\\\\\"flex justify-end space-x-3\\\\\\\\\\\\\\\">\\\\\\\\n                    <button @click=\\\\\\\\\\\\\\\"showAddRepoModal = false\\\\\\\\\\\\\\\" \\\\\\\\n                            class=\\\\\\\\\\\\\\\"px-4 py-2 text-gray-700 border border-gray-300 rounded-md hover:bg-gray-50\\\\\\\\\\\\\\\">\\\\\\\\n                        Cancel\\\\\\\\n                    </button>\\\\\\\\n                    <button @click=\\\\\\\\\\\\\\\"addRepository\\\\\\\\\\\\\\\" \\\\\\\\n                            :disabled=\\\\\\\\\\\\\\\"!newRepoPath.trim()\\\\\\\\\\\\\\\"\\\\\\\\n                            class=\\\\\\\\\\\\\\\"px-4 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700 disabled:opacity-50\\\\\\\\\\\\\\\">\\\\\\\\n                        Add Repository\\\\\\\\n                    </button>\\\\\\\\n                </div>\\\\\\\\n            </div>\\\\\\\\n        </div>\\\\\\\\n\\\\\\\\n        <!-- Document Viewer Modal -->\\\\\\\\n        <div v-if=\\\\\\\\\\\\\\\"showDocModal\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50\\\\\\\\\\\\\\\">\\\\\\\\n            <div class=\\\\\\\\\\\\\\\"bg-white rounded-lg w-full max-w-4xl mx-4 h-5/6 flex flex-col\\\\\\\\\\\\\\\">\\\\\\\\n                <div class=\\\\\\\\\\\\\\\"flex items-center justify-between p-4 border-b\\\\\\\\\\\\\\\">\\\\\\\\n                    <h3 class=\\\\\\\\\\\\\\\"text-lg font-medium\\\\\\\\\\\\\\\">{{ currentDoc?.name }}</h3>\\\\\\\\n                    <button @click=\\\\\\\\\\\\\\\"showDocModal = false\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"text-gray-500 hover:text-gray-700\\\\\\\\\\\\\\\">\\\\\\\\n                        <i class=\\\\\\\\\\\\\\\"fas fa-times\\\\\\\\\\\\\\\"></i>\\\\\\\\n                    </button>\\\\\\\\n                </div>\\\\\\\\n                <div class=\\\\\\\\\\\\\\\"flex-1 overflow-auto p-4\\\\\\\\\\\\\\\">\\\\\\\\n                    <div v-html=\\\\\\\\\\\\\\\"formatMarkdown(currentDocContent)\\\\\\\\\\\\\\\" class=\\\\\\\\\\\\\\\"prose max-w-none\\\\\\\\\\\\\\\"></div>\\\\\\\\n                </div>\\\\\\\\n            </div>\\\\\\\\n        </div>\\\\\\\\n    </div>\\\\\\\\n\\\\\\\\n    <script>\\\\\\\\n        const { createApp } = Vue;\\\\\\\\n\\\\\\\\n        createApp({\\\\\\\\n            data() {\\\\\\\\n                return {\\\\\\\\n                    sidebarOpen: true,\\\\\\\\n                    activeTab: 'chat',\\\\\\\\n                    systemStatus: {\\\\\\\\n                        ollama_available: false,\\\\\\\\n                        ollama_model: ''\\\\\\\\n                    },\\\\\\\\n                    stats: {},\\\\\\\\n                    repositories: [],\\\\\\\\n                    selectedRepo: null,\\\\\\\\n                    chatMessages: [],\\\\\\\\n                    chatInput: '',\\\\\\\\n                    isLoading: false,\\\\\\\\n                    searchQuery: '',\\\\\\\\n                    searchResults: [],\\\\\\\\n                    isSearching: false,\\\\\\\\n                    generatedDocs: [],\\\\\\\\n                    isGeneratingDocs: false,\\\\\\\\n                    showAddRepoModal: false,\\\\\\\\n                    newRepoPath: '',\\\\\\\\n                    newRepoName: '',\\\\\\\\n                    showDocModal: false,\\\\\\\\n                    currentDoc: null,\\\\\\\\n                    currentDocContent: '',\\\\\\\\n                    tabs: [\\\\\\\\n                        { id: 'chat', name: 'Chat', icon: 'fas fa-comments' },\\\\\\\\n                        { id: 'search', name: 'Search', icon: 'fas fa-search' },\\\\\\\\n                        { id: 'docs', name: 'Documentation', icon: 'fas fa-file-alt' }\\\\\\\\n                    ]\\\\\\\\n                };\\\\\\\\n            },\\\\\\\\n            async mounted() {\\\\\\\\n                await this.checkHealth();\\\\\\\\n                await this.loadRepositories();\\\\\\\\n                await this.loadStats();\\\\\\\\n            },\\\\\\\\n            methods: {\\\\\\\\n                toggleSidebar() {\\\\\\\\n                    this.sidebarOpen = !this.sidebarOpen;\\\\\\\\n                },\\\\\\\\n                async checkHealth() {\\\\\\\\n                    try {\\\\\\\\n                        const response = await axios.get('/health');\\\\\\\\n                        this.systemStatus = response.data;\\\\\\\\n                    } catch (error) {\\\\\\\\n                        console.error('Health check failed:', error);\\\\\\\\n                        this.systemStatus.ollama_available = false;\\\\\\\\n                    }\\\\\\\\n                },\\\\\\\\n                async loadRepositories() {\\\\\\\\n                    try {\\\\\\\\n                        const response = await axios.get('/repositories');\\\\\\\\n                        this.repositories = response.data.repositories;\\\\\\\\n                    } catch (error) {\\\\\\\\n                        console.error('Failed to load repositories:', error);\\\\\\\\n                    }\\\\\\\\n                },\\\\\\\\n                async loadStats() {\\\\\\\\n                    try {\\\\\\\\n                        const response = await axios.get('/stats');\\\\\\\\n                        this.stats = response.data;\\\\\\\\n                    } catch (error) {\\\\\\\\n                        console.error('Failed to load stats:', error);\\\\\\\\n                    }\\\\\\\\n                },\\\\\\\\n                selectRepository(repo) {\\\\\\\\n                    this.selectedRepo = repo;\\\\\\\\n                    this.loadGeneratedDocs();\\\\\\\\n                },\\\\\\\\n                async addRepository() {\\\\\\\\n                    if (!this.newRepoPath.trim()) return;\\\\\\\\n                    \\\\\\\\n                    try {\\\\\\\\n                        await axios.post('/repositories/analyze', {\\\\\\\\n                            repo_path: this.newRepoPath,\\\\\\\\n                            repo_name: this.newRepoName || undefined\\\\\\\\n                        });\\\\\\\\n                        \\\\\\\\n                        this.showAddRepoModal = false;\\\\\\\\n                        this.newRepoPath = '';\\\\\\\\n                        this.newRepoName = '';\\\\\\\\n                        \\\\\\\\n                        // Reload repositories after a short delay\\\\\\\\n                        setTimeout(() => {\\\\\\\\n                            this.loadRepositories();\\\\\\\\n                            this.loadStats();\\\\\\\\n                        }, 2000);\\\\\\\\n                        \\\\\\\\n                        alert('Repository analysis started. It may take a few moments to complete.');\\\\\\\\n                    } catch (error) {\\\\\\\\n                        console.error('Failed to add repository:', error);\\\\\\\\n                        alert('Failed to add repository: ' + (error.response?.data?.detail || error.message));\\\\\\\\n                    }\\\\\\\\n                },\\\\\\\\n                async deleteRepo(repoName) {\\\\\\\\n                    if (!confirm(`Are you sure you want to delete ${repoName}?`)) return;\\\\\\\\n                    \\\\\\\\n                    try {\\\\\\\\n                        await axios.delete(`/repositories/${repoName}`);\\\\\\\\n                        await this.loadRepositories();\\\\\\\\n                        await this.loadStats();\\\\\\\\n                        \\\\\\\\n                        if (this.selectedRepo?.name === repoName) {\\\\\\\\n                            this.selectedRepo = null;\\\\\\\\n                        }\\\\\\\\n                    } catch (error) {\\\\\\\\n                        console.error('Failed to delete repository:', error);\\\\\\\\n                        alert('Failed to delete repository');\\\\\\\\n                    }\\\\\\\\n                },\\\\\\\\n                async sendChatMessage() {\\\\\\\\n                    if (!this.chatInput.trim() || this.isLoading) return;\\\\\\\\n                    \\\\\\\\n                    const userMessage = {\\\\\\\\n                        role: 'user',\\\\\\\\n                        content: this.chatInput.trim()\\\\\\\\n                    };\\\\\\\\n                    \\\\\\\\n                    this.chatMessages.push(userMessage);\\\\\\\\n                    this.chatInput = '';\\\\\\\\n                    this.isLoading = true;\\\\\\\\n                    \\\\\\\\n                    try {\\\\\\\\n                        const response = await axios.post('/chat', {\\\\\\\\n                            messages: this.chatMessages,\\\\\\\\n                            repo_name: this.selectedRepo?.name\\\\\\\\n                        });\\\\\\\\n                        \\\\\\\\n                        this.chatMessages.push({\\\\\\\\n                            role: 'assistant',\\\\\\\\n                            content: response.data.response\\\\\\\\n                        });\\\\\\\\n                    } catch (error) {\\\\\\\\n                        console.error('Chat failed:', error);\\\\\\\\n                        this.chatMessages.push({\\\\\\\\n                            role: 'assistant',\\\\\\\\n                            content: 'Sorry, I encountered an error processing your request.'\\\\\\\\n                        });\\\\\\\\n                    } finally {\\\\\\\\n                        this.isLoading = false;\\\\\\\\n                        this.$nextTick(() => {\\\\\\\\n                            // Scroll to bottom\\\\\\\\n                            const chatContainer = document.querySelector('.overflow-y-auto');\\\\\\\\n                            if (chatContainer) {\\\\\\\\n                                chatContainer.scrollTop = chatContainer.scrollHeight;\\\\\\\\n                            }\\\\\\\\n                        });\\\\\\\\n                    }\\\\\\\\n                },\\\\\\\\n                async search() {\\\\\\\\n                    if (!this.searchQuery.trim()) return;\\\\\\\\n                    \\\\\\\\n                    this.isSearching = true;\\\\\\\\n                    this.searchResults = [];\\\\\\\\n                    \\\\\\\\n                    try {\\\\\\\\n                        const endpoint = this.selectedRepo \\\\\\\\n                            ? `/repositories/${this.selectedRepo.name}/search`\\\\\\\\n                            : '/search';\\\\\\\\n                        \\\\\\\\n                        const response = await axios.get(endpoint, {\\\\\\\\n                            params: { q: this.searchQuery, limit: 10 }\\\\\\\\n                        });\\\\\\\\n                        \\\\\\\\n                        this.searchResults = response.data.results;\\\\\\\\n                    } catch (error) {\\\\\\\\n                        console.error('Search failed:', error);\\\\\\\\n                    } finally {\\\\\\\\n                        this.isSearching = false;\\\\\\\\n                    }\\\\\\\\n                },\\\\\\\\n                async generateDocs() {\\\\\\\\n                    if (!this.selectedRepo) return;\\\\\\\\n                    \\\\\\\\n                    this.isGeneratingDocs = true;\\\\\\\\n                    \\\\\\\\n                    try {\\\\\\\\n                        await axios.post(`/repositories/${this.selectedRepo.name}/generate-docs`, {\\\\\\\\n                            repo_name: this.selectedRepo.name,\\\\\\\\n                            include_overview: true,\\\\\\\\n                            include_api_docs: true,\\\\\\\\n                            include_examples: true,\\\\\\\\n                            include_architecture: true\\\\\\\\n                        });\\\\\\\\n                        \\\\\\\\n                        alert('Documentation generation started. It may take a few moments to complete.');\\\\\\\\n                        \\\\\\\\n                        // Reload docs after a delay\\\\\\\\n                        setTimeout(() => {\\\\\\\\n                            this.loadGeneratedDocs();\\\\\\\\n                        }, 5000);\\\\\\\\n                    } catch (error) {\\\\\\\\n                        console.error('Failed to generate docs:', error);\\\\\\\\n                        alert('Failed to generate documentation');\\\\\\\\n                    } finally {\\\\\\\\n                        this.isGeneratingDocs = false;\\\\\\\\n                    }\\\\\\\\n                },\\\\\\\\n                async loadGeneratedDocs() {\\\\\\\\n                    if (!this.selectedRepo) return;\\\\\\\\n                    \\\\\\\\n                    try {\\\\\\\\n                        const response = await axios.get(`/repositories/${this.selectedRepo.name}/docs`);\\\\\\\\n                        this.generatedDocs = response.data.documents;\\\\\\\\n                    } catch (error) {\\\\\\\\n                        console.error('Failed to load generated docs:', error);\\\\\\\\n                        this.generatedDocs = [];\\\\\\\\n                    }\\\\\\\\n                },\\\\\\\\n                async viewDocument(doc) {\\\\\\\\n                    if (!this.selectedRepo) return;\\\\\\\\n                    \\\\\\\\n                    try {\\\\\\\\n                        const response = await axios.get(`/repositories/${this.selectedRepo.name}/docs/${doc.path}`);\\\\\\\\n                        this.currentDoc = doc;\\\\\\\\n                        this.currentDocContent = response.data.content;\\\\\\\\n                        this.showDocModal = true;\\\\\\\\n                    } catch (error) {\\\\\\\\n                        console.error('Failed to load document:', error);\\\\\\\\n                        alert('Failed to load document');\\\\\\\\n                    }\\\\\\\\n                },\\\\\\\\n                formatMessage(content) {\\\\\\\\n                    // Simple markdown-like formatting\\\\\\\\n                    return content\\\\\\\\n                        .replace(/```(\\\\\\\\\\\\\\\\w+)?\\\\\\\\\\\\\\\\n([\\\\\\\\\\\\\\\\s\\\\\\\\\\\\\\\\S]*?)```/g, '<pre class=\\\\\\\\\\\\\\\"code-block\\\\\\\\\\\\\\\"><code>$2</code></pre>')\\\\\\\\n                        .replace(/`([^`]+)`/g, '<code class=\\\\\\\\\\\\\\\"bg-gray-200 px-1 rounded\\\\\\\\\\\\\\\">$1</code>')\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\*\\\\\\\\\\\\\\\\*(.*?)\\\\\\\\\\\\\\\\*\\\\\\\\\\\\\\\\*/g, '<strong>$1</strong>')\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\*(.*?)\\\\\\\\\\\\\\\\*/g, '<em>$1</em>')\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\n/g, '<br>');\\\\\\\\n                },\\\\\\\\n                formatMarkdown(content) {\\\\\\\\n                    // Basic markdown formatting for document viewer\\\\\\\\n                    return content\\\\\\\\n                        .replace(/# (.*)/g, '<h1 class=\\\\\\\\\\\\\\\"text-3xl font-bold mb-4\\\\\\\\\\\\\\\">$1</h1>')\\\\\\\\n                        .replace(/## (.*)/g, '<h2 class=\\\\\\\\\\\\\\\"text-2xl font-semibold mb-3\\\\\\\\\\\\\\\">$1</h2>')\\\\\\\\n                        .replace(/### (.*)/g, '<h3 class=\\\\\\\\\\\\\\\"text-xl font-medium mb-2\\\\\\\\\\\\\\\">$1</h3>')\\\\\\\\n                        .replace(/```(\\\\\\\\\\\\\\\\w+)?\\\\\\\\\\\\\\\\n([\\\\\\\\\\\\\\\\s\\\\\\\\\\\\\\\\S]*?)```/g, '<pre class=\\\\\\\\\\\\\\\"bg-gray-900 text-white p-4 rounded-lg overflow-x-auto mb-4\\\\\\\\\\\\\\\"><code>$2</code></pre>')\\\\\\\\n                        .replace(/`([^`]+)`/g, '<code class=\\\\\\\\\\\\\\\"bg-gray-200 px-1 rounded\\\\\\\\\\\\\\\">$1</code>')\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\*\\\\\\\\\\\\\\\\*(.*?)\\\\\\\\\\\\\\\\*\\\\\\\\\\\\\\\\*/g, '<strong>$1</strong>')\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\*(.*?)\\\\\\\\\\\\\\\\*/g, '<em>$1</em>')\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n/g, '</p><p class=\\\\\\\\\\\\\\\"mb-4\\\\\\\\\\\\\\\">')\\\\\\\\n                        .replace(/\\\\\\\\\\\\\\\\n/g, '<br>')\\\\\\\\n                        .replace(/^/, '<p class=\\\\\\\\\\\\\\\"mb-4\\\\\\\\\\\\\\\">') + '</p>';\\\\\\\\n                }\\\\\\\\n            }\\\\\\\\n        }).mount('#app');\\\\\\\\n    </script>\\\\\\\\n</body>\\\\\\\\n</html>\\\\\\\\n\\\\\\\"\\\\n    }\\\\n  ],\\\\n  \\\\\\\"structure\\\\\\\": {\\\\n    \\\\\\\"name\\\\\\\": \\\\\\\"wikillm\\\\\\\",\\\\n    \\\\\\\"type\\\\\\\": \\\\\\\"directory\\\\\\\",\\\\n    \\\\\\\"children\\\\\\\": [\\\\n      {\\\\n        \\\\\\\"name\\\\\\\": \\\\\\\"api.py\\\\\\\",\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n        \\\\\\\"path\\\\\\\": \\\\\\\"api.py\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"name\\\\\\\": \\\\\\\"config.py\\\\\\\",\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n        \\\\\\\"path\\\\\\\": \\\\\\\"config.py\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"name\\\\\\\": \\\\\\\"data\\\\\\\",\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"directory\\\\\\\",\\\\n        \\\\\\\"children\\\\\\\": [\\\\n          {\\\\n            \\\\\\\"name\\\\\\\": \\\\\\\"chroma_db\\\\\\\",\\\\n            \\\\\\\"type\\\\\\\": \\\\\\\"directory\\\\\\\",\\\\n            \\\\\\\"children\\\\\\\": [\\\\n              {\\\\n                \\\\\\\"name\\\\\\\": \\\\\\\"f2e7f382-a1d1-45fd-b769-7e72a660468f\\\\\\\",\\\\n                \\\\\\\"type\\\\\\\": \\\\\\\"directory\\\\\\\",\\\\n                \\\\\\\"children\\\\\\\": []\\\\n              }\\\\n            ]\\\\n          },\\\\n          {\\\\n            \\\\\\\"name\\\\\\\": \\\\\\\"generated_docs\\\\\\\",\\\\n            \\\\\\\"type\\\\\\\": \\\\\\\"directory\\\\\\\",\\\\n            \\\\\\\"children\\\\\\\": []\\\\n          },\\\\n          {\\\\n            \\\\\\\"name\\\\\\\": \\\\\\\"repos\\\\\\\",\\\\n            \\\\\\\"type\\\\\\\": \\\\\\\"directory\\\\\\\",\\\\n            \\\\\\\"children\\\\\\\": [\\\\n              {\\\\n                \\\\\\\"name\\\\\\\": \\\\\\\"wikillm_analysis.json\\\\\\\",\\\\n                \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n                \\\\\\\"path\\\\\\\": \\\\\\\"data\\\\\\\\\\\\\\\\repos\\\\\\\\\\\\\\\\wikillm_analysis.json\\\\\\\"\\\\n              }\\\\n            ]\\\\n          }\\\\n        ]\\\\n      },\\\\n      {\\\\n        \\\\\\\"name\\\\\\\": \\\\\\\"documentation_generator.py\\\\\\\",\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n        \\\\\\\"path\\\\\\\": \\\\\\\"documentation_generator.py\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"name\\\\\\\": \\\\\\\"main.py\\\\\\\",\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n        \\\\\\\"path\\\\\\\": \\\\\\\"main.py\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"name\\\\\\\": \\\\\\\"ollama_client.py\\\\\\\",\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n        \\\\\\\"path\\\\\\\": \\\\\\\"ollama_client.py\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"name\\\\\\\": \\\\\\\"rag_system.py\\\\\\\",\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n        \\\\\\\"path\\\\\\\": \\\\\\\"rag_system.py\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"name\\\\\\\": \\\\\\\"README.md\\\\\\\",\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n        \\\\\\\"path\\\\\\\": \\\\\\\"README.md\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"name\\\\\\\": \\\\\\\"repository_analyzer.py\\\\\\\",\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n        \\\\\\\"path\\\\\\\": \\\\\\\"repository_analyzer.py\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"name\\\\\\\": \\\\\\\"requirements.txt\\\\\\\",\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n        \\\\\\\"path\\\\\\\": \\\\\\\"requirements.txt\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"name\\\\\\\": \\\\\\\"vector_store.py\\\\\\\",\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n        \\\\\\\"path\\\\\\\": \\\\\\\"vector_store.py\\\\\\\"\\\\n      },\\\\n      {\\\\n        \\\\\\\"name\\\\\\\": \\\\\\\"web\\\\\\\",\\\\n        \\\\\\\"type\\\\\\\": \\\\\\\"directory\\\\\\\",\\\\n        \\\\\\\"children\\\\\\\": [\\\\n          {\\\\n            \\\\\\\"name\\\\\\\": \\\\\\\"index.html\\\\\\\",\\\\n            \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n            \\\\\\\"path\\\\\\\": \\\\\\\"web\\\\\\\\\\\\\\\\index.html\\\\\\\"\\\\n          }\\\\n        ]\\\\n      }\\\\n    ]\\\\n  },\\\\n  \\\\\\\"statistics\\\\\\\": {\\\\n    \\\\\\\"total_files\\\\\\\": 12,\\\\n    \\\\\\\"code_files\\\\\\\": 10,\\\\n    \\\\\\\"doc_files\\\\\\\": 2,\\\\n    \\\\\\\"languages\\\\\\\": {\\\\n      \\\\\\\"python\\\\\\\": 8\\\\n    },\\\\n    \\\\\\\"total_lines\\\\\\\": 5807\\\\n  },\\\\n  \\\\\\\"git_info\\\\\\\": {\\\\n    \\\\\\\"remote_url\\\\\\\": \\\\\\\"https://github.com/sharmaharsh/wikillm.git\\\\\\\",\\\\n    \\\\\\\"current_branch\\\\\\\": \\\\\\\"main\\\\\\\",\\\\n    \\\\\\\"last_commit\\\\\\\": {\\\\n      \\\\\\\"hash\\\\\\\": \\\\\\\"f0138481\\\\\\\",\\\\n      \\\\\\\"message\\\\\\\": \\\\\\\"init\\\\\\\",\\\\n      \\\\\\\"author\\\\\\\": \\\\\\\"sharmaharsh\\\\\\\",\\\\n      \\\\\\\"date\\\\\\\": \\\\\\\"2025-08-08T21:50:42-05:00\\\\\\\"\\\\n    }\\\\n  }\\\\n}\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\docs\\\\\\\\project-overview.md\\\",\\n      \\\"file_type\\\": \\\"documentation\\\",\\n      \\\"language\\\": null,\\n      \\\"imports\\\": [],\\n      \\\"elements\\\": [],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"# Project Overview\\\\n\\\\nThis is Local DeepWiki - a system for analyzing code repositories using local LLMs.\\\\n\\\\n## Key Features\\\\n- Repository analysis and indexing\\\\n- RAG-based question answering\\\\n- Local LLM integration via Ollama\\\\n- REST API for programmatic access\\\\n\\\\n## Architecture\\\\n- **Repository Analyzer**: Parses code structure and extracts metadata\\\\n- **Vector Store**: Uses ChromaDB for semantic search\\\\n- **RAG System**: Retrieves context and generates responses\\\\n- **API Server**: FastAPI-based REST endpoints\\\"\\n    },\\n    {\\n      \\\"file_path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\\\\\\web\\\\\\\\index.html\\\",\\n      \\\"file_type\\\": \\\"code\\\",\\n      \\\"language\\\": null,\\n      \\\"imports\\\": [],\\n      \\\"elements\\\": [],\\n      \\\"summary\\\": null,\\n      \\\"content\\\": \\\"<!DOCTYPE html>\\\\n<html lang=\\\\\\\"en\\\\\\\">\\\\n<head>\\\\n    <meta charset=\\\\\\\"UTF-8\\\\\\\">\\\\n    <meta name=\\\\\\\"viewport\\\\\\\" content=\\\\\\\"width=device-width, initial-scale=1.0\\\\\\\">\\\\n    <title>Local DeepWiki</title>\\\\n    <script src=\\\\\\\"https://unpkg.com/vue@3/dist/vue.global.js\\\\\\\"></script>\\\\n    <script src=\\\\\\\"https://unpkg.com/axios/dist/axios.min.js\\\\\\\"></script>\\\\n    <link href=\\\\\\\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\\\\\\\" rel=\\\\\\\"stylesheet\\\\\\\">\\\\n    <link href=\\\\\\\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css\\\\\\\" rel=\\\\\\\"stylesheet\\\\\\\">\\\\n    <style>\\\\n        .chat-message {\\\\n            max-width: 80%;\\\\n        }\\\\n        .user-message {\\\\n            margin-left: auto;\\\\n            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\\\\n        }\\\\n        .assistant-message {\\\\n            margin-right: auto;\\\\n            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\\\\n        }\\\\n        .code-block {\\\\n            background-color: #1e1e1e;\\\\n            border-radius: 8px;\\\\n            padding: 1rem;\\\\n            overflow-x: auto;\\\\n        }\\\\n        .sidebar {\\\\n            transition: transform 0.3s ease-in-out;\\\\n        }\\\\n        .sidebar-closed {\\\\n            transform: translateX(-100%);\\\\n        }\\\\n        .loading-dots {\\\\n            display: inline-block;\\\\n        }\\\\n        .loading-dots:after {\\\\n            content: '';\\\\n            animation: dots 1.5s infinite;\\\\n        }\\\\n        @keyframes dots {\\\\n            0%, 20% { content: '.'; }\\\\n            40% { content: '..'; }\\\\n            60%, 100% { content: '...'; }\\\\n        }\\\\n    </style>\\\\n</head>\\\\n<body class=\\\\\\\"bg-gray-100 font-sans\\\\\\\">\\\\n    <div id=\\\\\\\"app\\\\\\\">\\\\n        <!-- Header -->\\\\n        <header class=\\\\\\\"bg-white shadow-lg\\\\\\\">\\\\n            <div class=\\\\\\\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\\\\\\\">\\\\n                <div class=\\\\\\\"flex justify-between items-center py-4\\\\\\\">\\\\n                    <div class=\\\\\\\"flex items-center\\\\\\\">\\\\n                        <button @click=\\\\\\\"toggleSidebar\\\\\\\" class=\\\\\\\"mr-4 text-gray-600 hover:text-gray-900\\\\\\\">\\\\n                            <i class=\\\\\\\"fas fa-bars text-xl\\\\\\\"></i>\\\\n                        </button>\\\\n                        <h1 class=\\\\\\\"text-2xl font-bold text-gray-900\\\\\\\">\\\\n                            <i class=\\\\\\\"fas fa-book text-blue-600 mr-2\\\\\\\"></i>\\\\n                            Local DeepWiki\\\\n                        </h1>\\\\n                    </div>\\\\n                    <div class=\\\\\\\"flex items-center space-x-4\\\\\\\">\\\\n                        <div class=\\\\\\\"flex items-center space-x-2\\\\\\\">\\\\n                            <div :class=\\\\\\\"{'bg-green-500': systemStatus.ollama_available, 'bg-red-500': !systemStatus.ollama_available}\\\\\\\" \\\\n                                 class=\\\\\\\"w-3 h-3 rounded-full\\\\\\\"></div>\\\\n                            <span class=\\\\\\\"text-sm text-gray-600\\\\\\\">\\\\n                                {{ systemStatus.ollama_available ? 'Ollama Connected' : 'Ollama Disconnected' }}\\\\n                            </span>\\\\n                        </div>\\\\n                        <button @click=\\\\\\\"checkHealth\\\\\\\" class=\\\\\\\"text-blue-600 hover:text-blue-800\\\\\\\">\\\\n                            <i class=\\\\\\\"fas fa-sync-alt\\\\\\\"></i>\\\\n                        </button>\\\\n                    </div>\\\\n                </div>\\\\n            </div>\\\\n        </header>\\\\n\\\\n        <div class=\\\\\\\"flex h-screen\\\\\\\">\\\\n            <!-- Sidebar -->\\\\n            <div :class=\\\\\\\"{'sidebar-closed': !sidebarOpen}\\\\\\\" class=\\\\\\\"sidebar fixed inset-y-0 left-0 z-50 w-64 bg-white shadow-lg transform lg:translate-x-0 lg:static lg:inset-0\\\\\\\">\\\\n                <div class=\\\\\\\"flex flex-col h-full\\\\\\\">\\\\n                    <!-- Sidebar Header -->\\\\n                    <div class=\\\\\\\"flex items-center justify-between p-4 border-b\\\\\\\">\\\\n                        <h2 class=\\\\\\\"text-lg font-semibold text-gray-900\\\\\\\">Repositories</h2>\\\\n                        <button @click=\\\\\\\"showAddRepoModal = true\\\\\\\" class=\\\\\\\"text-blue-600 hover:text-blue-800\\\\\\\">\\\\n                            <i class=\\\\\\\"fas fa-plus\\\\\\\"></i>\\\\n                        </button>\\\\n                    </div>\\\\n\\\\n                    <!-- Repository List -->\\\\n                    <div class=\\\\\\\"flex-1 overflow-y-auto p-4\\\\\\\">\\\\n                        <div v-if=\\\\\\\"repositories.length === 0\\\\\\\" class=\\\\\\\"text-gray-500 text-center py-8\\\\\\\">\\\\n                            <i class=\\\\\\\"fas fa-folder-open text-4xl mb-2\\\\\\\"></i>\\\\n                            <p>No repositories added yet</p>\\\\n                        </div>\\\\n                        <div v-for=\\\\\\\"repo in repositories\\\\\\\" :key=\\\\\\\"repo.name\\\\\\\" \\\\n                             @click=\\\\\\\"selectRepository(repo)\\\\\\\"\\\\n                             :class=\\\\\\\"{'bg-blue-50 border-blue-200': selectedRepo?.name === repo.name}\\\\\\\"\\\\n                             class=\\\\\\\"p-3 mb-2 border rounded-lg cursor-pointer hover:bg-gray-50 transition-colors\\\\\\\">\\\\n                            <div class=\\\\\\\"flex items-center justify-between\\\\\\\">\\\\n                                <div>\\\\n                                    <h3 class=\\\\\\\"font-medium text-gray-900\\\\\\\">{{ repo.name }}</h3>\\\\n                                    <p class=\\\\\\\"text-sm text-gray-600\\\\\\\">{{ repo.files }} files</p>\\\\n                                    <div class=\\\\\\\"flex flex-wrap gap-1 mt-1\\\\\\\">\\\\n                                        <span v-for=\\\\\\\"lang in repo.languages\\\\\\\" :key=\\\\\\\"lang\\\\\\\" \\\\n                                              class=\\\\\\\"px-2 py-1 bg-gray-200 text-gray-700 text-xs rounded\\\\\\\">\\\\n                                            {{ lang }}\\\\n                                        </span>\\\\n                                    </div>\\\\n                                </div>\\\\n                                <button @click.stop=\\\\\\\"deleteRepo(repo.name)\\\\\\\" \\\\n                                        class=\\\\\\\"text-red-500 hover:text-red-700 text-sm\\\\\\\">\\\\n                                    <i class=\\\\\\\"fas fa-trash\\\\\\\"></i>\\\\n                                </button>\\\\n                            </div>\\\\n                        </div>\\\\n                    </div>\\\\n\\\\n                    <!-- System Stats -->\\\\n                    <div class=\\\\\\\"p-4 border-t bg-gray-50\\\\\\\">\\\\n                        <div class=\\\\\\\"text-sm text-gray-600\\\\\\\">\\\\n                            <div>Repos: {{ stats.repositories || 0 }}</div>\\\\n                            <div>Documents: {{ stats.documents_in_vector_store || 0 }}</div>\\\\n                            <div>Model: {{ systemStatus.ollama_model || 'Unknown' }}</div>\\\\n                        </div>\\\\n                    </div>\\\\n                </div>\\\\n            </div>\\\\n\\\\n            <!-- Main Content -->\\\\n            <div class=\\\\\\\"flex-1 flex flex-col lg:ml-0\\\\\\\" :class=\\\\\\\"{'ml-0': !sidebarOpen, 'ml-64': sidebarOpen}\\\\\\\">\\\\n                <!-- Tab Navigation -->\\\\n                <div class=\\\\\\\"bg-white border-b\\\\\\\">\\\\n                    <nav class=\\\\\\\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\\\\\\\">\\\\n                        <div class=\\\\\\\"flex space-x-8\\\\\\\">\\\\n                            <button v-for=\\\\\\\"tab in tabs\\\\\\\" :key=\\\\\\\"tab.id\\\\\\\"\\\\n                                    @click=\\\\\\\"activeTab = tab.id\\\\\\\"\\\\n                                    :class=\\\\\\\"{'border-blue-500 text-blue-600': activeTab === tab.id, 'border-transparent text-gray-500': activeTab !== tab.id}\\\\\\\"\\\\n                                    class=\\\\\\\"py-4 px-1 border-b-2 font-medium text-sm hover:text-gray-700\\\\\\\">\\\\n                                <i :class=\\\\\\\"tab.icon\\\\\\\" class=\\\\\\\"mr-2\\\\\\\"></i>\\\\n                                {{ tab.name }}\\\\n                            </button>\\\\n                        </div>\\\\n                    </nav>\\\\n                </div>\\\\n\\\\n                <!-- Tab Content -->\\\\n                <div class=\\\\\\\"flex-1 overflow-hidden\\\\\\\">\\\\n                    <!-- Chat Tab -->\\\\n                    <div v-show=\\\\\\\"activeTab === 'chat'\\\\\\\" class=\\\\\\\"h-full flex flex-col\\\\\\\">\\\\n                        <div class=\\\\\\\"flex-1 overflow-y-auto p-6\\\\\\\">\\\\n                            <div v-if=\\\\\\\"chatMessages.length === 0\\\\\\\" class=\\\\\\\"text-center py-12\\\\\\\">\\\\n                                <i class=\\\\\\\"fas fa-comments text-6xl text-gray-300 mb-4\\\\\\\"></i>\\\\n                                <h3 class=\\\\\\\"text-xl font-medium text-gray-900 mb-2\\\\\\\">Start a conversation</h3>\\\\n                                <p class=\\\\\\\"text-gray-600\\\\\\\">Ask questions about your code repositories</p>\\\\n                            </div>\\\\n                            \\\\n                            <div v-for=\\\\\\\"(message, index) in chatMessages\\\\\\\" :key=\\\\\\\"index\\\\\\\" class=\\\\\\\"mb-6\\\\\\\">\\\\n                                <div :class=\\\\\\\"{'user-message': message.role === 'user', 'assistant-message': message.role === 'assistant'}\\\\\\\"\\\\n                                     class=\\\\\\\"chat-message p-4 rounded-lg text-white\\\\\\\">\\\\n                                    <div class=\\\\\\\"flex items-start space-x-3\\\\\\\">\\\\n                                        <div class=\\\\\\\"flex-shrink-0\\\\\\\">\\\\n                                            <i :class=\\\\\\\"message.role === 'user' ? 'fas fa-user' : 'fas fa-robot'\\\\\\\" \\\\n                                               class=\\\\\\\"text-lg\\\\\\\"></i>\\\\n                                        </div>\\\\n                                        <div class=\\\\\\\"flex-1\\\\\\\">\\\\n                                            <div v-html=\\\\\\\"formatMessage(message.content)\\\\\\\"></div>\\\\n                                        </div>\\\\n                                    </div>\\\\n                                </div>\\\\n                            </div>\\\\n                            \\\\n                            <div v-if=\\\\\\\"isLoading\\\\\\\" class=\\\\\\\"mb-6\\\\\\\">\\\\n                                <div class=\\\\\\\"assistant-message chat-message p-4 rounded-lg text-white\\\\\\\">\\\\n                                    <div class=\\\\\\\"flex items-start space-x-3\\\\\\\">\\\\n                                        <div class=\\\\\\\"flex-shrink-0\\\\\\\">\\\\n                                            <i class=\\\\\\\"fas fa-robot text-lg\\\\\\\"></i>\\\\n                                        </div>\\\\n                                        <div class=\\\\\\\"flex-1\\\\\\\">\\\\n                                            <span class=\\\\\\\"loading-dots\\\\\\\">Thinking</span>\\\\n                                        </div>\\\\n                                    </div>\\\\n                                </div>\\\\n                            </div>\\\\n                        </div>\\\\n                        \\\\n                        <!-- Chat Input -->\\\\n                        <div class=\\\\\\\"border-t bg-white p-4\\\\\\\">\\\\n                            <div class=\\\\\\\"max-w-4xl mx-auto\\\\\\\">\\\\n                                <div class=\\\\\\\"flex items-end space-x-4\\\\\\\">\\\\n                                    <div class=\\\\\\\"flex-1\\\\\\\">\\\\n                                        <textarea v-model=\\\\\\\"chatInput\\\\\\\" \\\\n                                                @keydown.enter.prevent=\\\\\\\"sendChatMessage\\\\\\\"\\\\n                                                :disabled=\\\\\\\"isLoading\\\\\\\"\\\\n                                                placeholder=\\\\\\\"Ask a question about your code...\\\\\\\"\\\\n                                                class=\\\\\\\"w-full px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-transparent resize-none\\\\\\\"\\\\n                                                rows=\\\\\\\"2\\\\\\\"></textarea>\\\\n                                    </div>\\\\n                                    <button @click=\\\\\\\"sendChatMessage\\\\\\\" \\\\n                                            :disabled=\\\\\\\"isLoading || !chatInput.trim()\\\\\\\"\\\\n                                            class=\\\\\\\"px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50 disabled:cursor-not-allowed\\\\\\\">\\\\n                                        <i class=\\\\\\\"fas fa-paper-plane\\\\\\\"></i>\\\\n                                    </button>\\\\n                                </div>\\\\n                                <div v-if=\\\\\\\"selectedRepo\\\\\\\" class=\\\\\\\"mt-2 text-sm text-gray-600\\\\\\\">\\\\n                                    Querying: {{ selectedRepo.name }}\\\\n                                </div>\\\\n                            </div>\\\\n                        </div>\\\\n                    </div>\\\\n\\\\n                    <!-- Search Tab -->\\\\n                    <div v-show=\\\\\\\"activeTab === 'search'\\\\\\\" class=\\\\\\\"h-full p-6\\\\\\\">\\\\n                        <div class=\\\\\\\"max-w-4xl mx-auto\\\\\\\">\\\\n                            <div class=\\\\\\\"mb-6\\\\\\\">\\\\n                                <div class=\\\\\\\"flex space-x-4\\\\\\\">\\\\n                                    <input v-model=\\\\\\\"searchQuery\\\\\\\" \\\\n                                           @keydown.enter=\\\\\\\"search\\\\\\\"\\\\n                                           type=\\\\\\\"text\\\\\\\" \\\\n                                           placeholder=\\\\\\\"Search across all repositories...\\\\\\\"\\\\n                                           class=\\\\\\\"flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500\\\\\\\">\\\\n                                    <button @click=\\\\\\\"search\\\\\\\" \\\\n                                            :disabled=\\\\\\\"!searchQuery.trim()\\\\\\\"\\\\n                                            class=\\\\\\\"px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50\\\\\\\">\\\\n                                        <i class=\\\\\\\"fas fa-search\\\\\\\"></i>\\\\n                                    </button>\\\\n                                </div>\\\\n                            </div>\\\\n                            \\\\n                            <div v-if=\\\\\\\"searchResults.length > 0\\\\\\\">\\\\n                                <h3 class=\\\\\\\"text-lg font-medium mb-4\\\\\\\">Search Results</h3>\\\\n                                <div v-for=\\\\\\\"result in searchResults\\\\\\\" :key=\\\\\\\"result.id\\\\\\\" \\\\n                                     class=\\\\\\\"mb-4 p-4 bg-white rounded-lg shadow\\\\\\\">\\\\n                                    <div class=\\\\\\\"flex justify-between items-start mb-2\\\\\\\">\\\\n                                        <div class=\\\\\\\"text-sm text-gray-600\\\\\\\">\\\\n                                            {{ result.metadata.file_path || 'Unknown file' }}\\\\n                                        </div>\\\\n                                        <div class=\\\\\\\"text-sm text-gray-500\\\\\\\">\\\\n                                            Score: {{ (1 - result.distance).toFixed(3) }}\\\\n                                        </div>\\\\n                                    </div>\\\\n                                    <div class=\\\\\\\"text-gray-900\\\\\\\">\\\\n                                        {{ result.text.substring(0, 300) }}...\\\\n                                    </div>\\\\n                                </div>\\\\n                            </div>\\\\n                            \\\\n                            <div v-else-if=\\\\\\\"searchQuery && !isSearching\\\\\\\" class=\\\\\\\"text-center py-12\\\\\\\">\\\\n                                <i class=\\\\\\\"fas fa-search text-6xl text-gray-300 mb-4\\\\\\\"></i>\\\\n                                <p class=\\\\\\\"text-gray-600\\\\\\\">No results found</p>\\\\n                            </div>\\\\n                        </div>\\\\n                    </div>\\\\n\\\\n                    <!-- Documentation Tab -->\\\\n                    <div v-show=\\\\\\\"activeTab === 'docs'\\\\\\\" class=\\\\\\\"h-full p-6\\\\\\\">\\\\n                        <div class=\\\\\\\"max-w-4xl mx-auto\\\\\\\">\\\\n                            <div class=\\\\\\\"mb-6\\\\\\\">\\\\n                                <h2 class=\\\\\\\"text-2xl font-bold mb-4\\\\\\\">Documentation</h2>\\\\n                                \\\\n                                <div v-if=\\\\\\\"selectedRepo\\\\\\\" class=\\\\\\\"mb-4\\\\\\\">\\\\n                                    <button @click=\\\\\\\"generateDocs\\\\\\\" \\\\n                                            :disabled=\\\\\\\"isGeneratingDocs\\\\\\\"\\\\n                                            class=\\\\\\\"px-4 py-2 bg-green-600 text-white rounded-lg hover:bg-green-700 disabled:opacity-50\\\\\\\">\\\\n                                        <i class=\\\\\\\"fas fa-file-alt mr-2\\\\\\\"></i>\\\\n                                        Generate Documentation\\\\n                                    </button>\\\\n                                </div>\\\\n                                \\\\n                                <div v-if=\\\\\\\"generatedDocs.length > 0\\\\\\\">\\\\n                                    <h3 class=\\\\\\\"text-lg font-medium mb-4\\\\\\\">Generated Documents</h3>\\\\n                                    <div class=\\\\\\\"grid gap-4\\\\\\\">\\\\n                                        <div v-for=\\\\\\\"doc in generatedDocs\\\\\\\" :key=\\\\\\\"doc.path\\\\\\\"\\\\n                                             @click=\\\\\\\"viewDocument(doc)\\\\\\\"\\\\n                                             class=\\\\\\\"p-4 bg-white rounded-lg shadow cursor-pointer hover:shadow-md transition-shadow\\\\\\\">\\\\n                                            <div class=\\\\\\\"flex items-center space-x-3\\\\\\\">\\\\n                                                <i class=\\\\\\\"fas fa-file-markdown text-blue-600\\\\\\\"></i>\\\\n                                                <div>\\\\n                                                    <div class=\\\\\\\"font-medium\\\\\\\">{{ doc.name }}</div>\\\\n                                                    <div class=\\\\\\\"text-sm text-gray-600\\\\\\\">{{ doc.path }}</div>\\\\n                                                </div>\\\\n                                            </div>\\\\n                                        </div>\\\\n                                    </div>\\\\n                                </div>\\\\n                            </div>\\\\n                        </div>\\\\n                    </div>\\\\n                </div>\\\\n            </div>\\\\n        </div>\\\\n\\\\n        <!-- Add Repository Modal -->\\\\n        <div v-if=\\\\\\\"showAddRepoModal\\\\\\\" class=\\\\\\\"fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50\\\\\\\">\\\\n            <div class=\\\\\\\"bg-white rounded-lg p-6 w-full max-w-md mx-4\\\\\\\">\\\\n                <h3 class=\\\\\\\"text-lg font-medium mb-4\\\\\\\">Add Repository</h3>\\\\n                <div class=\\\\\\\"mb-4\\\\\\\">\\\\n                    <label class=\\\\\\\"block text-sm font-medium text-gray-700 mb-2\\\\\\\">Repository Path</label>\\\\n                    <input v-model=\\\\\\\"newRepoPath\\\\\\\" \\\\n                           type=\\\\\\\"text\\\\\\\" \\\\n                           placeholder=\\\\\\\"/path/to/your/repository\\\\\\\"\\\\n                           class=\\\\\\\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500\\\\\\\">\\\\n                </div>\\\\n                <div class=\\\\\\\"mb-6\\\\\\\">\\\\n                    <label class=\\\\\\\"block text-sm font-medium text-gray-700 mb-2\\\\\\\">Repository Name (optional)</label>\\\\n                    <input v-model=\\\\\\\"newRepoName\\\\\\\" \\\\n                           type=\\\\\\\"text\\\\\\\" \\\\n                           placeholder=\\\\\\\"my-project\\\\\\\"\\\\n                           class=\\\\\\\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500\\\\\\\">\\\\n                </div>\\\\n                <div class=\\\\\\\"flex justify-end space-x-3\\\\\\\">\\\\n                    <button @click=\\\\\\\"showAddRepoModal = false\\\\\\\" \\\\n                            class=\\\\\\\"px-4 py-2 text-gray-700 border border-gray-300 rounded-md hover:bg-gray-50\\\\\\\">\\\\n                        Cancel\\\\n                    </button>\\\\n                    <button @click=\\\\\\\"addRepository\\\\\\\" \\\\n                            :disabled=\\\\\\\"!newRepoPath.trim()\\\\\\\"\\\\n                            class=\\\\\\\"px-4 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700 disabled:opacity-50\\\\\\\">\\\\n                        Add Repository\\\\n                    </button>\\\\n                </div>\\\\n            </div>\\\\n        </div>\\\\n\\\\n        <!-- Document Viewer Modal -->\\\\n        <div v-if=\\\\\\\"showDocModal\\\\\\\" class=\\\\\\\"fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50\\\\\\\">\\\\n            <div class=\\\\\\\"bg-white rounded-lg w-full max-w-4xl mx-4 h-5/6 flex flex-col\\\\\\\">\\\\n                <div class=\\\\\\\"flex items-center justify-between p-4 border-b\\\\\\\">\\\\n                    <h3 class=\\\\\\\"text-lg font-medium\\\\\\\">{{ currentDoc?.name }}</h3>\\\\n                    <button @click=\\\\\\\"showDocModal = false\\\\\\\" class=\\\\\\\"text-gray-500 hover:text-gray-700\\\\\\\">\\\\n                        <i class=\\\\\\\"fas fa-times\\\\\\\"></i>\\\\n                    </button>\\\\n                </div>\\\\n                <div class=\\\\\\\"flex-1 overflow-auto p-4\\\\\\\">\\\\n                    <div v-html=\\\\\\\"formatMarkdown(currentDocContent)\\\\\\\" class=\\\\\\\"prose max-w-none\\\\\\\"></div>\\\\n                </div>\\\\n            </div>\\\\n        </div>\\\\n    </div>\\\\n\\\\n    <script>\\\\n        const { createApp } = Vue;\\\\n\\\\n        createApp({\\\\n            data() {\\\\n                return {\\\\n                    sidebarOpen: true,\\\\n                    activeTab: 'chat',\\\\n                    systemStatus: {\\\\n                        ollama_available: false,\\\\n                        ollama_model: ''\\\\n                    },\\\\n                    stats: {},\\\\n                    repositories: [],\\\\n                    selectedRepo: null,\\\\n                    chatMessages: [],\\\\n                    chatInput: '',\\\\n                    isLoading: false,\\\\n                    searchQuery: '',\\\\n                    searchResults: [],\\\\n                    isSearching: false,\\\\n                    generatedDocs: [],\\\\n                    isGeneratingDocs: false,\\\\n                    showAddRepoModal: false,\\\\n                    newRepoPath: '',\\\\n                    newRepoName: '',\\\\n                    showDocModal: false,\\\\n                    currentDoc: null,\\\\n                    currentDocContent: '',\\\\n                    tabs: [\\\\n                        { id: 'chat', name: 'Chat', icon: 'fas fa-comments' },\\\\n                        { id: 'search', name: 'Search', icon: 'fas fa-search' },\\\\n                        { id: 'docs', name: 'Documentation', icon: 'fas fa-file-alt' }\\\\n                    ]\\\\n                };\\\\n            },\\\\n            async mounted() {\\\\n                await this.checkHealth();\\\\n                await this.loadRepositories();\\\\n                await this.loadStats();\\\\n            },\\\\n            methods: {\\\\n                toggleSidebar() {\\\\n                    this.sidebarOpen = !this.sidebarOpen;\\\\n                },\\\\n                async checkHealth() {\\\\n                    try {\\\\n                        const response = await axios.get('/health');\\\\n                        this.systemStatus = response.data;\\\\n                    } catch (error) {\\\\n                        console.error('Health check failed:', error);\\\\n                        this.systemStatus.ollama_available = false;\\\\n                    }\\\\n                },\\\\n                async loadRepositories() {\\\\n                    try {\\\\n                        const response = await axios.get('/repositories');\\\\n                        this.repositories = response.data.repositories;\\\\n                    } catch (error) {\\\\n                        console.error('Failed to load repositories:', error);\\\\n                    }\\\\n                },\\\\n                async loadStats() {\\\\n                    try {\\\\n                        const response = await axios.get('/stats');\\\\n                        this.stats = response.data;\\\\n                    } catch (error) {\\\\n                        console.error('Failed to load stats:', error);\\\\n                    }\\\\n                },\\\\n                selectRepository(repo) {\\\\n                    this.selectedRepo = repo;\\\\n                    this.loadGeneratedDocs();\\\\n                },\\\\n                async addRepository() {\\\\n                    if (!this.newRepoPath.trim()) return;\\\\n                    \\\\n                    try {\\\\n                        await axios.post('/repositories/analyze', {\\\\n                            repo_path: this.newRepoPath,\\\\n                            repo_name: this.newRepoName || undefined\\\\n                        });\\\\n                        \\\\n                        this.showAddRepoModal = false;\\\\n                        this.newRepoPath = '';\\\\n                        this.newRepoName = '';\\\\n                        \\\\n                        // Reload repositories after a short delay\\\\n                        setTimeout(() => {\\\\n                            this.loadRepositories();\\\\n                            this.loadStats();\\\\n                        }, 2000);\\\\n                        \\\\n                        alert('Repository analysis started. It may take a few moments to complete.');\\\\n                    } catch (error) {\\\\n                        console.error('Failed to add repository:', error);\\\\n                        alert('Failed to add repository: ' + (error.response?.data?.detail || error.message));\\\\n                    }\\\\n                },\\\\n                async deleteRepo(repoName) {\\\\n                    if (!confirm(`Are you sure you want to delete ${repoName}?`)) return;\\\\n                    \\\\n                    try {\\\\n                        await axios.delete(`/repositories/${repoName}`);\\\\n                        await this.loadRepositories();\\\\n                        await this.loadStats();\\\\n                        \\\\n                        if (this.selectedRepo?.name === repoName) {\\\\n                            this.selectedRepo = null;\\\\n                        }\\\\n                    } catch (error) {\\\\n                        console.error('Failed to delete repository:', error);\\\\n                        alert('Failed to delete repository');\\\\n                    }\\\\n                },\\\\n                async sendChatMessage() {\\\\n                    if (!this.chatInput.trim() || this.isLoading) return;\\\\n                    \\\\n                    const userMessage = {\\\\n                        role: 'user',\\\\n                        content: this.chatInput.trim()\\\\n                    };\\\\n                    \\\\n                    this.chatMessages.push(userMessage);\\\\n                    this.chatInput = '';\\\\n                    this.isLoading = true;\\\\n                    \\\\n                    try {\\\\n                        const response = await axios.post('/chat', {\\\\n                            messages: this.chatMessages,\\\\n                            repo_name: this.selectedRepo?.name\\\\n                        });\\\\n                        \\\\n                        this.chatMessages.push({\\\\n                            role: 'assistant',\\\\n                            content: response.data.response\\\\n                        });\\\\n                    } catch (error) {\\\\n                        console.error('Chat failed:', error);\\\\n                        this.chatMessages.push({\\\\n                            role: 'assistant',\\\\n                            content: 'Sorry, I encountered an error processing your request.'\\\\n                        });\\\\n                    } finally {\\\\n                        this.isLoading = false;\\\\n                        this.$nextTick(() => {\\\\n                            // Scroll to bottom\\\\n                            const chatContainer = document.querySelector('.overflow-y-auto');\\\\n                            if (chatContainer) {\\\\n                                chatContainer.scrollTop = chatContainer.scrollHeight;\\\\n                            }\\\\n                        });\\\\n                    }\\\\n                },\\\\n                async search() {\\\\n                    if (!this.searchQuery.trim()) return;\\\\n                    \\\\n                    this.isSearching = true;\\\\n                    this.searchResults = [];\\\\n                    \\\\n                    try {\\\\n                        const endpoint = this.selectedRepo \\\\n                            ? `/repositories/${this.selectedRepo.name}/search`\\\\n                            : '/search';\\\\n                        \\\\n                        const response = await axios.get(endpoint, {\\\\n                            params: { q: this.searchQuery, limit: 10 }\\\\n                        });\\\\n                        \\\\n                        this.searchResults = response.data.results;\\\\n                    } catch (error) {\\\\n                        console.error('Search failed:', error);\\\\n                    } finally {\\\\n                        this.isSearching = false;\\\\n                    }\\\\n                },\\\\n                async generateDocs() {\\\\n                    if (!this.selectedRepo) return;\\\\n                    \\\\n                    this.isGeneratingDocs = true;\\\\n                    \\\\n                    try {\\\\n                        await axios.post(`/repositories/${this.selectedRepo.name}/generate-docs`, {\\\\n                            repo_name: this.selectedRepo.name,\\\\n                            include_overview: true,\\\\n                            include_api_docs: true,\\\\n                            include_examples: true,\\\\n                            include_architecture: true\\\\n                        });\\\\n                        \\\\n                        alert('Documentation generation started. It may take a few moments to complete.');\\\\n                        \\\\n                        // Reload docs after a delay\\\\n                        setTimeout(() => {\\\\n                            this.loadGeneratedDocs();\\\\n                        }, 5000);\\\\n                    } catch (error) {\\\\n                        console.error('Failed to generate docs:', error);\\\\n                        alert('Failed to generate documentation');\\\\n                    } finally {\\\\n                        this.isGeneratingDocs = false;\\\\n                    }\\\\n                },\\\\n                async loadGeneratedDocs() {\\\\n                    if (!this.selectedRepo) return;\\\\n                    \\\\n                    try {\\\\n                        const response = await axios.get(`/repositories/${this.selectedRepo.name}/docs`);\\\\n                        this.generatedDocs = response.data.documents;\\\\n                    } catch (error) {\\\\n                        console.error('Failed to load generated docs:', error);\\\\n                        this.generatedDocs = [];\\\\n                    }\\\\n                },\\\\n                async viewDocument(doc) {\\\\n                    if (!this.selectedRepo) return;\\\\n                    \\\\n                    try {\\\\n                        const response = await axios.get(`/repositories/${this.selectedRepo.name}/docs/${doc.path}`);\\\\n                        this.currentDoc = doc;\\\\n                        this.currentDocContent = response.data.content;\\\\n                        this.showDocModal = true;\\\\n                    } catch (error) {\\\\n                        console.error('Failed to load document:', error);\\\\n                        alert('Failed to load document');\\\\n                    }\\\\n                },\\\\n                formatMessage(content) {\\\\n                    // Simple markdown-like formatting\\\\n                    return content\\\\n                        .replace(/```(\\\\\\\\w+)?\\\\\\\\n([\\\\\\\\s\\\\\\\\S]*?)```/g, '<pre class=\\\\\\\"code-block\\\\\\\"><code>$2</code></pre>')\\\\n                        .replace(/`([^`]+)`/g, '<code class=\\\\\\\"bg-gray-200 px-1 rounded\\\\\\\">$1</code>')\\\\n                        .replace(/\\\\\\\\*\\\\\\\\*(.*?)\\\\\\\\*\\\\\\\\*/g, '<strong>$1</strong>')\\\\n                        .replace(/\\\\\\\\*(.*?)\\\\\\\\*/g, '<em>$1</em>')\\\\n                        .replace(/\\\\\\\\n/g, '<br>');\\\\n                },\\\\n                formatMarkdown(content) {\\\\n                    // Basic markdown formatting for document viewer\\\\n                    return content\\\\n                        .replace(/# (.*)/g, '<h1 class=\\\\\\\"text-3xl font-bold mb-4\\\\\\\">$1</h1>')\\\\n                        .replace(/## (.*)/g, '<h2 class=\\\\\\\"text-2xl font-semibold mb-3\\\\\\\">$1</h2>')\\\\n                        .replace(/### (.*)/g, '<h3 class=\\\\\\\"text-xl font-medium mb-2\\\\\\\">$1</h3>')\\\\n                        .replace(/```(\\\\\\\\w+)?\\\\\\\\n([\\\\\\\\s\\\\\\\\S]*?)```/g, '<pre class=\\\\\\\"bg-gray-900 text-white p-4 rounded-lg overflow-x-auto mb-4\\\\\\\"><code>$2</code></pre>')\\\\n                        .replace(/`([^`]+)`/g, '<code class=\\\\\\\"bg-gray-200 px-1 rounded\\\\\\\">$1</code>')\\\\n                        .replace(/\\\\\\\\*\\\\\\\\*(.*?)\\\\\\\\*\\\\\\\\*/g, '<strong>$1</strong>')\\\\n                        .replace(/\\\\\\\\*(.*?)\\\\\\\\*/g, '<em>$1</em>')\\\\n                        .replace(/\\\\\\\\n\\\\\\\\n/g, '</p><p class=\\\\\\\"mb-4\\\\\\\">')\\\\n                        .replace(/\\\\\\\\n/g, '<br>')\\\\n                        .replace(/^/, '<p class=\\\\\\\"mb-4\\\\\\\">') + '</p>';\\\\n                }\\\\n            }\\\\n        }).mount('#app');\\\\n    </script>\\\\n</body>\\\\n</html>\\\\n\\\"\\n    }\\n  ],\\n  \\\"structure\\\": {\\n    \\\"name\\\": \\\"wikillm\\\",\\n    \\\"type\\\": \\\"directory\\\",\\n    \\\"children\\\": [\\n      {\\n        \\\"name\\\": \\\"api.py\\\",\\n        \\\"type\\\": \\\"file\\\",\\n        \\\"path\\\": \\\"api.py\\\"\\n      },\\n      {\\n        \\\"name\\\": \\\"config.py\\\",\\n        \\\"type\\\": \\\"file\\\",\\n        \\\"path\\\": \\\"config.py\\\"\\n      },\\n      {\\n        \\\"name\\\": \\\"data\\\",\\n        \\\"type\\\": \\\"directory\\\",\\n        \\\"children\\\": [\\n          {\\n            \\\"name\\\": \\\"chroma_db\\\",\\n            \\\"type\\\": \\\"directory\\\",\\n            \\\"children\\\": [\\n              {\\n                \\\"name\\\": \\\"f2e7f382-a1d1-45fd-b769-7e72a660468f\\\",\\n                \\\"type\\\": \\\"directory\\\",\\n                \\\"children\\\": []\\n              }\\n            ]\\n          },\\n          {\\n            \\\"name\\\": \\\"generated_docs\\\",\\n            \\\"type\\\": \\\"directory\\\",\\n            \\\"children\\\": []\\n          },\\n          {\\n            \\\"name\\\": \\\"repos\\\",\\n            \\\"type\\\": \\\"directory\\\",\\n            \\\"children\\\": [\\n              {\\n                \\\"name\\\": \\\"wikillm_analysis.json\\\",\\n                \\\"type\\\": \\\"file\\\",\\n                \\\"path\\\": \\\"data\\\\\\\\repos\\\\\\\\wikillm_analysis.json\\\"\\n              }\\n            ]\\n          }\\n        ]\\n      },\\n      {\\n        \\\"name\\\": \\\"DEVELOPMENT.md\\\",\\n        \\\"type\\\": \\\"file\\\",\\n        \\\"path\\\": \\\"DEVELOPMENT.md\\\"\\n      },\\n      {\\n        \\\"name\\\": \\\"docs\\\",\\n        \\\"type\\\": \\\"directory\\\",\\n        \\\"children\\\": [\\n          {\\n            \\\"name\\\": \\\"project-overview.md\\\",\\n            \\\"type\\\": \\\"file\\\",\\n            \\\"path\\\": \\\"docs\\\\\\\\project-overview.md\\\"\\n          }\\n        ]\\n      },\\n      {\\n        \\\"name\\\": \\\"documentation_generator.py\\\",\\n        \\\"type\\\": \\\"file\\\",\\n        \\\"path\\\": \\\"documentation_generator.py\\\"\\n      },\\n      {\\n        \\\"name\\\": \\\"main.py\\\",\\n        \\\"type\\\": \\\"file\\\",\\n        \\\"path\\\": \\\"main.py\\\"\\n      },\\n      {\\n        \\\"name\\\": \\\"ollama_client.py\\\",\\n        \\\"type\\\": \\\"file\\\",\\n        \\\"path\\\": \\\"ollama_client.py\\\"\\n      },\\n      {\\n        \\\"name\\\": \\\"rag_system.py\\\",\\n        \\\"type\\\": \\\"file\\\",\\n        \\\"path\\\": \\\"rag_system.py\\\"\\n      },\\n      {\\n        \\\"name\\\": \\\"README.md\\\",\\n        \\\"type\\\": \\\"file\\\",\\n        \\\"path\\\": \\\"README.md\\\"\\n      },\\n      {\\n        \\\"name\\\": \\\"repository_analyzer.py\\\",\\n        \\\"type\\\": \\\"file\\\",\\n        \\\"path\\\": \\\"repository_analyzer.py\\\"\\n      },\\n      {\\n        \\\"name\\\": \\\"requirements.txt\\\",\\n        \\\"type\\\": \\\"file\\\",\\n        \\\"path\\\": \\\"requirements.txt\\\"\\n      },\\n      {\\n        \\\"name\\\": \\\"vector_store.py\\\",\\n        \\\"type\\\": \\\"file\\\",\\n        \\\"path\\\": \\\"vector_store.py\\\"\\n      },\\n      {\\n        \\\"name\\\": \\\"web\\\",\\n        \\\"type\\\": \\\"directory\\\",\\n        \\\"children\\\": [\\n          {\\n            \\\"name\\\": \\\"index.html\\\",\\n            \\\"type\\\": \\\"file\\\",\\n            \\\"path\\\": \\\"web\\\\\\\\index.html\\\"\\n          }\\n        ]\\n      }\\n    ]\\n  },\\n  \\\"statistics\\\": {\\n    \\\"total_files\\\": 14,\\n    \\\"code_files\\\": 10,\\n    \\\"doc_files\\\": 4,\\n    \\\"languages\\\": {\\n      \\\"python\\\": 8\\n    },\\n    \\\"total_lines\\\": 5876\\n  },\\n  \\\"git_info\\\": {\\n    \\\"remote_url\\\": \\\"https://github.com/sharmaharsh/wikillm.git\\\",\\n    \\\"current_branch\\\": \\\"main\\\",\\n    \\\"last_commit\\\": {\\n      \\\"hash\\\": \\\"f0138481\\\",\\n      \\\"message\\\": \\\"init\\\",\\n      \\\"author\\\": \\\"sharmaharsh\\\",\\n      \\\"date\\\": \\\"2025-08-08T21:50:42-05:00\\\"\\n    }\\n  }\\n}\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\docs\\\\api-reference.md\",\n      \"file_type\": \"documentation\",\n      \"language\": null,\n      \"imports\": [],\n      \"elements\": [],\n      \"summary\": null,\n      \"content\": \"# API Reference\\n\\n## Base URL\\n```\\nhttp://localhost:8000\\n```\\n\\n## Health & System Endpoints\\n\\n### GET /health\\nCheck system health and configuration.\\n\\n**Response:**\\n```json\\n{\\n  \\\"status\\\": \\\"healthy\\\",\\n  \\\"ollama_available\\\": true,\\n  \\\"ollama_url\\\": \\\"http://localhost:11434\\\",\\n  \\\"ollama_model\\\": \\\"deepseek-coder:6.7b\\\",\\n  \\\"vector_store\\\": {\\n    \\\"total_documents\\\": 169,\\n    \\\"collection_name\\\": \\\"codebase_docs\\\"\\n  }\\n}\\n```\\n\\n### GET /stats\\nGet system statistics.\\n\\n**Response:**\\n```json\\n{\\n  \\\"repositories\\\": 1,\\n  \\\"documents_in_vector_store\\\": 169,\\n  \\\"generated_docs\\\": 0,\\n  \\\"ollama_available\\\": true,\\n  \\\"ollama_model\\\": \\\"deepseek-coder:6.7b\\\"\\n}\\n```\\n\\n## Repository Management\\n\\n### POST /repositories/analyze\\nAnalyze a repository and add it to the vector store.\\n\\n**Request:**\\n```json\\n{\\n  \\\"repo_path\\\": \\\"/path/to/repository\\\",\\n  \\\"repo_name\\\": \\\"optional-name\\\"\\n}\\n```\\n\\n### GET /repositories\\nList all analyzed repositories.\\n\\n**Response:**\\n```json\\n{\\n  \\\"repositories\\\": [\\n    {\\n      \\\"name\\\": \\\"wikillm\\\",\\n      \\\"path\\\": \\\"C:\\\\\\\\Users\\\\\\\\chuba\\\\\\\\wikillm\\\",\\n      \\\"files\\\": 14,\\n      \\\"languages\\\": [\\\"python\\\"]\\n    }\\n  ]\\n}\\n```\\n\\n## Query & Chat Endpoints\\n\\n### POST /query\\nQuery repositories using the RAG system.\\n\\n**Request:**\\n```json\\n{\\n  \\\"query\\\": \\\"How does authentication work?\\\",\\n  \\\"repo_name\\\": \\\"optional-filter\\\",\\n  \\\"stream\\\": false\\n}\\n```\\n\\n**Response:**\\n```json\\n{\\n  \\\"response\\\": \\\"Generated response text...\\\",\\n  \\\"context\\\": {...},\\n  \\\"sources\\\": [...]\\n}\\n```\\n\\n### POST /chat\\nInteractive chat with repository context.\\n\\n**Request:**\\n```json\\n{\\n  \\\"messages\\\": [\\n    {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"What is this project about?\\\"}\\n  ],\\n  \\\"repo_name\\\": \\\"wikillm\\\"\\n}\\n```\\n\\n## Code Analysis Endpoints\\n\\n### POST /explain\\nExplain code snippets.\\n\\n**Request:**\\n```json\\n{\\n  \\\"code\\\": \\\"def hello_world():\\\\n    print('Hello, World!')\\\",\\n  \\\"language\\\": \\\"python\\\",\\n  \\\"context\\\": \\\"Optional context\\\"\\n}\\n```\\n\\n### POST /improve\\nGet code improvement suggestions.\\n\\n**Request:**\\n```json\\n{\\n  \\\"code\\\": \\\"def hello_world():\\\\n    print('Hello, World!')\\\",\\n  \\\"language\\\": \\\"python\\\"\\n}\\n```\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\docs\\\\architecture.md\",\n      \"file_type\": \"documentation\",\n      \"language\": null,\n      \"imports\": [],\n      \"elements\": [],\n      \"summary\": null,\n      \"content\": \"# System Architecture\\n\\n## Overview\\nLocal DeepWiki follows a modular architecture with clear separation of concerns:\\n\\n```\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\nâ”‚   CLI/API       â”‚    â”‚   RAG System    â”‚    â”‚  Vector Store   â”‚\\nâ”‚   Interface     â”‚â—„â”€â”€â–ºâ”‚   (Core Logic)  â”‚â—„â”€â”€â–ºâ”‚   (ChromaDB)    â”‚\\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n         â–²                       â–²                       â–²\\n         â”‚                       â”‚                       â”‚\\n         â–¼                       â–¼                       â–¼\\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\\nâ”‚ Repository      â”‚    â”‚ Ollama Client   â”‚    â”‚ Documentation   â”‚\\nâ”‚ Analyzer        â”‚    â”‚ (LLM Interface) â”‚    â”‚ Generator       â”‚\\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\\n```\\n\\n## Core Components\\n\\n### Repository Analyzer\\n- **Purpose**: Parse and understand code structure\\n- **Input**: File paths and directory structures  \\n- **Output**: Structured analysis with metadata\\n- **Key Features**:\\n  - Multi-language support\\n  - Intelligent file filtering\\n  - Metadata extraction (functions, classes, imports)\\n  - Tree structure generation\\n\\n### Vector Store (ChromaDB)\\n- **Purpose**: Semantic search and retrieval\\n- **Storage**: Document embeddings and metadata\\n- **Features**:\\n  - Persistent storage\\n  - Similarity search\\n  - Metadata filtering\\n  - Batch operations\\n\\n### RAG System\\n- **Purpose**: Context retrieval and response generation\\n- **Components**:\\n  - Query understanding\\n  - Context retrieval\\n  - Response synthesis\\n  - Conversation management\\n\\n### Ollama Integration\\n- **Models Supported**:\\n  - Code generation: `deepseek-coder`, `codellama`\\n  - General purpose: `llama2`, `mistral`\\n  - Embeddings: `nomic-embed-text`\\n- **Features**:\\n  - Local inference\\n  - Streaming responses\\n  - Model management\\n\\n## Data Flow\\n\\n1. **Analysis Phase**:\\n   ```\\n   Source Code â†’ Repository Analyzer â†’ Structured Data â†’ Vector Store\\n   ```\\n\\n2. **Query Phase**:\\n   ```\\n   User Query â†’ Vector Search â†’ Context Retrieval â†’ LLM â†’ Response\\n   ```\\n\\n3. **Training Data Flow**:\\n   ```\\n   Markdown Files â†’ Text Chunks â†’ Embeddings â†’ Vector Store\\n   ```\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\docs\\\\project-overview.md\",\n      \"file_type\": \"documentation\",\n      \"language\": null,\n      \"imports\": [],\n      \"elements\": [],\n      \"summary\": null,\n      \"content\": \"# Project Overview\\n\\nThis is Local DeepWiki - a system for analyzing code repositories using local LLMs.\\n\\n## Key Features\\n- Repository analysis and indexing\\n- RAG-based question answering\\n- Local LLM integration via Ollama\\n- REST API for programmatic access\\n\\n## Architecture\\n- **Repository Analyzer**: Parses code structure and extracts metadata\\n- **Vector Store**: Uses ChromaDB for semantic search\\n- **RAG System**: Retrieves context and generates responses\\n- **API Server**: FastAPI-based REST endpoints\"\n    },\n    {\n      \"file_path\": \"C:\\\\Users\\\\chuba\\\\wikillm\\\\web\\\\index.html\",\n      \"file_type\": \"code\",\n      \"language\": null,\n      \"imports\": [],\n      \"elements\": [],\n      \"summary\": null,\n      \"content\": \"<!DOCTYPE html>\\n<html lang=\\\"en\\\">\\n<head>\\n    <meta charset=\\\"UTF-8\\\">\\n    <meta name=\\\"viewport\\\" content=\\\"width=device-width, initial-scale=1.0\\\">\\n    <title>Local DeepWiki</title>\\n    <script src=\\\"https://unpkg.com/vue@3/dist/vue.global.js\\\"></script>\\n    <script src=\\\"https://unpkg.com/axios/dist/axios.min.js\\\"></script>\\n    <link href=\\\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\\\" rel=\\\"stylesheet\\\">\\n    <link href=\\\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css\\\" rel=\\\"stylesheet\\\">\\n    <style>\\n        .chat-message {\\n            max-width: 80%;\\n        }\\n        .user-message {\\n            margin-left: auto;\\n            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\\n        }\\n        .assistant-message {\\n            margin-right: auto;\\n            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\\n        }\\n        .code-block {\\n            background-color: #1e1e1e;\\n            border-radius: 8px;\\n            padding: 1rem;\\n            overflow-x: auto;\\n        }\\n        .sidebar {\\n            transition: transform 0.3s ease-in-out;\\n        }\\n        .sidebar-closed {\\n            transform: translateX(-100%);\\n        }\\n        .loading-dots {\\n            display: inline-block;\\n        }\\n        .loading-dots:after {\\n            content: '';\\n            animation: dots 1.5s infinite;\\n        }\\n        @keyframes dots {\\n            0%, 20% { content: '.'; }\\n            40% { content: '..'; }\\n            60%, 100% { content: '...'; }\\n        }\\n    </style>\\n</head>\\n<body class=\\\"bg-gray-100 font-sans\\\">\\n    <div id=\\\"app\\\">\\n        <!-- Header -->\\n        <header class=\\\"bg-white shadow-lg\\\">\\n            <div class=\\\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\\\">\\n                <div class=\\\"flex justify-between items-center py-4\\\">\\n                    <div class=\\\"flex items-center\\\">\\n                        <button @click=\\\"toggleSidebar\\\" class=\\\"mr-4 text-gray-600 hover:text-gray-900\\\">\\n                            <i class=\\\"fas fa-bars text-xl\\\"></i>\\n                        </button>\\n                        <h1 class=\\\"text-2xl font-bold text-gray-900\\\">\\n                            <i class=\\\"fas fa-book text-blue-600 mr-2\\\"></i>\\n                            Local DeepWiki\\n                        </h1>\\n                    </div>\\n                    <div class=\\\"flex items-center space-x-4\\\">\\n                        <div class=\\\"flex items-center space-x-2\\\">\\n                            <div :class=\\\"{'bg-green-500': systemStatus.ollama_available, 'bg-red-500': !systemStatus.ollama_available}\\\" \\n                                 class=\\\"w-3 h-3 rounded-full\\\"></div>\\n                            <span class=\\\"text-sm text-gray-600\\\">\\n                                {{ systemStatus.ollama_available ? 'Ollama Connected' : 'Ollama Disconnected' }}\\n                            </span>\\n                        </div>\\n                        <button @click=\\\"checkHealth\\\" class=\\\"text-blue-600 hover:text-blue-800\\\">\\n                            <i class=\\\"fas fa-sync-alt\\\"></i>\\n                        </button>\\n                    </div>\\n                </div>\\n            </div>\\n        </header>\\n\\n        <div class=\\\"flex h-screen\\\">\\n            <!-- Sidebar -->\\n            <div :class=\\\"{'sidebar-closed': !sidebarOpen}\\\" class=\\\"sidebar fixed inset-y-0 left-0 z-50 w-64 bg-white shadow-lg transform lg:translate-x-0 lg:static lg:inset-0\\\">\\n                <div class=\\\"flex flex-col h-full\\\">\\n                    <!-- Sidebar Header -->\\n                    <div class=\\\"flex items-center justify-between p-4 border-b\\\">\\n                        <h2 class=\\\"text-lg font-semibold text-gray-900\\\">Repositories</h2>\\n                        <button @click=\\\"showAddRepoModal = true\\\" class=\\\"text-blue-600 hover:text-blue-800\\\">\\n                            <i class=\\\"fas fa-plus\\\"></i>\\n                        </button>\\n                    </div>\\n\\n                    <!-- Repository List -->\\n                    <div class=\\\"flex-1 overflow-y-auto p-4\\\">\\n                        <div v-if=\\\"repositories.length === 0\\\" class=\\\"text-gray-500 text-center py-8\\\">\\n                            <i class=\\\"fas fa-folder-open text-4xl mb-2\\\"></i>\\n                            <p>No repositories added yet</p>\\n                        </div>\\n                        <div v-for=\\\"repo in repositories\\\" :key=\\\"repo.name\\\" \\n                             @click=\\\"selectRepository(repo)\\\"\\n                             :class=\\\"{'bg-blue-50 border-blue-200': selectedRepo?.name === repo.name}\\\"\\n                             class=\\\"p-3 mb-2 border rounded-lg cursor-pointer hover:bg-gray-50 transition-colors\\\">\\n                            <div class=\\\"flex items-center justify-between\\\">\\n                                <div>\\n                                    <h3 class=\\\"font-medium text-gray-900\\\">{{ repo.name }}</h3>\\n                                    <p class=\\\"text-sm text-gray-600\\\">{{ repo.files }} files</p>\\n                                    <div class=\\\"flex flex-wrap gap-1 mt-1\\\">\\n                                        <span v-for=\\\"lang in repo.languages\\\" :key=\\\"lang\\\" \\n                                              class=\\\"px-2 py-1 bg-gray-200 text-gray-700 text-xs rounded\\\">\\n                                            {{ lang }}\\n                                        </span>\\n                                    </div>\\n                                </div>\\n                                <button @click.stop=\\\"deleteRepo(repo.name)\\\" \\n                                        class=\\\"text-red-500 hover:text-red-700 text-sm\\\">\\n                                    <i class=\\\"fas fa-trash\\\"></i>\\n                                </button>\\n                            </div>\\n                        </div>\\n                    </div>\\n\\n                    <!-- System Stats -->\\n                    <div class=\\\"p-4 border-t bg-gray-50\\\">\\n                        <div class=\\\"text-sm text-gray-600\\\">\\n                            <div>Repos: {{ stats.repositories || 0 }}</div>\\n                            <div>Documents: {{ stats.documents_in_vector_store || 0 }}</div>\\n                            <div>Model: {{ systemStatus.ollama_model || 'Unknown' }}</div>\\n                        </div>\\n                    </div>\\n                </div>\\n            </div>\\n\\n            <!-- Main Content -->\\n            <div class=\\\"flex-1 flex flex-col lg:ml-0\\\" :class=\\\"{'ml-0': !sidebarOpen, 'ml-64': sidebarOpen}\\\">\\n                <!-- Tab Navigation -->\\n                <div class=\\\"bg-white border-b\\\">\\n                    <nav class=\\\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\\\">\\n                        <div class=\\\"flex space-x-8\\\">\\n                            <button v-for=\\\"tab in tabs\\\" :key=\\\"tab.id\\\"\\n                                    @click=\\\"activeTab = tab.id\\\"\\n                                    :class=\\\"{'border-blue-500 text-blue-600': activeTab === tab.id, 'border-transparent text-gray-500': activeTab !== tab.id}\\\"\\n                                    class=\\\"py-4 px-1 border-b-2 font-medium text-sm hover:text-gray-700\\\">\\n                                <i :class=\\\"tab.icon\\\" class=\\\"mr-2\\\"></i>\\n                                {{ tab.name }}\\n                            </button>\\n                        </div>\\n                    </nav>\\n                </div>\\n\\n                <!-- Tab Content -->\\n                <div class=\\\"flex-1 overflow-hidden\\\">\\n                    <!-- Chat Tab -->\\n                    <div v-show=\\\"activeTab === 'chat'\\\" class=\\\"h-full flex flex-col\\\">\\n                        <div class=\\\"flex-1 overflow-y-auto p-6\\\">\\n                            <div v-if=\\\"chatMessages.length === 0\\\" class=\\\"text-center py-12\\\">\\n                                <i class=\\\"fas fa-comments text-6xl text-gray-300 mb-4\\\"></i>\\n                                <h3 class=\\\"text-xl font-medium text-gray-900 mb-2\\\">Start a conversation</h3>\\n                                <p class=\\\"text-gray-600\\\">Ask questions about your code repositories</p>\\n                            </div>\\n                            \\n                            <div v-for=\\\"(message, index) in chatMessages\\\" :key=\\\"index\\\" class=\\\"mb-6\\\">\\n                                <div :class=\\\"{'user-message': message.role === 'user', 'assistant-message': message.role === 'assistant'}\\\"\\n                                     class=\\\"chat-message p-4 rounded-lg text-white\\\">\\n                                    <div class=\\\"flex items-start space-x-3\\\">\\n                                        <div class=\\\"flex-shrink-0\\\">\\n                                            <i :class=\\\"message.role === 'user' ? 'fas fa-user' : 'fas fa-robot'\\\" \\n                                               class=\\\"text-lg\\\"></i>\\n                                        </div>\\n                                        <div class=\\\"flex-1\\\">\\n                                            <div v-html=\\\"formatMessage(message.content)\\\"></div>\\n                                        </div>\\n                                    </div>\\n                                </div>\\n                            </div>\\n                            \\n                            <div v-if=\\\"isLoading\\\" class=\\\"mb-6\\\">\\n                                <div class=\\\"assistant-message chat-message p-4 rounded-lg text-white\\\">\\n                                    <div class=\\\"flex items-start space-x-3\\\">\\n                                        <div class=\\\"flex-shrink-0\\\">\\n                                            <i class=\\\"fas fa-robot text-lg\\\"></i>\\n                                        </div>\\n                                        <div class=\\\"flex-1\\\">\\n                                            <span class=\\\"loading-dots\\\">Thinking</span>\\n                                        </div>\\n                                    </div>\\n                                </div>\\n                            </div>\\n                        </div>\\n                        \\n                        <!-- Chat Input -->\\n                        <div class=\\\"border-t bg-white p-4\\\">\\n                            <div class=\\\"max-w-4xl mx-auto\\\">\\n                                <div class=\\\"flex items-end space-x-4\\\">\\n                                    <div class=\\\"flex-1\\\">\\n                                        <textarea v-model=\\\"chatInput\\\" \\n                                                @keydown.enter.prevent=\\\"sendChatMessage\\\"\\n                                                :disabled=\\\"isLoading\\\"\\n                                                placeholder=\\\"Ask a question about your code...\\\"\\n                                                class=\\\"w-full px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-transparent resize-none\\\"\\n                                                rows=\\\"2\\\"></textarea>\\n                                    </div>\\n                                    <button @click=\\\"sendChatMessage\\\" \\n                                            :disabled=\\\"isLoading || !chatInput.trim()\\\"\\n                                            class=\\\"px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50 disabled:cursor-not-allowed\\\">\\n                                        <i class=\\\"fas fa-paper-plane\\\"></i>\\n                                    </button>\\n                                </div>\\n                                <div v-if=\\\"selectedRepo\\\" class=\\\"mt-2 text-sm text-gray-600\\\">\\n                                    Querying: {{ selectedRepo.name }}\\n                                </div>\\n                            </div>\\n                        </div>\\n                    </div>\\n\\n                    <!-- Search Tab -->\\n                    <div v-show=\\\"activeTab === 'search'\\\" class=\\\"h-full p-6\\\">\\n                        <div class=\\\"max-w-4xl mx-auto\\\">\\n                            <div class=\\\"mb-6\\\">\\n                                <div class=\\\"flex space-x-4\\\">\\n                                    <input v-model=\\\"searchQuery\\\" \\n                                           @keydown.enter=\\\"search\\\"\\n                                           type=\\\"text\\\" \\n                                           placeholder=\\\"Search across all repositories...\\\"\\n                                           class=\\\"flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500\\\">\\n                                    <button @click=\\\"search\\\" \\n                                            :disabled=\\\"!searchQuery.trim()\\\"\\n                                            class=\\\"px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50\\\">\\n                                        <i class=\\\"fas fa-search\\\"></i>\\n                                    </button>\\n                                </div>\\n                            </div>\\n                            \\n                            <div v-if=\\\"searchResults.length > 0\\\">\\n                                <h3 class=\\\"text-lg font-medium mb-4\\\">Search Results</h3>\\n                                <div v-for=\\\"result in searchResults\\\" :key=\\\"result.id\\\" \\n                                     class=\\\"mb-4 p-4 bg-white rounded-lg shadow\\\">\\n                                    <div class=\\\"flex justify-between items-start mb-2\\\">\\n                                        <div class=\\\"text-sm text-gray-600\\\">\\n                                            {{ result.metadata.file_path || 'Unknown file' }}\\n                                        </div>\\n                                        <div class=\\\"text-sm text-gray-500\\\">\\n                                            Score: {{ (1 - result.distance).toFixed(3) }}\\n                                        </div>\\n                                    </div>\\n                                    <div class=\\\"text-gray-900\\\">\\n                                        {{ result.text.substring(0, 300) }}...\\n                                    </div>\\n                                </div>\\n                            </div>\\n                            \\n                            <div v-else-if=\\\"searchQuery && !isSearching\\\" class=\\\"text-center py-12\\\">\\n                                <i class=\\\"fas fa-search text-6xl text-gray-300 mb-4\\\"></i>\\n                                <p class=\\\"text-gray-600\\\">No results found</p>\\n                            </div>\\n                        </div>\\n                    </div>\\n\\n                    <!-- Documentation Tab -->\\n                    <div v-show=\\\"activeTab === 'docs'\\\" class=\\\"h-full p-6\\\">\\n                        <div class=\\\"max-w-4xl mx-auto\\\">\\n                            <div class=\\\"mb-6\\\">\\n                                <h2 class=\\\"text-2xl font-bold mb-4\\\">Documentation</h2>\\n                                \\n                                <div v-if=\\\"selectedRepo\\\" class=\\\"mb-4\\\">\\n                                    <button @click=\\\"generateDocs\\\" \\n                                            :disabled=\\\"isGeneratingDocs\\\"\\n                                            class=\\\"px-4 py-2 bg-green-600 text-white rounded-lg hover:bg-green-700 disabled:opacity-50\\\">\\n                                        <i class=\\\"fas fa-file-alt mr-2\\\"></i>\\n                                        Generate Documentation\\n                                    </button>\\n                                </div>\\n                                \\n                                <div v-if=\\\"generatedDocs.length > 0\\\">\\n                                    <h3 class=\\\"text-lg font-medium mb-4\\\">Generated Documents</h3>\\n                                    <div class=\\\"grid gap-4\\\">\\n                                        <div v-for=\\\"doc in generatedDocs\\\" :key=\\\"doc.path\\\"\\n                                             @click=\\\"viewDocument(doc)\\\"\\n                                             class=\\\"p-4 bg-white rounded-lg shadow cursor-pointer hover:shadow-md transition-shadow\\\">\\n                                            <div class=\\\"flex items-center space-x-3\\\">\\n                                                <i class=\\\"fas fa-file-markdown text-blue-600\\\"></i>\\n                                                <div>\\n                                                    <div class=\\\"font-medium\\\">{{ doc.name }}</div>\\n                                                    <div class=\\\"text-sm text-gray-600\\\">{{ doc.path }}</div>\\n                                                </div>\\n                                            </div>\\n                                        </div>\\n                                    </div>\\n                                </div>\\n                            </div>\\n                        </div>\\n                    </div>\\n                </div>\\n            </div>\\n        </div>\\n\\n        <!-- Add Repository Modal -->\\n        <div v-if=\\\"showAddRepoModal\\\" class=\\\"fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50\\\">\\n            <div class=\\\"bg-white rounded-lg p-6 w-full max-w-md mx-4\\\">\\n                <h3 class=\\\"text-lg font-medium mb-4\\\">Add Repository</h3>\\n                <div class=\\\"mb-4\\\">\\n                    <label class=\\\"block text-sm font-medium text-gray-700 mb-2\\\">Repository Path</label>\\n                    <input v-model=\\\"newRepoPath\\\" \\n                           type=\\\"text\\\" \\n                           placeholder=\\\"/path/to/your/repository\\\"\\n                           class=\\\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500\\\">\\n                </div>\\n                <div class=\\\"mb-6\\\">\\n                    <label class=\\\"block text-sm font-medium text-gray-700 mb-2\\\">Repository Name (optional)</label>\\n                    <input v-model=\\\"newRepoName\\\" \\n                           type=\\\"text\\\" \\n                           placeholder=\\\"my-project\\\"\\n                           class=\\\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500\\\">\\n                </div>\\n                <div class=\\\"flex justify-end space-x-3\\\">\\n                    <button @click=\\\"showAddRepoModal = false\\\" \\n                            class=\\\"px-4 py-2 text-gray-700 border border-gray-300 rounded-md hover:bg-gray-50\\\">\\n                        Cancel\\n                    </button>\\n                    <button @click=\\\"addRepository\\\" \\n                            :disabled=\\\"!newRepoPath.trim()\\\"\\n                            class=\\\"px-4 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700 disabled:opacity-50\\\">\\n                        Add Repository\\n                    </button>\\n                </div>\\n            </div>\\n        </div>\\n\\n        <!-- Document Viewer Modal -->\\n        <div v-if=\\\"showDocModal\\\" class=\\\"fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50\\\">\\n            <div class=\\\"bg-white rounded-lg w-full max-w-4xl mx-4 h-5/6 flex flex-col\\\">\\n                <div class=\\\"flex items-center justify-between p-4 border-b\\\">\\n                    <h3 class=\\\"text-lg font-medium\\\">{{ currentDoc?.name }}</h3>\\n                    <button @click=\\\"showDocModal = false\\\" class=\\\"text-gray-500 hover:text-gray-700\\\">\\n                        <i class=\\\"fas fa-times\\\"></i>\\n                    </button>\\n                </div>\\n                <div class=\\\"flex-1 overflow-auto p-4\\\">\\n                    <div v-html=\\\"formatMarkdown(currentDocContent)\\\" class=\\\"prose max-w-none\\\"></div>\\n                </div>\\n            </div>\\n        </div>\\n    </div>\\n\\n    <script>\\n        const { createApp } = Vue;\\n\\n        createApp({\\n            data() {\\n                return {\\n                    sidebarOpen: true,\\n                    activeTab: 'chat',\\n                    systemStatus: {\\n                        ollama_available: false,\\n                        ollama_model: ''\\n                    },\\n                    stats: {},\\n                    repositories: [],\\n                    selectedRepo: null,\\n                    chatMessages: [],\\n                    chatInput: '',\\n                    isLoading: false,\\n                    searchQuery: '',\\n                    searchResults: [],\\n                    isSearching: false,\\n                    generatedDocs: [],\\n                    isGeneratingDocs: false,\\n                    showAddRepoModal: false,\\n                    newRepoPath: '',\\n                    newRepoName: '',\\n                    showDocModal: false,\\n                    currentDoc: null,\\n                    currentDocContent: '',\\n                    tabs: [\\n                        { id: 'chat', name: 'Chat', icon: 'fas fa-comments' },\\n                        { id: 'search', name: 'Search', icon: 'fas fa-search' },\\n                        { id: 'docs', name: 'Documentation', icon: 'fas fa-file-alt' }\\n                    ]\\n                };\\n            },\\n            async mounted() {\\n                await this.checkHealth();\\n                await this.loadRepositories();\\n                await this.loadStats();\\n            },\\n            methods: {\\n                toggleSidebar() {\\n                    this.sidebarOpen = !this.sidebarOpen;\\n                },\\n                async checkHealth() {\\n                    try {\\n                        const response = await axios.get('/health');\\n                        this.systemStatus = response.data;\\n                    } catch (error) {\\n                        console.error('Health check failed:', error);\\n                        this.systemStatus.ollama_available = false;\\n                    }\\n                },\\n                async loadRepositories() {\\n                    try {\\n                        const response = await axios.get('/repositories');\\n                        this.repositories = response.data.repositories;\\n                    } catch (error) {\\n                        console.error('Failed to load repositories:', error);\\n                    }\\n                },\\n                async loadStats() {\\n                    try {\\n                        const response = await axios.get('/stats');\\n                        this.stats = response.data;\\n                    } catch (error) {\\n                        console.error('Failed to load stats:', error);\\n                    }\\n                },\\n                selectRepository(repo) {\\n                    this.selectedRepo = repo;\\n                    this.loadGeneratedDocs();\\n                },\\n                async addRepository() {\\n                    if (!this.newRepoPath.trim()) return;\\n                    \\n                    try {\\n                        await axios.post('/repositories/analyze', {\\n                            repo_path: this.newRepoPath,\\n                            repo_name: this.newRepoName || undefined\\n                        });\\n                        \\n                        this.showAddRepoModal = false;\\n                        this.newRepoPath = '';\\n                        this.newRepoName = '';\\n                        \\n                        // Reload repositories after a short delay\\n                        setTimeout(() => {\\n                            this.loadRepositories();\\n                            this.loadStats();\\n                        }, 2000);\\n                        \\n                        alert('Repository analysis started. It may take a few moments to complete.');\\n                    } catch (error) {\\n                        console.error('Failed to add repository:', error);\\n                        alert('Failed to add repository: ' + (error.response?.data?.detail || error.message));\\n                    }\\n                },\\n                async deleteRepo(repoName) {\\n                    if (!confirm(`Are you sure you want to delete ${repoName}?`)) return;\\n                    \\n                    try {\\n                        await axios.delete(`/repositories/${repoName}`);\\n                        await this.loadRepositories();\\n                        await this.loadStats();\\n                        \\n                        if (this.selectedRepo?.name === repoName) {\\n                            this.selectedRepo = null;\\n                        }\\n                    } catch (error) {\\n                        console.error('Failed to delete repository:', error);\\n                        alert('Failed to delete repository');\\n                    }\\n                },\\n                async sendChatMessage() {\\n                    if (!this.chatInput.trim() || this.isLoading) return;\\n                    \\n                    const userMessage = {\\n                        role: 'user',\\n                        content: this.chatInput.trim()\\n                    };\\n                    \\n                    this.chatMessages.push(userMessage);\\n                    this.chatInput = '';\\n                    this.isLoading = true;\\n                    \\n                    try {\\n                        const response = await axios.post('/chat', {\\n                            messages: this.chatMessages,\\n                            repo_name: this.selectedRepo?.name\\n                        });\\n                        \\n                        this.chatMessages.push({\\n                            role: 'assistant',\\n                            content: response.data.response\\n                        });\\n                    } catch (error) {\\n                        console.error('Chat failed:', error);\\n                        this.chatMessages.push({\\n                            role: 'assistant',\\n                            content: 'Sorry, I encountered an error processing your request.'\\n                        });\\n                    } finally {\\n                        this.isLoading = false;\\n                        this.$nextTick(() => {\\n                            // Scroll to bottom\\n                            const chatContainer = document.querySelector('.overflow-y-auto');\\n                            if (chatContainer) {\\n                                chatContainer.scrollTop = chatContainer.scrollHeight;\\n                            }\\n                        });\\n                    }\\n                },\\n                async search() {\\n                    if (!this.searchQuery.trim()) return;\\n                    \\n                    this.isSearching = true;\\n                    this.searchResults = [];\\n                    \\n                    try {\\n                        const endpoint = this.selectedRepo \\n                            ? `/repositories/${this.selectedRepo.name}/search`\\n                            : '/search';\\n                        \\n                        const response = await axios.get(endpoint, {\\n                            params: { q: this.searchQuery, limit: 10 }\\n                        });\\n                        \\n                        this.searchResults = response.data.results;\\n                    } catch (error) {\\n                        console.error('Search failed:', error);\\n                    } finally {\\n                        this.isSearching = false;\\n                    }\\n                },\\n                async generateDocs() {\\n                    if (!this.selectedRepo) return;\\n                    \\n                    this.isGeneratingDocs = true;\\n                    \\n                    try {\\n                        await axios.post(`/repositories/${this.selectedRepo.name}/generate-docs`, {\\n                            repo_name: this.selectedRepo.name,\\n                            include_overview: true,\\n                            include_api_docs: true,\\n                            include_examples: true,\\n                            include_architecture: true\\n                        });\\n                        \\n                        alert('Documentation generation started. It may take a few moments to complete.');\\n                        \\n                        // Reload docs after a delay\\n                        setTimeout(() => {\\n                            this.loadGeneratedDocs();\\n                        }, 5000);\\n                    } catch (error) {\\n                        console.error('Failed to generate docs:', error);\\n                        alert('Failed to generate documentation');\\n                    } finally {\\n                        this.isGeneratingDocs = false;\\n                    }\\n                },\\n                async loadGeneratedDocs() {\\n                    if (!this.selectedRepo) return;\\n                    \\n                    try {\\n                        const response = await axios.get(`/repositories/${this.selectedRepo.name}/docs`);\\n                        this.generatedDocs = response.data.documents;\\n                    } catch (error) {\\n                        console.error('Failed to load generated docs:', error);\\n                        this.generatedDocs = [];\\n                    }\\n                },\\n                async viewDocument(doc) {\\n                    if (!this.selectedRepo) return;\\n                    \\n                    try {\\n                        const response = await axios.get(`/repositories/${this.selectedRepo.name}/docs/${doc.path}`);\\n                        this.currentDoc = doc;\\n                        this.currentDocContent = response.data.content;\\n                        this.showDocModal = true;\\n                    } catch (error) {\\n                        console.error('Failed to load document:', error);\\n                        alert('Failed to load document');\\n                    }\\n                },\\n                formatMessage(content) {\\n                    // Simple markdown-like formatting\\n                    return content\\n                        .replace(/```(\\\\w+)?\\\\n([\\\\s\\\\S]*?)```/g, '<pre class=\\\"code-block\\\"><code>$2</code></pre>')\\n                        .replace(/`([^`]+)`/g, '<code class=\\\"bg-gray-200 px-1 rounded\\\">$1</code>')\\n                        .replace(/\\\\*\\\\*(.*?)\\\\*\\\\*/g, '<strong>$1</strong>')\\n                        .replace(/\\\\*(.*?)\\\\*/g, '<em>$1</em>')\\n                        .replace(/\\\\n/g, '<br>');\\n                },\\n                formatMarkdown(content) {\\n                    // Basic markdown formatting for document viewer\\n                    return content\\n                        .replace(/# (.*)/g, '<h1 class=\\\"text-3xl font-bold mb-4\\\">$1</h1>')\\n                        .replace(/## (.*)/g, '<h2 class=\\\"text-2xl font-semibold mb-3\\\">$1</h2>')\\n                        .replace(/### (.*)/g, '<h3 class=\\\"text-xl font-medium mb-2\\\">$1</h3>')\\n                        .replace(/```(\\\\w+)?\\\\n([\\\\s\\\\S]*?)```/g, '<pre class=\\\"bg-gray-900 text-white p-4 rounded-lg overflow-x-auto mb-4\\\"><code>$2</code></pre>')\\n                        .replace(/`([^`]+)`/g, '<code class=\\\"bg-gray-200 px-1 rounded\\\">$1</code>')\\n                        .replace(/\\\\*\\\\*(.*?)\\\\*\\\\*/g, '<strong>$1</strong>')\\n                        .replace(/\\\\*(.*?)\\\\*/g, '<em>$1</em>')\\n                        .replace(/\\\\n\\\\n/g, '</p><p class=\\\"mb-4\\\">')\\n                        .replace(/\\\\n/g, '<br>')\\n                        .replace(/^/, '<p class=\\\"mb-4\\\">') + '</p>';\\n                }\\n            }\\n        }).mount('#app');\\n    </script>\\n</body>\\n</html>\\n\"\n    }\n  ],\n  \"structure\": {\n    \"name\": \"wikillm\",\n    \"type\": \"directory\",\n    \"children\": [\n      {\n        \"name\": \"api.py\",\n        \"type\": \"file\",\n        \"path\": \"api.py\"\n      },\n      {\n        \"name\": \"basic_station.md\",\n        \"type\": \"file\",\n        \"path\": \"basic_station.md\"\n      },\n      {\n        \"name\": \"config.py\",\n        \"type\": \"file\",\n        \"path\": \"config.py\"\n      },\n      {\n        \"name\": \"data\",\n        \"type\": \"directory\",\n        \"children\": [\n          {\n            \"name\": \"chroma_db\",\n            \"type\": \"directory\",\n            \"children\": [\n              {\n                \"name\": \"f2e7f382-a1d1-45fd-b769-7e72a660468f\",\n                \"type\": \"directory\",\n                \"children\": []\n              }\n            ]\n          },\n          {\n            \"name\": \"generated_docs\",\n            \"type\": \"directory\",\n            \"children\": []\n          },\n          {\n            \"name\": \"repos\",\n            \"type\": \"directory\",\n            \"children\": [\n              {\n                \"name\": \"wikillm_analysis.json\",\n                \"type\": \"file\",\n                \"path\": \"data\\\\repos\\\\wikillm_analysis.json\"\n              }\n            ]\n          }\n        ]\n      },\n      {\n        \"name\": \"DEVELOPMENT.md\",\n        \"type\": \"file\",\n        \"path\": \"DEVELOPMENT.md\"\n      },\n      {\n        \"name\": \"docs\",\n        \"type\": \"directory\",\n        \"children\": [\n          {\n            \"name\": \"api-reference.md\",\n            \"type\": \"file\",\n            \"path\": \"docs\\\\api-reference.md\"\n          },\n          {\n            \"name\": \"architecture.md\",\n            \"type\": \"file\",\n            \"path\": \"docs\\\\architecture.md\"\n          },\n          {\n            \"name\": \"project-overview.md\",\n            \"type\": \"file\",\n            \"path\": \"docs\\\\project-overview.md\"\n          }\n        ]\n      },\n      {\n        \"name\": \"documentation_generator.py\",\n        \"type\": \"file\",\n        \"path\": \"documentation_generator.py\"\n      },\n      {\n        \"name\": \"main.py\",\n        \"type\": \"file\",\n        \"path\": \"main.py\"\n      },\n      {\n        \"name\": \"ollama_client.py\",\n        \"type\": \"file\",\n        \"path\": \"ollama_client.py\"\n      },\n      {\n        \"name\": \"rag_system.py\",\n        \"type\": \"file\",\n        \"path\": \"rag_system.py\"\n      },\n      {\n        \"name\": \"README.md\",\n        \"type\": \"file\",\n        \"path\": \"README.md\"\n      },\n      {\n        \"name\": \"repository_analyzer.py\",\n        \"type\": \"file\",\n        \"path\": \"repository_analyzer.py\"\n      },\n      {\n        \"name\": \"requirements.txt\",\n        \"type\": \"file\",\n        \"path\": \"requirements.txt\"\n      },\n      {\n        \"name\": \"vector_store.py\",\n        \"type\": \"file\",\n        \"path\": \"vector_store.py\"\n      },\n      {\n        \"name\": \"web\",\n        \"type\": \"directory\",\n        \"children\": [\n          {\n            \"name\": \"index.html\",\n            \"type\": \"file\",\n            \"path\": \"web\\\\index.html\"\n          }\n        ]\n      }\n    ]\n  },\n  \"statistics\": {\n    \"total_files\": 17,\n    \"code_files\": 10,\n    \"doc_files\": 7,\n    \"languages\": {\n      \"python\": 8\n    },\n    \"total_lines\": 6282\n  },\n  \"git_info\": {\n    \"remote_url\": \"https://github.com/sharmaharsh/wikillm.git\",\n    \"current_branch\": \"main\",\n    \"last_commit\": {\n      \"hash\": \"f0138481\",\n      \"message\": \"init\",\n      \"author\": \"sharmaharsh\",\n      \"date\": \"2025-08-08T21:50:42-05:00\"\n    }\n  }\n}"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\docs\\api-reference.md",
      "file_type": "documentation",
      "language": null,
      "imports": [],
      "elements": [],
      "summary": null,
      "content": "# API Reference\n\n## Base URL\n```\nhttp://localhost:8000\n```\n\n## Health & System Endpoints\n\n### GET /health\nCheck system health and configuration.\n\n**Response:**\n```json\n{\n  \"status\": \"healthy\",\n  \"ollama_available\": true,\n  \"ollama_url\": \"http://localhost:11434\",\n  \"ollama_model\": \"deepseek-coder:6.7b\",\n  \"vector_store\": {\n    \"total_documents\": 169,\n    \"collection_name\": \"codebase_docs\"\n  }\n}\n```\n\n### GET /stats\nGet system statistics.\n\n**Response:**\n```json\n{\n  \"repositories\": 1,\n  \"documents_in_vector_store\": 169,\n  \"generated_docs\": 0,\n  \"ollama_available\": true,\n  \"ollama_model\": \"deepseek-coder:6.7b\"\n}\n```\n\n## Repository Management\n\n### POST /repositories/analyze\nAnalyze a repository and add it to the vector store.\n\n**Request:**\n```json\n{\n  \"repo_path\": \"/path/to/repository\",\n  \"repo_name\": \"optional-name\"\n}\n```\n\n### GET /repositories\nList all analyzed repositories.\n\n**Response:**\n```json\n{\n  \"repositories\": [\n    {\n      \"name\": \"wikillm\",\n      \"path\": \"C:\\\\Users\\\\chuba\\\\wikillm\",\n      \"files\": 14,\n      \"languages\": [\"python\"]\n    }\n  ]\n}\n```\n\n## Query & Chat Endpoints\n\n### POST /query\nQuery repositories using the RAG system.\n\n**Request:**\n```json\n{\n  \"query\": \"How does authentication work?\",\n  \"repo_name\": \"optional-filter\",\n  \"stream\": false\n}\n```\n\n**Response:**\n```json\n{\n  \"response\": \"Generated response text...\",\n  \"context\": {...},\n  \"sources\": [...]\n}\n```\n\n### POST /chat\nInteractive chat with repository context.\n\n**Request:**\n```json\n{\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"What is this project about?\"}\n  ],\n  \"repo_name\": \"wikillm\"\n}\n```\n\n## Code Analysis Endpoints\n\n### POST /explain\nExplain code snippets.\n\n**Request:**\n```json\n{\n  \"code\": \"def hello_world():\\n    print('Hello, World!')\",\n  \"language\": \"python\",\n  \"context\": \"Optional context\"\n}\n```\n\n### POST /improve\nGet code improvement suggestions.\n\n**Request:**\n```json\n{\n  \"code\": \"def hello_world():\\n    print('Hello, World!')\",\n  \"language\": \"python\"\n}\n```"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\docs\\architecture.md",
      "file_type": "documentation",
      "language": null,
      "imports": [],
      "elements": [],
      "summary": null,
      "content": "# System Architecture\n\n## Overview\nLocal DeepWiki follows a modular architecture with clear separation of concerns:\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚   CLI/API       â”‚    â”‚   RAG System    â”‚    â”‚  Vector Store   â”‚\nâ”‚   Interface     â”‚â—„â”€â”€â–ºâ”‚   (Core Logic)  â”‚â—„â”€â”€â–ºâ”‚   (ChromaDB)    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â–²                       â–²                       â–²\n         â”‚                       â”‚                       â”‚\n         â–¼                       â–¼                       â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ Repository      â”‚    â”‚ Ollama Client   â”‚    â”‚ Documentation   â”‚\nâ”‚ Analyzer        â”‚    â”‚ (LLM Interface) â”‚    â”‚ Generator       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Core Components\n\n### Repository Analyzer\n- **Purpose**: Parse and understand code structure\n- **Input**: File paths and directory structures  \n- **Output**: Structured analysis with metadata\n- **Key Features**:\n  - Multi-language support\n  - Intelligent file filtering\n  - Metadata extraction (functions, classes, imports)\n  - Tree structure generation\n\n### Vector Store (ChromaDB)\n- **Purpose**: Semantic search and retrieval\n- **Storage**: Document embeddings and metadata\n- **Features**:\n  - Persistent storage\n  - Similarity search\n  - Metadata filtering\n  - Batch operations\n\n### RAG System\n- **Purpose**: Context retrieval and response generation\n- **Components**:\n  - Query understanding\n  - Context retrieval\n  - Response synthesis\n  - Conversation management\n\n### Ollama Integration\n- **Models Supported**:\n  - Code generation: `deepseek-coder`, `codellama`\n  - General purpose: `llama2`, `mistral`\n  - Embeddings: `nomic-embed-text`\n- **Features**:\n  - Local inference\n  - Streaming responses\n  - Model management\n\n## Data Flow\n\n1. **Analysis Phase**:\n   ```\n   Source Code â†’ Repository Analyzer â†’ Structured Data â†’ Vector Store\n   ```\n\n2. **Query Phase**:\n   ```\n   User Query â†’ Vector Search â†’ Context Retrieval â†’ LLM â†’ Response\n   ```\n\n3. **Training Data Flow**:\n   ```\n   Markdown Files â†’ Text Chunks â†’ Embeddings â†’ Vector Store\n   ```"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\docs\\project-overview.md",
      "file_type": "documentation",
      "language": null,
      "imports": [],
      "elements": [],
      "summary": null,
      "content": "# Project Overview\n\nThis is Local DeepWiki - a system for analyzing code repositories using local LLMs.\n\n## Key Features\n- Repository analysis and indexing\n- RAG-based question answering\n- Local LLM integration via Ollama\n- REST API for programmatic access\n\n## Architecture\n- **Repository Analyzer**: Parses code structure and extracts metadata\n- **Vector Store**: Uses ChromaDB for semantic search\n- **RAG System**: Retrieves context and generates responses\n- **API Server**: FastAPI-based REST endpoints"
    },
    {
      "file_path": "C:\\Users\\chuba\\wikillm\\web\\index.html",
      "file_type": "code",
      "language": null,
      "imports": [],
      "elements": [],
      "summary": null,
      "content": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Local DeepWiki</title>\n    <script src=\"https://unpkg.com/vue@3/dist/vue.global.js\"></script>\n    <script src=\"https://unpkg.com/axios/dist/axios.min.js\"></script>\n    <link href=\"https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css\" rel=\"stylesheet\">\n    <link href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css\" rel=\"stylesheet\">\n    <style>\n        .chat-message {\n            max-width: 80%;\n        }\n        .user-message {\n            margin-left: auto;\n            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n        }\n        .assistant-message {\n            margin-right: auto;\n            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);\n        }\n        .code-block {\n            background-color: #1e1e1e;\n            border-radius: 8px;\n            padding: 1rem;\n            overflow-x: auto;\n        }\n        .sidebar {\n            transition: transform 0.3s ease-in-out;\n        }\n        .sidebar-closed {\n            transform: translateX(-100%);\n        }\n        .loading-dots {\n            display: inline-block;\n        }\n        .loading-dots:after {\n            content: '';\n            animation: dots 1.5s infinite;\n        }\n        @keyframes dots {\n            0%, 20% { content: '.'; }\n            40% { content: '..'; }\n            60%, 100% { content: '...'; }\n        }\n    </style>\n</head>\n<body class=\"bg-gray-100 font-sans\">\n    <div id=\"app\">\n        <!-- Header -->\n        <header class=\"bg-white shadow-lg\">\n            <div class=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\">\n                <div class=\"flex justify-between items-center py-4\">\n                    <div class=\"flex items-center\">\n                        <button @click=\"toggleSidebar\" class=\"mr-4 text-gray-600 hover:text-gray-900\">\n                            <i class=\"fas fa-bars text-xl\"></i>\n                        </button>\n                        <h1 class=\"text-2xl font-bold text-gray-900\">\n                            <i class=\"fas fa-book text-blue-600 mr-2\"></i>\n                            Local DeepWiki\n                        </h1>\n                    </div>\n                    <div class=\"flex items-center space-x-4\">\n                        <div class=\"flex items-center space-x-2\">\n                            <div :class=\"{'bg-green-500': systemStatus.ollama_available, 'bg-red-500': !systemStatus.ollama_available}\" \n                                 class=\"w-3 h-3 rounded-full\"></div>\n                            <span class=\"text-sm text-gray-600\">\n                                {{ systemStatus.ollama_available ? 'Ollama Connected' : 'Ollama Disconnected' }}\n                            </span>\n                        </div>\n                        <button @click=\"checkHealth\" class=\"text-blue-600 hover:text-blue-800\">\n                            <i class=\"fas fa-sync-alt\"></i>\n                        </button>\n                    </div>\n                </div>\n            </div>\n        </header>\n\n        <div class=\"flex h-screen\">\n            <!-- Sidebar -->\n            <div :class=\"{'sidebar-closed': !sidebarOpen}\" class=\"sidebar fixed inset-y-0 left-0 z-50 w-64 bg-white shadow-lg transform lg:translate-x-0 lg:static lg:inset-0\">\n                <div class=\"flex flex-col h-full\">\n                    <!-- Sidebar Header -->\n                    <div class=\"flex items-center justify-between p-4 border-b\">\n                        <h2 class=\"text-lg font-semibold text-gray-900\">Repositories</h2>\n                        <button @click=\"showAddRepoModal = true\" class=\"text-blue-600 hover:text-blue-800\">\n                            <i class=\"fas fa-plus\"></i>\n                        </button>\n                    </div>\n\n                    <!-- Repository List -->\n                    <div class=\"flex-1 overflow-y-auto p-4\">\n                        <div v-if=\"repositories.length === 0\" class=\"text-gray-500 text-center py-8\">\n                            <i class=\"fas fa-folder-open text-4xl mb-2\"></i>\n                            <p>No repositories added yet</p>\n                        </div>\n                        <div v-for=\"repo in repositories\" :key=\"repo.name\" \n                             @click=\"selectRepository(repo)\"\n                             :class=\"{'bg-blue-50 border-blue-200': selectedRepo?.name === repo.name}\"\n                             class=\"p-3 mb-2 border rounded-lg cursor-pointer hover:bg-gray-50 transition-colors\">\n                            <div class=\"flex items-center justify-between\">\n                                <div>\n                                    <h3 class=\"font-medium text-gray-900\">{{ repo.name }}</h3>\n                                    <p class=\"text-sm text-gray-600\">{{ repo.files }} files</p>\n                                    <div class=\"flex flex-wrap gap-1 mt-1\">\n                                        <span v-for=\"lang in repo.languages\" :key=\"lang\" \n                                              class=\"px-2 py-1 bg-gray-200 text-gray-700 text-xs rounded\">\n                                            {{ lang }}\n                                        </span>\n                                    </div>\n                                </div>\n                                <button @click.stop=\"deleteRepo(repo.name)\" \n                                        class=\"text-red-500 hover:text-red-700 text-sm\">\n                                    <i class=\"fas fa-trash\"></i>\n                                </button>\n                            </div>\n                        </div>\n                    </div>\n\n                    <!-- System Stats -->\n                    <div class=\"p-4 border-t bg-gray-50\">\n                        <div class=\"text-sm text-gray-600\">\n                            <div>Repos: {{ stats.repositories || 0 }}</div>\n                            <div>Documents: {{ stats.documents_in_vector_store || 0 }}</div>\n                            <div>Model: {{ systemStatus.ollama_model || 'Unknown' }}</div>\n                        </div>\n                    </div>\n                </div>\n            </div>\n\n            <!-- Main Content -->\n            <div class=\"flex-1 flex flex-col lg:ml-0\" :class=\"{'ml-0': !sidebarOpen, 'ml-64': sidebarOpen}\">\n                <!-- Tab Navigation -->\n                <div class=\"bg-white border-b\">\n                    <nav class=\"max-w-7xl mx-auto px-4 sm:px-6 lg:px-8\">\n                        <div class=\"flex space-x-8\">\n                            <button v-for=\"tab in tabs\" :key=\"tab.id\"\n                                    @click=\"activeTab = tab.id\"\n                                    :class=\"{'border-blue-500 text-blue-600': activeTab === tab.id, 'border-transparent text-gray-500': activeTab !== tab.id}\"\n                                    class=\"py-4 px-1 border-b-2 font-medium text-sm hover:text-gray-700\">\n                                <i :class=\"tab.icon\" class=\"mr-2\"></i>\n                                {{ tab.name }}\n                            </button>\n                        </div>\n                    </nav>\n                </div>\n\n                <!-- Tab Content -->\n                <div class=\"flex-1 overflow-hidden\">\n                    <!-- Chat Tab -->\n                    <div v-show=\"activeTab === 'chat'\" class=\"h-full flex flex-col\">\n                        <div class=\"flex-1 overflow-y-auto p-6\">\n                            <div v-if=\"chatMessages.length === 0\" class=\"text-center py-12\">\n                                <i class=\"fas fa-comments text-6xl text-gray-300 mb-4\"></i>\n                                <h3 class=\"text-xl font-medium text-gray-900 mb-2\">Start a conversation</h3>\n                                <p class=\"text-gray-600\">Ask questions about your code repositories</p>\n                            </div>\n                            \n                            <div v-for=\"(message, index) in chatMessages\" :key=\"index\" class=\"mb-6\">\n                                <div :class=\"{'user-message': message.role === 'user', 'assistant-message': message.role === 'assistant'}\"\n                                     class=\"chat-message p-4 rounded-lg text-white\">\n                                    <div class=\"flex items-start space-x-3\">\n                                        <div class=\"flex-shrink-0\">\n                                            <i :class=\"message.role === 'user' ? 'fas fa-user' : 'fas fa-robot'\" \n                                               class=\"text-lg\"></i>\n                                        </div>\n                                        <div class=\"flex-1\">\n                                            <div v-html=\"formatMessage(message.content)\"></div>\n                                        </div>\n                                    </div>\n                                </div>\n                            </div>\n                            \n                            <div v-if=\"isLoading\" class=\"mb-6\">\n                                <div class=\"assistant-message chat-message p-4 rounded-lg text-white\">\n                                    <div class=\"flex items-start space-x-3\">\n                                        <div class=\"flex-shrink-0\">\n                                            <i class=\"fas fa-robot text-lg\"></i>\n                                        </div>\n                                        <div class=\"flex-1\">\n                                            <span class=\"loading-dots\">Thinking</span>\n                                        </div>\n                                    </div>\n                                </div>\n                            </div>\n                        </div>\n                        \n                        <!-- Chat Input -->\n                        <div class=\"border-t bg-white p-4\">\n                            <div class=\"max-w-4xl mx-auto\">\n                                <div class=\"flex items-end space-x-4\">\n                                    <div class=\"flex-1\">\n                                        <textarea v-model=\"chatInput\" \n                                                @keydown.enter.prevent=\"sendChatMessage\"\n                                                :disabled=\"isLoading\"\n                                                placeholder=\"Ask a question about your code...\"\n                                                class=\"w-full px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-transparent resize-none\"\n                                                rows=\"2\"></textarea>\n                                    </div>\n                                    <button @click=\"sendChatMessage\" \n                                            :disabled=\"isLoading || !chatInput.trim()\"\n                                            class=\"px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50 disabled:cursor-not-allowed\">\n                                        <i class=\"fas fa-paper-plane\"></i>\n                                    </button>\n                                </div>\n                                <div v-if=\"selectedRepo\" class=\"mt-2 text-sm text-gray-600\">\n                                    Querying: {{ selectedRepo.name }}\n                                </div>\n                            </div>\n                        </div>\n                    </div>\n\n                    <!-- Search Tab -->\n                    <div v-show=\"activeTab === 'search'\" class=\"h-full p-6\">\n                        <div class=\"max-w-4xl mx-auto\">\n                            <div class=\"mb-6\">\n                                <div class=\"flex space-x-4\">\n                                    <input v-model=\"searchQuery\" \n                                           @keydown.enter=\"search\"\n                                           type=\"text\" \n                                           placeholder=\"Search across all repositories...\"\n                                           class=\"flex-1 px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500\">\n                                    <button @click=\"search\" \n                                            :disabled=\"!searchQuery.trim()\"\n                                            class=\"px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 disabled:opacity-50\">\n                                        <i class=\"fas fa-search\"></i>\n                                    </button>\n                                </div>\n                            </div>\n                            \n                            <div v-if=\"searchResults.length > 0\">\n                                <h3 class=\"text-lg font-medium mb-4\">Search Results</h3>\n                                <div v-for=\"result in searchResults\" :key=\"result.id\" \n                                     class=\"mb-4 p-4 bg-white rounded-lg shadow\">\n                                    <div class=\"flex justify-between items-start mb-2\">\n                                        <div class=\"text-sm text-gray-600\">\n                                            {{ result.metadata.file_path || 'Unknown file' }}\n                                        </div>\n                                        <div class=\"text-sm text-gray-500\">\n                                            Score: {{ (1 - result.distance).toFixed(3) }}\n                                        </div>\n                                    </div>\n                                    <div class=\"text-gray-900\">\n                                        {{ result.text.substring(0, 300) }}...\n                                    </div>\n                                </div>\n                            </div>\n                            \n                            <div v-else-if=\"searchQuery && !isSearching\" class=\"text-center py-12\">\n                                <i class=\"fas fa-search text-6xl text-gray-300 mb-4\"></i>\n                                <p class=\"text-gray-600\">No results found</p>\n                            </div>\n                        </div>\n                    </div>\n\n                    <!-- Documentation Tab -->\n                    <div v-show=\"activeTab === 'docs'\" class=\"h-full p-6\">\n                        <div class=\"max-w-4xl mx-auto\">\n                            <div class=\"mb-6\">\n                                <h2 class=\"text-2xl font-bold mb-4\">Documentation</h2>\n                                \n                                <div v-if=\"selectedRepo\" class=\"mb-4\">\n                                    <button @click=\"generateDocs\" \n                                            :disabled=\"isGeneratingDocs\"\n                                            class=\"px-4 py-2 bg-green-600 text-white rounded-lg hover:bg-green-700 disabled:opacity-50\">\n                                        <i class=\"fas fa-file-alt mr-2\"></i>\n                                        Generate Documentation\n                                    </button>\n                                </div>\n                                \n                                <div v-if=\"generatedDocs.length > 0\">\n                                    <h3 class=\"text-lg font-medium mb-4\">Generated Documents</h3>\n                                    <div class=\"grid gap-4\">\n                                        <div v-for=\"doc in generatedDocs\" :key=\"doc.path\"\n                                             @click=\"viewDocument(doc)\"\n                                             class=\"p-4 bg-white rounded-lg shadow cursor-pointer hover:shadow-md transition-shadow\">\n                                            <div class=\"flex items-center space-x-3\">\n                                                <i class=\"fas fa-file-markdown text-blue-600\"></i>\n                                                <div>\n                                                    <div class=\"font-medium\">{{ doc.name }}</div>\n                                                    <div class=\"text-sm text-gray-600\">{{ doc.path }}</div>\n                                                </div>\n                                            </div>\n                                        </div>\n                                    </div>\n                                </div>\n                            </div>\n                        </div>\n                    </div>\n                </div>\n            </div>\n        </div>\n\n        <!-- Add Repository Modal -->\n        <div v-if=\"showAddRepoModal\" class=\"fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50\">\n            <div class=\"bg-white rounded-lg p-6 w-full max-w-md mx-4\">\n                <h3 class=\"text-lg font-medium mb-4\">Add Repository</h3>\n                <div class=\"mb-4\">\n                    <label class=\"block text-sm font-medium text-gray-700 mb-2\">Repository Path</label>\n                    <input v-model=\"newRepoPath\" \n                           type=\"text\" \n                           placeholder=\"/path/to/your/repository\"\n                           class=\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500\">\n                </div>\n                <div class=\"mb-6\">\n                    <label class=\"block text-sm font-medium text-gray-700 mb-2\">Repository Name (optional)</label>\n                    <input v-model=\"newRepoName\" \n                           type=\"text\" \n                           placeholder=\"my-project\"\n                           class=\"w-full px-3 py-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500\">\n                </div>\n                <div class=\"flex justify-end space-x-3\">\n                    <button @click=\"showAddRepoModal = false\" \n                            class=\"px-4 py-2 text-gray-700 border border-gray-300 rounded-md hover:bg-gray-50\">\n                        Cancel\n                    </button>\n                    <button @click=\"addRepository\" \n                            :disabled=\"!newRepoPath.trim()\"\n                            class=\"px-4 py-2 bg-blue-600 text-white rounded-md hover:bg-blue-700 disabled:opacity-50\">\n                        Add Repository\n                    </button>\n                </div>\n            </div>\n        </div>\n\n        <!-- Document Viewer Modal -->\n        <div v-if=\"showDocModal\" class=\"fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50\">\n            <div class=\"bg-white rounded-lg w-full max-w-4xl mx-4 h-5/6 flex flex-col\">\n                <div class=\"flex items-center justify-between p-4 border-b\">\n                    <h3 class=\"text-lg font-medium\">{{ currentDoc?.name }}</h3>\n                    <button @click=\"showDocModal = false\" class=\"text-gray-500 hover:text-gray-700\">\n                        <i class=\"fas fa-times\"></i>\n                    </button>\n                </div>\n                <div class=\"flex-1 overflow-auto p-4\">\n                    <div v-html=\"formatMarkdown(currentDocContent)\" class=\"prose max-w-none\"></div>\n                </div>\n            </div>\n        </div>\n    </div>\n\n    <script>\n        const { createApp } = Vue;\n\n        createApp({\n            data() {\n                return {\n                    sidebarOpen: true,\n                    activeTab: 'chat',\n                    systemStatus: {\n                        ollama_available: false,\n                        ollama_model: ''\n                    },\n                    stats: {},\n                    repositories: [],\n                    selectedRepo: null,\n                    chatMessages: [],\n                    chatInput: '',\n                    isLoading: false,\n                    searchQuery: '',\n                    searchResults: [],\n                    isSearching: false,\n                    generatedDocs: [],\n                    isGeneratingDocs: false,\n                    showAddRepoModal: false,\n                    newRepoPath: '',\n                    newRepoName: '',\n                    showDocModal: false,\n                    currentDoc: null,\n                    currentDocContent: '',\n                    tabs: [\n                        { id: 'chat', name: 'Chat', icon: 'fas fa-comments' },\n                        { id: 'search', name: 'Search', icon: 'fas fa-search' },\n                        { id: 'docs', name: 'Documentation', icon: 'fas fa-file-alt' }\n                    ]\n                };\n            },\n            async mounted() {\n                await this.checkHealth();\n                await this.loadRepositories();\n                await this.loadStats();\n            },\n            methods: {\n                toggleSidebar() {\n                    this.sidebarOpen = !this.sidebarOpen;\n                },\n                async checkHealth() {\n                    try {\n                        const response = await axios.get('/health');\n                        this.systemStatus = response.data;\n                    } catch (error) {\n                        console.error('Health check failed:', error);\n                        this.systemStatus.ollama_available = false;\n                    }\n                },\n                async loadRepositories() {\n                    try {\n                        const response = await axios.get('/repositories');\n                        this.repositories = response.data.repositories;\n                    } catch (error) {\n                        console.error('Failed to load repositories:', error);\n                    }\n                },\n                async loadStats() {\n                    try {\n                        const response = await axios.get('/stats');\n                        this.stats = response.data;\n                    } catch (error) {\n                        console.error('Failed to load stats:', error);\n                    }\n                },\n                selectRepository(repo) {\n                    this.selectedRepo = repo;\n                    this.loadGeneratedDocs();\n                },\n                async addRepository() {\n                    if (!this.newRepoPath.trim()) return;\n                    \n                    try {\n                        await axios.post('/repositories/analyze', {\n                            repo_path: this.newRepoPath,\n                            repo_name: this.newRepoName || undefined\n                        });\n                        \n                        this.showAddRepoModal = false;\n                        this.newRepoPath = '';\n                        this.newRepoName = '';\n                        \n                        // Reload repositories after a short delay\n                        setTimeout(() => {\n                            this.loadRepositories();\n                            this.loadStats();\n                        }, 2000);\n                        \n                        alert('Repository analysis started. It may take a few moments to complete.');\n                    } catch (error) {\n                        console.error('Failed to add repository:', error);\n                        alert('Failed to add repository: ' + (error.response?.data?.detail || error.message));\n                    }\n                },\n                async deleteRepo(repoName) {\n                    if (!confirm(`Are you sure you want to delete ${repoName}?`)) return;\n                    \n                    try {\n                        await axios.delete(`/repositories/${repoName}`);\n                        await this.loadRepositories();\n                        await this.loadStats();\n                        \n                        if (this.selectedRepo?.name === repoName) {\n                            this.selectedRepo = null;\n                        }\n                    } catch (error) {\n                        console.error('Failed to delete repository:', error);\n                        alert('Failed to delete repository');\n                    }\n                },\n                async sendChatMessage() {\n                    if (!this.chatInput.trim() || this.isLoading) return;\n                    \n                    const userMessage = {\n                        role: 'user',\n                        content: this.chatInput.trim()\n                    };\n                    \n                    this.chatMessages.push(userMessage);\n                    this.chatInput = '';\n                    this.isLoading = true;\n                    \n                    try {\n                        const response = await axios.post('/chat', {\n                            messages: this.chatMessages,\n                            repo_name: this.selectedRepo?.name\n                        });\n                        \n                        this.chatMessages.push({\n                            role: 'assistant',\n                            content: response.data.response\n                        });\n                    } catch (error) {\n                        console.error('Chat failed:', error);\n                        this.chatMessages.push({\n                            role: 'assistant',\n                            content: 'Sorry, I encountered an error processing your request.'\n                        });\n                    } finally {\n                        this.isLoading = false;\n                        this.$nextTick(() => {\n                            // Scroll to bottom\n                            const chatContainer = document.querySelector('.overflow-y-auto');\n                            if (chatContainer) {\n                                chatContainer.scrollTop = chatContainer.scrollHeight;\n                            }\n                        });\n                    }\n                },\n                async search() {\n                    if (!this.searchQuery.trim()) return;\n                    \n                    this.isSearching = true;\n                    this.searchResults = [];\n                    \n                    try {\n                        const endpoint = this.selectedRepo \n                            ? `/repositories/${this.selectedRepo.name}/search`\n                            : '/search';\n                        \n                        const response = await axios.get(endpoint, {\n                            params: { q: this.searchQuery, limit: 10 }\n                        });\n                        \n                        this.searchResults = response.data.results;\n                    } catch (error) {\n                        console.error('Search failed:', error);\n                    } finally {\n                        this.isSearching = false;\n                    }\n                },\n                async generateDocs() {\n                    if (!this.selectedRepo) return;\n                    \n                    this.isGeneratingDocs = true;\n                    \n                    try {\n                        await axios.post(`/repositories/${this.selectedRepo.name}/generate-docs`, {\n                            repo_name: this.selectedRepo.name,\n                            include_overview: true,\n                            include_api_docs: true,\n                            include_examples: true,\n                            include_architecture: true\n                        });\n                        \n                        alert('Documentation generation started. It may take a few moments to complete.');\n                        \n                        // Reload docs after a delay\n                        setTimeout(() => {\n                            this.loadGeneratedDocs();\n                        }, 5000);\n                    } catch (error) {\n                        console.error('Failed to generate docs:', error);\n                        alert('Failed to generate documentation');\n                    } finally {\n                        this.isGeneratingDocs = false;\n                    }\n                },\n                async loadGeneratedDocs() {\n                    if (!this.selectedRepo) return;\n                    \n                    try {\n                        const response = await axios.get(`/repositories/${this.selectedRepo.name}/docs`);\n                        this.generatedDocs = response.data.documents;\n                    } catch (error) {\n                        console.error('Failed to load generated docs:', error);\n                        this.generatedDocs = [];\n                    }\n                },\n                async viewDocument(doc) {\n                    if (!this.selectedRepo) return;\n                    \n                    try {\n                        const response = await axios.get(`/repositories/${this.selectedRepo.name}/docs/${doc.path}`);\n                        this.currentDoc = doc;\n                        this.currentDocContent = response.data.content;\n                        this.showDocModal = true;\n                    } catch (error) {\n                        console.error('Failed to load document:', error);\n                        alert('Failed to load document');\n                    }\n                },\n                formatMessage(content) {\n                    // Simple markdown-like formatting\n                    return content\n                        .replace(/```(\\w+)?\\n([\\s\\S]*?)```/g, '<pre class=\"code-block\"><code>$2</code></pre>')\n                        .replace(/`([^`]+)`/g, '<code class=\"bg-gray-200 px-1 rounded\">$1</code>')\n                        .replace(/\\*\\*(.*?)\\*\\*/g, '<strong>$1</strong>')\n                        .replace(/\\*(.*?)\\*/g, '<em>$1</em>')\n                        .replace(/\\n/g, '<br>');\n                },\n                formatMarkdown(content) {\n                    // Basic markdown formatting for document viewer\n                    return content\n                        .replace(/# (.*)/g, '<h1 class=\"text-3xl font-bold mb-4\">$1</h1>')\n                        .replace(/## (.*)/g, '<h2 class=\"text-2xl font-semibold mb-3\">$1</h2>')\n                        .replace(/### (.*)/g, '<h3 class=\"text-xl font-medium mb-2\">$1</h3>')\n                        .replace(/```(\\w+)?\\n([\\s\\S]*?)```/g, '<pre class=\"bg-gray-900 text-white p-4 rounded-lg overflow-x-auto mb-4\"><code>$2</code></pre>')\n                        .replace(/`([^`]+)`/g, '<code class=\"bg-gray-200 px-1 rounded\">$1</code>')\n                        .replace(/\\*\\*(.*?)\\*\\*/g, '<strong>$1</strong>')\n                        .replace(/\\*(.*?)\\*/g, '<em>$1</em>')\n                        .replace(/\\n\\n/g, '</p><p class=\"mb-4\">')\n                        .replace(/\\n/g, '<br>')\n                        .replace(/^/, '<p class=\"mb-4\">') + '</p>';\n                }\n            }\n        }).mount('#app');\n    </script>\n</body>\n</html>\n"
    }
  ],
  "structure": {
    "name": "wikillm",
    "type": "directory",
    "children": [
      {
        "name": "api.py",
        "type": "file",
        "path": "api.py"
      },
      {
        "name": "basic_station.md",
        "type": "file",
        "path": "basic_station.md"
      },
      {
        "name": "config.py",
        "type": "file",
        "path": "config.py"
      },
      {
        "name": "data",
        "type": "directory",
        "children": [
          {
            "name": "chroma_db",
            "type": "directory",
            "children": [
              {
                "name": "f2e7f382-a1d1-45fd-b769-7e72a660468f",
                "type": "directory",
                "children": []
              }
            ]
          },
          {
            "name": "generated_docs",
            "type": "directory",
            "children": []
          },
          {
            "name": "repos",
            "type": "directory",
            "children": [
              {
                "name": "wikillm_analysis.json",
                "type": "file",
                "path": "data\\repos\\wikillm_analysis.json"
              }
            ]
          }
        ]
      },
      {
        "name": "DEVELOPMENT.md",
        "type": "file",
        "path": "DEVELOPMENT.md"
      },
      {
        "name": "docs",
        "type": "directory",
        "children": [
          {
            "name": "api-reference.md",
            "type": "file",
            "path": "docs\\api-reference.md"
          },
          {
            "name": "architecture.md",
            "type": "file",
            "path": "docs\\architecture.md"
          },
          {
            "name": "project-overview.md",
            "type": "file",
            "path": "docs\\project-overview.md"
          }
        ]
      },
      {
        "name": "documentation_generator.py",
        "type": "file",
        "path": "documentation_generator.py"
      },
      {
        "name": "main.py",
        "type": "file",
        "path": "main.py"
      },
      {
        "name": "ollama_client.py",
        "type": "file",
        "path": "ollama_client.py"
      },
      {
        "name": "rag_system.py",
        "type": "file",
        "path": "rag_system.py"
      },
      {
        "name": "README.md",
        "type": "file",
        "path": "README.md"
      },
      {
        "name": "repository_analyzer.py",
        "type": "file",
        "path": "repository_analyzer.py"
      },
      {
        "name": "requirements.txt",
        "type": "file",
        "path": "requirements.txt"
      },
      {
        "name": "vector_store.py",
        "type": "file",
        "path": "vector_store.py"
      },
      {
        "name": "web",
        "type": "directory",
        "children": [
          {
            "name": "index.html",
            "type": "file",
            "path": "web\\index.html"
          }
        ]
      }
    ]
  },
  "statistics": {
    "total_files": 17,
    "code_files": 10,
    "doc_files": 7,
    "languages": {
      "python": 8
    },
    "total_lines": 6324
  },
  "git_info": {
    "remote_url": "https://github.com/sharmaharsh/wikillm.git",
    "current_branch": "main",
    "last_commit": {
      "hash": "f0138481",
      "message": "init",
      "author": "sharmaharsh",
      "date": "2025-08-08T21:50:42-05:00"
    }
  }
}